{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visdataの抽出",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vdslab/t-taiki0620/blob/main/visdata%E3%81%AE%E6%8A%BD%E5%87%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po0gcFRHeqU6",
        "outputId": "714426c7-725e-458c-bccd-e65db98cac6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qvBzaVreynS"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSnknD0OfcQs",
        "outputId": "8425bd04-0d9a-4cea-f171-341667f79875"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/pre-judgit/IEEE VIS papers 1990-2020 - Main dataset.csv', encoding='utf8')as f:\n",
        "  df = pd.read_csv(f)\n",
        "\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3394 entries, 0 to 3393\n",
            "Data columns (total 18 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Conference                     3394 non-null   object \n",
            " 1   Year                           3394 non-null   int64  \n",
            " 2   Title                          3394 non-null   object \n",
            " 3   DOI                            3394 non-null   object \n",
            " 4   Link                           3394 non-null   object \n",
            " 5   FirstPage                      3361 non-null   object \n",
            " 6   LastPage                       3351 non-null   object \n",
            " 7   PaperType                      3394 non-null   object \n",
            " 8   Abstract                       3321 non-null   object \n",
            " 9   AuthorNames-Deduped            3394 non-null   object \n",
            " 10  AuthorNames                    3390 non-null   object \n",
            " 11  AuthorAffiliation              3263 non-null   object \n",
            " 12  InternalReferences             2638 non-null   object \n",
            " 13  AuthorKeywords                 2414 non-null   object \n",
            " 14  AminerCitationCount_04-2020    3151 non-null   float64\n",
            " 15  XploreCitationCount - 2021-02  3391 non-null   float64\n",
            " 16  PubsCited                      3391 non-null   float64\n",
            " 17  Award                          178 non-null    object \n",
            "dtypes: float64(3), int64(1), object(14)\n",
            "memory usage: 477.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0huswqB3iUvR"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "trainings = []\n",
        "for i in range(len(df)):\n",
        "  try:\n",
        "    trainings.append(TaggedDocument(df.loc[i]['Abstract'].split(), [i]))\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm_16GqwCRIp"
      },
      "source": [
        "model = Doc2Vec(trainings, epochs=30, min_alpha=1e-4, sample=1e-3, min_count=4, window=15, vector_size=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEhyNQbZIaSa"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/pre-judgit/VIS1990-2020.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH_fW5ImL-7Q"
      },
      "source": [
        "model = Doc2Vec.load('/content/drive/MyDrive/Colab Notebooks/pre-judgit/VIS1990-2020.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFefCJWCzdc4",
        "outputId": "276086da-b5a4-4376-f98b-3197321e36df"
      },
      "source": [
        "samples_list = []\n",
        "df_exp = []\n",
        "for i in range(len(trainings)):\n",
        "  tmp = {}\n",
        "  ind = df.index.get_loc(trainings[i].tags[0])\n",
        "  if numpy.isnan(float('NaN')) != df.loc[ind]['AuthorKeywords']:\n",
        "    tmp['Title'] = df.loc[ind]['Title']\n",
        "    tmp['Abstract'] = df.loc[ind]['Abstract']\n",
        "    try:\n",
        "      tmp['AuthorKeywords'] = df.loc[ind]['AuthorKeywords'].split()\n",
        "    except:\n",
        "      tmp['AuthorKeywords'] = []\n",
        "    df_exp.append(model.docvecs[trainings[i].tags[0]])\n",
        "    samples_list.append(tmp)\n",
        "  if i%1000 == 0:\n",
        "    print('doing')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doing\n",
            "doing\n",
            "doing\n",
            "doing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E36gWER1LEh_",
        "outputId": "38a55d69-8a5e-4c63-c154-4801cea73aae"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        " \n",
        "linkage_result = linkage(df_exp, method='ward', metric='euclidean')\n",
        "plt.figure(num=None, figsize=(16, 9), dpi=200, facecolor='w', edgecolor='k')\n",
        "dendrogram(linkage_result, labels=df.index)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 3200x1800 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUSw91eZC87D",
        "outputId": "968a611e-906a-4cd6-c4cd-e290e686b6d5"
      },
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!python -m nltk.downloader stopwords\n",
        "!python -m nltk.downloader universal_tagset\n",
        "!python -m spacy download en_core_web_sm # download the english model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-_expph5t\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-_expph5t\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (3.2.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pke==1.8.1) (0.22.2.post1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2021.5.30)\n",
            "Building wheels for collected packages: pke\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-1.8.1-py3-none-any.whl size=8764035 sha256=02e4bd4d5b2bbe176c512b9d537f03bed40c432fd1ac8f115f37e2cf0d873973\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sd75xg9w/wheels/fa/b3/09/612ee93bf3ee4164bcd5783e742942cdfc892a86039d3e0a33\n",
            "Successfully built pke\n",
            "Installing collected packages: unidecode, pke\n",
            "Successfully installed pke-1.8.1 unidecode-1.3.2\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrYsS2x7EMJi"
      },
      "source": [
        "pkeのdocumentを読む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLX8PbC0SVPR",
        "outputId": "70b1c012-5771-447f-a058-57081d3abed8"
      },
      "source": [
        "import pke\n",
        "import sys\n",
        "\n",
        "sys.setrecursionlimit(10000)\n",
        "def get_key_phrase(text, n = 5):\n",
        "    \"\"\"キーフレーズ処理\n",
        "\n",
        "    Args:\n",
        "        text ([type]): キーフレーズ対象の文字列\n",
        "        n (int, optional): [description]. Defaults to 10.\n",
        "        gc_collect (bool, optional): [description]. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        [type]: [description]\n",
        "    \"\"\"\n",
        "    #MultipartiteRankなどのキーフレーズの手法については以下のサイトが参考になります\n",
        "    #https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/part5.html\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    extractor.load_document(input=text, language='en')\n",
        "    extractor.candidate_selection()\n",
        "    extractor.candidate_weighting(threshold=0.74, method='average', alpha=1.1)\n",
        "    key_phrase = extractor.get_n_best(n)\n",
        "    \n",
        "    return  key_phrase\n",
        "    \n",
        "    \n",
        "#spacyに設定されているstopwordを使う\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKNhfEfYV4j7",
        "outputId": "d4938b07-2b00-4c7c-e651-d2bdf96adb73"
      },
      "source": [
        "df_pke = {}\n",
        "df_enpty = []\n",
        "for i in range(len(samples_list)):\n",
        "  pke_test = {}\n",
        "  for words in get_key_phrase(samples_list[i]['Abstract']):\n",
        "    for word in words[0].split():\n",
        "      if word in pke_test:\n",
        "        pke_test[word] += words[1]\n",
        "      else:\n",
        "        pke_test[word] = words[1]\n",
        "\n",
        "  df_pke[samples_list[i]['Title']] = pke_test\n",
        "  if i % 500 == 0:\n",
        "    print(df_pke[samples_list[i]['Title']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'novel': 0.09499765414441311, 'representation': 0.09499765414441311, 'data': 0.0786458467582725, 'transparent': 0.07442014062323143, 'approach': 0.07442014062323143, 'documents': 0.06506261017642279, 'visualization': 0.04704243515034964}\n",
            "{'domain': 0.05819691859338583, 'experts': 0.05819691859338583, 'evaluation': 0.056235590767543586, 'groups': 0.05471581143726882, 'research': 0.0517921940948385, 'goal': 0.05095899534248677}\n",
            "{'twitter': 0.11687001888986476, 'tweets': 0.08249329751541506, 'opinions': 0.04933091098830689, 'topics': 0.040704041072813814, 'large': 0.04027119779410551, 'number': 0.04027119779410551}\n",
            "{'complex': 0.06049549652321821, 'sets': 0.06049549652321821, 'differences': 0.05644672115584749, 'images': 0.054734513848413796, 'data': 0.04431656726820678, 'analysis': 0.04040706429954716}\n",
            "{'gridded': 0.11054072076990354, 'data': 0.11054072076990354, 'experience': 0.05858727101403499, 'complete': 0.0501112129063023, 'sets': 0.0501112129063023, 'shelf': 0.04710373578926365, 'visualization': 0.04710373578926365, 'algorithms': 0.04710373578926365, 'paper': 0.04276473557765019}\n",
            "{'biclusters': 0.11355960340849439, 'bidots': 0.059743573742152674, 'sets': 0.04497259350164036, 'output': 0.03513209908370344, 'visual': 0.034705575389191216, 'approaches': 0.034705575389191216}\n",
            "{'scagnostics': 0.07353914993582022, 'scagnostic': 0.06116614090411916, 'measures': 0.06116614090411916, 'sensitivity': 0.05722885087989248, 'robustness': 0.053314355336269964, 'human': 0.04806041745202153, 'judgments': 0.04806041745202153}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PScgS-ndfUVU"
      },
      "source": [
        "for i in range(len(samples_list)):\n",
        "  word_score = []\n",
        "  tmp_list = sorted(df_pke[samples_list[i]['Title']].items(), key=lambda x: x[1], reverse=True)\n",
        "  for data in tmp_list:\n",
        "    word_score.append({\"word\" : data[0],\n",
        "                      \"score\" : data[1]})\n",
        "  samples_list[i]['MultipartiteRank'] = word_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8JY5G-DM5XH",
        "outputId": "b6bbba48-8b55-4625-b996-f393873e6254"
      },
      "source": [
        "obj = []\n",
        "for i in range(len(samples_list)):\n",
        "  obj.append({\"no\":str(int(i)),\n",
        "              \"parent\":\"\",\n",
        "              \"distance\":0,\n",
        "              \"Title\":samples_list[i][\"Title\"],\n",
        "              \"Abstract\":samples_list[i][\"Abstract\"],\n",
        "              \"AuthorKeywords\":samples_list[i][\"AuthorKeywords\"],\n",
        "              \"MultipartiteRank\":samples_list[i][\"MultipartiteRank\"]\n",
        "              })\n",
        "\n",
        "for i in range(len(linkage_result)):\n",
        "  obj.append({\"no\":str(len(linkage_result)+i+1),\n",
        "              \"parent\":\"\",\n",
        "              \"distance\":linkage_result[i][2],\n",
        "              \"Title\":\"\",\n",
        "              \"Abstract\":\"\",\n",
        "              \"AuthorKeywords\":[],\n",
        "              \"MultipartiteRank\":[]\n",
        "              })\n",
        "\n",
        "for i in range(len(obj)):\n",
        "  if i % 1000 == 0 :\n",
        "    print(\"running\", i)\n",
        "  for j in range(len(linkage_result)):\n",
        "    if int(obj[i][\"no\"]) == linkage_result[j][0] or int(obj[i][\"no\"]) == linkage_result[j][1]:\n",
        "      obj[i][\"parent\"] = str(len(linkage_result)+j+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running 0\n",
            "running 1000\n",
            "running 2000\n",
            "running 3000\n",
            "running 4000\n",
            "running 5000\n",
            "running 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaqdSu0lNk6m"
      },
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/pre-judgit/test1018.json', 'w', encoding='utf8')as f:\n",
        "  json.dump(obj, f, indent = 2, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTLT9biiudfD",
        "outputId": "693d45b9-1e9a-4aea-b475-d640f9969b46"
      },
      "source": [
        "words_array = []\n",
        "for i in range(len(samples_list)):\n",
        "  if i%1000 == 0:\n",
        "    print(i)\n",
        "  try:\n",
        "    for words in samples_list[i]['MultipartiteRank']:\n",
        "      if words[\"word\"] not in words_array:\n",
        "        words_array.append(words[\"word\"])\n",
        "  except:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhw30N41CRLm"
      },
      "source": [
        "vector_data = []\n",
        "no_vectors_word = []\n",
        "for word in words_array:\n",
        "  try:\n",
        "    tmp = {\"word\":word, \"vector\":list(float(x) for x in model.infer_vector(word))}\n",
        "    vector_data.append(tmp)\n",
        "  except:\n",
        "    no_vectors_word.append(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW5EjeouCwxZ",
        "outputId": "03560a02-0c8b-4363-f1e5-d72a09fc3ead"
      },
      "source": [
        "print(len(vector_data), len(no_vectors_word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4578 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axWBKbS3CdOC"
      },
      "source": [
        "import json\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/pre-judgit/word_vector1018.json\", 'w', encoding=\"utf8\")as f:\n",
        "  json.dump(vector_data, f, indent=2, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRpIm3mrjUU2"
      },
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/pre-judgit/test1018.json', encoding='utf8')as f:\n",
        "  obj = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlIbCn9BjtY5",
        "outputId": "b10c4d84-d795-477a-bedc-c900b6fcc9b4"
      },
      "source": [
        "df.loc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conference                                                                 InfoVis\n",
              "Year                                                                          2011\n",
              "Title                                                     D³ Data-Driven Documents\n",
              "DOI                                                          10.1109/TVCG.2011.185\n",
              "Link                                       http://dx.doi.org/10.1109/TVCG.2011.185\n",
              "FirstPage                                                                     2301\n",
              "LastPage                                                                      2309\n",
              "PaperType                                                                        J\n",
              "Abstract                         Data-Driven Documents (D3) is a novel represen...\n",
              "AuthorNames-Deduped                  Michael Bostock;Vadim Ogievetsky;Jeffrey Heer\n",
              "AuthorNames                          Michael Bostock;Vadim Ogievetsky;Jeffrey Heer\n",
              "AuthorAffiliation                                                              NaN\n",
              "InternalReferences               10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000...\n",
              "AuthorKeywords                   Information visualization, user interfaces, to...\n",
              "AminerCitationCount_04-2020                                                   1537\n",
              "XploreCitationCount - 2021-02                                                 1197\n",
              "PubsCited                                                                       41\n",
              "Award                                                                          NaN\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvegCuI2iQ5e",
        "outputId": "545f51da-2600-4235-8f42-99fcd536efe6"
      },
      "source": [
        "for data in obj:\n",
        "  data.append()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Abstract': 'Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'toolkits,',\n",
              "   '2D',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.09499765414441311, 'word': 'novel'},\n",
              "   {'score': 0.09499765414441311, 'word': 'representation'},\n",
              "   {'score': 0.0786458467582725, 'word': 'data'},\n",
              "   {'score': 0.07442014062323143, 'word': 'transparent'},\n",
              "   {'score': 0.07442014062323143, 'word': 'approach'},\n",
              "   {'score': 0.06506261017642279, 'word': 'documents'},\n",
              "   {'score': 0.04704243515034964, 'word': 'visualization'}],\n",
              "  'Title': 'D³ Data-Driven Documents',\n",
              "  'distance': 0,\n",
              "  'no': '0',\n",
              "  'parent': '4566'},\n",
              " {'Abstract': 'A method for visualizing hierarchically structured information is described. The tree-map visualization technique makes 100% use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information. Tree-maps can depict both the structure and content of the hierarchy. However, the approach is best suited to hierarchies in which the content of the leaf nodes and the structure of the hierarchy are of primary importance, and the content information associated with internal nodes is largely derived from their children.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10714621139419575, 'word': 'full'},\n",
              "   {'score': 0.10714621139419575, 'word': 'hierarchy'},\n",
              "   {'score': 0.08733830761564224, 'word': 'available'},\n",
              "   {'score': 0.08733830761564224, 'word': 'display'},\n",
              "   {'score': 0.08733830761564224, 'word': 'space'},\n",
              "   {'score': 0.07094779229482308, 'word': 'structured'},\n",
              "   {'score': 0.07094779229482308, 'word': 'information'},\n",
              "   {'score': 0.06758799681492211, 'word': 'tree'},\n",
              "   {'score': 0.06147273603785266, 'word': 'map'},\n",
              "   {'score': 0.06147273603785266, 'word': 'visualization'},\n",
              "   {'score': 0.06147273603785266, 'word': 'technique'}],\n",
              "  'Title': 'Tree-maps: a space-filling approach to the visualization of hierarchical information structures',\n",
              "  'distance': 0,\n",
              "  'no': '1',\n",
              "  'parent': '3838'},\n",
              " {'Abstract': \"A methodology for visualizing analytic and synthetic geometry in R/sup N/ is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point from to line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R/sup N/. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications are discussed.&lt;&lt;ETX&gt;&gt;\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08441210437781604, 'word': 'hypersurfaces'},\n",
              "   {'score': 0.07530332677167086, 'word': 'point'},\n",
              "   {'score': 0.07104908352340635, 'word': 'geometrical'},\n",
              "   {'score': 0.07104908352340635, 'word': 'properties'},\n",
              "   {'score': 0.07104908352340635, 'word': 'analogous'},\n",
              "   {'score': 0.053001844974187313, 'word': 'line'},\n",
              "   {'score': 0.053001844974187313, 'word': 'duality'},\n",
              "   {'score': 0.05231498869477191, 'word': 'representation'}],\n",
              "  'Title': 'Parallel coordinates: a tool for visualizing multi-dimensional geometry',\n",
              "  'distance': 0,\n",
              "  'no': '2',\n",
              "  'parent': '3610'},\n",
              " {'Abstract': 'A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations',\n",
              "  'AuthorKeywords': ['Network',\n",
              "   'visualization,',\n",
              "   'edge',\n",
              "   'bundling,',\n",
              "   'edge',\n",
              "   'aggregation,',\n",
              "   'edge',\n",
              "   'concentration,',\n",
              "   'curves,',\n",
              "   'graph',\n",
              "   'visualization,',\n",
              "   'tree',\n",
              "   'visualization,',\n",
              "   'node-link',\n",
              "   'diagrams,',\n",
              "   'hierarchies,',\n",
              "   'treemaps'],\n",
              "  'MultipartiteRank': [{'score': 0.08466536489144315, 'word': 'adjacency'},\n",
              "   {'score': 0.08466536489144315, 'word': 'edges'},\n",
              "   {'score': 0.06876657606147489, 'word': 'node'},\n",
              "   {'score': 0.05283898419338727, 'word': 'hierarchical'},\n",
              "   {'score': 0.05283898419338727, 'word': 'bundling'},\n",
              "   {'score': 0.0500231870678539, 'word': 'visual'},\n",
              "   {'score': 0.0500231870678539, 'word': 'clutter'},\n",
              "   {'score': 0.047781676117319205, 'word': 'items'}],\n",
              "  'Title': 'Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data',\n",
              "  'distance': 0,\n",
              "  'no': '3',\n",
              "  'parent': '4580'},\n",
              " {'Abstract': \"Terrain visualization is a difficult problem for applications requiring accurate images of large datasets at high frame rates, such as flight simulation and ground-based aircraft testing using synthetic sensor simulation. On current graphics hardware, the problem is to maintain dynamic, view-dependent triangle meshes and texture maps that produce good images at the required frame rate. We present an algorithm for constructing triangle meshes that optimizes flexible view-dependent error metrics, produces guaranteed error bounds, achieves specified triangle counts directly and uses frame-to-frame coherence to operate at high frame rates for thousands of triangles per frame. Our method, dubbed Real-time Optimally Adapting Meshes (ROAM), uses two priority queues to drive split and merge operations that maintain continuous triangulations built from pre-processed bintree triangles. We introduce two additional performance optimizations: incremental triangle stripping and priority-computation deferral lists. ROAM's execution time is proportional to the number of triangle changes per frame, which is typically a few percent of the output mesh size; hence ROAM's performance is insensitive to the resolution and extent of the input terrain. Dynamic terrain and simple vertex morphing are supported.\",\n",
              "  'AuthorKeywords': ['triangle',\n",
              "   'bintree,',\n",
              "   'view-dependent',\n",
              "   'mesh,',\n",
              "   'frame-to-frame',\n",
              "   'coherence,',\n",
              "   'greedy',\n",
              "   'algorithms'],\n",
              "  'MultipartiteRank': [{'score': 0.09830375183259105, 'word': 'triangle'},\n",
              "   {'score': 0.07663361010128812, 'word': 'high'},\n",
              "   {'score': 0.07663361010128812, 'word': 'frame'},\n",
              "   {'score': 0.07663361010128812, 'word': 'rates'},\n",
              "   {'score': 0.048719384737501634, 'word': 'dependent'},\n",
              "   {'score': 0.048719384737501634, 'word': 'meshes'},\n",
              "   {'score': 0.03994788016356929, 'word': 'difficult'},\n",
              "   {'score': 0.03994788016356929, 'word': 'problem'},\n",
              "   {'score': 0.03911329863764264, 'word': 'accurate'},\n",
              "   {'score': 0.03911329863764264, 'word': 'images'}],\n",
              "  'Title': 'ROAMing terrain: Real-time Optimally Adapting Meshes',\n",
              "  'distance': 0,\n",
              "  'no': '4',\n",
              "  'parent': '4617'},\n",
              " {'Abstract': 'Nowadays, direct volume rendering via 3D textures has positioned itself as an efficient tool for the display and visual analysis of volumetric scalar fields. It is commonly accepted, that for reasonably sized data sets appropriate quality at interactive rates can be achieved by means of this technique. However, despite these benefits one important issue has received little attention throughout the ongoing discussion of texture based volume rendering: the integration of acceleration techniques to reduce per-fragment operations. In this paper, we address the integration of early ray termination and empty-space skipping into texture based volume rendering on graphical processing units (GPU). Therefore, we describe volume ray-casting on programmable graphics hardware as an alternative to object-order approaches. We exploit the early z-test to terminate fragment processing once sufficient opacity has been accumulated, and to skip empty space along the rays of sight. We demonstrate performance gains up to a factor of 3 for typical renditions of volumetric data sets on the ATI 9700 graphics card.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   'Programmable',\n",
              "   'Graphics',\n",
              "   'Hardware,',\n",
              "   'Ray-Casting'],\n",
              "  'MultipartiteRank': [{'score': 0.0718041052511069, 'word': 'direct'},\n",
              "   {'score': 0.0718041052511069, 'word': 'volume'},\n",
              "   {'score': 0.07112419566588216, 'word': '3d'},\n",
              "   {'score': 0.07112419566588216, 'word': 'textures'},\n",
              "   {'score': 0.04318518201956716, 'word': 'early'},\n",
              "   {'score': 0.04318518201956716, 'word': 'ray'},\n",
              "   {'score': 0.04318518201956716, 'word': 'termination'},\n",
              "   {'score': 0.03630626865285368, 'word': 'integration'},\n",
              "   {'score': 0.035827007628413635, 'word': 'technique'}],\n",
              "  'Title': 'Acceleration techniques for GPU-based volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '5',\n",
              "  'parent': '4237'},\n",
              " {'Abstract': 'We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1242753249487847, 'word': 'methods'},\n",
              "   {'score': 0.11696621197644891, 'word': 'point'},\n",
              "   {'score': 0.08343023667963298, 'word': 'surface'},\n",
              "   {'score': 0.08343023667963298, 'word': 'simplification'},\n",
              "   {'score': 0.04524411173068127, 'word': 'approximations'},\n",
              "   {'score': 0.03848260027820932, 'word': 'high'},\n",
              "   {'score': 0.03848260027820932, 'word': 'curvature'}],\n",
              "  'Title': 'Efficient simplification of point-sampled surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '6',\n",
              "  'parent': '4609'},\n",
              " {'Abstract': 'Recent years have witnessed the dramatic popularity of online social networking services, in which millions of members publicly articulate mutual \"friendship\" relations. Guided by ethnographic research of these online communities, we have designed and implemented a visualization system for playful end-user exploration and navigation of large scale online social networks. Our design builds upon familiar node link network layouts to contribute customized techniques for exploring connectivity in large graph structures, supporting visual search and analysis, and automatically identifying and visualizing community structures. Both public installation and controlled studies of the system provide evidence of the system\\'s usability, capacity for facilitating discovery, and potential for fun and engaged social activity',\n",
              "  'AuthorKeywords': ['social',\n",
              "   'networks,',\n",
              "   'visualization,',\n",
              "   'graphs,',\n",
              "   'community,data',\n",
              "   'mining,',\n",
              "   'exploration,',\n",
              "   'play'],\n",
              "  'MultipartiteRank': [{'score': 0.1065029926834877, 'word': 'online'},\n",
              "   {'score': 0.10282399048951371, 'word': 'system'},\n",
              "   {'score': 0.0652443538337427, 'word': 'visualization'},\n",
              "   {'score': 0.06222583409518359, 'word': 'social'},\n",
              "   {'score': 0.06222583409518359, 'word': 'networking'},\n",
              "   {'score': 0.06222583409518359, 'word': 'services'},\n",
              "   {'score': 0.044277158588304104, 'word': 'communities'},\n",
              "   {'score': 0.038687484049078145, 'word': 'playful'},\n",
              "   {'score': 0.038687484049078145, 'word': 'end'}],\n",
              "  'Title': 'Vizster: visualizing online social networks',\n",
              "  'distance': 0,\n",
              "  'no': '7',\n",
              "  'parent': '3974'},\n",
              " {'Abstract': 'We advocate the use of point sets to represent shapes. We provide a definition of a smooth manifold surface from a set of points close to the original surface. The definition is based on local maps from differential geometry, which are approximated by the method of moving least squares (MLS). We present tools to increase or decrease the density of the points, thus, allowing an adjustment of the spacing among the points to control the fidelity of the representation. To display the point set surface, we introduce a novel point rendering technique. The idea is to evaluate the local maps according to the image resolution. This results in high quality shading effects and smooth silhouettes at interactive frame rates.',\n",
              "  'AuthorKeywords': ['surface',\n",
              "   'representation',\n",
              "   'and',\n",
              "   'reconstruction,',\n",
              "   'moving',\n",
              "   'least',\n",
              "   'squares,',\n",
              "   'point',\n",
              "   'sample',\n",
              "   'rendering,',\n",
              "   '3D',\n",
              "   'acquisition'],\n",
              "  'MultipartiteRank': [{'score': 0.14902512455443093, 'word': 'points'},\n",
              "   {'score': 0.09506225822185607, 'word': 'close'},\n",
              "   {'score': 0.08808619594358282, 'word': 'smooth'},\n",
              "   {'score': 0.08808619594358282, 'word': 'manifold'},\n",
              "   {'score': 0.08808619594358282, 'word': 'surface'},\n",
              "   {'score': 0.08485547292350931, 'word': 'point'},\n",
              "   {'score': 0.08485547292350931, 'word': 'sets'},\n",
              "   {'score': 0.0645916309438694, 'word': 'definition'}],\n",
              "  'Title': 'Point set surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '8',\n",
              "  'parent': '3807'},\n",
              " {'Abstract': 'We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'World',\n",
              "   'Wide',\n",
              "   'Web,',\n",
              "   'Social',\n",
              "   'Software,',\n",
              "   'Social',\n",
              "   'Data',\n",
              "   'Analysis,',\n",
              "   'Communication-Minded',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1674740967409138, 'word': 'visualizations'},\n",
              "   {'score': 0.10039102166709596, 'word': 'interactive'},\n",
              "   {'score': 0.09281420038289355, 'word': 'users'},\n",
              "   {'score': 0.08039432372386998, 'word': 'public'},\n",
              "   {'score': 0.08039432372386998, 'word': 'web'},\n",
              "   {'score': 0.08039432372386998, 'word': 'site'},\n",
              "   {'score': 0.06057355192256087, 'word': 'data'}],\n",
              "  'Title': 'ManyEyes: a Site for Visualization at Internet Scale',\n",
              "  'distance': 0,\n",
              "  'no': '9',\n",
              "  'parent': '3639'},\n",
              " {'Abstract': 'The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09365813296620285, 'word': 'text'},\n",
              "   {'score': 0.09365813296620285, 'word': 'content'},\n",
              "   {'score': 0.05803441347788542, 'word': 'spatial'},\n",
              "   {'score': 0.05803441347788542, 'word': 'representation'},\n",
              "   {'score': 0.04777642021585796, 'word': 'language'},\n",
              "   {'score': 0.04777642021585796, 'word': 'processing'},\n",
              "   {'score': 0.045892659166785865, 'word': 'procedures'},\n",
              "   {'score': 0.04544514862151808, 'word': 'regulations'}],\n",
              "  'Title': 'Visualizing the non-visual: spatial analysis and interaction with information from text documents',\n",
              "  'distance': 0,\n",
              "  'no': '10',\n",
              "  'parent': '4146'},\n",
              " {'Abstract': \"Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.\",\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'interaction,',\n",
              "   'interaction',\n",
              "   'techniques,',\n",
              "   'taxonomy,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.14878686564361934, 'word': 'interaction'},\n",
              "   {'score': 0.10881387182863281, 'word': 'infovis'},\n",
              "   {'score': 0.05288783412707795, 'word': 'low'},\n",
              "   {'score': 0.05288783412707795, 'word': 'level'},\n",
              "   {'score': 0.048090075658036704, 'word': 'systems'},\n",
              "   {'score': 0.04708154919699749, 'word': 'general'},\n",
              "   {'score': 0.04708154919699749, 'word': 'categories'}],\n",
              "  'Title': 'Toward a Deeper Understanding of the Role of Interaction in Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '11',\n",
              "  'parent': '4975'},\n",
              " {'Abstract': 'In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06949045151735488,\n",
              "    'word': 'visualizations'},\n",
              "   {'score': 0.062250561312061976, 'word': 'interfaces'},\n",
              "   {'score': 0.0485206379086475, 'word': 'exploration'},\n",
              "   {'score': 0.0485206379086475, 'word': 'tasks'},\n",
              "   {'score': 0.04692063714927574, 'word': 'analysis'},\n",
              "   {'score': 0.04293408941656967, 'word': 'data'},\n",
              "   {'score': 0.04293408941656967, 'word': 'warehousing'}],\n",
              "  'Title': 'Polaris: a system for query, analysis and visualization of multi-dimensional relational databases',\n",
              "  'distance': 0,\n",
              "  'no': '12',\n",
              "  'parent': '4382'},\n",
              " {'Abstract': 'The key to real-time rendering of large-scale surfaces is to locally adapt surface geometric complexity to changing view parameters. Several schemes have been developed to address this problem of view-dependent level-of-detail control. Among these, the view-dependent progressive mesh (VDPM) framework represents an arbitrary triangle mesh as a hierarchy of geometrically optimized refinement transformations, from which accurate approximating meshes can be efficiently retrieved. In this paper we extend the general VDPM framework to provide temporal coherence through the run-time creation of geomorphs. These geomorphs eliminate \"popping\" artifacts by smoothly interpolating geometry. Their implementation requires new output-sensitive data structures, which have the added benefit of reducing memory use. We specialize the VDPM framework to the important case of terrain rendering. To handle huge terrain grids, we introduce a block-based simplification scheme that constructs a progressive mesh as a hierarchy of block refinements. We demonstrate the need for an accurate approximation metric during simplification. Our contributions are highlighted in a real-time flyover of a large, rugged terrain. Notably, the use of geomorphs results in visually smooth rendering even at 72 frames/sec on a graphics workstation.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.083140716146645, 'word': 'view'},\n",
              "   {'score': 0.05989492286690375, 'word': 'dependent'},\n",
              "   {'score': 0.05989492286690375, 'word': 'progressive'},\n",
              "   {'score': 0.05989492286690375, 'word': 'mesh'},\n",
              "   {'score': 0.05412165132554672, 'word': 'vdpm'},\n",
              "   {'score': 0.050551333721103014, 'word': 'parameters'},\n",
              "   {'score': 0.04468473129895173, 'word': 'time'},\n",
              "   {'score': 0.04468473129895173, 'word': 'rendering'}],\n",
              "  'Title': 'Smooth view-dependent level-of-detail control and its application to terrain rendering',\n",
              "  'distance': 0,\n",
              "  'no': '13',\n",
              "  'parent': '4713'},\n",
              " {'Abstract': 'A method for computing isovalue or contour surfaces of a trivariate function is discussed. The input data are values of the trivariate function, F/sub ijk/, at the cuberille grid points (x/sub i/, y/sub j/, z/sub k/), and the output of a collection of triangles representing the surface consisting of all points where F(x,y,z) is a constant value. The method is a modification that is intended to correct a problem with a previous method.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1202227507456183, 'word': 'trivariate'},\n",
              "   {'score': 0.1202227507456183, 'word': 'function'},\n",
              "   {'score': 0.11684220160136527, 'word': 'contour'},\n",
              "   {'score': 0.11684220160136527, 'word': 'surfaces'},\n",
              "   {'score': 0.10860885538777842, 'word': 'values'},\n",
              "   {'score': 0.09074085620039293, 'word': 'method'},\n",
              "   {'score': 0.08190265868386348, 'word': 'input'},\n",
              "   {'score': 0.08190265868386348, 'word': 'data'}],\n",
              "  'Title': 'The asymptotic decider: resolving the ambiguity in marching cubes',\n",
              "  'distance': 0,\n",
              "  'no': '14',\n",
              "  'parent': '3336'},\n",
              " {'Abstract': 'Data visualization is regularly promoted for its ability to reveal stories within data, yet these “data stories” differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.',\n",
              "  'AuthorKeywords': ['Narrative',\n",
              "   'visualization,',\n",
              "   'storytelling,',\n",
              "   'design',\n",
              "   'methods,',\n",
              "   'case',\n",
              "   'study,',\n",
              "   'journalism,',\n",
              "   'social',\n",
              "   'data',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.20056293437114292, 'word': 'data'},\n",
              "   {'score': 0.15124987903019188, 'word': 'visualization'},\n",
              "   {'score': 0.06244215532147147, 'word': 'stories'},\n",
              "   {'score': 0.050513149443383025, 'word': 'narratives'},\n",
              "   {'score': 0.0478665545553213, 'word': 'storytelling'}],\n",
              "  'Title': 'Narrative Visualization: Telling Stories with Data',\n",
              "  'distance': 0,\n",
              "  'no': '15',\n",
              "  'parent': '3790'},\n",
              " {'Abstract': 'There are a variety of application areas in which there is a need for simplifying complex polygonal surface models. These models often have material properties such as colors, textures, and surface normals. Our surface simplification algorithm, based on iterative edge contraction and quadric error metrics, can rapidly produce high quality approximations of such models. We present a natural extension of our original error metric that can account for a wide range of vertex attributes.',\n",
              "  'AuthorKeywords': ['surface',\n",
              "   'simplification,',\n",
              "   'multiresolution',\n",
              "   'modeling,',\n",
              "   'level',\n",
              "   'of',\n",
              "   'detail,',\n",
              "   'quadric',\n",
              "   'error',\n",
              "   'metric,',\n",
              "   'edge',\n",
              "   'contraction,',\n",
              "   'surface',\n",
              "   'properties,',\n",
              "   'discontinuity',\n",
              "   'preservation'],\n",
              "  'MultipartiteRank': [{'score': 0.10318948080681109, 'word': 'quadric'},\n",
              "   {'score': 0.10318948080681109, 'word': 'error'},\n",
              "   {'score': 0.10318948080681109, 'word': 'metrics'},\n",
              "   {'score': 0.08122727451914263, 'word': 'iterative'},\n",
              "   {'score': 0.08122727451914263, 'word': 'edge'},\n",
              "   {'score': 0.08122727451914263, 'word': 'contraction'},\n",
              "   {'score': 0.07540456293371164, 'word': 'textures'},\n",
              "   {'score': 0.07212197372507306, 'word': 'surface'},\n",
              "   {'score': 0.07212197372507306, 'word': 'normals'},\n",
              "   {'score': 0.06991628579158095, 'word': 'colors'}],\n",
              "  'Title': 'Simplifying surfaces with color and texture using quadric error metrics',\n",
              "  'distance': 0,\n",
              "  'no': '16',\n",
              "  'parent': '3554'},\n",
              " {'Abstract': 'We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.',\n",
              "  'AuthorKeywords': ['Models,', 'frameworks,', 'design,', 'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.0870993760918013, 'word': 'level'},\n",
              "   {'score': 0.055637437969435405, 'word': 'data'},\n",
              "   {'score': 0.05298073710019757, 'word': 'model'},\n",
              "   {'score': 0.04866794235520282, 'word': 'visualization'},\n",
              "   {'score': 0.04866794235520282, 'word': 'design'},\n",
              "   {'score': 0.04859689994658377, 'word': 'validation'}],\n",
              "  'Title': 'A Nested Model for Visualization Design and Validation',\n",
              "  'distance': 0,\n",
              "  'no': '17',\n",
              "  'parent': '4435'},\n",
              " {'Abstract': 'Much of the attention in visualization research has focussed on data rooted in physical phenomena, which is generally limited to three or four dimensions. However, many sources of data do not share this dimensional restriction. A critical problem in the analysis of such data is providing researchers with tools to gain insights into characteristics of the data, such as anomalies and patterns. Several visualization methods have been developed to address this problem, and each has its strengths and weaknesses. This paper describes a system named XmdvTool which integrates several of the most common methods for projecting multivariate data onto a two-dimensional screen. This integration allows users to explore their data in a variety of formats with ease. A view enhancement mechanism called an N-dimensional brush is also described. The brush allows users to gain insights into spatial relationships over N dimensions by highlighting data which falls within a user-specified subspace.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09914062057965381, 'word': 'data'},\n",
              "   {'score': 0.04551530067381557, 'word': 'visualization'},\n",
              "   {'score': 0.04551530067381557, 'word': 'research'},\n",
              "   {'score': 0.04472358145533672, 'word': 'users'},\n",
              "   {'score': 0.04022643974618282, 'word': 'insights'},\n",
              "   {'score': 0.038547471206683594, 'word': 'dimensional'},\n",
              "   {'score': 0.038547471206683594, 'word': 'restriction'}],\n",
              "  'Title': 'XmdvTool: integrating multiple methods for visualizing multivariate data',\n",
              "  'distance': 0,\n",
              "  'no': '18',\n",
              "  'parent': '4149'},\n",
              " {'Abstract': 'In previous work, researchers have attempted to construct taxonomies of information visualization techniques by examining the data domains that are compatible with these techniques. This is useful because implementers can quickly identify various techniques that can be applied to their domain of interest. However, these taxonomies do not help the implementers understand how to apply and implement these techniques. The author extends and proposes a new way to taxonomize information visualization techniques by using the Data State Model (E.H. Chi and J.T. Reidl, 1998). In fact, as the taxonomic analysis in the paper will show, many of the techniques share similar operating steps that can easily be reused. The paper shows that the Data State Model not only helps researchers understand the space of design, but also helps implementers understand how information visualization techniques can be applied more broadly.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'Visualization,',\n",
              "   'Data',\n",
              "   'State',\n",
              "   'Model,Reference',\n",
              "   'Model,',\n",
              "   'Taxonomy,',\n",
              "   'Techniques,',\n",
              "   'Operators'],\n",
              "  'MultipartiteRank': [{'score': 0.22101404865566934, 'word': 'techniques'},\n",
              "   {'score': 0.15517477115407752, 'word': 'information'},\n",
              "   {'score': 0.15517477115407752, 'word': 'visualization'},\n",
              "   {'score': 0.07651795288808198, 'word': 'implementers'},\n",
              "   {'score': 0.05960604157512563, 'word': 'taxonomies'},\n",
              "   {'score': 0.059266950805541875, 'word': 'data'},\n",
              "   {'score': 0.059266950805541875, 'word': 'domains'}],\n",
              "  'Title': 'A taxonomy of visualization techniques using the data state reference model',\n",
              "  'distance': 0,\n",
              "  'no': '19',\n",
              "  'parent': '4664'},\n",
              " {'Abstract': 'The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.',\n",
              "  'AuthorKeywords': ['Network',\n",
              "   'visualization,',\n",
              "   'Matrix',\n",
              "   'visualization,',\n",
              "   'Hybrid',\n",
              "   'visualization,',\n",
              "   'Aggregation,',\n",
              "   'Interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.10316007404260766, 'word': 'large'},\n",
              "   {'score': 0.10316007404260766, 'word': 'social'},\n",
              "   {'score': 0.10316007404260766, 'word': 'networks'},\n",
              "   {'score': 0.04877119209358172, 'word': 'network'},\n",
              "   {'score': 0.04505126168897272, 'word': 'nodetrix'},\n",
              "   {'score': 0.04294176879621427, 'word': 'hardware'},\n",
              "   {'score': 0.04294176879621427, 'word': 'capabilities'},\n",
              "   {'score': 0.042520555596427076, 'word': 'detailed'},\n",
              "   {'score': 0.042520555596427076, 'word': 'analysis'}],\n",
              "  'Title': 'NodeTrix: a Hybrid Visualization of Social Networks',\n",
              "  'distance': 0,\n",
              "  'no': '20',\n",
              "  'parent': '4875'},\n",
              " {'Abstract': 'Our ability to accumulate large, complex (multivariate) data sets has far exceeded our ability to effectively process them in searching for patterns, anomalies and other interesting features. Conventional multivariate visualization techniques generally do not scale well with respect to the size of the data set. The focus of this paper is on the interactive visualization of large multivariate data sets based on a number of novel extensions to the parallel coordinates display technique. We develop a multi-resolution view of the data via hierarchical clustering, and use a variation of parallel coordinates to convey aggregation information for the resulting clusters. Users can then navigate the resulting structure until the desired focus region and level of detail is reached, using our suite of navigational and filtering tools. We describe the design and implementation of our hierarchical parallel coordinates system which is based on extending the XmdvTool system. Lastly, we show examples of the tools and techniques applied to large (hundreds of thousands of records) multivariate data sets.',\n",
              "  'AuthorKeywords': ['Large-scale',\n",
              "   'multivariate',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'hierarchical',\n",
              "   'data',\n",
              "   'exploration,',\n",
              "   'parallel',\n",
              "   'coordinates'],\n",
              "  'MultipartiteRank': [{'score': 0.087673083978786, 'word': 'data'},\n",
              "   {'score': 0.087673083978786, 'word': 'sets'},\n",
              "   {'score': 0.049743785806340514, 'word': 'parallel'},\n",
              "   {'score': 0.049743785806340514, 'word': 'coordinates'},\n",
              "   {'score': 0.04321399551972167, 'word': 'large'},\n",
              "   {'score': 0.03948496447656691, 'word': 'multivariate'},\n",
              "   {'score': 0.03732188387516612, 'word': 'ability'}],\n",
              "  'Title': 'Hierarchical parallel coordinates for exploration of large datasets',\n",
              "  'distance': 0,\n",
              "  'no': '21',\n",
              "  'parent': '4757'},\n",
              " {'Abstract': 'Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'analytics,',\n",
              "   'investigative',\n",
              "   'analysis,',\n",
              "   'intelligence',\n",
              "   'analysis,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'multiple',\n",
              "   'views'],\n",
              "  'MultipartiteRank': [{'score': 0.15902839268358848, 'word': 'documents'},\n",
              "   {'score': 0.10639696256858683, 'word': 'text'},\n",
              "   {'score': 0.09087352745781438, 'word': 'investigative'},\n",
              "   {'score': 0.09087352745781438, 'word': 'analysts'},\n",
              "   {'score': 0.057288930354758766, 'word': 'entities'},\n",
              "   {'score': 0.047901901058487684, 'word': 'order'}],\n",
              "  'Title': 'Jigsaw: Supporting Investigative Analysis through Interactive Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '22',\n",
              "  'parent': '3971'},\n",
              " {'Abstract': 'Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modem graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'visualization,',\n",
              "   'direct',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'multi-dimensional',\n",
              "   'transfer',\n",
              "   'functions,',\n",
              "   'direct',\n",
              "   'manipulation',\n",
              "   'widgets,',\n",
              "   'graphics',\n",
              "   'hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.11200680473355486, 'word': 'dimensional'},\n",
              "   {'score': 0.11200680473355486, 'word': 'transfer'},\n",
              "   {'score': 0.11200680473355486, 'word': 'functions'},\n",
              "   {'score': 0.06376606093741748, 'word': 'scalar'},\n",
              "   {'score': 0.06376606093741748, 'word': 'data'},\n",
              "   {'score': 0.04996074709511739, 'word': 'dimension'},\n",
              "   {'score': 0.04658562777131456, 'word': 'volume'},\n",
              "   {'score': 0.04639919361033113, 'word': 'direct'},\n",
              "   {'score': 0.04639919361033113, 'word': 'manipulation'},\n",
              "   {'score': 0.04639919361033113, 'word': 'widgets'}],\n",
              "  'Title': 'Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets',\n",
              "  'distance': 0,\n",
              "  'no': '23',\n",
              "  'parent': '4321'},\n",
              " {'Abstract': 'Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.',\n",
              "  'AuthorKeywords': ['Sets,',\n",
              "   'set',\n",
              "   'visualization,',\n",
              "   'sets',\n",
              "   'intersections,',\n",
              "   'set',\n",
              "   'attributes,',\n",
              "   'set',\n",
              "   'relationships,',\n",
              "   'multidimensional',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.071791850414854, 'word': 'sets'},\n",
              "   {'score': 0.0689818905488197, 'word': 'intersections'},\n",
              "   {'score': 0.06776614525500525, 'word': 'aggregates'},\n",
              "   {'score': 0.0477522242644941, 'word': 'visualization'},\n",
              "   {'score': 0.0477522242644941, 'word': 'community'},\n",
              "   {'score': 0.03769000856092087, 'word': 'elements'}],\n",
              "  'Title': 'UpSet: Visualization of Intersecting Sets',\n",
              "  'distance': 0,\n",
              "  'no': '24',\n",
              "  'parent': '4966'},\n",
              " {'Abstract': \"Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.\",\n",
              "  'AuthorKeywords': ['Analytic',\n",
              "   'activity,',\n",
              "   'taxonomy,',\n",
              "   'knowledge',\n",
              "   'discovery,',\n",
              "   'design,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.14743537208329785, 'word': 'visualization'},\n",
              "   {'score': 0.08988630162468818, 'word': 'tasks'},\n",
              "   {'score': 0.06155849068741774, 'word': 'user'},\n",
              "   {'score': 0.06155849068741774, 'word': 'analytic'},\n",
              "   {'score': 0.06155849068741774, 'word': 'activity'},\n",
              "   {'score': 0.059354794144979545, 'word': 'system'},\n",
              "   {'score': 0.059354794144979545, 'word': 'level'},\n",
              "   {'score': 0.059354794144979545, 'word': 'taxonomies'},\n",
              "   {'score': 0.05754907045860967, 'word': 'information'},\n",
              "   {'score': 0.05754907045860967, 'word': 'tools'},\n",
              "   {'score': 0.051070132025514144, 'word': 'sample'},\n",
              "   {'score': 0.051070132025514144, 'word': 'questions'}],\n",
              "  'Title': 'Low-level components of analytic activity in information visualization',\n",
              "  'distance': 0,\n",
              "  'no': '25',\n",
              "  'parent': '4433'},\n",
              " {'Abstract': 'ThemeRiver/sup TM/ is a prototype system that visualizes thematic variations over time within a large collection of documents. The \"river\" flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored \"currents\" flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0856657427045534, 'word': 'documents'},\n",
              "   {'score': 0.07726803042683694, 'word': 'river'},\n",
              "   {'score': 0.06739533430526179, 'word': 'time'},\n",
              "   {'score': 0.0654910522437911, 'word': 'thematic'},\n",
              "   {'score': 0.0654910522437911, 'word': 'strength'},\n",
              "   {'score': 0.05584986893377531, 'word': 'individual'},\n",
              "   {'score': 0.05584986893377531, 'word': 'topic'}],\n",
              "  'Title': 'ThemeRiver: visualizing theme changes over time',\n",
              "  'distance': 0,\n",
              "  'no': '26',\n",
              "  'parent': '3829'},\n",
              " {'Abstract': 'Direct volume rendering of scalar fields uses a transfer function to map locally measured data properties to opacities and colors. The domain of the transfer function is typically the one-dimensional space of scalar data values. This paper advances the use of curvature information in multi-dimensional transfer functions, with a methodology for computing high-quality curvature measurements. The proposed methodology combines an implicit formulation of curvature with convolution-based reconstruction of the field. We give concrete guidelines for implementing the methodology, and illustrate the importance of choosing accurate filters for computing derivatives with convolution. Curvature-based transfer functions are shown to extend the expressivity and utility of volume rendering through contributions in three different application areas: nonphotorealistic volume rendering, surface smoothing via anisotropic diffusion, and visualization of isosurface uncertainty.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'rendering,',\n",
              "   'implicit',\n",
              "   'surface',\n",
              "   'curvature,',\n",
              "   'convolution-based',\n",
              "   'differentiation,',\n",
              "   'non-photorealistic',\n",
              "   'rendering,',\n",
              "   'surface',\n",
              "   'processing,',\n",
              "   'uncertainty',\n",
              "   'visualization,',\n",
              "   'flowline',\n",
              "   'curvature'],\n",
              "  'MultipartiteRank': [{'score': 0.09071408012992757, 'word': 'direct'},\n",
              "   {'score': 0.09071408012992757, 'word': 'volume'},\n",
              "   {'score': 0.07515451566929586, 'word': 'curvature'},\n",
              "   {'score': 0.07515451566929586, 'word': 'information'},\n",
              "   {'score': 0.06764450590955573, 'word': 'transfer'},\n",
              "   {'score': 0.06764450590955573, 'word': 'function'},\n",
              "   {'score': 0.05544993302320174, 'word': 'scalar'},\n",
              "   {'score': 0.05544993302320174, 'word': 'fields'},\n",
              "   {'score': 0.048665710516349665, 'word': 'methodology'}],\n",
              "  'Title': 'Curvature-based transfer functions for direct volume rendering: methods and applications',\n",
              "  'distance': 0,\n",
              "  'no': '27',\n",
              "  'parent': '4040'},\n",
              " {'Abstract': 'Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0820485904362845, 'word': 'information'},\n",
              "   {'score': 0.0820485904362845, 'word': 'hierarchies'},\n",
              "   {'score': 0.07135499313307449, 'word': 'visualizations'},\n",
              "   {'score': 0.0650912559317355, 'word': 'small'},\n",
              "   {'score': 0.05859954890275129, 'word': 'space'},\n",
              "   {'score': 0.05850542540304628, 'word': 'interaction'},\n",
              "   {'score': 0.05850542540304628, 'word': 'techniques'}],\n",
              "  'Title': 'Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '28',\n",
              "  'parent': '3477'},\n",
              " {'Abstract': 'A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09075968579107081, 'word': 'patterns'},\n",
              "   {'score': 0.07210051008324539, 'word': 'days'},\n",
              "   {'score': 0.06604857361434946, 'word': 'insight'},\n",
              "   {'score': 0.05553067561142812, 'word': 'trends'},\n",
              "   {'score': 0.05382466545766845, 'word': 'multiple'},\n",
              "   {'score': 0.05382466545766845, 'word': 'time'},\n",
              "   {'score': 0.05382466545766845, 'word': 'scales'}],\n",
              "  'Title': 'Cluster and calendar based visualization of time series data',\n",
              "  'distance': 0,\n",
              "  'no': '29',\n",
              "  'parent': '3549'},\n",
              " {'Abstract': 'Complex triangle meshes arise naturally in many areas of computer graphics and visualization. Previous work has shown that a quadric error metric allows fast and accurate geometric simplification of meshes. This quadric approach was recently generalized to handle meshes with appearance attributes. In this paper we present an improved quadric error metric for simplifying meshes with attributes. The new metric, based on geometric correspondence in 3D, requires less storage, evaluates more quickly, and results in more accurate simplified meshes. Meshes often have attribute discontinuities, such as surface creases and material boundaries, which require multiple attribute vectors per vertex. We show that a wedge-based mesh data structure captures such discontinuities efficiently and permits simultaneous optimization of these multiple attribute vectors. In addition to the new quadric metric, we experiment with two techniques proposed in geometric simplification, memoryless simplification and volume preservation, and show that both of these are beneficial within the quadric framework. The new scheme is demonstrated on a variety of meshes with colors and normals.',\n",
              "  'AuthorKeywords': ['level',\n",
              "   'of',\n",
              "   'detail,',\n",
              "   'mesh',\n",
              "   'decimation,',\n",
              "   'multiresolution'],\n",
              "  'MultipartiteRank': [{'score': 0.2440310681174803, 'word': 'meshes'},\n",
              "   {'score': 0.18883113946943922, 'word': 'complex'},\n",
              "   {'score': 0.18883113946943922, 'word': 'triangle'},\n",
              "   {'score': 0.06205812160546068, 'word': 'quadric'},\n",
              "   {'score': 0.06205812160546068, 'word': 'error'},\n",
              "   {'score': 0.06205812160546068, 'word': 'metric'},\n",
              "   {'score': 0.058592370284727316, 'word': 'appearance'},\n",
              "   {'score': 0.058592370284727316, 'word': 'attributes'},\n",
              "   {'score': 0.054159216969900684, 'word': 'many'},\n",
              "   {'score': 0.054159216969900684, 'word': 'areas'}],\n",
              "  'Title': 'New quadric metric for simplifying meshes with appearance attributes',\n",
              "  'distance': 0,\n",
              "  'no': '30',\n",
              "  'parent': '5554'},\n",
              " {'Abstract': 'Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.',\n",
              "  'AuthorKeywords': ['display,',\n",
              "   'projection,',\n",
              "   'spatially',\n",
              "   'immersive',\n",
              "   'display,',\n",
              "   'panoramic',\n",
              "   'image',\n",
              "   'display,',\n",
              "   'virtual',\n",
              "   'environments,',\n",
              "   'intensity',\n",
              "   'blending,',\n",
              "   'image-based',\n",
              "   'modeling,',\n",
              "   'depth,',\n",
              "   'calibration,',\n",
              "   'auto-calibration,',\n",
              "   'structured',\n",
              "   'light,',\n",
              "   'camera-based',\n",
              "   'registration'],\n",
              "  'MultipartiteRank': [{'score': 0.15124769527764229, 'word': 'conventional'},\n",
              "   {'score': 0.15124769527764229, 'word': 'projector'},\n",
              "   {'score': 0.12062952847275651, 'word': 'display'},\n",
              "   {'score': 0.12062952847275651, 'word': 'systems'},\n",
              "   {'score': 0.04997751614440987, 'word': 'projectors'},\n",
              "   {'score': 0.03443031019096798, 'word': 'conference'},\n",
              "   {'score': 0.03443031019096798, 'word': 'rooms'},\n",
              "   {'score': 0.03403743917094734, 'word': 'simplicity'}],\n",
              "  'Title': 'Multi-projector displays using camera-based registration',\n",
              "  'distance': 0,\n",
              "  'no': '31',\n",
              "  'parent': '4295'},\n",
              " {'Abstract': 'Volume visualization techniques typically provide support for visual exploration of data, however additional information can be conveyed by allowing a user to see as well as feel virtual objects. We present a haptic interaction method that is suitable for both volume visualization and modeling applications. Point contact forces are computed directly from the volume data and are consistent with the isosurface and volume rendering methods, providing a strong correspondence between visual and haptic feedback. Virtual tools are simulated by applying three-dimensional filters to some properties of the data within the extent of the tool, and interactive visual feedback rates are obtained by using an accelerated ray casting method. This haptic interaction method was implemented using a PHANToM haptic interface.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1852548205104607, 'word': 'volume'},\n",
              "   {'score': 0.1852548205104607, 'word': 'visualization'},\n",
              "   {'score': 0.1852548205104607, 'word': 'techniques'},\n",
              "   {'score': 0.08180617921616629, 'word': 'data'},\n",
              "   {'score': 0.0727883252623662, 'word': 'support'},\n",
              "   {'score': 0.06772095791399839, 'word': 'haptic'},\n",
              "   {'score': 0.06772095791399839, 'word': 'interaction'},\n",
              "   {'score': 0.06772095791399839, 'word': 'method'},\n",
              "   {'score': 0.04014689319559143, 'word': 'virtual'},\n",
              "   {'score': 0.04014689319559143, 'word': 'tools'}],\n",
              "  'Title': 'A haptic interaction method for volume visualization',\n",
              "  'distance': 0,\n",
              "  'no': '32',\n",
              "  'parent': '4010'},\n",
              " {'Abstract': 'We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07800989839165595, 'word': 'branches'},\n",
              "   {'score': 0.06767770330964187, 'word': 'topology'},\n",
              "   {'score': 0.0615158491338742, 'word': 'novel'},\n",
              "   {'score': 0.0615158491338742, 'word': 'tree'},\n",
              "   {'score': 0.0615158491338742, 'word': 'browser'},\n",
              "   {'score': 0.05044627153654707, 'word': 'preview'},\n",
              "   {'score': 0.05044627153654707, 'word': 'icons'},\n",
              "   {'score': 0.045962961008218534, 'word': 'use'}],\n",
              "  'Title': 'SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation',\n",
              "  'distance': 0,\n",
              "  'no': '33',\n",
              "  'parent': '3410'},\n",
              " {'Abstract': 'In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in &lt;i&gt;DynaVis&lt;/i&gt;, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.',\n",
              "  'AuthorKeywords': ['Statistical',\n",
              "   'data',\n",
              "   'graphics,',\n",
              "   'animation,',\n",
              "   'transitions,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'design,',\n",
              "   'experiment'],\n",
              "  'MultipartiteRank': [{'score': 0.13250335886809592, 'word': 'transitions'},\n",
              "   {'score': 0.09691316082386245, 'word': 'data'},\n",
              "   {'score': 0.09691316082386245, 'word': 'graphics'},\n",
              "   {'score': 0.08788792349418403, 'word': 'effectiveness'},\n",
              "   {'score': 0.0693121531991752, 'word': 'bar'},\n",
              "   {'score': 0.0693121531991752, 'word': 'charts'},\n",
              "   {'score': 0.06583293076205758, 'word': 'design'},\n",
              "   {'score': 0.06583293076205758, 'word': 'principles'}],\n",
              "  'Title': 'Animated Transitions in Statistical Data Graphics',\n",
              "  'distance': 0,\n",
              "  'no': '34',\n",
              "  'parent': '4043'},\n",
              " {'Abstract': 'Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'exploration,',\n",
              "   'visual',\n",
              "   'queries,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'navigation,',\n",
              "   'multivariate',\n",
              "   'data,',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.10037033021320882,\n",
              "    'word': 'multidimensional'},\n",
              "   {'score': 0.08803588536940056, 'word': 'scatterplots'},\n",
              "   {'score': 0.05511052986493653, 'word': 'space'},\n",
              "   {'score': 0.04940080107406366, 'word': 'visual'},\n",
              "   {'score': 0.04940080107406366, 'word': 'representations'},\n",
              "   {'score': 0.04525980034827229, 'word': 'data'},\n",
              "   {'score': 0.03831391762731053, 'word': 'interactive'},\n",
              "   {'score': 0.03831391762731053, 'word': 'navigation'}],\n",
              "  'Title': 'Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation',\n",
              "  'distance': 0,\n",
              "  'no': '35',\n",
              "  'parent': '4382'},\n",
              " {'Abstract': 'Real-time rendering of triangulated surfaces has attracted growing interest in the last few years. However, interactive visualization of very large scale grid digital elevation models is still difficult. The graphics load must be controlled by adaptive surface triangulation and by taking advantage of different levels of detail. Furthermore, management of the visible scene requires efficient access to the terrain database. We describe an all-in-one visualization system which integrates adaptive triangulation, dynamic scene management and spatial data handling. The triangulation model is based on the restricted quadtree triangulation. Furthermore, we present new algorithms of restricted quadtree triangulation. These include among others exact error approximation, progressive meshing, performance enhancements and spatial access.',\n",
              "  'AuthorKeywords': ['algorithms,',\n",
              "   'computer',\n",
              "   'graphics,',\n",
              "   'virtual',\n",
              "   'reality,',\n",
              "   'triangulated',\n",
              "   'surfaces,',\n",
              "   'terrain',\n",
              "   'visualization,',\n",
              "   'terascale',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.14068872157059548, 'word': 'triangulated'},\n",
              "   {'score': 0.14068872157059548, 'word': 'surfaces'},\n",
              "   {'score': 0.07826107054220276, 'word': 'time'},\n",
              "   {'score': 0.07826107054220276, 'word': 'rendering'},\n",
              "   {'score': 0.05492259243443365, 'word': 'management'},\n",
              "   {'score': 0.05262734384946907, 'word': 'real'},\n",
              "   {'score': 0.04882537704364175, 'word': 'efficient'},\n",
              "   {'score': 0.04882537704364175, 'word': 'access'}],\n",
              "  'Title': 'Large scale terrain visualization using the restricted quadtree triangulation',\n",
              "  'distance': 0,\n",
              "  'no': '36',\n",
              "  'parent': '3801'},\n",
              " {'Abstract': 'Presents an algorithm for performing view-dependent simplifications of a triangulated polygonal model in real-time. The simplifications are dependent on viewing direction, lighting and visibility, and are performed by taking advantage of image-space, object-space and frame-to-frame coherences. A continuous level-of-detail representation for an object is first constructed off-line. This representation is then used at run-time to guide the selection of appropriate triangles for display. The list of displayed triangles is updated incrementally from one frame to the next. Our approach is more effective than the current level-of-detail-based rendering approaches for most scientific visualization applications where there are a limited number of highly complex objects that stay relatively close to the viewer.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.05674190464522332, 'word': 'frame'},\n",
              "   {'score': 0.05511734126470242, 'word': 'object'},\n",
              "   {'score': 0.04899137875907653, 'word': 'space'},\n",
              "   {'score': 0.045574053547748926, 'word': 'dependent'},\n",
              "   {'score': 0.045574053547748926, 'word': 'simplifications'},\n",
              "   {'score': 0.04353366713510954, 'word': 'time'}],\n",
              "  'Title': 'Dynamic view-dependent simplification for polygonal models',\n",
              "  'distance': 0,\n",
              "  'no': '37',\n",
              "  'parent': '3782'},\n",
              " {'Abstract': \"The paper presents a set of combined techniques to enhance the real-time visualization of simple or complex molecules (up to order of 10&lt;sup&gt;6&lt;/sup&gt; atoms) space fill mode. The proposed approach includes an innovative technique for efficient computation and storage of ambient occlusion terms, a small set of GPU accelerated procedural impostors for space-fill and ball-and-stick rendering, and novel edge-cueing techniques. As a result, the user's understanding of the three-dimensional structure under inspection is strongly increased (even for'still images), while the rendering still occurs in real time\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08989962581919667, 'word': 'combined'},\n",
              "   {'score': 0.08989962581919667, 'word': 'techniques'},\n",
              "   {'score': 0.0715005061342377, 'word': 'set'},\n",
              "   {'score': 0.05459788708962496, 'word': 'space'},\n",
              "   {'score': 0.05459788708962496, 'word': 'fill'},\n",
              "   {'score': 0.05459788708962496, 'word': 'mode'},\n",
              "   {'score': 0.05016154557090181, 'word': 'real'},\n",
              "   {'score': 0.04487010201123548, 'word': 'time'},\n",
              "   {'score': 0.04487010201123548, 'word': 'visualization'}],\n",
              "  'Title': 'Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '38',\n",
              "  'parent': '3504'},\n",
              " {'Abstract': \"Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.\",\n",
              "  'AuthorKeywords': ['Design',\n",
              "   'study,',\n",
              "   'methodology,',\n",
              "   'visualization,',\n",
              "   'framework'],\n",
              "  'MultipartiteRank': [{'score': 0.1477155537476073, 'word': 'design'},\n",
              "   {'score': 0.1477155537476073, 'word': 'studies'},\n",
              "   {'score': 0.055975453006995406, 'word': 'problem'},\n",
              "   {'score': 0.05355113048792603, 'word': 'methodologies'},\n",
              "   {'score': 0.04667125569693259, 'word': 'visualization'},\n",
              "   {'score': 0.04667125569693259, 'word': 'research'},\n",
              "   {'score': 0.03508648856057954, 'word': 'practical'},\n",
              "   {'score': 0.03508648856057954, 'word': 'guidance'}],\n",
              "  'Title': 'Design Study Methodology: Reflections from the Trenches and the Stacks',\n",
              "  'distance': 0,\n",
              "  'no': '39',\n",
              "  'parent': '5335'},\n",
              " {'Abstract': 'As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.',\n",
              "  'AuthorKeywords': ['Spatio-temporal',\n",
              "   'queries,',\n",
              "   'urban',\n",
              "   'data,',\n",
              "   'taxi',\n",
              "   'movement',\n",
              "   'data,',\n",
              "   'visual',\n",
              "   'exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.09641133193669803, 'word': 'data'},\n",
              "   {'score': 0.06324521300240239, 'word': 'urban'},\n",
              "   {'score': 0.043165036591704196, 'word': 'taxi'},\n",
              "   {'score': 0.043165036591704196, 'word': 'trips'},\n",
              "   {'score': 0.03657636984857342, 'word': 'exploratory'},\n",
              "   {'score': 0.03657636984857342, 'word': 'queries'},\n",
              "   {'score': 0.033344905333791516, 'word': 'new'},\n",
              "   {'score': 0.033344905333791516, 'word': 'model'}],\n",
              "  'Title': 'Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips',\n",
              "  'distance': 0,\n",
              "  'no': '40',\n",
              "  'parent': '5719'},\n",
              " {'Abstract': 'We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07002324322925264, 'word': 'large'},\n",
              "   {'score': 0.07002324322925264, 'word': 'rectilinear'},\n",
              "   {'score': 0.07002324322925264, 'word': 'datasets'},\n",
              "   {'score': 0.06229839900861993, 'word': 'force'},\n",
              "   {'score': 0.06229839900861993, 'word': 'ray'},\n",
              "   {'score': 0.05582250242224447, 'word': 'interactive'},\n",
              "   {'score': 0.05582250242224447, 'word': 'isosurfacing'},\n",
              "   {'score': 0.048675626758127956, 'word': 'brute'},\n",
              "   {'score': 0.04411845092238469, 'word': 'volume'}],\n",
              "  'Title': 'Interactive ray tracing for isosurface rendering',\n",
              "  'distance': 0,\n",
              "  'no': '41',\n",
              "  'parent': '3570'},\n",
              " {'Abstract': 'This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.',\n",
              "  'AuthorKeywords': ['Automatic',\n",
              "   'presentation,',\n",
              "   'visual',\n",
              "   'analysis,',\n",
              "   'graphic',\n",
              "   'design,',\n",
              "   'best',\n",
              "   'practices,',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'small',\n",
              "   'multiples'],\n",
              "  'MultipartiteRank': [{'score': 0.09059371678074825, 'word': 'automatic'},\n",
              "   {'score': 0.09059371678074825, 'word': 'presentation'},\n",
              "   {'score': 0.0731870190997923, 'word': 'views'},\n",
              "   {'score': 0.054048828171220586, 'word': 'command'},\n",
              "   {'score': 0.049826832431508275, 'word': 'tableau'},\n",
              "   {'score': 0.04690800669480488, 'word': 'commercial'},\n",
              "   {'score': 0.04690800669480488, 'word': 'visual'},\n",
              "   {'score': 0.04690800669480488, 'word': 'analysis'},\n",
              "   {'score': 0.04690800669480488, 'word': 'system'}],\n",
              "  'Title': 'Show Me: Automatic Presentation for Visual Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '42',\n",
              "  'parent': '4760'},\n",
              " {'Abstract': 'We present the H3 layout technique for drawing large directed graphs as node-link diagrams in 3D hyperbolic space. We can lay out much larger structures than can be handled using traditional techniques for drawing general graphs because we assume a hierarchical nature of the data. We impose a hierarchy on the graph by using domain-specific knowledge to find an appropriate spanning tree. Links which are not part of the spanning tree do not influence the layout but can be selectively drawn by user request. The volume of hyperbolic 3-space increases exponentially, as opposed to the familiar geometric increase of euclidean 3-space. We exploit this exponential amount of room by computing the layout according to the hyperbolic metric. We optimize the cone tree layout algorithm for 3D hyperbolic space by placing children on a hemisphere around the cone mouth instead of on its perimeter. Hyperbolic navigation affords a Focus+Context view of the structure with minimal visual clutter. We have successfully laid out hierarchies of over 20,000 nodes. Our implementation accommodates navigation through graphs too large to be rendered interactively by allowing the user to explicitly prune or expand subtrees.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07200450277446119, 'word': 'graphs'},\n",
              "   {'score': 0.06901161365309802, 'word': '3d'},\n",
              "   {'score': 0.06901161365309802, 'word': 'hyperbolic'},\n",
              "   {'score': 0.06901161365309802, 'word': 'space'},\n",
              "   {'score': 0.047696935300887144, 'word': 'h3'},\n",
              "   {'score': 0.047696935300887144, 'word': 'layout'},\n",
              "   {'score': 0.047696935300887144, 'word': 'technique'},\n",
              "   {'score': 0.042890459097983065, 'word': 'link'},\n",
              "   {'score': 0.042890459097983065, 'word': 'diagrams'},\n",
              "   {'score': 0.041686101431010994, 'word': 'node'}],\n",
              "  'Title': 'H3: laying out large directed graphs in 3D hyperbolic space',\n",
              "  'distance': 0,\n",
              "  'no': '43',\n",
              "  'parent': '5348'},\n",
              " {'Abstract': 'A new multiscale method in surface processing is presented which combines the image processing methodology based on nonlinear diffusion equations and the theory of geometric evolution problems. Its aim is to smooth discretized surfaces while simultaneously enhancing geometric features such as edges and corners. This is obtained by an anisotropic curvature evolution, where time is the multiscale parameter. Here, the diffusion tensor depends on the shape operator of the evolving surface. A spatial finite element discretization on arbitrary unstructured triangular meshes and a semi-implicit finite difference discretization in time are the building blocks of the easy to code algorithm presented. The systems of linear equations in each timestep are solved by appropriate, preconditioned iterative solvers. Different applications underline the efficiency and flexibility of the presented type of surface processing tool.',\n",
              "  'AuthorKeywords': ['Image',\n",
              "   'Processing,',\n",
              "   'Geometric',\n",
              "   'Modeling,',\n",
              "   'Numerical',\n",
              "   'Analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.1030065325534825, 'word': 'surface'},\n",
              "   {'score': 0.1030065325534825, 'word': 'processing'},\n",
              "   {'score': 0.05106961516221095, 'word': 'new'},\n",
              "   {'score': 0.05106961516221095, 'word': 'multiscale'},\n",
              "   {'score': 0.05106961516221095, 'word': 'method'},\n",
              "   {'score': 0.04661138340741998, 'word': 'time'},\n",
              "   {'score': 0.03759455534015221, 'word': 'geometric'},\n",
              "   {'score': 0.03759455534015221, 'word': 'evolution'},\n",
              "   {'score': 0.03759455534015221, 'word': 'problems'},\n",
              "   {'score': 0.037355578836787556, 'word': 'nonlinear'},\n",
              "   {'score': 0.037355578836787556, 'word': 'diffusion'},\n",
              "   {'score': 0.037355578836787556, 'word': 'equations'}],\n",
              "  'Title': 'Anisotropic geometric diffusion in surface processing',\n",
              "  'distance': 0,\n",
              "  'no': '44',\n",
              "  'parent': '3854'},\n",
              " {'Abstract': 'Research on information visualization has reached the point where a number of successful point designs have been proposed and a variety of techniques have been discovered. It is now appropriate to describe and analyze portions of the design space so as to understand the differences among designs and to suggest new possibilities. This paper proposes an organization of the information visualization literature and illustrates it with a series of examples. The result is a framework for designing new visualizations and augmenting existing designs.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'taxonomy,',\n",
              "   'design',\n",
              "   'space,',\n",
              "   'morphological',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.09026537195139242, 'word': 'information'},\n",
              "   {'score': 0.09026537195139242, 'word': 'visualization'},\n",
              "   {'score': 0.08429437468644618, 'word': 'design'},\n",
              "   {'score': 0.08429437468644618, 'word': 'space'},\n",
              "   {'score': 0.08117688563553317, 'word': 'point'},\n",
              "   {'score': 0.06088080178441248, 'word': 'new'},\n",
              "   {'score': 0.06088080178441248, 'word': 'possibilities'},\n",
              "   {'score': 0.057474782988933645, 'word': 'number'}],\n",
              "  'Title': 'The structure of the information visualization design space',\n",
              "  'distance': 0,\n",
              "  'no': '45',\n",
              "  'parent': '3723'},\n",
              " {'Abstract': 'Conventional wisdom says that in order to produce high-quality simplified polygonal models, one must retain and use information about the original model during the simplification process. We demonstrate that excellent simplified models can be produced without the need to compare against information from the original geometry while performing local changes to the model. We use edge collapses to perform simplification, as do a number of other methods. We select the position of the new vertex so that the original volume of the model is maintained and we minimize the per-triangle change in volume of the tetrahedra swept out by those triangles that are moved. We also maintain surface area near boundaries and minimize the per-triangle area changes. Calculating the edge collapse priorities and the positions of the new vertices requires only the face connectivity and the the vertex locations in the intermediate model. This approach is memory efficient, allowing the simplification of very large polygonal models, and it is also fast. Moreover, simplified models created using this technique compare favorably to a number of other published simplification methods in terms of mean geometric error.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.16689063960914607, 'word': 'models'},\n",
              "   {'score': 0.12301396276103552, 'word': 'polygonal'},\n",
              "   {'score': 0.05854560908000233, 'word': 'simplification'},\n",
              "   {'score': 0.05854560908000233, 'word': 'process'},\n",
              "   {'score': 0.05259786699261619, 'word': 'quality'},\n",
              "   {'score': 0.04387533877933648, 'word': 'information'}],\n",
              "  'Title': 'Fast and memory efficient polygonal simplification',\n",
              "  'distance': 0,\n",
              "  'no': '46',\n",
              "  'parent': '4191'},\n",
              " {'Abstract': 'We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'text,',\n",
              "   'tag',\n",
              "   'cloud,',\n",
              "   'participatory',\n",
              "   'culture,',\n",
              "   'memory,',\n",
              "   'educational',\n",
              "   'visualization,',\n",
              "   'social',\n",
              "   'data',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.1121465757050721, 'word': 'wordle'},\n",
              "   {'score': 0.047339482845369305, 'word': 'results'},\n",
              "   {'score': 0.043254551232377994, 'word': 'tag'},\n",
              "   {'score': 0.040631649846260345, 'word': 'text'},\n",
              "   {'score': 0.03996596052240692, 'word': 'cloud'}],\n",
              "  'Title': 'Participatory Visualization with Wordle',\n",
              "  'distance': 0,\n",
              "  'no': '47',\n",
              "  'parent': '3629'},\n",
              " {'Abstract': 'Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.',\n",
              "  'AuthorKeywords': ['Clutter',\n",
              "   'reduction,',\n",
              "   'information',\n",
              "   'visualisation,',\n",
              "   'occlusion,',\n",
              "   'large',\n",
              "   'datasets,',\n",
              "   'taxonomy'],\n",
              "  'MultipartiteRank': [{'score': 0.11447514877599983, 'word': 'data'},\n",
              "   {'score': 0.11002423179574083, 'word': 'information'},\n",
              "   {'score': 0.11002423179574083, 'word': 'visualisation'},\n",
              "   {'score': 0.04731370541055957, 'word': 'techniques'},\n",
              "   {'score': 0.03988767274456206, 'word': 'insight'},\n",
              "   {'score': 0.03784768899856268, 'word': 'large'}],\n",
              "  'Title': 'A Taxonomy of Clutter Reduction for Information Visualisation',\n",
              "  'distance': 0,\n",
              "  'no': '48',\n",
              "  'parent': '4978'},\n",
              " {'Abstract': 'In this paper, we describe a taxonomy of generic graph related tasks and an evaluation aiming at assessing the readability of two representations of graphs: matrix-based representations and node-link diagrams. This evaluation bears on seven generic tasks and leads to important recommendations with regard to the representation of graphs according to their size and density. For instance, we show that when graphs are bigger than twenty vertices, the matrix-based visualization performs better than node-link diagrams on most tasks. Only path finding is consistently in favor of node-link diagrams throughout the evaluation',\n",
              "  'AuthorKeywords': ['Visualization',\n",
              "   'of',\n",
              "   'graphs,',\n",
              "   'adjacency',\n",
              "   'matrices,',\n",
              "   'node-link',\n",
              "   'representation,',\n",
              "   'readability,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.1134112047480547, 'word': 'generic'},\n",
              "   {'score': 0.1134112047480547, 'word': 'graph'},\n",
              "   {'score': 0.07620477370954941, 'word': 'representations'},\n",
              "   {'score': 0.0712245342735935, 'word': 'node'},\n",
              "   {'score': 0.06876419785863969, 'word': 'evaluation'},\n",
              "   {'score': 0.06790224476231159, 'word': 'tasks'}],\n",
              "  'Title': 'A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations',\n",
              "  'distance': 0,\n",
              "  'no': '49',\n",
              "  'parent': '3853'},\n",
              " {'Abstract': 'The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values /spl omega//spl isin/R. They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value /spl omega/ for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of /spl omega/) to assist in selecting relevant isovalues /spl omega//sub 0/ for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a 2D interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'Scalar',\n",
              "   'Data,',\n",
              "   'User',\n",
              "   'Interfaces,',\n",
              "   'Real-time',\n",
              "   'Quantitative',\n",
              "   'Query'],\n",
              "  'MultipartiteRank': [{'score': 0.08966285428919883, 'word': 'contour'},\n",
              "   {'score': 0.08966285428919883, 'word': 'spectrum'},\n",
              "   {'score': 0.07602552805821333, 'word': 'time'},\n",
              "   {'score': 0.07602552805821333, 'word': 'exact'},\n",
              "   {'score': 0.07602552805821333, 'word': 'quantification'},\n",
              "   {'score': 0.04949676564529333, 'word': 'user'},\n",
              "   {'score': 0.04949676564529333, 'word': 'interface'},\n",
              "   {'score': 0.04949676564529333, 'word': 'component'},\n",
              "   {'score': 0.047370739501647705, 'word': 'real'},\n",
              "   {'score': 0.043426512264961324, 'word': 'visualization'}],\n",
              "  'Title': 'The contour spectrum',\n",
              "  'distance': 0,\n",
              "  'no': '50',\n",
              "  'parent': '5429'},\n",
              " {'Abstract': 'VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.',\n",
              "  'AuthorKeywords': ['interrogative',\n",
              "   'visualization,',\n",
              "   'dataflow,',\n",
              "   'caching,',\n",
              "   'coordinated',\n",
              "   'views'],\n",
              "  'MultipartiteRank': [{'score': 0.1108885747507458, 'word': 'vistrails'},\n",
              "   {'score': 0.07610859607677971, 'word': 'view'},\n",
              "   {'score': 0.07610859607677971, 'word': 'visualizations'},\n",
              "   {'score': 0.06814436373416548, 'word': 'visualization'},\n",
              "   {'score': 0.06814436373416548, 'word': 'pipelines'},\n",
              "   {'score': 0.06303559436117512, 'word': 'new'},\n",
              "   {'score': 0.06303559436117512, 'word': 'system'},\n",
              "   {'score': 0.04027205682802633, 'word': 'interactive'},\n",
              "   {'score': 0.04027205682802633, 'word': 'multiple'}],\n",
              "  'Title': 'VisTrails: enabling interactive multiple-view visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '51',\n",
              "  'parent': '3676'},\n",
              " {'Abstract': 'Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations',\n",
              "  'AuthorKeywords': ['Network',\n",
              "   'visualization,',\n",
              "   'semantic',\n",
              "   'substrate,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'graphical',\n",
              "   'user',\n",
              "   'interfaces'],\n",
              "  'MultipartiteRank': [{'score': 0.09579317787545287, 'word': 'users'},\n",
              "   {'score': 0.09579317787545287, 'word': 'present'},\n",
              "   {'score': 0.08235072023745078, 'word': 'node'},\n",
              "   {'score': 0.050286317079996326, 'word': 'layout'},\n",
              "   {'score': 0.048278355127105474, 'word': 'link'},\n",
              "   {'score': 0.048278355127105474, 'word': 'visibility'},\n",
              "   {'score': 0.0458237958746069, 'word': 'tasks'}],\n",
              "  'Title': 'Network Visualization by Semantic Substrates',\n",
              "  'distance': 0,\n",
              "  'no': '52',\n",
              "  'parent': '4234'},\n",
              " {'Abstract': 'In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.',\n",
              "  'AuthorKeywords': ['Streamgraph,',\n",
              "   'ThemeRiver,',\n",
              "   'listening',\n",
              "   'history,',\n",
              "   'lastfm,',\n",
              "   'aesthetics,',\n",
              "   'communication-minded',\n",
              "   'visualization,',\n",
              "   'time',\n",
              "   'series'],\n",
              "  'MultipartiteRank': [{'score': 0.08268290221428666, 'word': 'complex'},\n",
              "   {'score': 0.08268290221428666, 'word': 'layered'},\n",
              "   {'score': 0.08268290221428666, 'word': 'graph'},\n",
              "   {'score': 0.04888237673863661, 'word': 'unusual'},\n",
              "   {'score': 0.04888237673863661, 'word': 'chart'},\n",
              "   {'score': 0.042863135106817565, 'word': 'paper'},\n",
              "   {'score': 0.038879561663178096, 'word': 'effective'},\n",
              "   {'score': 0.03731210557152244, 'word': 'type'}],\n",
              "  'Title': 'Stacked Graphs - Geometry & Aesthetics',\n",
              "  'distance': 0,\n",
              "  'no': '53',\n",
              "  'parent': '4278'},\n",
              " {'Abstract': 'In the area of scientific visualization, input data sets are often very large. In visualization of computational fluid dynamics (CFD) in particular, input data sets today can surpass 100 Gbytes, and are expected to scale with the ability of supercomputers to generate them. Some visualization tools already partition large data sets into segments, and load appropriate segments as they are needed. However, this does not remove the problem for two reasons: 1) there are data sets for which even the individual segments are too large for the largest graphics workstations, 2) many practitioners do not have access to workstations with the memory capacity required to load even a segment, especially since the state-of-the-art visualization tools tend to be developed by researchers with much more powerful machines. When the size of the data that must be accessed is larger than the size of memory, some form of virtual memory is simply required. This may be by segmentation, paging, or by paged segments. The authors demonstrate that complete reliance on operating system virtual memory for out-of-core visualization leads to egregious performance. They then describe a paged segment system that they have implemented, and explore the principles of memory management that can be employed by the application for out-of-core visualization. They show that application control over some of these can significantly improve performance. They show that sparse traversal can be exploited by loading only those data actually required.',\n",
              "  'AuthorKeywords': ['computational',\n",
              "   'fluid',\n",
              "   'dynamics,',\n",
              "   'visualization,',\n",
              "   'out-of-core',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.10242060434660737, 'word': 'scientific'},\n",
              "   {'score': 0.10242060434660737, 'word': 'visualization'},\n",
              "   {'score': 0.09526972911530493, 'word': 'input'},\n",
              "   {'score': 0.09526972911530493, 'word': 'data'},\n",
              "   {'score': 0.09526972911530493, 'word': 'sets'},\n",
              "   {'score': 0.06499949624126199, 'word': 'segments'},\n",
              "   {'score': 0.049722464048984255, 'word': 'memory'},\n",
              "   {'score': 0.049722464048984255, 'word': 'capacity'},\n",
              "   {'score': 0.042095680710740185, 'word': 'large'}],\n",
              "  'Title': 'Application-controlled demand paging for out-of-core visualization',\n",
              "  'distance': 0,\n",
              "  'no': '54',\n",
              "  'parent': '5126'},\n",
              " {'Abstract': 'Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11436521971229642, 'word': 'scientific'},\n",
              "   {'score': 0.11436521971229642, 'word': 'visualization'},\n",
              "   {'score': 0.10994397331133006, 'word': 'problem'},\n",
              "   {'score': 0.06583922892677091, 'word': 'workers'},\n",
              "   {'score': 0.059078568757386346, 'word': 'classification'},\n",
              "   {'score': 0.058765093010175615, 'word': 'subproblems'}],\n",
              "  'Title': 'A problem-oriented classification of visualization techniques',\n",
              "  'distance': 0,\n",
              "  'no': '55',\n",
              "  'parent': '3474'},\n",
              " {'Abstract': 'This article presents the InfoVis toolkit, designed to support the creation, extension and integration of advanced 2D information visualization components into interactive Java swing applications. The InfoVis toolkit provides specific data structures to achieve a fast action/feedback loop required by dynamic queries. It comes with a large set of components such as range sliders and tailored control panels required to control and configure the visualizations. These components are integrated into a coherent framework that simplifies the management of rich data structures and the design and extension of visualizations. Supported data structures currently include tables, trees and graphs. Supported visualizations include scatter plots, time series, parallel coordinates, treemaps, icicle trees, node-link diagrams for trees and graphs and adjacency matrices for graphs. All visualizations can use fisheye lenses and dynamic labeling. The InfoVis toolkit supports hardware acceleration when available through Agile2D, an implementation of the Java graphics API based on OpenGL, achieving speedups of 10 to 200 times. The article also shows how new visualizations can be added and extended to become components, enriching visualizations as well as general applications',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'Visualization,',\n",
              "   'Toolkit,',\n",
              "   'Graphics,',\n",
              "   'Integration'],\n",
              "  'MultipartiteRank': [{'score': 0.0737506860203448, 'word': 'visualizations'},\n",
              "   {'score': 0.04962180428364973, 'word': 'graphs'},\n",
              "   {'score': 0.04951295063505545, 'word': 'specific'},\n",
              "   {'score': 0.04951295063505545, 'word': 'data'},\n",
              "   {'score': 0.04951295063505545, 'word': 'structures'},\n",
              "   {'score': 0.04835287159029152, 'word': 'trees'},\n",
              "   {'score': 0.04706059997746992, 'word': 'infovis'},\n",
              "   {'score': 0.04706059997746992, 'word': 'toolkit'}],\n",
              "  'Title': 'The InfoVis Toolkit',\n",
              "  'distance': 0,\n",
              "  'no': '56',\n",
              "  'parent': '5395'},\n",
              " {'Abstract': 'Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.',\n",
              "  'AuthorKeywords': ['Casual',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'ambient',\n",
              "   'infovis,',\n",
              "   'social',\n",
              "   'infovis,',\n",
              "   'editorial,',\n",
              "   'design,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.08327420524691613, 'word': 'infovis'},\n",
              "   {'score': 0.08327420524691613, 'word': 'research'},\n",
              "   {'score': 0.0813733772355928, 'word': 'information'},\n",
              "   {'score': 0.0813733772355928, 'word': 'visualization'},\n",
              "   {'score': 0.04038720118725374, 'word': 'deep'},\n",
              "   {'score': 0.04038720118725374, 'word': 'insight'},\n",
              "   {'score': 0.03890762656109134, 'word': 'expert'},\n",
              "   {'score': 0.03890762656109134, 'word': 'user'},\n",
              "   {'score': 0.03890762656109134, 'word': 'populations'},\n",
              "   {'score': 0.03544004449580519, 'word': 'techniques'}],\n",
              "  'Title': 'Casual Information Visualization: Depictions of Data in Everyday Life',\n",
              "  'distance': 0,\n",
              "  'no': '57',\n",
              "  'parent': '5397'},\n",
              " {'Abstract': 'To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation. We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the interpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08577137747321685, 'word': 'sample'},\n",
              "   {'score': 0.08577137747321685, 'word': 'values'},\n",
              "   {'score': 0.08562482229648627, 'word': 'interpolation'},\n",
              "   {'score': 0.08562482229648627, 'word': 'methods'},\n",
              "   {'score': 0.07464175086289725, 'word': 'reconstruction'},\n",
              "   {'score': 0.07464175086289725, 'word': 'filter'},\n",
              "   {'score': 0.07061675626742829, 'word': 'images'},\n",
              "   {'score': 0.05303368584579499, 'word': 'samples'}],\n",
              "  'Title': 'An evaluation of reconstruction filters for volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '58',\n",
              "  'parent': '3870'},\n",
              " {'Abstract': 'Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated / validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media.',\n",
              "  'AuthorKeywords': ['social',\n",
              "   'media',\n",
              "   'analytics,',\n",
              "   'scenario-based',\n",
              "   'design,',\n",
              "   'geovisualization,',\n",
              "   'situational',\n",
              "   'awareness,',\n",
              "   'text',\n",
              "   'analytics,',\n",
              "   'crisis',\n",
              "   'management,',\n",
              "   'spatio-temporal',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.04231822738127408, 'word': 'design'},\n",
              "   {'score': 0.04231822738127408, 'word': 'methods'},\n",
              "   {'score': 0.03781589511375974, 'word': 'tweets'},\n",
              "   {'score': 0.03598690158706, 'word': 'crisis'},\n",
              "   {'score': 0.03598690158706, 'word': 'management'},\n",
              "   {'score': 0.033364816601409476, 'word': 'social'},\n",
              "   {'score': 0.033364816601409476, 'word': 'media'},\n",
              "   {'score': 0.03237365124014697, 'word': 'scenario'}],\n",
              "  'Title': 'SensePlace2: GeoTwitter analytics support for situational awareness',\n",
              "  'distance': 0,\n",
              "  'no': '59',\n",
              "  'parent': '4554'},\n",
              " {'Abstract': 'The field of visualization is getting mature. Many problems have been solved, and new directions are sought for. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. Especially, it would be nice if we could assess what a good visualization is. In this paper an attempt is made to determine the value of visualization. A technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented, and benefits and costs are established. Next, consequences (brand limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjective/less, and the role of interaction), as well as examples of the use of the model for the judgement of existing classes of methods and understanding why they are or are not used in practice. Furthermore, two alternative views on visualization are presented and discussed: viewing visualization as an art or as a scientific discipline. Implications and future directions are identified.',\n",
              "  'AuthorKeywords': ['Visualization,', 'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.1340571944792708, 'word': 'visualization'},\n",
              "   {'score': 0.04283045865742253, 'word': 'costs'},\n",
              "   {'score': 0.039609893243757736, 'word': 'economic'},\n",
              "   {'score': 0.039609893243757736, 'word': 'model'},\n",
              "   {'score': 0.038757555247283325, 'word': 'alternative'},\n",
              "   {'score': 0.038757555247283325, 'word': 'methods'},\n",
              "   {'score': 0.03654562412082074, 'word': 'use'}],\n",
              "  'Title': 'The value of visualization',\n",
              "  'distance': 0,\n",
              "  'no': '60',\n",
              "  'parent': '5324'},\n",
              " {'Abstract': 'Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.',\n",
              "  'AuthorKeywords': ['Text',\n",
              "   'visualization,',\n",
              "   'Topic',\n",
              "   'evolution,',\n",
              "   'Hierarchical',\n",
              "   'Dirichlet',\n",
              "   'process,',\n",
              "   'Critical',\n",
              "   'event'],\n",
              "  'MultipartiteRank': [{'score': 0.13651248670515764, 'word': 'topics'},\n",
              "   {'score': 0.07777598524818134, 'word': 'text'},\n",
              "   {'score': 0.07777598524818134, 'word': 'data'},\n",
              "   {'score': 0.06246608083799632, 'word': 'visualization'},\n",
              "   {'score': 0.04269786408030703, 'word': 'topic'},\n",
              "   {'score': 0.04269786408030703, 'word': 'mining'},\n",
              "   {'score': 0.04269786408030703, 'word': 'techniques'},\n",
              "   {'score': 0.04087111549395416, 'word': 'study'}],\n",
              "  'Title': 'TextFlow: Towards Better Understanding of Evolving Topics in Text',\n",
              "  'distance': 0,\n",
              "  'no': '61',\n",
              "  'parent': '4162'},\n",
              " {'Abstract': 'Accurately and automatically conveying the structure of a volume model is a problem that has not been fully solved by existing volume rendering approaches. Physics-based volume rendering approaches create images which may match the appearance of translucent materials in nature but may not embody important structural details. Transfer function approaches allow flexible design of the volume appearance but generally require substantial hand-tuning for each new data set in order to be effective. We introduce the volume illustration approach, combining the familiarity of a physics-based illumination model with the ability to enhance important features using non-photorealistic rendering techniques. Since the features to be enhanced are defined on the basis of local volume characteristics rather than volume sample values, the application of volume illustration techniques requires less manual tuning than the design of a good transfer function. Volume illustration provides a flexible unified framework for enhancing structural perception of volume models through the amplification of features and the addition of illumination effects.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'rendering,',\n",
              "   'non-photorealistic',\n",
              "   'rendering,illustration,',\n",
              "   'lighting',\n",
              "   'models,',\n",
              "   'shading,',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.13909702034110166, 'word': 'volume'},\n",
              "   {'score': 0.09970027128745355, 'word': 'model'},\n",
              "   {'score': 0.0605907755476925, 'word': 'structure'},\n",
              "   {'score': 0.03981419597896045, 'word': 'physics'},\n",
              "   {'score': 0.039396749053648095, 'word': 'rendering'},\n",
              "   {'score': 0.039396749053648095, 'word': 'approaches'},\n",
              "   {'score': 0.03836827240366008, 'word': 'appearance'}],\n",
              "  'Title': 'Volume illustration: non-photorealistic rendering of volume models',\n",
              "  'distance': 0,\n",
              "  'no': '62',\n",
              "  'parent': '5671'},\n",
              " {'Abstract': 'Two basic principles for interactive visualization of high-dimensional data-focusing and linking-are discussed. Focusing techniques may involve selecting subsets, dimension reduction, or some more general manipulation of the layout information on the page or screen. A consequent of focusing is that each view only conveys partial information about the data and needs to be linked so that the information contained in individual views can be integrated into a coherent image of the data as a whole. Examples are given of how graphical data analysis methods based on focusing and linking are used in applications including linguistics, geographic information systems, time series analysis, and the analysis of multi-channel images arising in radiology and remote sensing.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09728478819687926, 'word': 'layout'},\n",
              "   {'score': 0.09728478819687926, 'word': 'information'},\n",
              "   {'score': 0.07938910996183007, 'word': 'dimensional'},\n",
              "   {'score': 0.07938910996183007, 'word': 'data'},\n",
              "   {'score': 0.04930399399309629, 'word': 'linking'},\n",
              "   {'score': 0.04676205825694732, 'word': 'high'},\n",
              "   {'score': 0.04541133818724583, 'word': 'view'}],\n",
              "  'Title': 'Interactive data visualization using focusing and linking',\n",
              "  'distance': 0,\n",
              "  'no': '63',\n",
              "  'parent': '4149'},\n",
              " {'Abstract': \"Visual clutter denotes a disordered collection of graphical entities in information visualization. Clutter can obscure the structure present in the data. Even in a small dataset, clutter can make it hard for the viewer to find patterns, relationships and structure. In this paper, we define visual clutter as any aspect of the visualization that interferes with the viewer's understanding of the data, and present the concept of clutter-based dimension reordering. Dimension order is an attribute that can significantly affect a visualization's expressiveness. By varying the dimension order in a display, it is possible to reduce clutter without reducing information content or modifying the data in any way. Clutter reduction is a display-dependent task. In this paper, we follow a three-step procedure for four different visualization techniques. For each display technique, first, we determine what constitutes clutter in terms of display properties; then we design a metric to measure visual clutter in this display; finally we search for an order that minimizes the clutter in a display\",\n",
              "  'AuthorKeywords': ['Multidimensional',\n",
              "   'visualization,',\n",
              "   'dimension',\n",
              "   'order,',\n",
              "   'visual',\n",
              "   'clutter,',\n",
              "   'visual',\n",
              "   'structure'],\n",
              "  'MultipartiteRank': [{'score': 0.25267606356592665, 'word': 'clutter'},\n",
              "   {'score': 0.15659462995499718, 'word': 'visual'},\n",
              "   {'score': 0.07146569663326045, 'word': 'display'},\n",
              "   {'score': 0.04372817517013929, 'word': 'data'},\n",
              "   {'score': 0.040623323641870414, 'word': 'dimension'},\n",
              "   {'score': 0.040623323641870414, 'word': 'order'}],\n",
              "  'Title': 'Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering',\n",
              "  'distance': 0,\n",
              "  'no': '64',\n",
              "  'parent': '5782'},\n",
              " {'Abstract': 'Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'animation,',\n",
              "   'trends,',\n",
              "   'design,',\n",
              "   'experiment'],\n",
              "  'MultipartiteRank': [{'score': 0.10187581160451788, 'word': 'trends'},\n",
              "   {'score': 0.07161004308961887, 'word': 'presentations'},\n",
              "   {'score': 0.062369902045916296, 'word': 'analysis'},\n",
              "   {'score': 0.052311707166335215, 'word': 'animation'},\n",
              "   {'score': 0.04146263857399271, 'word': 'display'}],\n",
              "  'Title': 'Effectiveness of Animation in Trend Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '65',\n",
              "  'parent': '5172'},\n",
              " {'Abstract': 'Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency - the effort required to specify a visualization - and accessibility - the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'toolkits,',\n",
              "   '2D',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.1254196401481082, 'word': 'visualization'},\n",
              "   {'score': 0.08402986645991248, 'word': 'level'},\n",
              "   {'score': 0.08402986645991248, 'word': 'systems'},\n",
              "   {'score': 0.08172699124145194, 'word': 'visual'},\n",
              "   {'score': 0.08172699124145194, 'word': 'thinking'},\n",
              "   {'score': 0.042508179454114565, 'word': 'expressiveness'},\n",
              "   {'score': 0.03877306957498868, 'word': 'notational'},\n",
              "   {'score': 0.03877306957498868, 'word': 'efficiency'}],\n",
              "  'Title': 'Protovis: A Graphical Toolkit for Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '66',\n",
              "  'parent': '4740'},\n",
              " {'Abstract': 'The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.',\n",
              "  'AuthorKeywords': ['Typology,',\n",
              "   'visualization',\n",
              "   'models,',\n",
              "   'task',\n",
              "   'and',\n",
              "   'requirements',\n",
              "   'analysis,',\n",
              "   'qualitative',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.07554315232098367, 'word': 'task'},\n",
              "   {'score': 0.06427042860990617, 'word': 'visualization'},\n",
              "   {'score': 0.06427042860990617, 'word': 'usage'},\n",
              "   {'score': 0.04335701713338286, 'word': 'level'},\n",
              "   {'score': 0.04335701713338286, 'word': 'tasks'},\n",
              "   {'score': 0.04260258560445412, 'word': 'flexible'},\n",
              "   {'score': 0.04260258560445412, 'word': 'descriptions'},\n",
              "   {'score': 0.02992378815109262, 'word': 'gap'}],\n",
              "  'Title': 'A Multi-Level Typology of Abstract Visualization Tasks',\n",
              "  'distance': 0,\n",
              "  'no': '67',\n",
              "  'parent': '5306'},\n",
              " {'Abstract': 'The authors present a tool for the display and analysis of N-dimensional data based on a technique called dimensional stacking. This technique is described. The primary goal is to create a tool that enables the user to project data of arbitrary dimensions onto a two-dimensional image. Of equal importance is the ability to control the viewing parameters, so that one can interactively adjust what ranges of values each dimension takes and the form in which the dimensions are displayed. This will allow an intuitive feel for the data to be developed as the database is explored. The system uses dimensional stacking, to collapse and N-dimension space down into a 2-D space and then render the values contained therein. Each value can then be represented as a pixel or rectangular region on a 2-D screen whose intensity corresponds to the data value at that point.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1682511968704533, 'word': 'dimensional'},\n",
              "   {'score': 0.08947491536885989, 'word': 'data'},\n",
              "   {'score': 0.07877628150159342, 'word': 'stacking'},\n",
              "   {'score': 0.06313397972000888, 'word': 'arbitrary'},\n",
              "   {'score': 0.06313397972000888, 'word': 'dimensions'},\n",
              "   {'score': 0.06012972555154678, 'word': 'technique'},\n",
              "   {'score': 0.0519291649507836, 'word': 'tool'}],\n",
              "  'Title': 'Exploring N-dimensional databases',\n",
              "  'distance': 0,\n",
              "  'no': '68',\n",
              "  'parent': '4261'},\n",
              " {'Abstract': 'We present an elegant and simple to implement framework for performing out-of-core visualization and view-dependent refinement of large terrain surfaces. Contrary to the trend of increasingly elaborate algorithms for large-scale terrain visualization, our algorithms and data structures have been designed with the primary goal of simplicity and efficiency of implementation. Our approach to managing large terrain data also departs from more conventional strategies based on data tiling. Rather than emphasizing how to segment and efficiently bring data in and out of memory, we focus on the manner in which the data is laid out to achieve good memory coherency for data accesses made in a top-down (coarse-to-fine) refinement of the terrain. We present and compare the results of using several different data indexing schemes, and propose a simple to compute index that yields substantial improvements in locality and speed over more commonly used data layouts. Our second contribution is a new and simple, yet easy to generalize method for view-dependent refinement. Similar to several published methods in this area, we use longest edge bisection in a top-down traversal of the mesh hierarchy to produce a continuous surface with subdivision connectivity. In tandem with the refinement, we perform view frustum culling and triangle stripping. These three components are done together in a single pass over the mesh. We show how this framework supports virtually any error metric, while still being highly memory and compute efficient.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.05497375901101331, 'word': 'data'},\n",
              "   {'score': 0.05497375901101331, 'word': 'structures'},\n",
              "   {'score': 0.05462410288324101, 'word': 'dependent'},\n",
              "   {'score': 0.05462410288324101, 'word': 'refinement'},\n",
              "   {'score': 0.048313459229348155, 'word': 'large'},\n",
              "   {'score': 0.048313459229348155, 'word': 'terrain'},\n",
              "   {'score': 0.048313459229348155, 'word': 'surfaces'},\n",
              "   {'score': 0.04211691845304113, 'word': 'view'},\n",
              "   {'score': 0.0377364665482679, 'word': 'elaborate'},\n",
              "   {'score': 0.0377364665482679, 'word': 'algorithms'}],\n",
              "  'Title': 'Visualization of large terrains made easy',\n",
              "  'distance': 0,\n",
              "  'no': '69',\n",
              "  'parent': '5763'},\n",
              " {'Abstract': 'Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'clutter,',\n",
              "   'mesh,',\n",
              "   'edge',\n",
              "   'clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.192443159560429, 'word': 'graphs'},\n",
              "   {'score': 0.16643533079491776, 'word': 'edge'},\n",
              "   {'score': 0.11662008208819774, 'word': 'excessive'},\n",
              "   {'score': 0.11662008208819774, 'word': 'crossings'},\n",
              "   {'score': 0.04122119568255432, 'word': 'large'},\n",
              "   {'score': 0.040344513832058525, 'word': 'control'},\n",
              "   {'score': 0.040344513832058525, 'word': 'mesh'}],\n",
              "  'Title': 'Geometry-Based Edge Clustering for Graph Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '70',\n",
              "  'parent': '4459'},\n",
              " {'Abstract': 'A new method is presented for the visualization of hierarchical information, such as directory structures and organization structures. Cushion treemaps inherit the elegance of standard treemaps: compact, space-filling displays of hierarchical information, based on recursive subdivision of a rectangular image space. Intuitive shading is used to provide insight in the hierarchical structure. During the subdivision, ridges are added per rectangle, which are rendered with a simple shading model. The result is a surface that consists of recursive cushions. The method is efficient, effective, easy to use and implement, and has a wide applicability.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'Visualization,',\n",
              "   'Tree',\n",
              "   'Visualization,',\n",
              "   'Treemaps'],\n",
              "  'MultipartiteRank': [{'score': 0.08046563016123714, 'word': 'directory'},\n",
              "   {'score': 0.08046563016123714, 'word': 'structures'},\n",
              "   {'score': 0.07302188175681917, 'word': 'hierarchical'},\n",
              "   {'score': 0.07302188175681917, 'word': 'information'},\n",
              "   {'score': 0.06905517757285524, 'word': 'space'},\n",
              "   {'score': 0.0620400270551285, 'word': 'cushion'},\n",
              "   {'score': 0.0620400270551285, 'word': 'treemaps'},\n",
              "   {'score': 0.052301469892800954, 'word': 'new'},\n",
              "   {'score': 0.052301469892800954, 'word': 'method'}],\n",
              "  'Title': 'Cushion treemaps: visualization of hierarchical information',\n",
              "  'distance': 0,\n",
              "  'no': '71',\n",
              "  'parent': '3629'},\n",
              " {'Abstract': 'We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional \"keyword-in-context\" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.',\n",
              "  'AuthorKeywords': ['Text',\n",
              "   'visualization,',\n",
              "   'document',\n",
              "   'visualization,',\n",
              "   'Many',\n",
              "   'Eyes,',\n",
              "   'case',\n",
              "   'study,',\n",
              "   'concordance,',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'search'],\n",
              "  'MultipartiteRank': [{'score': 0.08453254911583831, 'word': 'word'},\n",
              "   {'score': 0.08453254911583831, 'word': 'tree'},\n",
              "   {'score': 0.06289774322536319, 'word': 'retrieval'},\n",
              "   {'score': 0.06289774322536319, 'word': 'technique'},\n",
              "   {'score': 0.06279499493465199, 'word': 'text'},\n",
              "   {'score': 0.06279499493465199, 'word': 'documents'},\n",
              "   {'score': 0.05412960424900089, 'word': 'new'},\n",
              "   {'score': 0.05412960424900089, 'word': 'visualization'},\n",
              "   {'score': 0.04533157818837899, 'word': 'information'}],\n",
              "  'Title': 'The Word Tree, an Interactive Visual Concordance',\n",
              "  'distance': 0,\n",
              "  'no': '72',\n",
              "  'parent': '3420'},\n",
              " {'Abstract': 'Almost all scientific visualization involving surfaces is currently done via triangles. The speed at which such triangulated surfaces can be displayed is crucial to interactive visualization and is bounded by the rate at which triangulated data can be sent to the graphics subsystem for rendering. Partitioning polygonal models into triangle strips can significantly reduce rendering times over transmitting each triangle individually. We present new and efficient algorithms for constructing triangle strips from partially triangulated models, and experimental results showing these strips are on average 15% better than those from previous codes. Further, we study the impact of larger buffer sizes and various queuing disciplines on the effectiveness of triangle strips.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12182812863357842, 'word': 'triangle'},\n",
              "   {'score': 0.12182812863357842, 'word': 'strips'},\n",
              "   {'score': 0.07087653917351847, 'word': 'scientific'},\n",
              "   {'score': 0.07087653917351847, 'word': 'visualization'},\n",
              "   {'score': 0.06979420069606014, 'word': 'polygonal'},\n",
              "   {'score': 0.06979420069606014, 'word': 'models'},\n",
              "   {'score': 0.06469365763185235, 'word': 'triangles'},\n",
              "   {'score': 0.0473953170587814, 'word': 'surfaces'}],\n",
              "  'Title': 'Optimizing triangle strips for fast rendering',\n",
              "  'distance': 0,\n",
              "  'no': '73',\n",
              "  'parent': '4373'},\n",
              " {'Abstract': 'Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.',\n",
              "  'AuthorKeywords': ['visualization,',\n",
              "   'analysis,',\n",
              "   'collaboration,',\n",
              "   'design,',\n",
              "   'computer-supported',\n",
              "   'cooperative',\n",
              "   'work'],\n",
              "  'MultipartiteRank': [{'score': 0.07625553175863092, 'word': 'sensemaking'},\n",
              "   {'score': 0.07518819829985642, 'word': 'process'},\n",
              "   {'score': 0.06683146289775348, 'word': 'information'},\n",
              "   {'score': 0.06683146289775348, 'word': 'visualization'},\n",
              "   {'score': 0.049697278287643955, 'word': 'human'},\n",
              "   {'score': 0.049697278287643955, 'word': 'visual'},\n",
              "   {'score': 0.049697278287643955, 'word': 'system'},\n",
              "   {'score': 0.045000585339148504, 'word': 'parallelization'}],\n",
              "  'Title': 'Design Considerations for Collaborative Visual Analytics',\n",
              "  'distance': 0,\n",
              "  'no': '74',\n",
              "  'parent': '3803'},\n",
              " {'Abstract': 'The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12557542920973297, 'word': 'dimensions'},\n",
              "   {'score': 0.09575602451603608, 'word': 'similarity'},\n",
              "   {'score': 0.06810080791155519, 'word': 'arrangement'},\n",
              "   {'score': 0.04394282606403524, 'word': 'problem'},\n",
              "   {'score': 0.03913671845388407, 'word': 'large'},\n",
              "   {'score': 0.03913671845388407, 'word': 'number'}],\n",
              "  'Title': 'Similarity clustering of dimensions for an enhanced visualization of multidimensional data',\n",
              "  'distance': 0,\n",
              "  'no': '75',\n",
              "  'parent': '4621'},\n",
              " {'Abstract': 'Cartographers have long used flow maps to show the movement of objects from one location to another, such as the number of people in a migration, the amount of goods being traded, or the number of packets in a network. The advantage of flow maps is that they reduce visual clutter by merging edges. Most flow maps are drawn by hand and there are few computer algorithms available. We present a method for generating flow maps using hierarchical clustering given a set of nodes, positions, and flow data between the nodes. Our techniques are inspired by graph layout algorithms that minimize edge crossings and distort node positions while maintaining their relative position to one another. We demonstrate our technique by producing flow maps for network traffic, census data, and trade data.',\n",
              "  'AuthorKeywords': ['flow', 'maps,', 'GIS,', 'hierarchical', 'clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.09145592618062706, 'word': 'flow'},\n",
              "   {'score': 0.09145592618062706, 'word': 'maps'},\n",
              "   {'score': 0.057022156006141626, 'word': 'positions'},\n",
              "   {'score': 0.05627956643783412, 'word': 'nodes'},\n",
              "   {'score': 0.05561597234801472, 'word': 'number'},\n",
              "   {'score': 0.051692306601061, 'word': 'network'}],\n",
              "  'Title': 'Flow map layout',\n",
              "  'distance': 0,\n",
              "  'no': '76',\n",
              "  'parent': '4412'},\n",
              " {'Abstract': 'This paper introduces a method for smoothing complex, noisy surfaces, while preserving (and enhancing) sharp, geometric features. It has two main advantages over previous approaches to feature preserving surface smoothing. First is the use of level set surface models, which allows us to process very complex shapes of arbitrary and changing topology. This generality makes it well suited for processing surfaces that are derived directly from measured data. The second advantage is that the proposed method derives from a well-founded formulation, which is a natural generalization of anisotropic diffusion, as used in image processing. This formulation is based on the proposition that the generalization of image filtering entails filtering the normals of the surface, rather than processing the positions of points on a mesh.',\n",
              "  'AuthorKeywords': ['anisotropic',\n",
              "   'diffusion,',\n",
              "   'surface',\n",
              "   'fairing,',\n",
              "   'geometric',\n",
              "   'surface',\n",
              "   'processing,',\n",
              "   'intrinsic',\n",
              "   'Laplacian',\n",
              "   'of',\n",
              "   'curvature,',\n",
              "   'level',\n",
              "   'sets'],\n",
              "  'MultipartiteRank': [{'score': 0.1157955260370354, 'word': 'noisy'},\n",
              "   {'score': 0.1157955260370354, 'word': 'surfaces'},\n",
              "   {'score': 0.07591784427631351, 'word': 'complex'},\n",
              "   {'score': 0.05939822256264311, 'word': 'generality'},\n",
              "   {'score': 0.05685260376611036, 'word': 'method'},\n",
              "   {'score': 0.048659819775622545, 'word': 'main'},\n",
              "   {'score': 0.048659819775622545, 'word': 'advantages'}],\n",
              "  'Title': 'Geometric surface smoothing via anisotropic diffusion of normals',\n",
              "  'distance': 0,\n",
              "  'no': '77',\n",
              "  'parent': '3691'},\n",
              " {'Abstract': \"An important goal of visualization technology is to support the exploration and analysis of very large amounts of data. In this paper, we propose a new visualization technique called a 'recursive pattern', which has been developed for visualizing large amounts of multidimensional data. The technique is based on a generic recursive scheme which generalizes a wide range of pixel-oriented arrangements for displaying large data sets. By instantiating the technique with adequate data- and application-dependent parameters, the user may greatly influence the structure of the resulting visualizations. Since the technique uses one pixel for presenting each data value, the amount of data which can be displayed is only limited by the resolution of current display technology and by the limitations of human perceptibility. Beside describing the basic idea of the 'recursive pattern' technique, we provide several examples of useful parameter settings for the various recursion levels. We further show that our 'recursive pattern' technique is particularly advantageous for the large class of data sets which have a natural order according to one dimension (e.g. time series data). We demonstrate the usefulness of our technique by using a stock market application.\",\n",
              "  'AuthorKeywords': ['Visualizing',\n",
              "   'Large',\n",
              "   'Data',\n",
              "   'Sets,',\n",
              "   'Visualizing',\n",
              "   'Multidimensional',\n",
              "   'and',\n",
              "   'Multivariate',\n",
              "   'Data,',\n",
              "   'Visualizing',\n",
              "   'Large',\n",
              "   'Sequential',\n",
              "   'Data',\n",
              "   'Sets,',\n",
              "   'Recursive',\n",
              "   'Visualization',\n",
              "   'Techniques,',\n",
              "   'Interfaces',\n",
              "   'to',\n",
              "   'Databases'],\n",
              "  'MultipartiteRank': [{'score': 0.1592967236153184, 'word': 'technique'},\n",
              "   {'score': 0.09370625880317486, 'word': 'data'},\n",
              "   {'score': 0.0909034129463398, 'word': 'new'},\n",
              "   {'score': 0.0909034129463398, 'word': 'visualization'},\n",
              "   {'score': 0.06700717366220853, 'word': 'large'},\n",
              "   {'score': 0.06700717366220853, 'word': 'amounts'},\n",
              "   {'score': 0.0479683886577833, 'word': 'recursive'},\n",
              "   {'score': 0.0479683886577833, 'word': 'pattern'}],\n",
              "  'Title': 'Recursive pattern: a technique for visualizing very large amounts of data',\n",
              "  'distance': 0,\n",
              "  'no': '78',\n",
              "  'parent': '4211'},\n",
              " {'Abstract': 'We present a multiresolution technique for interactive texture-based volume visualization of very large data sets. This method uses an adaptive scheme that renders the volume in a region-of-interest at a high resolution and the volume away from this region at progressively lower resolutions. The algorithm is based on the segmentation of texture space into an octree, where the leaves of the tree define the original data and the internal nodes define lower-resolution versions. Rendering is done adaptively by selecting high-resolution cells close to a center of attention and low-resolution cells away from this area. We limit the artifacts introduced by this method by modifying the transfer functions in the lower-resolution data sets and utilizing spherical shells as a proxy geometry. It is possible to use this technique to produce viewpoint-dependent renderings of very large data sets.',\n",
              "  'AuthorKeywords': ['multiresolution',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'hardware',\n",
              "   'texture'],\n",
              "  'MultipartiteRank': [{'score': 0.062369058275585684, 'word': 'volume'},\n",
              "   {'score': 0.062369058275585684, 'word': 'visualization'},\n",
              "   {'score': 0.05508650275105963, 'word': 'lower'},\n",
              "   {'score': 0.05508650275105963, 'word': 'resolutions'},\n",
              "   {'score': 0.05307381532759037, 'word': 'interactive'},\n",
              "   {'score': 0.05307381532759037, 'word': 'texture'},\n",
              "   {'score': 0.0507668624123458, 'word': 'resolution'},\n",
              "   {'score': 0.0507668624123458, 'word': 'versions'},\n",
              "   {'score': 0.05042029656094771, 'word': 'large'},\n",
              "   {'score': 0.05042029656094771, 'word': 'data'},\n",
              "   {'score': 0.05042029656094771, 'word': 'sets'}],\n",
              "  'Title': 'Multiresolution Techniques for Interactive Texture-based Volume Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '79',\n",
              "  'parent': '4076'},\n",
              " {'Abstract': 'This paper presents efficient methods for implementing general non-linear magnification transformations. Techniques are provided for: combining linear and non-linear magnifications, constraining the domain of magnifications, combining multiple transformations, and smoothly interpolating between magnified and normal views. In addition, piecewise linear methods are introduced which allow greater efficiency and expressiveness than their continuous counterparts.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12900500941368065, 'word': 'efficient'},\n",
              "   {'score': 0.12900500941368065, 'word': 'methods'},\n",
              "   {'score': 0.10308736317485805, 'word': 'linear'},\n",
              "   {'score': 0.08832720785186317, 'word': 'paper'},\n",
              "   {'score': 0.07807559360219746, 'word': 'magnifications'},\n",
              "   {'score': 0.07365911807525925, 'word': 'domain'}],\n",
              "  'Title': 'Techniques for non-linear magnification transformations',\n",
              "  'distance': 0,\n",
              "  'no': '80',\n",
              "  'parent': '3522'},\n",
              " {'Abstract': \"A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 3*3 matrix Delta v. Critical points are classified by examining Delta v's eigenvalues. The eigenvectors of Delta v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.&lt;&lt;ETX&gt;&gt;\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12047314072016233, 'word': 'critical'},\n",
              "   {'score': 0.12047314072016233, 'word': 'points'},\n",
              "   {'score': 0.07067273527246776, 'word': 'dimensional'},\n",
              "   {'score': 0.07067273527246776, 'word': 'vector'},\n",
              "   {'score': 0.07067273527246776, 'word': 'field'},\n",
              "   {'score': 0.06330886980589491, 'word': 'invariant'},\n",
              "   {'score': 0.06330886980589491, 'word': 'manifolds'},\n",
              "   {'score': 0.0631022826494668, 'word': 'topological'},\n",
              "   {'score': 0.0631022826494668, 'word': 'aspects'},\n",
              "   {'score': 0.045752337061843784, 'word': 'integral'},\n",
              "   {'score': 0.045752337061843784, 'word': 'curves'}],\n",
              "  'Title': 'A tool for visualizing the topology of three-dimensional vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '81',\n",
              "  'parent': '4486'},\n",
              " {'Abstract': 'Describes data exploration techniques designed to classify DNA sequences. Several visualization and data mining techniques were used to validate and attempt to discover new methods for distinguishing coding DNA sequences (exons) from non-coding DNA sequences (introns). The goal of the data mining was to see whether some other, possibly non-linear combination of the fundamental position-dependent DNA nucleotide frequency values could be a better predictor than the AMI (average mutual information). We tried many different classification techniques including rule-based classifiers and neural networks. We also used visualization of both the original data and the results of the data mining to help verify patterns and to understand the distinction between the different types of data and classifications. In particular, the visualization helped us develop refinements to neural network classifiers, which have accuracies as high as any known method. Finally, we discuss the interactions between visualization and data mining and suggest an integrated approach.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1523823725788113, 'word': 'data'},\n",
              "   {'score': 0.1523823725788113, 'word': 'exploration'},\n",
              "   {'score': 0.1523823725788113, 'word': 'techniques'},\n",
              "   {'score': 0.12737208153882099, 'word': 'visualization'},\n",
              "   {'score': 0.10652985723027976, 'word': 'dna'},\n",
              "   {'score': 0.10652985723027976, 'word': 'sequences'},\n",
              "   {'score': 0.08904240304914354, 'word': 'several'},\n",
              "   {'score': 0.03702220364825567, 'word': 'new'},\n",
              "   {'score': 0.03702220364825567, 'word': 'methods'}],\n",
              "  'Title': 'DNA visual and analytic data mining',\n",
              "  'distance': 0,\n",
              "  'no': '82',\n",
              "  'parent': '3918'},\n",
              " {'Abstract': 'Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data',\n",
              "  'AuthorKeywords': ['High',\n",
              "   'throughput,',\n",
              "   'lossless',\n",
              "   'compression,',\n",
              "   'file',\n",
              "   'compaction',\n",
              "   'for',\n",
              "   'I/O',\n",
              "   'efficiency,',\n",
              "   'fast',\n",
              "   'entropy',\n",
              "   'coding,',\n",
              "   'range',\n",
              "   'coder,',\n",
              "   'predictive',\n",
              "   'coding,',\n",
              "   'large',\n",
              "   'scale',\n",
              "   'simulation',\n",
              "   'and',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1639102037362653, 'word': 'data'},\n",
              "   {'score': 0.07274750404695093, 'word': 'sets'},\n",
              "   {'score': 0.051565207099501305, 'word': 'cpus'},\n",
              "   {'score': 0.045079765467996545, 'word': 'compression'},\n",
              "   {'score': 0.04353336675145492, 'word': 'simple'},\n",
              "   {'score': 0.04353336675145492, 'word': 'scheme'}],\n",
              "  'Title': 'Fast and Efficient Compression of Floating-Point Data',\n",
              "  'distance': 0,\n",
              "  'no': '83',\n",
              "  'parent': '4347'},\n",
              " {'Abstract': 'Most existing visualization applications use 3D geometry as their basic rendering primitive. As users demand more complex data sets, the memory requirements for retrieving and storing large 3D models are becoming excessive. In addition, the current 3D rendering hardware is facing a large memory bus bandwidth bottleneck at the processor to graphics pipeline interface. Rendering 1 million triangles with 24 bytes per triangle at 30 Hz requires as much as 720 MB/sec memory bus bandwidth. This transfer rate is well beyond the current low-cost graphics systems. A solution is to compress the static 3D geometry as an off-line pre-process. Then, only the compressed geometry needs to be stored in main memory and sent down to the graphics pipeline for real-time decompression and rendering. The author presents several new techniques for compression of 3D geometry that produce 2 to 3 times better compression ratios than existing methods. They first introduce several algorithms for the efficient encoding of the original geometry as generalized triangle meshes. This encoding allows most of the mesh vertices to be reused when forming new triangles. Their second contribution allows various parts of a geometric model to be compressed with different precision depending on the level of details present. Together, the meshifying algorithms and the variable compression method achieve compression ratios of 30 and 37 to one over ASCII encoded formats and 10 and 15 to one over binary encoded triangle strips. The experimental results show a dramatically lowered memory bandwidth required for real-time visualization of complex data sets.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09199984728004047, 'word': 'geometry'},\n",
              "   {'score': 0.08500233292681658, 'word': '3d'},\n",
              "   {'score': 0.05375634280457577, 'word': 'triangles'},\n",
              "   {'score': 0.041503769527920176, 'word': 'compressed'},\n",
              "   {'score': 0.03951119613030474, 'word': 'large'},\n",
              "   {'score': 0.03951119613030474, 'word': 'memory'},\n",
              "   {'score': 0.03951119613030474, 'word': 'bus'},\n",
              "   {'score': 0.03951119613030474, 'word': 'bandwidth'},\n",
              "   {'score': 0.03951119613030474, 'word': 'bottleneck'},\n",
              "   {'score': 0.03450625517469629, 'word': 'current'}],\n",
              "  'Title': 'Optimized geometry compression for real-time rendering',\n",
              "  'distance': 0,\n",
              "  'no': '84',\n",
              "  'parent': '5453'},\n",
              " {'Abstract': 'We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'graph',\n",
              "   'visualization,',\n",
              "   'graph',\n",
              "   'clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.08507878334094196, 'word': 'clustering'},\n",
              "   {'score': 0.07377245097752082, 'word': 'interactive'},\n",
              "   {'score': 0.07377245097752082, 'word': 'navigation'},\n",
              "   {'score': 0.07352115228185331, 'word': 'graph'},\n",
              "   {'score': 0.07352115228185331, 'word': 'visualization'},\n",
              "   {'score': 0.07352115228185331, 'word': 'system'},\n",
              "   {'score': 0.06384255616018138, 'word': 'large'},\n",
              "   {'score': 0.06384255616018138, 'word': 'graphs'},\n",
              "   {'score': 0.05534966970759129, 'word': 'graphview'}],\n",
              "  'Title': 'ASK-graphView: a large scale graph visualization system',\n",
              "  'distance': 0,\n",
              "  'no': '85',\n",
              "  'parent': '3409'},\n",
              " {'Abstract': 'MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process',\n",
              "  'AuthorKeywords': ['social',\n",
              "   'networks',\n",
              "   'visualization,',\n",
              "   'node-link',\n",
              "   'diagrams,',\n",
              "   'matrix-based',\n",
              "   'representations,',\n",
              "   'exploratory',\n",
              "   'process,',\n",
              "   'matrix',\n",
              "   'ordering,',\n",
              "   'interactive',\n",
              "   'clustering,',\n",
              "   'consensus'],\n",
              "  'MultipartiteRank': [{'score': 0.07605680377340958, 'word': 'network'},\n",
              "   {'score': 0.07605680377340958, 'word': 'visualization'},\n",
              "   {'score': 0.07605680377340958, 'word': 'system'},\n",
              "   {'score': 0.06932038708406983, 'word': 'representations'},\n",
              "   {'score': 0.060525732919013024, 'word': 'matrices'},\n",
              "   {'score': 0.05766151479414327, 'word': 'node'},\n",
              "   {'score': 0.056610317029513434, 'word': 'matrixexplorer'}],\n",
              "  'Title': 'MatrixExplorer: a Dual-Representation System to Explore Social Networks',\n",
              "  'distance': 0,\n",
              "  'no': '86',\n",
              "  'parent': '4376'},\n",
              " {'Abstract': 'Existing information visualization techniques are usually limited to the display of a few thousand items. This article describes new interactive techniques capable of handling a million items (effectively visible and manageable on screen). We evaluate the use of hardware-based techniques available with newer graphics cards, as well as new animation techniques and non-standard graphical features such as stereovision and overlap count. These techniques have been applied to two popular information visualizations: treemaps and scatter plot diagrams; but are generic enough to be applied to other 2D representations as well.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.22574275097335628, 'word': 'techniques'},\n",
              "   {'score': 0.0884464427398767, 'word': 'items'},\n",
              "   {'score': 0.08141844626389763, 'word': 'new'},\n",
              "   {'score': 0.08141844626389763, 'word': 'interactive'},\n",
              "   {'score': 0.08141844626389763, 'word': 'capable'},\n",
              "   {'score': 0.07255723399600411, 'word': 'available'},\n",
              "   {'score': 0.07176707071345455, 'word': 'information'},\n",
              "   {'score': 0.07176707071345455, 'word': 'visualization'},\n",
              "   {'score': 0.0584812613685202, 'word': 'manageable'}],\n",
              "  'Title': 'Interactive information visualization of a million items',\n",
              "  'distance': 0,\n",
              "  'no': '87',\n",
              "  'parent': '3697'},\n",
              " {'Abstract': 'The marching cubes (MC) algorithm is a method for generating isosurfaces. It also generates an excessively large number of triangles to represent an isosurface; this increases the rendering time. This paper presents a decimation method to reduce the number of triangles generated. Decimation is carried out before creating a large number of triangles. Four major steps comprise the algorithm: surface tracking, merging, crack patching and triangulation. Surface tracking is an enhanced implementation of the MC algorithm. Starting from a seed point, the surface tracker visits only those cells likely to compose part of the desired isosurface. The cells making up the extracted surface are stored in an octree that is further processed. A bottom-up approach is taken in merging the cells containing a relatively flat approximating surface. The finer surface details are maintained. Cells are merged as long as the error due to such an operation is within a user-specified error parameter, or a cell acquires more than one connected surface component in it. A crack patching method is described that forces edges of smaller cells to lie along those of the larger neighboring cells. The overall saving in the number of triangles depends both on the specified error value and the nature of the data. Use of the hierarchical octree data structure also presents the potential of incremental representation of surfaces. We can generate a highly smoothed surface representation which can be progressively refined as the user-specified error value is decreased.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08214666380627735, 'word': 'surface'},\n",
              "   {'score': 0.08214666380627735, 'word': 'tracking'},\n",
              "   {'score': 0.058538777923410654, 'word': 'cells'},\n",
              "   {'score': 0.058538777923410654, 'word': 'likely'},\n",
              "   {'score': 0.052695150865895296, 'word': 'triangles'},\n",
              "   {'score': 0.05195527852457093, 'word': 'algorithm'},\n",
              "   {'score': 0.04956469641166416, 'word': 'large'},\n",
              "   {'score': 0.04956469641166416, 'word': 'number'}],\n",
              "  'Title': 'Octree-based decimation of marching cubes surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '88',\n",
              "  'parent': '5843'},\n",
              " {'Abstract': 'Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'history,',\n",
              "   'undo,',\n",
              "   'analysis,',\n",
              "   'presentation,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.1635370857649174, 'word': 'history'},\n",
              "   {'score': 0.12262165240312659, 'word': 'design'},\n",
              "   {'score': 0.0990285616951488, 'word': 'interactive'},\n",
              "   {'score': 0.0990285616951488, 'word': 'tools'},\n",
              "   {'score': 0.0645085240697686, 'word': 'mechanisms'},\n",
              "   {'score': 0.05441278947361348, 'word': 'space'},\n",
              "   {'score': 0.05441278947361348, 'word': 'analysis'},\n",
              "   {'score': 0.040744636580518245, 'word': 'basic'},\n",
              "   {'score': 0.040744636580518245, 'word': 'undo'}],\n",
              "  'Title': 'Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation',\n",
              "  'distance': 0,\n",
              "  'no': '89',\n",
              "  'parent': '4196'},\n",
              " {'Abstract': 'This paper presents a novel approach to assist the user in exploring appropriate transfer functions for the visualization of volumetric datasets. The search for a transfer function is treated as a parameter optimization problem and addressed with stochastic search techniques. Starting from an initial population of (random or pre-defined) transfer functions, the evolution of the stochastic algorithms is controlled by either direct user selection of intermediate images or automatic fitness evaluation using user-specified objective functions. This approach essentially shields the user from the complex and tedious \"trial and error\" approach, and demonstrates effective and convenient generation of transfer functions.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17092904620950344, 'word': 'transfer'},\n",
              "   {'score': 0.11490167359921076, 'word': 'appropriate'},\n",
              "   {'score': 0.11490167359921076, 'word': 'functions'},\n",
              "   {'score': 0.10035233856490507, 'word': 'user'},\n",
              "   {'score': 0.07804234332401577, 'word': 'novel'},\n",
              "   {'score': 0.07804234332401577, 'word': 'approach'},\n",
              "   {'score': 0.05602737261029267, 'word': 'function'},\n",
              "   {'score': 0.052638489028133104, 'word': 'search'}],\n",
              "  'Title': 'Generation of Transfer Functions with Stochastic Search Technique',\n",
              "  'distance': 0,\n",
              "  'no': '90',\n",
              "  'parent': '4067'},\n",
              " {'Abstract': 'While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.',\n",
              "  'AuthorKeywords': ['clustering,',\n",
              "   'spatial',\n",
              "   'layout,',\n",
              "   'graph',\n",
              "   'visualization,',\n",
              "   'tree',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1414645006297364, 'word': 'many'},\n",
              "   {'score': 0.1414645006297364, 'word': 'data'},\n",
              "   {'score': 0.1414645006297364, 'word': 'sets'},\n",
              "   {'score': 0.06992651043748467, 'word': 'multiple'},\n",
              "   {'score': 0.06992651043748467, 'word': 'relationships'},\n",
              "   {'score': 0.06091997821547787, 'word': 'visualization'},\n",
              "   {'score': 0.06091997821547787, 'word': 'technique'},\n",
              "   {'score': 0.043378031690033805, 'word': 'significant'},\n",
              "   {'score': 0.043378031690033805, 'word': 'spatial'},\n",
              "   {'score': 0.043378031690033805, 'word': 'organization'},\n",
              "   {'score': 0.04300126336688512, 'word': 'membership'},\n",
              "   {'score': 0.04300126336688512, 'word': 'relation'}],\n",
              "  'Title': 'Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '91',\n",
              "  'parent': '5087'},\n",
              " {'Abstract': 'Tracking linear features through tensor field datasets is an open research problem with widespread utility in medical and engineering disciplines. Existing tracking methods, which consider only the preferred local diffusion direction as they propagate, fail to accurately follow features as they enter regions of local complexity. This shortcoming is a result of partial voluming; that is, voxels in these regions often contain contributions from multiple features. These combined contributions result in ambiguities when deciding local primary feature orientation based solely on the preferred diffusion direction. We introduce a novel feature extraction method which we term tensorline propagation. Our method resolves the above ambiguity by incorporating information about the nearby orientation of the feature, as well as the anisotropic classification of the local tensor. The nearby orientation information is added in the spirit of an advection term in a standard diffusion based propagation technique, and has the effect of stabilizing the tracking. To demonstrate the efficacy of tensorlines, we apply this method to the neuroscience problem of tracking white-matter bundles within the brain.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0967017371227299, 'word': 'linear'},\n",
              "   {'score': 0.0967017371227299, 'word': 'features'},\n",
              "   {'score': 0.050390625334605046, 'word': 'tracking'},\n",
              "   {'score': 0.050390625334605046, 'word': 'methods'},\n",
              "   {'score': 0.04655181823702001, 'word': 'tensor'},\n",
              "   {'score': 0.04655181823702001, 'word': 'field'},\n",
              "   {'score': 0.03881831610595739, 'word': 'regions'},\n",
              "   {'score': 0.03704191019293704, 'word': 'widespread'},\n",
              "   {'score': 0.03704191019293704, 'word': 'utility'}],\n",
              "  'Title': 'Tensorlines: Advection-Diffusion based Propagation through Diffusion Tensor Fields',\n",
              "  'distance': 0,\n",
              "  'no': '92',\n",
              "  'parent': '4059'},\n",
              " {'Abstract': 'The Visualization Toolkit (vtk) is a freely available C++ class library for 3D graphics and visualization. We describe core characteristics of the toolkit. This includes a description of object oriented models for graphics and visualization; methods for synchronizing system execution; a summary of data representation schemes; the role of C++; issues in portability across PC and Unix systems; and how we automatically wrap the C++ class library with interpreted languages such as Java and Tcl. We also demonstrate the capabilities of the system for scalar, vector, tensor, and other visualization techniques.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1525463518156197, 'word': 'visualization'},\n",
              "   {'score': 0.0773173363715708, 'word': 'system'},\n",
              "   {'score': 0.0773173363715708, 'word': 'execution'},\n",
              "   {'score': 0.07350921489576248, 'word': 'toolkit'},\n",
              "   {'score': 0.071528894794192, 'word': '3d'},\n",
              "   {'score': 0.071528894794192, 'word': 'graphics'},\n",
              "   {'score': 0.044226049539786705, 'word': 'vtk'}],\n",
              "  'Title': 'The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '93',\n",
              "  'parent': '4049'},\n",
              " {'Abstract': 'In many cases the surfaces of geometric models consist of a large number of triangles. Several algorithms were developed to reduce the number of triangles required to approximate such objects. Algorithms that measure the deviation between the approximated object and the original object are only available for special cases. We use the Hausdorff distance between the original and the simplified mesh as a geometrically meaningful error value which can be applied to arbitrary triangle meshes. We present a new algorithm to reduce the number of triangles of a mesh without exceeding a user defined Hausdorff distance between the original and simplified mesh. As this distance is parameterization independent, its use as error measure is superior to the use of the L/sup /spl infin//-Norm between parameterized surfaces. Furthermore the Hausdorff distance is always less than the distance induced by the L/sup /spl infin//-Norm. This results in higher reduction rates. Excellent results were achieved by the new decimation algorithm for triangle meshes that has been used in different application areas such as volume rendering, terrain modeling and the approximations of parameterized surfaces. The key advantages of the new algorithm are: it guarantees a user defined position dependent approximation error; it allows one to generate a hierarchical geometric representation in a canonical way; it automatically preserves sharp edges.',\n",
              "  'AuthorKeywords': ['hierarchical',\n",
              "   'approximation,',\n",
              "   'model',\n",
              "   'simplification,',\n",
              "   'levels-of-detail',\n",
              "   'generation,',\n",
              "   'shape',\n",
              "   'approximation'],\n",
              "  'MultipartiteRank': [{'score': 0.08426354986735901, 'word': 'triangles'},\n",
              "   {'score': 0.06789575095691551, 'word': 'several'},\n",
              "   {'score': 0.06789575095691551, 'word': 'algorithms'},\n",
              "   {'score': 0.06094233023014778, 'word': 'large'},\n",
              "   {'score': 0.06094233023014778, 'word': 'number'},\n",
              "   {'score': 0.056887591023711534, 'word': 'hausdorff'},\n",
              "   {'score': 0.056887591023711534, 'word': 'distance'},\n",
              "   {'score': 0.048619013286499216, 'word': 'surfaces'}],\n",
              "  'Title': 'Mesh reduction with error control',\n",
              "  'distance': 0,\n",
              "  'no': '94',\n",
              "  'parent': '5938'},\n",
              " {'Abstract': \"Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.\",\n",
              "  'AuthorKeywords': ['Data,', 'analysis,', 'visualization,', 'enterprise'],\n",
              "  'MultipartiteRank': [{'score': 0.07575365732212677, 'word': 'data'},\n",
              "   {'score': 0.07575365732212677, 'word': 'analysts'},\n",
              "   {'score': 0.07519139570404644, 'word': 'numerous'},\n",
              "   {'score': 0.07519139570404644, 'word': 'analysis'},\n",
              "   {'score': 0.04524019872400051, 'word': 'visualization'},\n",
              "   {'score': 0.04524019872400051, 'word': 'tools'},\n",
              "   {'score': 0.03939050130878597, 'word': 'organizational'},\n",
              "   {'score': 0.03939050130878597, 'word': 'context'},\n",
              "   {'score': 0.039033763973406625, 'word': 'organizations'}],\n",
              "  'Title': 'Enterprise Data Analysis and Visualization: An Interview Study',\n",
              "  'distance': 0,\n",
              "  'no': '95',\n",
              "  'parent': '3862'},\n",
              " {'Abstract': 'Maintenance of a front of particles, an efficient method of generating a set of sample points over a two-dimensional stream surface, is described. The particles are repeatedly advanced a short distance through the flow field. New polygons are appended to the downstream edge of the surface. The spacing of the particles is adjusted to maintain an adequate sampling across the width of the growing surface. Curve and ribbon methods of vector field visualization are reviewed.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12031443439839072, 'word': 'particles'},\n",
              "   {'score': 0.10109791908609335, 'word': 'dimensional'},\n",
              "   {'score': 0.10109791908609335, 'word': 'stream'},\n",
              "   {'score': 0.10109791908609335, 'word': 'surface'},\n",
              "   {'score': 0.08925483547911967, 'word': 'sample'},\n",
              "   {'score': 0.08925483547911967, 'word': 'points'},\n",
              "   {'score': 0.08424522940112315, 'word': 'efficient'},\n",
              "   {'score': 0.08424522940112315, 'word': 'method'},\n",
              "   {'score': 0.06683452316557903, 'word': 'set'}],\n",
              "  'Title': 'Constructing stream surfaces in steady 3D vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '96',\n",
              "  'parent': '3392'},\n",
              " {'Abstract': 'We describe a technique for choosing multiple colours for use during data visualization. Our goal is a systematic method for maximizing the total number of colours available for use, while still allowing an observer to rapidly and accurately search a display for any one of the given colours. Previous research suggests that we need to consider three separate effects during colour selection: colour distance, linear separation, and colour category. We describe a simple method for measuring and controlling all of these effects. Our method was tested by performing a set of target identification studies; we analysed the ability of thirty eight observers to find a colour target in displays that contained differently coloured background elements. Results showed our method can be used to select a group of colours that will provide good differentiation between data elements during data visualization.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15162132002305206, 'word': 'multiple'},\n",
              "   {'score': 0.15162132002305206, 'word': 'colours'},\n",
              "   {'score': 0.0853298748883867, 'word': 'use'},\n",
              "   {'score': 0.072676512818566, 'word': 'systematic'},\n",
              "   {'score': 0.072676512818566, 'word': 'method'},\n",
              "   {'score': 0.0614498261361398, 'word': 'data'},\n",
              "   {'score': 0.0614498261361398, 'word': 'visualization'},\n",
              "   {'score': 0.041415791895159176, 'word': 'technique'}],\n",
              "  'Title': 'Choosing effective colours for data visualization',\n",
              "  'distance': 0,\n",
              "  'no': '97',\n",
              "  'parent': '4202'},\n",
              " {'Abstract': 'We introduce a technique to visualize the gradual evolutionary change of the shapes of living things as a morph between known three-dimensional shapes. Given geometric computer models of anatomical shapes for some collection of specimens - here the skulls of the some of the extant members of a family of monkeys - an evolutionary tree for the group implies a hypothesis about the way in which the shape changed through time. We use a statistical model which expresses the value of some continuous variable at an internal point in the tree as a weighted average of the values at the leaves. The framework of geometric morphometrics can then be used to define a shape-space, based on the correspondences of landmark points on the surfaces, within which these weighted averages can be realized as actual surfaces. Our software provides tools for performing and visualizing such an analysis in three dimensions. Beginning with laser range scans of crania, we use our landmark editor to interactively place landmark points on the surface. We use these to compute a \"tree-morph\" that smoothly interpolates the shapes across the tree. Each intermediate shape in the morph is a linear combination of all of the input surfaces. We create a surface model for an intermediate shape by warping all the input meshes towards the correct shape and then blending them together. To do the blending, we compute a weighted average of their associated trivariate distance functions and then extract a surface from the resulting function. We implement this idea using the squared distance function, rather than the usual signed distance function, in a novel way.',\n",
              "  'AuthorKeywords': ['morphometrics,',\n",
              "   'morphing,',\n",
              "   'surface',\n",
              "   'blending,',\n",
              "   'merging,',\n",
              "   'warping,',\n",
              "   'distance',\n",
              "   'fields,',\n",
              "   'extremal',\n",
              "   'surface'],\n",
              "  'MultipartiteRank': [{'score': 0.0868582053714366, 'word': 'shapes'},\n",
              "   {'score': 0.08631900314514844, 'word': 'tree'},\n",
              "   {'score': 0.052074615630831156, 'word': 'evolutionary'},\n",
              "   {'score': 0.045600092964374644, 'word': 'surfaces'},\n",
              "   {'score': 0.037186167555514044, 'word': 'internal'},\n",
              "   {'score': 0.037186167555514044, 'word': 'point'}],\n",
              "  'Title': 'Evolutionary morphing',\n",
              "  'distance': 0,\n",
              "  'no': '98',\n",
              "  'parent': '5650'},\n",
              " {'Abstract': 'This paper introduces a new visualization method, the arc diagram, which is capable of representing complex patterns of repetition in string data. Arc diagrams improve over previous methods such as dotplots because they scale efficiently for strings that contain many instances of the same subsequence. This paper describes design and implementation issues related to arc diagrams and shows how they may be applied to visualize such diverse data as music, text, and compiled code.',\n",
              "  'AuthorKeywords': ['string,',\n",
              "   'sequence,',\n",
              "   'visualization,',\n",
              "   'arc',\n",
              "   'diagram,',\n",
              "   'music,',\n",
              "   'text,',\n",
              "   'code'],\n",
              "  'MultipartiteRank': [{'score': 0.14241613110734358, 'word': 'arc'},\n",
              "   {'score': 0.14241613110734358, 'word': 'diagram'},\n",
              "   {'score': 0.11054078083716595, 'word': 'string'},\n",
              "   {'score': 0.11054078083716595, 'word': 'data'},\n",
              "   {'score': 0.0861617304048401, 'word': 'paper'},\n",
              "   {'score': 0.08000571015209329, 'word': 'repetition'},\n",
              "   {'score': 0.07340746678985369, 'word': 'complex'},\n",
              "   {'score': 0.07340746678985369, 'word': 'patterns'}],\n",
              "  'Title': 'Arc diagrams: visualizing structure in strings',\n",
              "  'distance': 0,\n",
              "  'no': '99',\n",
              "  'parent': '3437'},\n",
              " {'Abstract': \"The Information Visualization and Exploration Environment (NEE) is a system for automatic creation of dynamic queries applications. IVEE imports database relations and automatically creates environments holding visualizations and query devices. IVEE offers multiple visualizations such as maps and starfields, and multiple query devices, such as sliders, alphasliders, and toggles. Arbitrary graphical objects can be attached to database objects in visualizations. Multiple visualizations may be active simultaneously. Users can interactively lay out and change between types of query devices. Users may retrieve details-on-demand by clicking on visualization objects. An HTML file may be provided along with the database, specifying how details-on-demand information should be presented, allowing for presentation of multimedia information in database objects. Finally, multiple IVEE clients running on separate workstations on a network can communicate by letting one user's actions affect the visualization in an another IVEE client.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12714948620141928, 'word': 'information'},\n",
              "   {'score': 0.12714948620141928, 'word': 'visualization'},\n",
              "   {'score': 0.07498222547440975, 'word': 'exploration'},\n",
              "   {'score': 0.07498222547440975, 'word': 'environment'},\n",
              "   {'score': 0.05691255947239539, 'word': 'ivee'},\n",
              "   {'score': 0.053275189164611804, 'word': 'query'},\n",
              "   {'score': 0.053275189164611804, 'word': 'devices'},\n",
              "   {'score': 0.0419981413369322, 'word': 'arbitrary'},\n",
              "   {'score': 0.0419981413369322, 'word': 'graphical'},\n",
              "   {'score': 0.0419981413369322, 'word': 'objects'}],\n",
              "  'Title': 'IVEE: an Information Visualization and Exploration Environment',\n",
              "  'distance': 0,\n",
              "  'no': '100',\n",
              "  'parent': '4830'},\n",
              " {'Abstract': \"Do court cases differ from place to place? What kind of picture do we get by looking at a country's collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity.\",\n",
              "  'AuthorKeywords': ['Text',\n",
              "   'visualization,',\n",
              "   'corpus',\n",
              "   'visualization,',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'text',\n",
              "   'mining,',\n",
              "   'tag',\n",
              "   'clouds'],\n",
              "  'MultipartiteRank': [{'score': 0.07588305919148797, 'word': 'parallel'},\n",
              "   {'score': 0.07588305919148797, 'word': 'tag'},\n",
              "   {'score': 0.07588305919148797, 'word': 'clouds'},\n",
              "   {'score': 0.06355866969178572, 'word': 'collection'},\n",
              "   {'score': 0.050177474554635684, 'word': 'differences'},\n",
              "   {'score': 0.04861577157894778, 'word': 'court'},\n",
              "   {'score': 0.04861577157894778, 'word': 'cases'},\n",
              "   {'score': 0.04620043578836899, 'word': 'facets'}],\n",
              "  'Title': 'Parallel Tag Clouds to explore and analyze faceted text corpora',\n",
              "  'distance': 0,\n",
              "  'no': '101',\n",
              "  'parent': '4929'},\n",
              " {'Abstract': 'The display of multivariate datasets in parallel coordinates, transforms the search for relations among the variables into a 2-D pattern recognition problem. This is the basis for the application to visual data mining. The knowledge discovery process together with some general guidelines are illustrated on a dataset from the production of a VLSI chip. The special strength of parallel coordinates is in modeling relations. As an example, a simplified economic model is constructed with data from various economic sectors of a real country. The visual model shows the interelationship and dependencies between the sectors, circumstances where there is competition for the same resource, and feasible economic policies. Interactively, the model can be used to do trade-off analyses, discover sensitivities, do approximate optimization, monitor (as in a process) and provide decision support.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.05711807869933503, 'word': 'visual'},\n",
              "   {'score': 0.05711807869933503, 'word': 'data'},\n",
              "   {'score': 0.05711807869933503, 'word': 'mining'},\n",
              "   {'score': 0.056708385429820506, 'word': 'simplified'},\n",
              "   {'score': 0.056708385429820506, 'word': 'economic'},\n",
              "   {'score': 0.056708385429820506, 'word': 'model'},\n",
              "   {'score': 0.05438927353734857, 'word': 'parallel'},\n",
              "   {'score': 0.05438927353734857, 'word': 'coordinates'},\n",
              "   {'score': 0.054337986825711504, 'word': 'multivariate'},\n",
              "   {'score': 0.054337986825711504, 'word': 'datasets'},\n",
              "   {'score': 0.049019231473912975, 'word': 'relations'}],\n",
              "  'Title': 'Multidimensional detective',\n",
              "  'distance': 0,\n",
              "  'no': '102',\n",
              "  'parent': '3836'},\n",
              " {'Abstract': 'This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.',\n",
              "  'AuthorKeywords': ['large-format',\n",
              "   'projection',\n",
              "   'display,',\n",
              "   'camera-based',\n",
              "   'registration',\n",
              "   'and',\n",
              "   'calibration'],\n",
              "  'MultipartiteRank': [{'score': 0.06206049066230849, 'word': 'pixelflex'},\n",
              "   {'score': 0.045987135670566184, 'word': 'new'},\n",
              "   {'score': 0.045987135670566184, 'word': 'layouts'},\n",
              "   {'score': 0.04520254974651396, 'word': 'size'},\n",
              "   {'score': 0.04428267557418757, 'word': 'spatial'},\n",
              "   {'score': 0.04428267557418757, 'word': 'formats'},\n",
              "   {'score': 0.03635138196644741, 'word': 'projectors'}],\n",
              "  'Title': 'PixelFlex: a reconfigurable multi-projector display system',\n",
              "  'distance': 0,\n",
              "  'no': '103',\n",
              "  'parent': '4079'},\n",
              " {'Abstract': 'In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'parallel',\n",
              "   'coordinates,',\n",
              "   'brushing,',\n",
              "   'linear',\n",
              "   'correlations,',\n",
              "   'focus+context',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1452981881359034, 'word': 'rational'},\n",
              "   {'score': 0.1452981881359034, 'word': 'data'},\n",
              "   {'score': 0.1303002174456691, 'word': 'angular'},\n",
              "   {'score': 0.1303002174456691, 'word': 'brushing'},\n",
              "   {'score': 0.09253316908477174, 'word': 'parallel'},\n",
              "   {'score': 0.09253316908477174, 'word': 'coordinates'},\n",
              "   {'score': 0.0881478503310972, 'word': 'properties'},\n",
              "   {'score': 0.08232782292211197, 'word': 'new'},\n",
              "   {'score': 0.08232782292211197, 'word': 'approach'}],\n",
              "  'Title': 'Angular brushing of extended parallel coordinates',\n",
              "  'distance': 0,\n",
              "  'no': '104',\n",
              "  'parent': '3671'},\n",
              " {'Abstract': 'We present a new algorithm for rendering very large volume data sets at interactive frame rates on standard PC hardware. The algorithm accepts scalar data sampled on a regular grid as input. The input data is converted into a compressed hierarchical wavelet representation in a preprocessing step. During rendering, the wavelet representation is decompressed on-the-fly and rendered using hardware texture mapping. The level of detail used for rendering is adapted to the local frequency spectrum of the data and its position relative to the viewer. Using a prototype implementation of the algorithm we were able to perform an interactive walkthrough of large data sets such as the visible human on a single off-the-shelf PC.',\n",
              "  'AuthorKeywords': ['Compression',\n",
              "   'Algorithms,',\n",
              "   'Level',\n",
              "   'of',\n",
              "   'Detail',\n",
              "   'Algorithms,',\n",
              "   'Scientific',\n",
              "   'Visualization,',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   'Wavelets'],\n",
              "  'MultipartiteRank': [{'score': 0.1585592345412336, 'word': 'algorithm'},\n",
              "   {'score': 0.13846123463844684, 'word': 'data'},\n",
              "   {'score': 0.09847797382917971, 'word': 'new'},\n",
              "   {'score': 0.08839079354887748, 'word': 'scalar'},\n",
              "   {'score': 0.05007044108956936, 'word': 'large'},\n",
              "   {'score': 0.05007044108956936, 'word': 'volume'},\n",
              "   {'score': 0.05007044108956936, 'word': 'sets'},\n",
              "   {'score': 0.048459911268409116, 'word': 'compressed'},\n",
              "   {'score': 0.048459911268409116, 'word': 'hierarchical'},\n",
              "   {'score': 0.048459911268409116, 'word': 'wavelet'},\n",
              "   {'score': 0.048459911268409116, 'word': 'representation'}],\n",
              "  'Title': 'Interactive rendering of large volume data sets',\n",
              "  'distance': 0,\n",
              "  'no': '105',\n",
              "  'parent': '3813'},\n",
              " {'Abstract': \"Virtualized reality is a modeling technique that constructs full 3D virtual representations of dynamic events from multiple video streams. Image-based stereo is used to compute a range image corresponding to each intensity image in each video stream. Each range and intensity image pair encodes the scene structure and appearance of the scene visible to the camera at that moment, and is therefore called a visible surface model (VSM). A single time instant of the dynamic event can be modeled as a collection of VSMs from different viewpoints, and the full event can be modeled as a sequence of static scenes-the 3D equivalent of video. Alternatively, the collection of VSMs at a single time can be fused into a global 3D surface model, thus creating a traditional virtual representation out of real world events. Global modeling has the added benefit of eliminating the need to hand-edit the range images to correct errors made in stereo, a drawback of previous techniques. Like image-based rendering models, these virtual representations can be used to synthesize nearly any view of the virtualized event. For this reason, the paper includes a detailed comparison of existing view synthesis techniques with the authors' own approach. In the virtualized representations, however, scene structure is explicitly represented and therefore easily manipulated, for example by adding virtual objects to (or removing virtualized objects from) the model without interfering with real event. Virtualized reality, then, is a platform not only for image-based rendering but also for 3D scene manipulation.\",\n",
              "  'AuthorKeywords': ['view',\n",
              "   'synthesis,',\n",
              "   'dynamic',\n",
              "   'scene',\n",
              "   'analysis,',\n",
              "   'modeling',\n",
              "   'from',\n",
              "   'image',\n",
              "   'sequences,',\n",
              "   'computer',\n",
              "   'vision',\n",
              "   'and',\n",
              "   'scene',\n",
              "   'understanding,',\n",
              "   'virtual',\n",
              "   'worlds'],\n",
              "  'MultipartiteRank': [{'score': 0.07604325639577027, 'word': 'image'},\n",
              "   {'score': 0.0705144882691416, 'word': 'dynamic'},\n",
              "   {'score': 0.0705144882691416, 'word': 'events'},\n",
              "   {'score': 0.05932138467587293, 'word': 'modeling'},\n",
              "   {'score': 0.05932138467587293, 'word': 'technique'},\n",
              "   {'score': 0.05348524555556065, 'word': 'full'},\n",
              "   {'score': 0.05348524555556065, 'word': '3d'},\n",
              "   {'score': 0.05348524555556065, 'word': 'virtual'},\n",
              "   {'score': 0.05348524555556065, 'word': 'representations'},\n",
              "   {'score': 0.04564334312009765, 'word': 'multiple'},\n",
              "   {'score': 0.04564334312009765, 'word': 'video'},\n",
              "   {'score': 0.04564334312009765, 'word': 'streams'}],\n",
              "  'Title': 'Virtualized reality: constructing time-varying virtual worlds from real world events',\n",
              "  'distance': 0,\n",
              "  'no': '106',\n",
              "  'parent': '6104'},\n",
              " {'Abstract': 'This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'interface',\n",
              "   'toolkits,',\n",
              "   'information',\n",
              "   'foraging,',\n",
              "   'social',\n",
              "   'navigation,',\n",
              "   'social',\n",
              "   'data',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.09617006991587763, 'word': 'widgets'},\n",
              "   {'score': 0.06731360316279392, 'word': 'navigation'},\n",
              "   {'score': 0.06686909213044041, 'word': 'applications'},\n",
              "   {'score': 0.0647756192449357, 'word': 'embedded'},\n",
              "   {'score': 0.0647756192449357, 'word': 'visualizations'},\n",
              "   {'score': 0.04691339303877344, 'word': 'unfamiliar'},\n",
              "   {'score': 0.04691339303877344, 'word': 'data'}],\n",
              "  'Title': 'Scented Widgets: Improving Navigation Cues with Embedded Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '107',\n",
              "  'parent': '3742'},\n",
              " {'Abstract': 'Many computer graphics operations, such as texture mapping, 3D painting, remeshing, mesh compression, and digital geometry processing, require finding a low-distortion parameterization for irregular connectivity triangulations of arbitrary genus 2-manifolds. This paper presents a simple and fast method for computing parameterizations with strictly bounded distortion. The new method operates by flattening the mesh onto a region of the 2D plane. To comply with the distortion bound, the mesh is automatically cut and partitioned on-the-fly. The method guarantees avoiding global and local self-intersections, while attempting to minimize the total length of the introduced seams. To our knowledge, this is the first method to compute the mesh partitioning and the parameterization simultaneously and entirely automatically, while providing guaranteed distortion bounds. Our results on a variety of objects demonstrate that the method is fast enough to work with large complex irregular meshes in interactive applications.',\n",
              "  'AuthorKeywords': ['atlas,',\n",
              "   'mesh',\n",
              "   'partitioning,',\n",
              "   'parameterization,',\n",
              "   'surface',\n",
              "   'flattening,',\n",
              "   'texture',\n",
              "   'mapping,',\n",
              "   '3D',\n",
              "   'painting'],\n",
              "  'MultipartiteRank': [{'score': 0.11777159322019054, 'word': 'distortion'},\n",
              "   {'score': 0.07920830574008446, 'word': 'fast'},\n",
              "   {'score': 0.07920830574008446, 'word': 'method'},\n",
              "   {'score': 0.07557376627558138, 'word': 'mesh'},\n",
              "   {'score': 0.07557376627558138, 'word': 'compression'},\n",
              "   {'score': 0.07057341263927375, 'word': 'parameterization'},\n",
              "   {'score': 0.04005521633192223, 'word': 'remeshing'}],\n",
              "  'Title': 'Bounded-distortion piecewise mesh parameterization',\n",
              "  'distance': 0,\n",
              "  'no': '108',\n",
              "  'parent': '4095'},\n",
              " {'Abstract': \"An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.\",\n",
              "  'AuthorKeywords': ['Visualization',\n",
              "   'taxonomy,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'memorability'],\n",
              "  'MultipartiteRank': [{'score': 0.12080693092400002, 'word': 'visualization'},\n",
              "   {'score': 0.12080693092400002, 'word': 'community'},\n",
              "   {'score': 0.07038775389559902, 'word': 'memorability'},\n",
              "   {'score': 0.03850757681376235, 'word': 'role'},\n",
              "   {'score': 0.037753607266344885, 'word': 'data'},\n",
              "   {'score': 0.037753607266344885, 'word': 'understanding'},\n",
              "   {'score': 0.032835721942853606, 'word': 'ongoing'},\n",
              "   {'score': 0.032835721942853606, 'word': 'debate'}],\n",
              "  'Title': 'What Makes a Visualization Memorable?',\n",
              "  'distance': 0,\n",
              "  'no': '109',\n",
              "  'parent': '4318'},\n",
              " {'Abstract': 'Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.',\n",
              "  'AuthorKeywords': ['computed',\n",
              "   'tomography',\n",
              "   'angiography,',\n",
              "   'vessel',\n",
              "   'analysis,',\n",
              "   'curved',\n",
              "   'planar',\n",
              "   'reformation'],\n",
              "  'MultipartiteRank': [{'score': 0.1245886560930505, 'word': 'cpr'},\n",
              "   {'score': 0.07847946752493366, 'word': 'different'},\n",
              "   {'score': 0.07847946752493366, 'word': 'methods'},\n",
              "   {'score': 0.03819443874136178, 'word': 'curved'},\n",
              "   {'score': 0.03819443874136178, 'word': 'planar'},\n",
              "   {'score': 0.03819443874136178, 'word': 'reformation'},\n",
              "   {'score': 0.03710044620646875, 'word': 'thick'},\n",
              "   {'score': 0.03638230379849939, 'word': 'tube'}],\n",
              "  'Title': 'CPR - curved planar reformation',\n",
              "  'distance': 0,\n",
              "  'no': '110',\n",
              "  'parent': '3520'},\n",
              " {'Abstract': 'Many networks under study in information visualization are \"small world\" networks. These networks first appeared in the study of social networks and were shown to be relevant models in other application domains such as software reverse engineering and biology. Furthermore, many of these networks actually have a multiscale nature: they can be viewed as a network of groups that are themselves small world networks. We describe a metric that has been designed in order to identify the weakest edges in a small world network leading to an easy and low cost filtering procedure that breaks up a graph into smaller and highly connected components. We show how this metric can be exploited through an interactive navigation of the network based on semantic zooming. Once the network is decomposed into a hierarchy of sub-networks, a user can easily find groups and subgroups of actors and understand their dynamics.',\n",
              "  'AuthorKeywords': ['Small',\n",
              "   'world',\n",
              "   'networks,',\n",
              "   'multiscale',\n",
              "   'graphs,clustering',\n",
              "   'metric,',\n",
              "   'semantic',\n",
              "   'zooming'],\n",
              "  'MultipartiteRank': [{'score': 0.2212618403825335, 'word': 'networks'},\n",
              "   {'score': 0.08080849097544583, 'word': 'many'},\n",
              "   {'score': 0.0740943017754039, 'word': 'small'},\n",
              "   {'score': 0.0740943017754039, 'word': 'world'},\n",
              "   {'score': 0.07089233973443118, 'word': 'study'},\n",
              "   {'score': 0.045724121967003595, 'word': 'groups'}],\n",
              "  'Title': 'Multiscale Visualization of Small World Networks',\n",
              "  'distance': 0,\n",
              "  'no': '111',\n",
              "  'parent': '3821'},\n",
              " {'Abstract': 'Social network analysis (SNA) has emerged as a powerful method for understanding the importance of relationships in networks. However, interactive exploration of networks is currently challenging because: (1) it is difficult to find patterns and comprehend the structure of networks with many nodes and links, and (2) current systems are often a medley of statistical methods and overwhelming visual output which leaves many analysts uncertain about how to explore in an orderly manner. This results in exploration that is largely opportunistic. Our contributions are techniques to help structural analysts understand social networks more effectively. We present SocialAction, a system that uses attribute ranking and coordinated views to help users systematically examine numerous SNA measures. Users can (1) flexibly iterate through visualizations of measures to gain an overview, filter nodes, and find outliers, (2) aggregate networks using link structure, find cohesive subgroups, and focus on communities of interest, and (3) untangle networks by viewing different link types separately, or find patterns across different link types using a matrix overview. For each operation, a stable node layout is maintained in the network visualization so users can make comparisons. SocialAction offers analysts a strategy beyond opportunism, as it provides systematic, yet flexible, techniques for exploring social networks',\n",
              "  'AuthorKeywords': ['Social',\n",
              "   'networks,',\n",
              "   'interactive',\n",
              "   'graph',\n",
              "   'visualization,',\n",
              "   'attribute',\n",
              "   'ranking,',\n",
              "   'coordinated',\n",
              "   'views,',\n",
              "   'exploratory',\n",
              "   'data',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.17413465558855606, 'word': 'social'},\n",
              "   {'score': 0.17413465558855606, 'word': 'network'},\n",
              "   {'score': 0.17413465558855606, 'word': 'analysis'},\n",
              "   {'score': 0.062480495746647095, 'word': 'sna'},\n",
              "   {'score': 0.043378730270271434, 'word': 'powerful'},\n",
              "   {'score': 0.043378730270271434, 'word': 'method'},\n",
              "   {'score': 0.035317934401857536, 'word': 'links'},\n",
              "   {'score': 0.03428640660595372, 'word': 'networks'}],\n",
              "  'Title': 'Balancing Systematic and Flexible Exploration of Social Networks',\n",
              "  'distance': 0,\n",
              "  'no': '112',\n",
              "  'parent': '5614'},\n",
              " {'Abstract': 'This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views',\n",
              "  'AuthorKeywords': ['Illustrative',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'interacting',\n",
              "   'with',\n",
              "   'volumetric',\n",
              "   'datasets,',\n",
              "   'characteristic',\n",
              "   'viewpoint',\n",
              "   'estimation,',\n",
              "   'focus+context',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.13669299885920047, 'word': 'features'},\n",
              "   {'score': 0.06762035523782291, 'word': 'focus'},\n",
              "   {'score': 0.06688118779084233, 'word': 'characteristic'},\n",
              "   {'score': 0.06688118779084233, 'word': 'viewpoint'},\n",
              "   {'score': 0.054009587644126264, 'word': 'expressive'},\n",
              "   {'score': 0.054009587644126264, 'word': 'view'},\n",
              "   {'score': 0.047672364593685956, 'word': 'importance'},\n",
              "   {'score': 0.047672364593685956, 'word': 'distribution'}],\n",
              "  'Title': 'Importance-Driven Focus of Attention',\n",
              "  'distance': 0,\n",
              "  'no': '113',\n",
              "  'parent': '4174'},\n",
              " {'Abstract': \"Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical 'mashups' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial 'tag clouds', 'tag maps', 'data dials' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the 'mashup' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.\",\n",
              "  'AuthorKeywords': ['Large',\n",
              "   'dataset',\n",
              "   'visualization,',\n",
              "   'text',\n",
              "   'and',\n",
              "   'document',\n",
              "   'visualization,',\n",
              "   'multiresolution',\n",
              "   'visualization,',\n",
              "   'geographic',\n",
              "   'visualization,',\n",
              "   'applications',\n",
              "   'of',\n",
              "   'infovis'],\n",
              "  'MultipartiteRank': [{'score': 0.10627819247591352, 'word': 'visual'},\n",
              "   {'score': 0.0633644303588442, 'word': 'exploratory'},\n",
              "   {'score': 0.0633644303588442, 'word': 'analysis'},\n",
              "   {'score': 0.04291376211706932, 'word': 'appropriate'},\n",
              "   {'score': 0.04291376211706932, 'word': 'encodings'},\n",
              "   {'score': 0.0402343081117315, 'word': 'data'},\n",
              "   {'score': 0.03846133915351415, 'word': 'interactions'},\n",
              "   {'score': 0.03640505589182763, 'word': 'approach'}],\n",
              "  'Title': 'Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.',\n",
              "  'distance': 0,\n",
              "  'no': '114',\n",
              "  'parent': '5709'},\n",
              " {'Abstract': 'We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.',\n",
              "  'AuthorKeywords': ['visualization,', 'statistical', 'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.20832797633559658, 'word': 'graph'},\n",
              "   {'score': 0.19302134451746658, 'word': 'theoretic'},\n",
              "   {'score': 0.19302134451746658, 'word': 'methods'},\n",
              "   {'score': 0.18792756066587185, 'word': 'tukey'},\n",
              "   {'score': 0.1645285966503327, 'word': 'procedure'},\n",
              "   {'score': 0.14539033066762824, 'word': 'large'},\n",
              "   {'score': 0.14539033066762824, 'word': 'datasets'}],\n",
              "  'Title': 'Graph-theoretic scagnostics',\n",
              "  'distance': 0,\n",
              "  'no': '115',\n",
              "  'parent': '3329'},\n",
              " {'Abstract': \"The paper presents an interactive approach for guiding the user's select of colormaps in visualization. PRAVDAColor, implemented as a module in the IBM Visualization Data Explorer, provides the user a selection of appropriate colormaps given the data type and spatial frequency, the user's task, and properties of the human perceptual system.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14206169392024753, 'word': 'user'},\n",
              "   {'score': 0.11937678494642495, 'word': 'select'},\n",
              "   {'score': 0.11562835297309948, 'word': 'colormaps'},\n",
              "   {'score': 0.07346215742207235, 'word': 'visualization'},\n",
              "   {'score': 0.062064556160898884, 'word': 'pravdacolor'}],\n",
              "  'Title': 'A rule-based tool for assisting colormap selection',\n",
              "  'distance': 0,\n",
              "  'no': '116',\n",
              "  'parent': '3351'},\n",
              " {'Abstract': 'Illustrations play a major role in the education process. Whether used to teach a surgical or radiologic procedure, to illustrate normal or aberrant anatomy, or to explain the functioning of a technical device, illustration significantly impacts learning. Although many specimens are readily available as volumetric data sets, particularly in medicine, illustrations are commonly produced manually as static images in a time-consuming process. Our goal is to create a fully dynamic three-dimensional illustration environment which directly operates on volume data. Single images have the aesthetic appeal of traditional illustrations, but can be interactively altered and explored. In this paper we present methods to realize such a system which combines artistic visual styles and expressive visualization techniques. We introduce a novel concept for direct multi-object volume visualization which allows control of the appearance of inter-penetrating objects via two-dimensional transfer functions. Furthermore, a unifying approach to efficiently integrate many non-photorealistic rendering models is presented. We discuss several illustrative concepts which can be realized by combining cutaways, ghosting, and selective deformation. Finally, we also propose a simple interface to specify objects of interest through three-dimensional volumetric painting. All presented methods are integrated into VolumeShop, an interactive hardware-accelerated application for direct volume illustration.',\n",
              "  'AuthorKeywords': ['illustrative',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'focus+context',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.1428406807584748, 'word': 'illustrations'},\n",
              "   {'score': 0.0438164404809267, 'word': 'education'},\n",
              "   {'score': 0.0438164404809267, 'word': 'process'},\n",
              "   {'score': 0.036830106432590874, 'word': 'static'},\n",
              "   {'score': 0.036830106432590874, 'word': 'images'},\n",
              "   {'score': 0.034875351803567045, 'word': 'functioning'},\n",
              "   {'score': 0.03439639744125921, 'word': 'technical'},\n",
              "   {'score': 0.03439639744125921, 'word': 'device'}],\n",
              "  'Title': 'VolumeShop: an interactive system for direct volume illustration',\n",
              "  'distance': 0,\n",
              "  'no': '117',\n",
              "  'parent': '4044'},\n",
              " {'Abstract': \"We present the novel high-level visualization taxonomy. Our taxonomy classifies visualization algorithms rather than data. Algorithms are categorized based on the assumptions they make about the data being visualized; we call this set of assumptions the design model. Because our taxonomy is based on design models, it is more flexible than existing taxonomies and considers the user's conceptual model, emphasizing the human aspect of visualization. Design models are classified according to whether they are discrete or continuous and by how much the algorithm designer chooses display attributes such as spatialization, timing, colour, and transparency. This novel approach provides an alternative view of the visualization field that helps explain how traditional divisions (e.g., information and scientific visualization) relates and overlap, and that may inspire research ideas in hybrid visualization areas\",\n",
              "  'AuthorKeywords': ['visualization,',\n",
              "   'taxonomy,',\n",
              "   'classification,',\n",
              "   'design',\n",
              "   'model,',\n",
              "   'user',\n",
              "   'model,',\n",
              "   'conceptual',\n",
              "   'model'],\n",
              "  'MultipartiteRank': [{'score': 0.15792219130650773, 'word': 'visualization'},\n",
              "   {'score': 0.09567923910046333, 'word': 'level'},\n",
              "   {'score': 0.09567923910046333, 'word': 'taxonomy'},\n",
              "   {'score': 0.08349812008365241, 'word': 'design'},\n",
              "   {'score': 0.08349812008365241, 'word': 'model'},\n",
              "   {'score': 0.07163342518135296, 'word': 'algorithms'},\n",
              "   {'score': 0.06382760939152843, 'word': 'novel'},\n",
              "   {'score': 0.06382760939152843, 'word': 'high'}],\n",
              "  'Title': 'Rethinking Visualization: A High-Level Taxonomy',\n",
              "  'distance': 0,\n",
              "  'no': '118',\n",
              "  'parent': '4290'},\n",
              " {'Abstract': 'Information visualization encounters a wide variety of different data domains. The visualization community has developed representation methods and interactive techniques. As a community, we have realized that the requirements in each domain are often dramatically different. In order to easily apply existing methods, researchers have developed a semiology of graphic representations. We have extended this research into a framework that includes operators and interactions in visualization systems, such as a visualization spreadsheet. We discuss properties of this framework and use it to characterize operations spanning a variety of different visualization techniques. The framework developed in the paper enables a new way of exploring and evaluating the design space of visualization operators, and helps end users in their analysis tasks.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'operators,',\n",
              "   'user',\n",
              "   'interactions,',\n",
              "   'view/value,',\n",
              "   'framework,',\n",
              "   'spreadsheet,',\n",
              "   'design,',\n",
              "   'extensibility,',\n",
              "   'visualization',\n",
              "   'systems'],\n",
              "  'MultipartiteRank': [{'score': 0.17348283140549187, 'word': 'visualization'},\n",
              "   {'score': 0.10147425144495106, 'word': 'information'},\n",
              "   {'score': 0.09356433113472423, 'word': 'different'},\n",
              "   {'score': 0.09356433113472423, 'word': 'data'},\n",
              "   {'score': 0.09356433113472423, 'word': 'domains'},\n",
              "   {'score': 0.07690518430370008, 'word': 'wide'},\n",
              "   {'score': 0.07690518430370008, 'word': 'variety'},\n",
              "   {'score': 0.07200857996054079, 'word': 'community'},\n",
              "   {'score': 0.06678532854897026, 'word': 'representation'},\n",
              "   {'score': 0.06678532854897026, 'word': 'methods'}],\n",
              "  'Title': 'An operator interaction framework for visualization systems',\n",
              "  'distance': 0,\n",
              "  'no': '119',\n",
              "  'parent': '4181'},\n",
              " {'Abstract': \"We examine how animating a viewpoint change in a spatial information system affects a user's ability to build a mental map of the information in the space. We found that animation improves users' ability to reconstruct the information space, with no penalty on task performance time. We believe that this study provides strong evidence for adding animated transitions in many applications with fixed spatial data where the user navigates around the data space.\",\n",
              "  'AuthorKeywords': ['Evaluation,',\n",
              "   'animation,',\n",
              "   'real-time',\n",
              "   'computer',\n",
              "   'graphics,',\n",
              "   'Zoomable',\n",
              "   'User',\n",
              "   'Interfaces',\n",
              "   '(ZUIs),',\n",
              "   'multiscale',\n",
              "   'interfaces,',\n",
              "   'Pad++'],\n",
              "  'MultipartiteRank': [{'score': 0.13472382488352455, 'word': 'user'},\n",
              "   {'score': 0.11991893620532579, 'word': 'spatial'},\n",
              "   {'score': 0.11991893620532579, 'word': 'information'},\n",
              "   {'score': 0.11991893620532579, 'word': 'system'},\n",
              "   {'score': 0.09676291818740738, 'word': 'ability'},\n",
              "   {'score': 0.08420513494477637, 'word': 'animation'},\n",
              "   {'score': 0.06761249860400716, 'word': 'space'}],\n",
              "  'Title': 'Does animation help users build mental maps of spatial information?',\n",
              "  'distance': 0,\n",
              "  'no': '120',\n",
              "  'parent': '3732'},\n",
              " {'Abstract': 'We introduce nonlinear magnification fields as an abstract representation of nonlinear magnification, providing methods for converting transformation routines to magnification fields and vice-versa. This new representation provides ease of manipulation and power of expression. By removing the restrictions of explicit foci and allowing precise specification of magnification values, we can achieve magnification effects which were not previously possible. Of particular interest are techniques we introduce for expressing complex and subtle magnification effects through magnification brushing, and allowing intrinsic properties of the data being visualized to create data-driven magnifications.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'nonlinear',\n",
              "   'magnification,',\n",
              "   'data-driven',\n",
              "   'magnification,',\n",
              "   'fisheye',\n",
              "   'views,',\n",
              "   'magnification',\n",
              "   'brushing,',\n",
              "   'data-mining'],\n",
              "  'MultipartiteRank': [{'score': 0.17863943831898846, 'word': 'nonlinear'},\n",
              "   {'score': 0.17863943831898846, 'word': 'magnification'},\n",
              "   {'score': 0.17863943831898846, 'word': 'fields'},\n",
              "   {'score': 0.10900172792356592, 'word': 'abstract'},\n",
              "   {'score': 0.10900172792356592, 'word': 'representation'},\n",
              "   {'score': 0.043879838889529475, 'word': 'methods'},\n",
              "   {'score': 0.04224370643497194, 'word': 'transformation'},\n",
              "   {'score': 0.04224370643497194, 'word': 'routines'},\n",
              "   {'score': 0.038824691823351964, 'word': 'vice'}],\n",
              "  'Title': 'Nonlinear magnification fields',\n",
              "  'distance': 0,\n",
              "  'no': '121',\n",
              "  'parent': '3733'},\n",
              " {'Abstract': 'This work introduces importance-driven volume rendering as a novel technique for automatic focus and context display of volumetric data. Our technique is a generalization of cut-away views, which - depending on the viewpoint - remove or suppress less important parts of a scene to reveal more important underlying information. We automatize and apply this idea to volumetric data. Each part of the volumetric data is assigned an object importance, which encodes visibility priority. This property determines which structures should be readily discernible and which structures are less important. In those image regions, where an object occludes more important structures it is displayed more sparsely than in those areas where no occlusion occurs. Thus the objects of interest are clearly visible. For each object several representations, i.e., levels of sparseness, are specified. The display of an individual object may incorporate different levels of sparseness. The goal is to emphasize important structures and to maximize the information content in the final image. This work also discusses several possible schemes for level of sparseness specification and different ways how object importance can be composited to determine the final appearance of a particular object.',\n",
              "  'AuthorKeywords': ['view-dependent',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'focus+context',\n",
              "   'techniques,',\n",
              "   'level-of-detail',\n",
              "   'techniques,',\n",
              "   'non-photorealistic',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.13736068837074927, 'word': 'importance'},\n",
              "   {'score': 0.07910924141310315, 'word': 'object'},\n",
              "   {'score': 0.05495279001227158, 'word': 'structures'},\n",
              "   {'score': 0.05017314686901047, 'word': 'volumetric'},\n",
              "   {'score': 0.05017314686901047, 'word': 'data'},\n",
              "   {'score': 0.04333911017582085, 'word': 'sparseness'}],\n",
              "  'Title': 'Importance-driven volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '122',\n",
              "  'parent': '5407'},\n",
              " {'Abstract': 'We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.',\n",
              "  'AuthorKeywords': ['Backchannel,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'events,',\n",
              "   'multiple',\n",
              "   'views,',\n",
              "   'microblogging,',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'World',\n",
              "   'Wide',\n",
              "   'Web'],\n",
              "  'MultipartiteRank': [{'score': 0.05094564734451281, 'word': 'timely'},\n",
              "   {'score': 0.05094564734451281, 'word': 'exchange'},\n",
              "   {'score': 0.04752706647147832, 'word': 'visual'},\n",
              "   {'score': 0.04752706647147832, 'word': 'backchannel'},\n",
              "   {'score': 0.04389904736228263, 'word': 'online'},\n",
              "   {'score': 0.04389904736228263, 'word': 'conversations'},\n",
              "   {'score': 0.03769995407194108, 'word': 'large'},\n",
              "   {'score': 0.03401846786628472, 'word': 'scale'},\n",
              "   {'score': 0.03401846786628472, 'word': 'events'}],\n",
              "  'Title': 'A Visual Backchannel for Large-Scale Events',\n",
              "  'distance': 0,\n",
              "  'no': '123',\n",
              "  'parent': '4814'},\n",
              " {'Abstract': 'A technique is presented for the layout of high dimensional data in a low dimensional space. This technique builds upon the force based methods that have been used previously to make visualisations of various types of data such as bibliographies and sets of software modules. The canonical force based model, related to solutions of the N body problem, has a computational complexity of O(N/sup 2/) per iteration. The paper presents a stochastically based algorithm of linear complexity per iteration which produces good layouts, has low overhead, and is easy to implement. Its performance and accuracy are discussed, in particular with regard to the data to which it is applied. Experience with application to bibliographic and time series data, which may have a dimensionality in the tens of thousands, is described.',\n",
              "  'AuthorKeywords': ['layout',\n",
              "   'algorithms,',\n",
              "   'visualization,',\n",
              "   'high-dimensional',\n",
              "   'data,',\n",
              "   'spring',\n",
              "   'models,',\n",
              "   'stochastic',\n",
              "   'algorithms,',\n",
              "   'force-directed',\n",
              "   'placement'],\n",
              "  'MultipartiteRank': [{'score': 0.12357443361538478, 'word': 'dimensional'},\n",
              "   {'score': 0.07251466410197234, 'word': 'high'},\n",
              "   {'score': 0.07251466410197234, 'word': 'data'},\n",
              "   {'score': 0.057525042037862226, 'word': 'force'},\n",
              "   {'score': 0.05727062762740249, 'word': 'layout'},\n",
              "   {'score': 0.053258084089483654, 'word': 'technique'},\n",
              "   {'score': 0.05105976951341244, 'word': 'low'},\n",
              "   {'score': 0.05105976951341244, 'word': 'space'}],\n",
              "  'Title': 'A linear iteration time layout algorithm for visualising high-dimensional data',\n",
              "  'distance': 0,\n",
              "  'no': '124',\n",
              "  'parent': '4640'},\n",
              " {'Abstract': 'Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration',\n",
              "  'AuthorKeywords': ['coordinated',\n",
              "   'queries,',\n",
              "   'coordination,',\n",
              "   'exploratory',\n",
              "   'visualization,',\n",
              "   'multiple',\n",
              "   'views,',\n",
              "   'visual',\n",
              "   'abstraction',\n",
              "   'language'],\n",
              "  'MultipartiteRank': [{'score': 0.13122039820649783, 'word': 'browse'},\n",
              "   {'score': 0.13122039820649783, 'word': 'multiview'},\n",
              "   {'score': 0.13122039820649783, 'word': 'visualizations'},\n",
              "   {'score': 0.0996845139919782, 'word': 'users'},\n",
              "   {'score': 0.084510003685241, 'word': 'object'},\n",
              "   {'score': 0.084510003685241, 'word': 'coordination'},\n",
              "   {'score': 0.084510003685241, 'word': 'mechanism'},\n",
              "   {'score': 0.053493622237378254, 'word': 'visualization'},\n",
              "   {'score': 0.04587288690931335, 'word': 'simple'}],\n",
              "  'Title': 'Building Highly-Coordinated Visualizations in Improvise',\n",
              "  'distance': 0,\n",
              "  'no': '125',\n",
              "  'parent': '3615'},\n",
              " {'Abstract': 'Advances in computer graphics hardware and algorithms, visualization, and interactive techniques for analysis offer the components for a highly integrated, efficient real-time 3D Geographic Information System. We have developed \"Virtual GIS\", a system with truly immersive capability for navigating and understanding complex and dynamic terrain-based databases. The system provides the means for visualizing terrain models consisting of elevation and imagery data, along with GIS raster layers, protruding features, buildings, vehicles, and other objects. We have implemented window-based and virtual reality versions and in both cases provide a direct manipulation, visual interface for accessing the GIS data. Unique terrain data structures and algorithms allow rendering of large, high resolution datasets at interactive rates.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.053757354757748746, 'word': 'algorithms'},\n",
              "   {'score': 0.05325556975579299, 'word': 'dynamic'},\n",
              "   {'score': 0.05325556975579299, 'word': 'terrain'},\n",
              "   {'score': 0.05019659545942307, 'word': 'visualization'},\n",
              "   {'score': 0.048308134382445134, 'word': 'system'},\n",
              "   {'score': 0.04715709961589117, 'word': 'interactive'},\n",
              "   {'score': 0.04715709961589117, 'word': 'techniques'}],\n",
              "  'Title': 'Virtual GIS: a real-time 3D geographic information system',\n",
              "  'distance': 0,\n",
              "  'no': '126',\n",
              "  'parent': '3716'},\n",
              " {'Abstract': 'This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.',\n",
              "  'AuthorKeywords': ['large-format',\n",
              "   'tiled',\n",
              "   'projection',\n",
              "   'display,',\n",
              "   'display',\n",
              "   'wall,',\n",
              "   'camera-projector',\n",
              "   'systems,',\n",
              "   'camera-based',\n",
              "   'registration',\n",
              "   'and',\n",
              "   'calibration,',\n",
              "   'automatic',\n",
              "   'alignment,',\n",
              "   'scalability,',\n",
              "   'simulation,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.10974074655960647, 'word': 'display'},\n",
              "   {'score': 0.06983030836125523, 'word': 'single'},\n",
              "   {'score': 0.06983030836125523, 'word': 'camera'},\n",
              "   {'score': 0.06983030836125523, 'word': 'view'},\n",
              "   {'score': 0.06603040482956418, 'word': 'resolution'},\n",
              "   {'score': 0.04929780404726354, 'word': 'naive'},\n",
              "   {'score': 0.04929780404726354, 'word': 'approaches'},\n",
              "   {'score': 0.04893395842459823, 'word': 'geometric'},\n",
              "   {'score': 0.04893395842459823, 'word': 'alignment'},\n",
              "   {'score': 0.04893395842459823, 'word': 'system'},\n",
              "   {'score': 0.0437103417300423, 'word': 'large'},\n",
              "   {'score': 0.0437103417300423, 'word': 'wall'}],\n",
              "  'Title': 'Scalable alignment of large-format multi-projector displays using camera homography trees',\n",
              "  'distance': 0,\n",
              "  'no': '127',\n",
              "  'parent': '5127'},\n",
              " {'Abstract': \"Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd's response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010.\",\n",
              "  'AuthorKeywords': ['Computational',\n",
              "   'Journalism,',\n",
              "   'Computer',\n",
              "   'Assisted',\n",
              "   'Reporting,',\n",
              "   'Social',\n",
              "   'Media,',\n",
              "   'Sensemaking'],\n",
              "  'MultipartiteRank': [{'score': 0.07168712976250828, 'word': 'social'},\n",
              "   {'score': 0.07168712976250828, 'word': 'media'},\n",
              "   {'score': 0.05639103885943574, 'word': 'content'},\n",
              "   {'score': 0.042879926859073283, 'word': 'journalists'},\n",
              "   {'score': 0.04099552866303589, 'word': 'large'},\n",
              "   {'score': 0.03961126560386801, 'word': 'information'}],\n",
              "  'Title': 'Diamonds in the rough: Social media visual analytics for journalistic inquiry',\n",
              "  'distance': 0,\n",
              "  'no': '128',\n",
              "  'parent': '4120'},\n",
              " {'Abstract': 'Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 \"Superstorm\". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.',\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'weather',\n",
              "   'ensemble,',\n",
              "   'geographic/geospatial',\n",
              "   'visualization,',\n",
              "   'glyph-based',\n",
              "   'techniques,',\n",
              "   'time-varying',\n",
              "   'data,',\n",
              "   'qualitative',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.10238873818818657, 'word': 'weather'},\n",
              "   {'score': 0.0889640676572851, 'word': 'ensembles'},\n",
              "   {'score': 0.06801482473352766, 'word': 'members'},\n",
              "   {'score': 0.05419485839196425, 'word': 'uncertainties'},\n",
              "   {'score': 0.053216596676564414, 'word': 'operational'},\n",
              "   {'score': 0.053216596676564414, 'word': 'forecasting'},\n",
              "   {'score': 0.04917214151162216, 'word': 'numerical'},\n",
              "   {'score': 0.04917214151162216, 'word': 'prediction'}],\n",
              "  'Title': 'Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty',\n",
              "  'distance': 0,\n",
              "  'no': '129',\n",
              "  'parent': '5149'},\n",
              " {'Abstract': 'A new technique for interactive vector field visualization using large numbers of properly illuminated stream lines is presented. Taking into account ambient, diffuse, and specular reflection terms as well as transparency, we employ a realistic shading model which significantly increases quality and realism of the resulting images. While many graphics workstations offer hardware support for illuminating surface primitives, usually no means for an accurate shading of line primitives are provided. However, we show that proper illumination of lines can be implemented by exploiting the texture mapping capabilities of modern graphics hardware. In this way high rendering performance with interactive frame rates can be achieved. We apply the technique to render large numbers of integral curves in a vector field. The impression of the resulting images can be further improved by making the curves partially transparent. We also describe methods for controlling the distribution of stream lines in space. These methods enable us to use illuminated stream lines within an interactive visualization environment.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09094153486457693, 'word': 'stream'},\n",
              "   {'score': 0.09094153486457693, 'word': 'lines'},\n",
              "   {'score': 0.061900981480766955, 'word': 'interactive'},\n",
              "   {'score': 0.061900981480766955, 'word': 'vector'},\n",
              "   {'score': 0.061900981480766955, 'word': 'field'},\n",
              "   {'score': 0.061900981480766955, 'word': 'visualization'},\n",
              "   {'score': 0.05628965135012463, 'word': 'new'},\n",
              "   {'score': 0.05628965135012463, 'word': 'technique'},\n",
              "   {'score': 0.05613802577327384, 'word': 'large'},\n",
              "   {'score': 0.05613802577327384, 'word': 'numbers'},\n",
              "   {'score': 0.04219833653331864, 'word': 'integral'},\n",
              "   {'score': 0.04219833653331864, 'word': 'curves'}],\n",
              "  'Title': 'Interactive visualization of 3D-vector fields using illuminated stream lines',\n",
              "  'distance': 0,\n",
              "  'no': '130',\n",
              "  'parent': '4306'},\n",
              " {'Abstract': 'In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.',\n",
              "  'AuthorKeywords': ['Traffic',\n",
              "   'visualization,',\n",
              "   'traffic',\n",
              "   'jam',\n",
              "   'propagation'],\n",
              "  'MultipartiteRank': [{'score': 0.1347373343994777, 'word': 'traffic'},\n",
              "   {'score': 0.08901883711908666, 'word': 'jam'},\n",
              "   {'score': 0.08901883711908666, 'word': 'information'},\n",
              "   {'score': 0.08438120397674323, 'word': 'gps'},\n",
              "   {'score': 0.08438120397674323, 'word': 'trajectories'},\n",
              "   {'score': 0.05939139987413829, 'word': 'interactive'},\n",
              "   {'score': 0.05939139987413829, 'word': 'system'},\n",
              "   {'score': 0.052451239731854886, 'word': 'road'},\n",
              "   {'score': 0.052451239731854886, 'word': 'network'},\n",
              "   {'score': 0.045718497280391034, 'word': 'urban'},\n",
              "   {'score': 0.045718497280391034, 'word': 'congestion'}],\n",
              "  'Title': 'Visual Traffic Jam Analysis Based on Trajectory Data',\n",
              "  'distance': 0,\n",
              "  'no': '131',\n",
              "  'parent': '4541'},\n",
              " {'Abstract': 'Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication',\n",
              "  'AuthorKeywords': ['Design',\n",
              "   'patterns,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'software',\n",
              "   'engineering,',\n",
              "   'object-oriented',\n",
              "   'programming'],\n",
              "  'MultipartiteRank': [{'score': 0.15408796353786364, 'word': 'design'},\n",
              "   {'score': 0.08524154735043327, 'word': 'patterns'},\n",
              "   {'score': 0.07416223163584293, 'word': 'information'},\n",
              "   {'score': 0.07416223163584293, 'word': 'visualization'},\n",
              "   {'score': 0.06884641618743037, 'word': 'solutions'},\n",
              "   {'score': 0.05665886704354993, 'word': 'software'},\n",
              "   {'score': 0.05665886704354993, 'word': 'architectures'},\n",
              "   {'score': 0.04552035244273813, 'word': 'particular'},\n",
              "   {'score': 0.04552035244273813, 'word': 'context'}],\n",
              "  'Title': 'Software Design Patterns for Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '132',\n",
              "  'parent': '4231'},\n",
              " {'Abstract': \"A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.\",\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'network',\n",
              "   'visualization,',\n",
              "   'degree',\n",
              "   'of',\n",
              "   'interest,',\n",
              "   'legal',\n",
              "   'citation',\n",
              "   'networks,',\n",
              "   'focus+context'],\n",
              "  'MultipartiteRank': [{'score': 0.0970118067553008, 'word': 'graph'},\n",
              "   {'score': 0.09566549157628233, 'word': 'users'},\n",
              "   {'score': 0.060626807863680104, 'word': 'overview'},\n",
              "   {'score': 0.05591798488367504, 'word': 'entire'},\n",
              "   {'score': 0.04916558273445233, 'word': 'interest'},\n",
              "   {'score': 0.04109382187162575, 'word': 'visualization'},\n",
              "   {'score': 0.04109382187162575, 'word': 'research'}],\n",
              "  'Title': '\"Search, Show Context, Expand on Demand\": Supporting Large Graph Exploration with Degree-of-Interest',\n",
              "  'distance': 0,\n",
              "  'no': '133',\n",
              "  'parent': '5635'},\n",
              " {'Abstract': 'Focus+context visualization integrates a visually accentuated representation of selected data items in focus (more details, more opacity, etc.) with a visually deemphasized representation of the rest of the data, i.e., the context. The role of context visualization is to provide an overview of the data for improved user orientation and improved navigation. A good overview comprises the representation of both outliers and trends. Up to now, however, context visualization not really treated outliers sufficiently. In this paper we present a new approach to focus+context visualization in parallel coordinates which is truthful to outliers in the sense that small-scale features are detected before visualization and then treated specially during context visualization. Generally, we present a solution which enables context visualization at several levels of abstraction, both for the representation of outliers and trends. We introduce outlier detection and context generation to parallel coordinates on the basis of a binned data representation. This leads to an output-oriented visualization approach which means that only those parts of the visualization process are executed which actually affect the final rendering. Accordingly, the performance of this solution is much more dependent on the visualization size than on the data size which makes it especially interesting for large datasets. Previous approaches are outperformed, the new solution was successfully applied to datasets with up to 3 million data records and up to 50 dimensions',\n",
              "  'AuthorKeywords': ['Parallel',\n",
              "   'coordinates,',\n",
              "   'focus+context',\n",
              "   'visualization,',\n",
              "   'outliers',\n",
              "   '&',\n",
              "   'trends,',\n",
              "   'large',\n",
              "   'data',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08490935599752898, 'word': 'context'},\n",
              "   {'score': 0.08490935599752898, 'word': 'visualization'},\n",
              "   {'score': 0.06981099372560234, 'word': 'outliers'},\n",
              "   {'score': 0.06952264001088851, 'word': 'representation'},\n",
              "   {'score': 0.0638832217856997, 'word': 'data'},\n",
              "   {'score': 0.0638832217856997, 'word': 'items'},\n",
              "   {'score': 0.032019690248952654, 'word': 'overview'}],\n",
              "  'Title': 'Outlier-Preserving Focus+Context Visualization in Parallel Coordinates',\n",
              "  'distance': 0,\n",
              "  'no': '134',\n",
              "  'parent': '4480'},\n",
              " {'Abstract': 'Recent interest in large displays has led to renewed development of tiled displays, which are comprised of several individual displays arranged in an array and used as one large logical display. Stanford\\'s \"Interactive Mural\" is an example of such a display, using an overlapping four by two array of projectors that back-project onto a diffuse screen to form a 6\\' by 2\\' display area with a resolution of over 60 dpi. Writing software to make effective use of the large display space is a challenge because normal window system interaction metaphors break down. One promising approach is to switch to immersive applications; another approach, the one we are investigating, is to emulate office, conference room or studio environments which use the space to display a collection of visual material to support group activities. We describe a virtual graphics system that is designed to support multiple simultaneous rendering streams from both local and remote sites. The system abstracts the physical number of computers, graphics subsystems and projectors used to create the display. We provide performance measurements to show that the system scales well and thus supports a variety of different hardware configurations. The system is also interesting because it uses transparent \"layers\", instead of windows, to manage the screen.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14396851051601617, 'word': 'displays'},\n",
              "   {'score': 0.11163993152119016, 'word': 'large'},\n",
              "   {'score': 0.06635553285614586, 'word': 'recent'},\n",
              "   {'score': 0.06635553285614586, 'word': 'interest'},\n",
              "   {'score': 0.03910702492932598, 'word': 'virtual'},\n",
              "   {'score': 0.03910702492932598, 'word': 'graphics'},\n",
              "   {'score': 0.03910702492932598, 'word': 'system'},\n",
              "   {'score': 0.030983364996091802, 'word': 'array'}],\n",
              "  'Title': 'A distributed graphics system for large tiled displays',\n",
              "  'distance': 0,\n",
              "  'no': '135',\n",
              "  'parent': '4766'},\n",
              " {'Abstract': 'Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'interaction,',\n",
              "   'exploratory',\n",
              "   'analysis,',\n",
              "   'trajectory',\n",
              "   'attribute',\n",
              "   'data,',\n",
              "   'spatio-temporal',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.09318482446324336, 'word': 'trajectories'},\n",
              "   {'score': 0.0417714324276619, 'word': 'solution'},\n",
              "   {'score': 0.03956872082899878, 'word': 'attribute'},\n",
              "   {'score': 0.03956872082899878, 'word': 'values'},\n",
              "   {'score': 0.03949747015398549, 'word': 'visualization'},\n",
              "   {'score': 0.03804222856697307, 'word': 'time'}],\n",
              "  'Title': 'Stacking-Based Visualization of Trajectory Attribute Data',\n",
              "  'distance': 0,\n",
              "  'no': '136',\n",
              "  'parent': '5680'},\n",
              " {'Abstract': 'We present a fast volume rendering algorithm for time-varying fields. We propose a new data structure, called time-space partitioning (TSP) tree, that can effectively capture both the spatial and the temporal coherence from a time-varying field. Using the proposed data structure, the rendering speed is substantially improved. In addition, our data structure helps to maintain the memory access locality and to provide the sparse data traversal so that our algorithm becomes suitable for large-scale out-of-core applications. Finally, our algorithm allows flexible error control for both the temporal and the spatial coherence so that a trade-off between image quality and rendering speed is possible. We demonstrate the utility and speed of our algorithm with data from several time-varying CFD simulations. Our rendering algorithm can achieve substantial speedup while the storage space overhead for the TSP tree is kept at a minimum.',\n",
              "  'AuthorKeywords': ['scalar',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'time-varying',\n",
              "   'fields'],\n",
              "  'MultipartiteRank': [{'score': 0.0943580756706826, 'word': 'time'},\n",
              "   {'score': 0.08904983853450261, 'word': 'new'},\n",
              "   {'score': 0.08904983853450261, 'word': 'data'},\n",
              "   {'score': 0.08904983853450261, 'word': 'structure'},\n",
              "   {'score': 0.07893753172574851, 'word': 'algorithm'},\n",
              "   {'score': 0.04842794146476039, 'word': 'fields'},\n",
              "   {'score': 0.04804354318952567, 'word': 'space'},\n",
              "   {'score': 0.04804354318952567, 'word': 'partitioning'}],\n",
              "  'Title': 'A fast volume rendering algorithm for time-varying fields using a time-space partitioning (TSP) tree',\n",
              "  'distance': 0,\n",
              "  'no': '137',\n",
              "  'parent': '4303'},\n",
              " {'Abstract': \"VisIt is a richly featured visualization tool that is used to visualize some of the largest simulations ever run. The scale of these simulations requires that optimizations are incorporated into every operation VisIt performs. But the set of applicable optimizations that VisIt can perform is dependent on the types of operations being done. Complicating the issue, VisIt has a plugin capability that allows new, unforeseen components to be added, making it even harder to determine which optimizations can be applied. We introduce the concept of a contract to the standard data flow network design. This contract enables each component of the data flow network to modify the set of optimizations used. In addition, the contract allows for new components to be accommodated gracefully within VisIt's data flow network system.\",\n",
              "  'AuthorKeywords': ['large',\n",
              "   'data',\n",
              "   'set',\n",
              "   'visualization,',\n",
              "   'data',\n",
              "   'flow',\n",
              "   'networks,',\n",
              "   'contract-based',\n",
              "   'system'],\n",
              "  'MultipartiteRank': [{'score': 0.09475088723730972, 'word': 'optimizations'},\n",
              "   {'score': 0.08725190116946988, 'word': 'visit'},\n",
              "   {'score': 0.07412399024380938, 'word': 'contract'},\n",
              "   {'score': 0.07131212940088305, 'word': 'unforeseen'},\n",
              "   {'score': 0.07131212940088305, 'word': 'components'},\n",
              "   {'score': 0.06289967473892745, 'word': 'standard'},\n",
              "   {'score': 0.06289967473892745, 'word': 'data'},\n",
              "   {'score': 0.06289967473892745, 'word': 'flow'},\n",
              "   {'score': 0.06289967473892745, 'word': 'network'},\n",
              "   {'score': 0.06289967473892745, 'word': 'design'}],\n",
              "  'Title': 'A contract based system for large data visualization',\n",
              "  'distance': 0,\n",
              "  'no': '138',\n",
              "  'parent': '4360'},\n",
              " {'Abstract': 'We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'node-link',\n",
              "   'diagrams,',\n",
              "   'structural',\n",
              "   'comparison,',\n",
              "   'hierarchies,',\n",
              "   '3D',\n",
              "   'visualization,',\n",
              "   'edge',\n",
              "   'aggregation'],\n",
              "  'MultipartiteRank': [{'score': 0.14633479847744488,\n",
              "    'word': 'visualizations'},\n",
              "   {'score': 0.0705410762536212, 'word': 'relationships'},\n",
              "   {'score': 0.058138354608001784, 'word': 'side'},\n",
              "   {'score': 0.05482241882506743, 'word': 'multiple'},\n",
              "   {'score': 0.047854409015989, 'word': 'vislink'}],\n",
              "  'Title': 'VisLink: Revealing Relationships Amongst Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '139',\n",
              "  'parent': '3681'},\n",
              " {'Abstract': 'One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.',\n",
              "  'AuthorKeywords': ['Spatio-temporal',\n",
              "   'data,',\n",
              "   'movement',\n",
              "   'data,',\n",
              "   'trajectories,',\n",
              "   'clustering,',\n",
              "   'classification,',\n",
              "   'scalable',\n",
              "   'visualization,',\n",
              "   'geovisualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08047256324588406, 'word': 'objects'},\n",
              "   {'score': 0.06979195298487158, 'word': 'clustering'},\n",
              "   {'score': 0.0566170140969231, 'word': 'similar'},\n",
              "   {'score': 0.0566170140969231, 'word': 'properties'},\n",
              "   {'score': 0.050974918854798074, 'word': 'data'},\n",
              "   {'score': 0.04046421680059967, 'word': 'large'},\n",
              "   {'score': 0.04046421680059967, 'word': 'datasets'}],\n",
              "  'Title': 'Interactive visual clustering of large collections of trajectories',\n",
              "  'distance': 0,\n",
              "  'no': '140',\n",
              "  'parent': '4046'},\n",
              " {'Abstract': \"Visage is a prototype user interface environment for exploring and analyzing information. It represents an approach to coordinating multiple visualizations, analysis and presentation tools in data-intensive domains. Visage is based on an information-centric approach to user interface design which strives to eliminate impediments to direct user access to information objects across applications and visualizations. Visage consists of a set of data manipulation operations, an intelligent system for generating a wide variety of data visualizations (SAGE) and a briefing tool that supports the conversion of visual displays used during exploration into interactive presentation slides. This paper presents the user interface components and styles of interaction that are central to Visage's information-centric approach.\",\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'exploratory',\n",
              "   'data',\n",
              "   'analysis,',\n",
              "   'graphics,',\n",
              "   'user',\n",
              "   'interface',\n",
              "   'environment,',\n",
              "   'human-computer',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.07742984416411038, 'word': 'information'},\n",
              "   {'score': 0.07514363337195187, 'word': 'visage'},\n",
              "   {'score': 0.07116903489131507, 'word': 'multiple'},\n",
              "   {'score': 0.07116903489131507, 'word': 'visualizations'},\n",
              "   {'score': 0.06567203807661284, 'word': 'data'},\n",
              "   {'score': 0.06342646716167126, 'word': 'approach'}],\n",
              "  'Title': 'Visage: a user interface environment for exploring information',\n",
              "  'distance': 0,\n",
              "  'no': '141',\n",
              "  'parent': '3981'},\n",
              " {'Abstract': 'We propose an elementary operation on a pair of vector fields as a building block for defining and computing global line-type features of vector or scalar fields. While usual feature definitions often are procedural and therefore implicit, our operator allows precise mathematical definitions. It can serve as a basis for comparing feature definitions and for reuse of algorithms and implementations. Applications focus on vortex core methods.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11061977446392116, 'word': 'type'},\n",
              "   {'score': 0.11061977446392116, 'word': 'features'},\n",
              "   {'score': 0.10760946507800015, 'word': 'vector'},\n",
              "   {'score': 0.10760946507800015, 'word': 'fields'},\n",
              "   {'score': 0.07873401961208627, 'word': 'elementary'},\n",
              "   {'score': 0.07873401961208627, 'word': 'operation'},\n",
              "   {'score': 0.0663355381007553, 'word': 'pair'},\n",
              "   {'score': 0.05468840144025957, 'word': 'global'},\n",
              "   {'score': 0.05468840144025957, 'word': 'line'}],\n",
              "  'Title': 'The \"Parallel Vectors\" operator-a vector field visualization primitive',\n",
              "  'distance': 0,\n",
              "  'no': '142',\n",
              "  'parent': '3396'},\n",
              " {'Abstract': 'We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   'Isosurfaces,',\n",
              "   'Unstructured',\n",
              "   'Meshes,',\n",
              "   'Cell',\n",
              "   'Projection,',\n",
              "   'Graphics',\n",
              "   'Hardware,',\n",
              "   'Texture',\n",
              "   'Mapping,',\n",
              "   'Compositing'],\n",
              "  'MultipartiteRank': [{'score': 0.12675584035229642, 'word': 'extensions'},\n",
              "   {'score': 0.07759972354310624, 'word': 'algorithm'},\n",
              "   {'score': 0.06188877106629356, 'word': 'beneficial'},\n",
              "   {'score': 0.06188877106629356, 'word': 'rendering'},\n",
              "   {'score': 0.052799929730300815, 'word': 'multiple'},\n",
              "   {'score': 0.052799929730300815, 'word': 'shaded'},\n",
              "   {'score': 0.052799929730300815, 'word': 'isosurfaces'},\n",
              "   {'score': 0.04212126884065834, 'word': '3d'},\n",
              "   {'score': 0.04212126884065834, 'word': 'texture'},\n",
              "   {'score': 0.04212126884065834, 'word': 'mapping'}],\n",
              "  'Title': 'Hardware-accelerated volume and isosurface rendering based on cell-projection',\n",
              "  'distance': 0,\n",
              "  'no': '143',\n",
              "  'parent': '3618'},\n",
              " {'Abstract': 'Many real world graphs have small world characteristics, that is, they have a small diameter compared to the number of nodes and exhibit a local cluster structure. Examples are social networks, software structures, bibliographic references and biological neural nets. Their high connectivity makes both finding a pleasing layout and a suitable clustering hard. In this paper we present a method to create scalable, interactive visualizations of small world graphs, allowing the user to inspect local clusters while maintaining a global overview of the entire structure. The visualization method uses a combination of both semantical and geometrical distortions, while the layout is generated by a spring embedder algorithm using recently developed force model. We use a cross referenced database of 500 artists as a running example',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'Visualization,',\n",
              "   'Graph',\n",
              "   'Drawing,',\n",
              "   'Clustering,',\n",
              "   'Small',\n",
              "   'World',\n",
              "   'Graphs'],\n",
              "  'MultipartiteRank': [{'score': 0.09438503867072084, 'word': 'many'},\n",
              "   {'score': 0.09438503867072084, 'word': 'real'},\n",
              "   {'score': 0.09438503867072084, 'word': 'world'},\n",
              "   {'score': 0.09438503867072084, 'word': 'graphs'},\n",
              "   {'score': 0.0750172302874412, 'word': 'local'},\n",
              "   {'score': 0.0750172302874412, 'word': 'cluster'},\n",
              "   {'score': 0.0750172302874412, 'word': 'structure'},\n",
              "   {'score': 0.05599382618838479, 'word': 'software'},\n",
              "   {'score': 0.05599382618838479, 'word': 'structures'},\n",
              "   {'score': 0.05404039312004412, 'word': 'examples'},\n",
              "   {'score': 0.04311153629629551, 'word': 'social'},\n",
              "   {'score': 0.04311153629629551, 'word': 'networks'}],\n",
              "  'Title': 'Interactive Visualization of Small World Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '144',\n",
              "  'parent': '3821'},\n",
              " {'Abstract': 'Many traditional techniques for \"looking inside\" volumetric data involve removing portions of the data, for example using various cutting tools, to reveal the interior. This allows the user to see hidden parts of the data, but has the disadvantage of removing potentially important surrounding contextual information. We explore an alternate strategy for browsing that uses deformations, where the user can cut into and open up, spread apart, or peel away parts of the volume in real time, making the interior visible while still retaining surrounding context. We consider various deformation strategies and present a number of interaction techniques based on different metaphors. Our designs pay special attention to the semantic layers that might compose a volume (e.g. the skin, muscle, bone in a scan of a human). Users can apply deformations to only selected layers, or apply a given deformation to a different degree to each layer, making browsing more flexible and facilitating the visualization of relationships between layers. Our interaction techniques are controlled with direct, \"in place\" manipulation, using pop-up menus and 3D widgets, to avoid the divided attention and awkwardness that would come with panels of traditional widgets. Initial user feedback indicates that our techniques are valuable, especially for showing portions of the data spatially situated in context with surrounding data.',\n",
              "  'AuthorKeywords': ['volumetric',\n",
              "   'data,',\n",
              "   'volume',\n",
              "   'data,',\n",
              "   'deformations,',\n",
              "   'browsing,',\n",
              "   'layers,',\n",
              "   'interaction',\n",
              "   'techniques,',\n",
              "   '3D',\n",
              "   'widgets'],\n",
              "  'MultipartiteRank': [{'score': 0.08845304409070527, 'word': 'many'},\n",
              "   {'score': 0.08845304409070527, 'word': 'traditional'},\n",
              "   {'score': 0.08845304409070527, 'word': 'techniques'},\n",
              "   {'score': 0.0642238625544847, 'word': 'volumetric'},\n",
              "   {'score': 0.0642238625544847, 'word': 'data'},\n",
              "   {'score': 0.04457029677352217, 'word': 'user'},\n",
              "   {'score': 0.04074212917426615, 'word': 'deformations'},\n",
              "   {'score': 0.039915875742214814, 'word': 'semantic'},\n",
              "   {'score': 0.039915875742214814, 'word': 'layers'}],\n",
              "  'Title': 'Using deformations for browsing volumetric data',\n",
              "  'distance': 0,\n",
              "  'no': '145',\n",
              "  'parent': '5015'},\n",
              " {'Abstract': 'Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns.',\n",
              "  'AuthorKeywords': ['hierarchical',\n",
              "   'clustering,',\n",
              "   'graph',\n",
              "   'partitioning,',\n",
              "   'flow',\n",
              "   'mapping,',\n",
              "   'spatial',\n",
              "   'interaction,',\n",
              "   'contiguity',\n",
              "   'constraints,',\n",
              "   'multidimensional',\n",
              "   'visualization,',\n",
              "   'coordinated',\n",
              "   'views,',\n",
              "   'data',\n",
              "   'mining'],\n",
              "  'MultipartiteRank': [{'score': 0.05171642531250698, 'word': 'graph'},\n",
              "   {'score': 0.042768978239587446, 'word': 'county'},\n",
              "   {'score': 0.041522131068485575, 'word': 'geographic'},\n",
              "   {'score': 0.041522131068485575, 'word': 'patterns'},\n",
              "   {'score': 0.04068617552684972, 'word': 'geographical'},\n",
              "   {'score': 0.04068617552684972, 'word': 'regions'},\n",
              "   {'score': 0.040626007137645435, 'word': 'flow'}],\n",
              "  'Title': 'Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data',\n",
              "  'distance': 0,\n",
              "  'no': '146',\n",
              "  'parent': '4883'},\n",
              " {'Abstract': 'Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06417189534005649, 'word': 'time'},\n",
              "   {'score': 0.05831018741410577, 'word': 'social'},\n",
              "   {'score': 0.05831018741410577, 'word': 'media'},\n",
              "   {'score': 0.05831018741410577, 'word': 'services'},\n",
              "   {'score': 0.044836094296022665, 'word': 'data'},\n",
              "   {'score': 0.03907393887826461, 'word': 'large'},\n",
              "   {'score': 0.03907393887826461, 'word': 'volume'},\n",
              "   {'score': 0.03772827493882149, 'word': 'local'},\n",
              "   {'score': 0.03772827493882149, 'word': 'events'}],\n",
              "  'Title': 'Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition',\n",
              "  'distance': 0,\n",
              "  'no': '147',\n",
              "  'parent': '3939'},\n",
              " {'Abstract': 'Visualizations which depict entire information spaces provide context for navigation and browsing tasks; however, the limited size of the display screen makes creating effective global views difficult. We have developed a technique for displaying and navigating large information spaces. The key concept is the use of an information mural, a two-dimensional reduced representation of an entire information space that fits completely within a display window or screen. Information murals use grayscale shading and color along with anti-aliasing techniques to create a miniature version of the entire data set. By incorporating navigational capabilities, information murals become a tool that can be used as a global view along with more detailed informational displays. Information murals are utilized in our software visualization research to help depict the execution of object-oriented programs, and can also be used in more general information visualization applications.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17968323103362555, 'word': 'information'},\n",
              "   {'score': 0.0959845575617325, 'word': 'entire'},\n",
              "   {'score': 0.0959845575617325, 'word': 'spaces'},\n",
              "   {'score': 0.08369867347189303, 'word': 'mural'},\n",
              "   {'score': 0.06738711970730173, 'word': 'navigation'},\n",
              "   {'score': 0.06313935516956266, 'word': 'visualizations'},\n",
              "   {'score': 0.0618504301239914, 'word': 'display'},\n",
              "   {'score': 0.0618504301239914, 'word': 'screen'}],\n",
              "  'Title': 'The information mural: a technique for displaying and navigating large information spaces',\n",
              "  'distance': 0,\n",
              "  'no': '148',\n",
              "  'parent': '4834'},\n",
              " {'Abstract': 'Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks',\n",
              "  'AuthorKeywords': ['3-D',\n",
              "   'visualization,',\n",
              "   'spatiotemporal,',\n",
              "   'geospatial,',\n",
              "   'interactive',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'data',\n",
              "   'analysis,',\n",
              "   'link',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.0598659701004914, 'word': 'displaying'},\n",
              "   {'score': 0.056682827005357254, 'word': 'objective'},\n",
              "   {'score': 0.05574915037751366, 'word': 'time'},\n",
              "   {'score': 0.05559334303237364, 'word': 'novel'},\n",
              "   {'score': 0.05559334303237364, 'word': 'visualization'},\n",
              "   {'score': 0.05559334303237364, 'word': 'technique'},\n",
              "   {'score': 0.05386873717074746, 'word': 'geography'}],\n",
              "  'Title': 'GeoTime Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '149',\n",
              "  'parent': '3657'},\n",
              " {'Abstract': 'Recent years have seen an immense increase in the complexity of geometric data sets. Today\\'s gigabyte-sized polygon models can no longer be completely loaded into the main memory of common desktop PCs. Unfortunately, current mesh formats, which were designed years ago when meshes were orders of magnitudes smaller, do not account for this. Using such formats to store large meshes is inefficient and complicates all subsequent processing. We describe a streaming format for polygon meshes that is simple enough to replace current offline mesh formats and is more suitable for representing large data sets. Furthermore, it is an ideal input and output format for I/O-efficient out-of-core algorithms that process meshes in a streaming, possibly pipelined, fashion. This paper chiefly concerns the underlying theory and the practical aspects of creating and working with this new representation. In particular, we describe desirable qualities for streaming meshes and methods for converting meshes from a traditional to a streaming format. A central theme of this paper is the issue of coherent and compatible layouts of the mesh vertices and polygons. We present metrics and diagrams that characterize the coherence of a mesh layout and suggest appropriate strategies for improving its \"streamability\". To this end, we outline several out-of-core algorithms for reordering meshes with poor coherence, and present results for a menagerie of well known and generally incoherent surface meshes.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08268563475120991, 'word': 'meshes'},\n",
              "   {'score': 0.046965837326412976, 'word': 'recent'},\n",
              "   {'score': 0.046965837326412976, 'word': 'years'},\n",
              "   {'score': 0.04462143487549908, 'word': 'sized'},\n",
              "   {'score': 0.04462143487549908, 'word': 'polygon'},\n",
              "   {'score': 0.04462143487549908, 'word': 'models'},\n",
              "   {'score': 0.0364689691843785, 'word': 'geometric'},\n",
              "   {'score': 0.0364689691843785, 'word': 'data'},\n",
              "   {'score': 0.0364689691843785, 'word': 'sets'},\n",
              "   {'score': 0.03575646973031961, 'word': 'coherent'}],\n",
              "  'Title': 'Streaming meshes',\n",
              "  'distance': 0,\n",
              "  'no': '150',\n",
              "  'parent': '5763'},\n",
              " {'Abstract': 'In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'World',\n",
              "   'Wide',\n",
              "   'Web,',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'exploratory',\n",
              "   'search,',\n",
              "   'visual',\n",
              "   'information',\n",
              "   'seeking'],\n",
              "  'MultipartiteRank': [{'score': 0.11549333163159854, 'word': 'common'},\n",
              "   {'score': 0.11549333163159854, 'word': 'web'},\n",
              "   {'score': 0.08144175947493751, 'word': 'search'},\n",
              "   {'score': 0.08144175947493751, 'word': 'interfaces'},\n",
              "   {'score': 0.07335035098970327, 'word': 'queries'},\n",
              "   {'score': 0.0728479746479153, 'word': 'information'},\n",
              "   {'score': 0.042724016678698816, 'word': 'visgets'}],\n",
              "  'Title': 'VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery',\n",
              "  'distance': 0,\n",
              "  'no': '151',\n",
              "  'parent': '4477'},\n",
              " {'Abstract': \"General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.\",\n",
              "  'AuthorKeywords': ['User',\n",
              "   'interfaces,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'exploratory',\n",
              "   'analysis,',\n",
              "   'visualization',\n",
              "   'recommendation,',\n",
              "   'mixed-initiative',\n",
              "   'systems'],\n",
              "  'MultipartiteRank': [{'score': 0.15121518758700742, 'word': 'general'},\n",
              "   {'score': 0.15121518758700742, 'word': 'visualization'},\n",
              "   {'score': 0.15121518758700742, 'word': 'tools'},\n",
              "   {'score': 0.06856520085347989, 'word': 'manual'},\n",
              "   {'score': 0.06856520085347989, 'word': 'specification'},\n",
              "   {'score': 0.050017149593246886, 'word': 'voyager'},\n",
              "   {'score': 0.049247555927090604, 'word': 'data'},\n",
              "   {'score': 0.049247555927090604, 'word': 'variables'},\n",
              "   {'score': 0.048934783583357386, 'word': 'views'}],\n",
              "  'Title': 'Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations',\n",
              "  'distance': 0,\n",
              "  'no': '152',\n",
              "  'parent': '4017'},\n",
              " {'Abstract': 'A recently completed implementation of a virtual environment for exploring numerically generated three-dimensional unsteady flowfields is described. A boom-mounted six-degree-of-freedom head-position-sensitive stereo CRT system is used for viewing. A hand-position-sensitive glove controller is used for injecting various tracers (e.g. smoke) into the virtual flowfield. A multiprocessor graphics workstation is used for computation and rendering. The techniques for visualizing unsteady flows are described, and the computer requirements for a variety of visualization techniques are discussed. These techniques generalize to visualization of other 3D vector fields.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08925472176810272, 'word': 'position'},\n",
              "   {'score': 0.08630399086120712, 'word': 'techniques'},\n",
              "   {'score': 0.07319544956523326, 'word': 'computation'},\n",
              "   {'score': 0.07146913892099134, 'word': 'virtual'},\n",
              "   {'score': 0.07146913892099134, 'word': 'environment'},\n",
              "   {'score': 0.05291479646301836, 'word': 'rendering'}],\n",
              "  'Title': 'The virtual windtunnel: An environment for the exploration of three-dimensional unsteady flows',\n",
              "  'distance': 0,\n",
              "  'no': '153',\n",
              "  'parent': '3583'},\n",
              " {'Abstract': 'Since the introduction of standard techniques for isosurface extraction from volumetric datasets, one of the hardest problems has been to reduce the number of triangles (or polygons) generated. The paper presents an algorithm that considerably reduces the number of polygons generated by a Marching Cubes-like scheme (W. Lorensen and H. Cline, 1987) without excessively increasing the overall computational complexity. The algorithm assumes discretization of the dataset space and replaces cell edge interpolation by midpoint selection. Under these assumptions, the extracted surfaces are composed of polygons lying within a finite number of incidences, thus allowing simple merging of the output facets into large coplanar polygons. An experimental evaluation of the proposed approach on datasets related to biomedical imaging and chemical modelling is reported.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09426321196603198, 'word': 'polygons'},\n",
              "   {'score': 0.08043531776788454, 'word': 'number'},\n",
              "   {'score': 0.08012497640719715, 'word': 'volumetric'},\n",
              "   {'score': 0.08012497640719715, 'word': 'datasets'},\n",
              "   {'score': 0.05283068039832052, 'word': 'algorithm'},\n",
              "   {'score': 0.049054799337901904, 'word': 'isosurface'},\n",
              "   {'score': 0.049054799337901904, 'word': 'extraction'}],\n",
              "  'Title': 'Discretized Marching Cubes',\n",
              "  'distance': 0,\n",
              "  'no': '154',\n",
              "  'parent': '3586'},\n",
              " {'Abstract': 'We present efficient sequential and parallel algorithms for isosurface extraction. Based on the Span Space data representation, new data subdivision and searching methods are described. We also present a parallel implementation with an emphasis on load balancing. The performance of our sequential algorithm to locate the cell elements intersected by isosurfaces is faster than the Kd tree searching method originally used for the Span Space algorithm. The parallel algorithm can achieve high load balancing for massively parallel machines with distributed memory architectures.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14550016123860277, 'word': 'parallel'},\n",
              "   {'score': 0.14550016123860277, 'word': 'algorithms'},\n",
              "   {'score': 0.08579855095529833, 'word': 'isosurface'},\n",
              "   {'score': 0.08579855095529833, 'word': 'extraction'},\n",
              "   {'score': 0.08475299999996107, 'word': 'efficient'},\n",
              "   {'score': 0.08475299999996107, 'word': 'sequential'},\n",
              "   {'score': 0.07962184328495649, 'word': 'span'},\n",
              "   {'score': 0.07962184328495649, 'word': 'space'},\n",
              "   {'score': 0.07962184328495649, 'word': 'data'},\n",
              "   {'score': 0.07962184328495649, 'word': 'representation'},\n",
              "   {'score': 0.06910979468925856, 'word': 'load'},\n",
              "   {'score': 0.06910979468925856, 'word': 'balancing'}],\n",
              "  'Title': 'Isosurfacing in span space with utmost efficiency (ISSUE)',\n",
              "  'distance': 0,\n",
              "  'no': '155',\n",
              "  'parent': '3567'},\n",
              " {'Abstract': 'Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that \"tell a story\" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation.',\n",
              "  'AuthorKeywords': ['Rhetoric,',\n",
              "   'narrative',\n",
              "   'visualization,',\n",
              "   'framing',\n",
              "   'effects,',\n",
              "   'semiotics,',\n",
              "   'denotation,',\n",
              "   'connotation'],\n",
              "  'MultipartiteRank': [{'score': 0.2000173901238535, 'word': 'narrative'},\n",
              "   {'score': 0.2000173901238535, 'word': 'visualizations'},\n",
              "   {'score': 0.07376309982892526, 'word': 'conventions'},\n",
              "   {'score': 0.04841576799670325, 'word': 'communicative'},\n",
              "   {'score': 0.04505031963806437, 'word': 'exploratory'},\n",
              "   {'score': 0.04505031963806437, 'word': 'information'},\n",
              "   {'score': 0.04505031963806437, 'word': 'visualization'},\n",
              "   {'score': 0.03226335338370679, 'word': 'intended'},\n",
              "   {'score': 0.03226335338370679, 'word': 'story'}],\n",
              "  'Title': 'Visualization Rhetoric: Framing Effects in Narrative Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '156',\n",
              "  'parent': '5154'},\n",
              " {'Abstract': 'One of the most important goals in volume rendering is to be able to visually separate and selectively enable specific objects of interest contained in a single volumetric data set, which can be approached by using explicit segmentation information. We show how segmented data sets can be rendered interactively on current consumer graphics hardware with high image quality and pixel-resolution filtering of object boundaries. In order to enhance object perception, we employ different levels of object distinction. First, each object can be assigned an individual transfer function, multiple of which can be applied in a single rendering pass. Second, different rendering modes such as direct volume rendering, iso-surfacing, and non-photorealistic techniques can be selected for each object. A minimal number of rendering passes is achieved by processing sets of objects that share the same rendering mode in a single pass. Third, local compositing modes such as alpha blending and MIP can be selected for each object in addition to a single global mode, thus enabling high-quality two-level volume rendering on GPUs.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'rendering,',\n",
              "   'segmentation,',\n",
              "   'non-photorealistic',\n",
              "   'rendering,',\n",
              "   'consumer',\n",
              "   'graphics',\n",
              "   'hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.12531899362112586, 'word': 'specific'},\n",
              "   {'score': 0.12531899362112586, 'word': 'objects'},\n",
              "   {'score': 0.05892996890854762, 'word': 'single'},\n",
              "   {'score': 0.05892996890854762, 'word': 'volumetric'},\n",
              "   {'score': 0.05892996890854762, 'word': 'data'},\n",
              "   {'score': 0.05892996890854762, 'word': 'set'},\n",
              "   {'score': 0.05555382333664165, 'word': 'interest'},\n",
              "   {'score': 0.048808610342705894, 'word': 'volume'},\n",
              "   {'score': 0.048808610342705894, 'word': 'rendering'},\n",
              "   {'score': 0.041507045941647724, 'word': 'separate'}],\n",
              "  'Title': 'High-quality two-level volume rendering of segmented data sets on consumer graphics hardware',\n",
              "  'distance': 0,\n",
              "  'no': '157',\n",
              "  'parent': '4987'},\n",
              " {'Abstract': 'Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.',\n",
              "  'AuthorKeywords': ['Line',\n",
              "   'graphs,',\n",
              "   'braided',\n",
              "   'graphs,',\n",
              "   'horizon',\n",
              "   'graphs,',\n",
              "   'small',\n",
              "   'multiples,',\n",
              "   'stacked',\n",
              "   'graphs,',\n",
              "   'evaluation,',\n",
              "   'design',\n",
              "   'guidelines'],\n",
              "  'MultipartiteRank': [{'score': 0.1374067874262018, 'word': 'line'},\n",
              "   {'score': 0.1374067874262018, 'word': 'graphs'},\n",
              "   {'score': 0.08396946930212833, 'word': 'visualization'},\n",
              "   {'score': 0.07273980589361728, 'word': 'multiple'},\n",
              "   {'score': 0.07273980589361728, 'word': 'simultaneous'},\n",
              "   {'score': 0.07273980589361728, 'word': 'time'},\n",
              "   {'score': 0.07273980589361728, 'word': 'series'},\n",
              "   {'score': 0.061327853690459296, 'word': 'choice'},\n",
              "   {'score': 0.05367795166642701, 'word': 'comparison'}],\n",
              "  'Title': 'Graphical Perception of Multiple Time Series',\n",
              "  'distance': 0,\n",
              "  'no': '158',\n",
              "  'parent': '4380'},\n",
              " {'Abstract': \"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.\",\n",
              "  'AuthorKeywords': ['Data',\n",
              "   'cube,',\n",
              "   'Data',\n",
              "   'structures,',\n",
              "   'Interactive',\n",
              "   'exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.09875722666081768, 'word': 'time'},\n",
              "   {'score': 0.06889943378181004, 'word': 'data'},\n",
              "   {'score': 0.06226956307705671, 'word': 'exploration'},\n",
              "   {'score': 0.03221354345215391, 'word': 'real'},\n",
              "   {'score': 0.0308193863174162, 'word': 'nanocube'}],\n",
              "  'Title': 'Nanocubes for Real-Time Exploration of Spatiotemporal Datasets',\n",
              "  'distance': 0,\n",
              "  'no': '159',\n",
              "  'parent': '5630'},\n",
              " {'Abstract': 'Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.',\n",
              "  'AuthorKeywords': ['Event',\n",
              "   'sequences,',\n",
              "   'simplification,',\n",
              "   'electronic',\n",
              "   'heath',\n",
              "   'records,',\n",
              "   'temporal',\n",
              "   'query'],\n",
              "  'MultipartiteRank': [{'score': 0.08241776063494559, 'word': 'medical'},\n",
              "   {'score': 0.08241776063494559, 'word': 'research'},\n",
              "   {'score': 0.05936438441152405, 'word': 'noisy'},\n",
              "   {'score': 0.05936438441152405, 'word': 'datasets'},\n",
              "   {'score': 0.05352733177797375, 'word': 'record'},\n",
              "   {'score': 0.05352733177797375, 'word': 'analysis'},\n",
              "   {'score': 0.043818037969253494, 'word': 'ehrs'},\n",
              "   {'score': 0.032067613187478625, 'word': 'aggregated'},\n",
              "   {'score': 0.032067613187478625, 'word': 'display'}],\n",
              "  'Title': 'Temporal Event Sequence Simplification',\n",
              "  'distance': 0,\n",
              "  'no': '160',\n",
              "  'parent': '3712'},\n",
              " {'Abstract': 'The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.',\n",
              "  'AuthorKeywords': ['Isosurfaces,',\n",
              "   'contourtrees,',\n",
              "   'topological',\n",
              "   'simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.1523499495006891, 'word': 'contour'},\n",
              "   {'score': 0.1523499495006891, 'word': 'tree'},\n",
              "   {'score': 0.08907122378815521, 'word': 'isosurfaces'},\n",
              "   {'score': 0.07206345500951493, 'word': 'local'},\n",
              "   {'score': 0.07206345500951493, 'word': 'geometric'},\n",
              "   {'score': 0.07206345500951493, 'word': 'measures'},\n",
              "   {'score': 0.05104142714808255, 'word': 'volume'},\n",
              "   {'score': 0.04776833213300358, 'word': 'world'},\n",
              "   {'score': 0.04776833213300358, 'word': 'data'},\n",
              "   {'score': 0.04776833213300358, 'word': 'sets'}],\n",
              "  'Title': 'Simplifying flexible isosurfaces using local geometric measures',\n",
              "  'distance': 0,\n",
              "  'no': '161',\n",
              "  'parent': '4736'},\n",
              " {'Abstract': 'In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.',\n",
              "  'AuthorKeywords': ['Quality',\n",
              "   'Metrics,',\n",
              "   'High-Dimensional',\n",
              "   'Data',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.09831834875088445, 'word': 'quality'},\n",
              "   {'score': 0.09831834875088445, 'word': 'metrics'},\n",
              "   {'score': 0.05744487296718592, 'word': 'approach'},\n",
              "   {'score': 0.053396729670004646, 'word': 'paper'},\n",
              "   {'score': 0.04456691439088377, 'word': 'high'},\n",
              "   {'score': 0.040726596365118814, 'word': 'dimensional'},\n",
              "   {'score': 0.040726596365118814, 'word': 'data'}],\n",
              "  'Title': 'Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization',\n",
              "  'distance': 0,\n",
              "  'no': '162',\n",
              "  'parent': '4252'},\n",
              " {'Abstract': 'This paper introduces a novel representation, called the InfoCrystal, that can be used as a visualization tool as well as a visual query language to help users search for information. The InfoCrystal visualizes all the possible relationships among N concepts. Users can assign relevance weights to the concepts and use thresholding to select relationships of interest. The InfoCrystal allows users to specify Boolean as well as vector-space queries graphically. Arbitrarily complex queries can be created by using the InfoCrystals as building blocks and organizing them in a hierarchical structure. The InfoCrystal enables users to explore and filter information in a flexible, dynamic and interactive way.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'query',\n",
              "   'language,',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'graphical',\n",
              "   'user',\n",
              "   'interface,',\n",
              "   'human',\n",
              "   'factors'],\n",
              "  'MultipartiteRank': [{'score': 0.13200459466895637, 'word': 'infocrystal'},\n",
              "   {'score': 0.12383946841426652, 'word': 'users'},\n",
              "   {'score': 0.07146142962256966, 'word': 'concepts'},\n",
              "   {'score': 0.06971148618290735, 'word': 'possible'},\n",
              "   {'score': 0.06971148618290735, 'word': 'relationships'},\n",
              "   {'score': 0.057865279538135195, 'word': 'information'}],\n",
              "  'Title': 'InfoCrystal: A visual tool for information retrieval',\n",
              "  'distance': 0,\n",
              "  'no': '163',\n",
              "  'parent': '3708'},\n",
              " {'Abstract': 'We present a method for interactive rendering of large outdoor scenes. Complex polygonal plant models and whole plant populations are represented by relatively small sets of point and line primitives. This enables us to show landscapes faithfully using only a limited percentage of primitives. In addition, a hierarchical data structure allows us to smoothly reduce the geometrical representation to any desired number of primitives. The scene is hierarchically divided into local portions of geometry to achieve large reduction factors for distant regions. Additionally, the data reduction is adapted to the visual importance of geometric objects. This allows us to maintain the visual fidelity of the representation while reducing most of the geometry drastically. With our system, we are able to interactively render very complex landscapes with good visual quality.',\n",
              "  'AuthorKeywords': ['Synthetic',\n",
              "   'Plants,',\n",
              "   'Ecosystems,',\n",
              "   'Point-based',\n",
              "   'rendering,',\n",
              "   'Level-of-detail',\n",
              "   'Algorithms'],\n",
              "  'MultipartiteRank': [{'score': 0.136902365235472, 'word': 'primitives'},\n",
              "   {'score': 0.0861887919303532, 'word': 'line'},\n",
              "   {'score': 0.06406712013443647, 'word': 'large'},\n",
              "   {'score': 0.06406712013443647, 'word': 'outdoor'},\n",
              "   {'score': 0.06406712013443647, 'word': 'scenes'},\n",
              "   {'score': 0.05024193327422093, 'word': 'point'},\n",
              "   {'score': 0.04472143418902982, 'word': 'complex'},\n",
              "   {'score': 0.04472143418902982, 'word': 'polygonal'},\n",
              "   {'score': 0.04472143418902982, 'word': 'plant'},\n",
              "   {'score': 0.04472143418902982, 'word': 'models'}],\n",
              "  'Title': 'Interactive visualization of complex plant ecosystems',\n",
              "  'distance': 0,\n",
              "  'no': '164',\n",
              "  'parent': '3753'},\n",
              " {'Abstract': 'Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.',\n",
              "  'AuthorKeywords': ['Movement',\n",
              "   'data,',\n",
              "   'spatio-temporal',\n",
              "   'data,',\n",
              "   'aggregation,',\n",
              "   'scalable',\n",
              "   'visualization,',\n",
              "   'geovisualization'],\n",
              "  'MultipartiteRank': [{'score': 0.13724045167611112, 'word': 'data'},\n",
              "   {'score': 0.1177345833826122, 'word': 'movements'},\n",
              "   {'score': 0.06987242028166026, 'word': 'aggregation'},\n",
              "   {'score': 0.05339308699541688, 'word': 'movement'},\n",
              "   {'score': 0.05032618187992195, 'word': 'visual'},\n",
              "   {'score': 0.05032618187992195, 'word': 'analysis'}],\n",
              "  'Title': 'Spatio-temporal aggregation for visual analysis of movements',\n",
              "  'distance': 0,\n",
              "  'no': '165',\n",
              "  'parent': '3661'},\n",
              " {'Abstract': 'In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint \"goodness\" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests \"interesting\" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the \"interesting\" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.',\n",
              "  'AuthorKeywords': ['viewpoint',\n",
              "   'selection,',\n",
              "   'view',\n",
              "   'space',\n",
              "   'partitioning,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'entropy,',\n",
              "   'visibility'],\n",
              "  'MultipartiteRank': [{'score': 0.08234511793014533, 'word': 'view'},\n",
              "   {'score': 0.08234511793014533, 'word': 'selection'},\n",
              "   {'score': 0.08234511793014533, 'word': 'method'},\n",
              "   {'score': 0.04883697685363242, 'word': 'data'},\n",
              "   {'score': 0.04883697685363242, 'word': 'understanding'},\n",
              "   {'score': 0.0363351547109513, 'word': 'visualization'},\n",
              "   {'score': 0.03457127911251415, 'word': 'viewpoint'},\n",
              "   {'score': 0.034074966149170376, 'word': 'interesting'},\n",
              "   {'score': 0.034074966149170376, 'word': 'viewpoints'}],\n",
              "  'Title': 'View selection for volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '166',\n",
              "  'parent': '4174'},\n",
              " {'Abstract': 'Front-projection display environments suffer from a fundamental problem: users and other objects in the environment can easily and inadvertently block projectors, creating shadows on the displayed image. We introduce a technique that detects and corrects transient shadows in a multi-projector display. Our approach is to minimize the difference between predicted (generated) and observed (camera) images by continuous modification of the projected image values for each display device. We speculate that the general predictive monitoring framework introduced here is capable of addressing more general radiometric consistency problems. Using an automatically-derived relative position of cameras and projectors in the display environment and a straightforward color correction scheme, the system renders an expected image for each camera location. Cameras observe the displayed image, which is compared with the expected image to detect shadowed regions. These regions are transformed to the appropriate projector frames, where corresponding pixel values are increased. In display regions where more than one projector contributes to the image, shadow regions are eliminated. We demonstrate an implementation of the technique in a multiprojector system.',\n",
              "  'AuthorKeywords': ['Large-scale',\n",
              "   'display,',\n",
              "   'shadow',\n",
              "   'removal,',\n",
              "   'immersive',\n",
              "   'media,',\n",
              "   'calibration'],\n",
              "  'MultipartiteRank': [{'score': 0.10888775657861097, 'word': 'image'},\n",
              "   {'score': 0.08307943027446345, 'word': 'projection'},\n",
              "   {'score': 0.08307943027446345, 'word': 'display'},\n",
              "   {'score': 0.08307943027446345, 'word': 'environments'},\n",
              "   {'score': 0.07471936452461328, 'word': 'block'},\n",
              "   {'score': 0.07471936452461328, 'word': 'projectors'},\n",
              "   {'score': 0.0643469072721963, 'word': 'camera'},\n",
              "   {'score': 0.057821719040769284, 'word': 'shadows'}],\n",
              "  'Title': 'Dynamic Shadow Removal from Front Projection Displays',\n",
              "  'distance': 0,\n",
              "  'no': '167',\n",
              "  'parent': '4362'},\n",
              " {'Abstract': \"This paper describes Thread Arcs, a novel interactive visualization technique designed to help people use threads found in email. Thread Arcs combine the chronology of messages with the branching tree structure of a conversational thread in a mixed-model visualization by Venolia and Neustaedter (2003) that is stable and compact. By quickly scanning and interacting with Thread Arcs, people can see various attributes of conversations and find relevant messages in them easily. We tested this technique against other visualization techniques with users' own email in a functional prototype email client. Thread Arcs proved an excellent match for the types of threads found in users' email for the qualities users wanted in small-scale visualizations.\",\n",
              "  'AuthorKeywords': ['conversations,',\n",
              "   'discussions,',\n",
              "   'electronic',\n",
              "   'mail,',\n",
              "   'email,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'threads,',\n",
              "   'tree',\n",
              "   'structures,',\n",
              "   'user',\n",
              "   'interfaces'],\n",
              "  'MultipartiteRank': [{'score': 0.1827233284615167, 'word': 'thread'},\n",
              "   {'score': 0.13012771997991168, 'word': 'arcs'},\n",
              "   {'score': 0.052595608481605015, 'word': 'conversational'},\n",
              "   {'score': 0.050265360080355065, 'word': 'messages'},\n",
              "   {'score': 0.05010539351786095, 'word': 'model'},\n",
              "   {'score': 0.05010539351786095, 'word': 'visualization'},\n",
              "   {'score': 0.04997001788359227, 'word': 'email'}],\n",
              "  'Title': 'Thread Arcs: an email thread visualization',\n",
              "  'distance': 0,\n",
              "  'no': '168',\n",
              "  'parent': '4036'},\n",
              " {'Abstract': 'We present a new visualization method for 2D flows which allows us to combine multiple data values in an image for simultaneous viewing. We utilize concepts from oil painting, art and design as introduced in (Laidlaw et al., 1998) to examine problems within fluid mechanics. We use a combination of discrete and continuous visual elements arranged in multiple layers to visually represent the data. The representations are inspired by the brush strokes artists apply in layers to create an oil painting. We display commonly visualized quantities such as velocity and vorticity together with three additional mathematically derived quantities: the rate of strain tensor, and the turbulent charge and turbulent current. We describe the motivation for simultaneously examining these quantities and use the motivation to guide our choice of visual representation for each particular quantity. We present visualizations of three flow examples and observations concerning some of the physical relationships made apparent by the simultaneous display technique that we employed.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09034343164463013, 'word': 'new'},\n",
              "   {'score': 0.09034343164463013, 'word': 'visualization'},\n",
              "   {'score': 0.09034343164463013, 'word': 'method'},\n",
              "   {'score': 0.060869828646176856, 'word': '2d'},\n",
              "   {'score': 0.060869828646176856, 'word': 'flows'},\n",
              "   {'score': 0.049000831282895035, 'word': 'multiple'},\n",
              "   {'score': 0.049000831282895035, 'word': 'data'},\n",
              "   {'score': 0.049000831282895035, 'word': 'values'},\n",
              "   {'score': 0.04665443502738303, 'word': 'oil'},\n",
              "   {'score': 0.04665443502738303, 'word': 'painting'},\n",
              "   {'score': 0.045442873686492004, 'word': 'quantities'}],\n",
              "  'Title': 'Visualizing Multivalued Data from 2D Incompressible Flows Using Concepts from Painting',\n",
              "  'distance': 0,\n",
              "  'no': '169',\n",
              "  'parent': '4368'},\n",
              " {'Abstract': 'We present a novel approach to visualize and explore unstructured text. The underlying technology, called TOPIC-O-GRAPHY/sup TM/, applies wavelet transforms to a custom digital signal constructed from words within a document. The resultant multiresolution wavelet energy is used to analyze the characteristics of the narrative flow in the frequency domain, such as theme changes, which is then related to the overall thematic content of the text document using statistical methods. The thematic characteristics of a document can be analyzed at varying degrees of detail, ranging from section-sized text partitions to partitions consisting of a few words. Using this technology, we are developing a visualization system prototype known as TOPIC ISLANDS to browse a document, generate fuzzy document outlines, summarize text by levels of detail and according to user interests, define meaningful subdocuments, query text content, and provide summaries of topic evolution.',\n",
              "  'AuthorKeywords': ['text',\n",
              "   'visualization,',\n",
              "   'information',\n",
              "   'visualization,wavelet',\n",
              "   'transform,',\n",
              "   'information',\n",
              "   'retrieval'],\n",
              "  'MultipartiteRank': [{'score': 0.08875746593223656, 'word': 'document'},\n",
              "   {'score': 0.05831705951357182, 'word': 'topic'},\n",
              "   {'score': 0.05789816137287058, 'word': 'unstructured'},\n",
              "   {'score': 0.05789816137287058, 'word': 'text'},\n",
              "   {'score': 0.04835748987826172, 'word': 'technology'},\n",
              "   {'score': 0.04483293229639381, 'word': 'characteristics'}],\n",
              "  'Title': 'TOPIC ISLANDS TM - a wavelet-based text visualization system',\n",
              "  'distance': 0,\n",
              "  'no': '170',\n",
              "  'parent': '3961'},\n",
              " {'Abstract': 'The recently introduced notion of Finite-Time Lyapunov Exponent to characterize Coherent Lagrangian Structures provides a powerful framework for the visualization and analysis of complex technical flows. Its definition is simple and intuitive, and it has a deep theoretical foundation. While the application of this approach seems straightforward in theory, the associated computational cost is essentially prohibitive. Due to the Lagrangian nature of this technique, a huge number of particle paths must be computed to fill the space-time flow domain. In this paper, we propose a novel scheme for the adaptive computation of FTLE fields in two and three dimensions that significantly reduces the number of required particle paths. Furthermore, for three-dimensional flows, we show on several examples that meaningful results can be obtained by restricting the analysis to a well-chosen plane intersecting the flow domain. Finally, we examine some of the visualization aspects of FTLE-based methods and introduce several new variations that help in the analysis of specific aspects of a flow.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'feature',\n",
              "   'detection,',\n",
              "   '3D',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.055813331635129464, 'word': 'time'},\n",
              "   {'score': 0.055813331635129464, 'word': 'flow'},\n",
              "   {'score': 0.055813331635129464, 'word': 'domain'},\n",
              "   {'score': 0.04914357438969119, 'word': 'analysis'},\n",
              "   {'score': 0.0416714652248459, 'word': 'particle'},\n",
              "   {'score': 0.0416714652248459, 'word': 'paths'},\n",
              "   {'score': 0.04130350140651927, 'word': 'huge'},\n",
              "   {'score': 0.04130350140651927, 'word': 'number'},\n",
              "   {'score': 0.03686942407884301, 'word': 'visualization'}],\n",
              "  'Title': 'Efficient Computation and Visualization of Coherent Structures in Fluid Flow Applications',\n",
              "  'distance': 0,\n",
              "  'no': '171',\n",
              "  'parent': '4718'},\n",
              " {'Abstract': 'The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.',\n",
              "  'AuthorKeywords': ['Transfer',\n",
              "   'Functions,',\n",
              "   'Interactive',\n",
              "   'Visualization,',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   'Scale',\n",
              "   'Space,',\n",
              "   'GPU',\n",
              "   'Techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.07877295026866653, 'word': 'size'},\n",
              "   {'score': 0.06469003566875903, 'word': 'features'},\n",
              "   {'score': 0.053437217764931266, 'word': 'segment'},\n",
              "   {'score': 0.053437217764931266, 'word': 'volume'},\n",
              "   {'score': 0.053437217764931266, 'word': 'data'},\n",
              "   {'score': 0.044669353084872354, 'word': 'transfer'},\n",
              "   {'score': 0.044669353084872354, 'word': 'functions'},\n",
              "   {'score': 0.043746433799768725, 'word': 'local'},\n",
              "   {'score': 0.043746433799768725, 'word': 'scale'}],\n",
              "  'Title': 'Size-based Transfer Functions: A New Volume Exploration Technique',\n",
              "  'distance': 0,\n",
              "  'no': '172',\n",
              "  'parent': '5170'},\n",
              " {'Abstract': 'It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.',\n",
              "  'AuthorKeywords': ['Empirical',\n",
              "   'study,',\n",
              "   'visualization,',\n",
              "   'visualization',\n",
              "   'construction,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'visual',\n",
              "   'mapping,',\n",
              "   'novices'],\n",
              "  'MultipartiteRank': [{'score': 0.13443915960733538,\n",
              "    'word': 'visualizations'},\n",
              "   {'score': 0.04564382685611549, 'word': 'information'},\n",
              "   {'score': 0.04564382685611549, 'word': 'visualization'},\n",
              "   {'score': 0.04564382685611549, 'word': 'novices'},\n",
              "   {'score': 0.04474418567153207, 'word': 'data'},\n",
              "   {'score': 0.04474418567153207, 'word': 'attribute'},\n",
              "   {'score': 0.04474418567153207, 'word': 'selection'},\n",
              "   {'score': 0.03814772814986507, 'word': 'participants'},\n",
              "   {'score': 0.03463349096123526, 'word': 'major'},\n",
              "   {'score': 0.03463349096123526, 'word': 'barriers'}],\n",
              "  'Title': 'How Information Visualization Novices Construct Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '173',\n",
              "  'parent': '3994'},\n",
              " {'Abstract': \"The one-to-one strategy of mapping each single data item into a graphical marker adopted in many visualization techniques has limited usefulness when the number of records and/or the dimensionality of the data set are very high. In this situation, the strong overlapping of graphical markers severely hampers the user's ability to identify patterns in the data from its visual representation. We tackle this problem here with a strategy that computes frequency or density information from the data set, and uses such information in parallel coordinates visualizations to filter out the information to be presented to the user, thus reducing visual clutter and allowing the analyst to observe relevant patterns in the data. The algorithms to construct such visualizations, and the interaction mechanisms supported, inspired by traditional image processing techniques such as grayscale manipulation and thresholding are also presented. We also illustrate how such algorithms can assist users to effectively identify clusters in very noisy large data sets\",\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'clustering,',\n",
              "   'density-based',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'data',\n",
              "   'mining'],\n",
              "  'MultipartiteRank': [{'score': 0.10416270371287688, 'word': 'data'},\n",
              "   {'score': 0.05968508958816152, 'word': 'user'},\n",
              "   {'score': 0.05311493185711813, 'word': 'patterns'},\n",
              "   {'score': 0.0517963893934523, 'word': 'graphical'},\n",
              "   {'score': 0.0517963893934523, 'word': 'marker'},\n",
              "   {'score': 0.04779271658007406, 'word': 'visual'},\n",
              "   {'score': 0.04779271658007406, 'word': 'representation'}],\n",
              "  'Title': 'Uncovering Clusters in Crowded Parallel Coordinates Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '174',\n",
              "  'parent': '3976'},\n",
              " {'Abstract': 'Large number of dimensions not only cause clutter in multi-dimensional visualizations, but also make it difficult for users to navigate the data space. Effective dimension management, such as dimension ordering, spacing and filtering, is critical for visual exploration of such datasets. Dimension ordering and spacing explicitly reveal dimension relationships in arrangement-sensitive multidimensional visualization techniques, such as parallel coordinates, star glyphs, and pixel-oriented techniques. They facilitate the visual discovery of patterns within the data. Dimension filtering hides some of the dimensions to reduce clutter while preserving the major information of the dataset. In this paper, we propose an interactive hierarchical dimension ordering, spacing and filtering approach, called DOSFA. DOSFA is based on dimension hierarchies derived from similarities among dimensions. It is scalable multi-resolution approach making dimensional management a tractable task. On the one hand, it automatically generates default settings for dimension ordering, spacing and filtering. On the other hand, it allows users to efficiently control all aspects of this dimension management process via visual interaction tools for dimension hierarchy manipulation. A case study visualizing a dataset containing over 200 dimensions reveals high dimensional visualization techniques.',\n",
              "  'AuthorKeywords': ['Dimension',\n",
              "   'ordering,',\n",
              "   'dimension',\n",
              "   'spacing,',\n",
              "   'dimension',\n",
              "   'filtering,',\n",
              "   'multidimensional',\n",
              "   'visualization,',\n",
              "   'high',\n",
              "   'dimensional',\n",
              "   'datasets'],\n",
              "  'MultipartiteRank': [{'score': 0.16164691461588945, 'word': 'dimensions'},\n",
              "   {'score': 0.07147840312960363, 'word': 'dimension'},\n",
              "   {'score': 0.03725103949060019, 'word': 'ordering'},\n",
              "   {'score': 0.03650420594396124, 'word': 'data'},\n",
              "   {'score': 0.03650420594396124, 'word': 'space'},\n",
              "   {'score': 0.03596208572143648, 'word': 'sensitive'},\n",
              "   {'score': 0.03596208572143648, 'word': 'multidimensional'},\n",
              "   {'score': 0.03596208572143648, 'word': 'visualization'},\n",
              "   {'score': 0.03596208572143648, 'word': 'techniques'},\n",
              "   {'score': 0.03422736363900343, 'word': 'effective'},\n",
              "   {'score': 0.03422736363900343, 'word': 'management'}],\n",
              "  'Title': 'Interactive hierarchical dimension ordering, spacing and filtering for exploration of high dimensional datasets',\n",
              "  'distance': 0,\n",
              "  'no': '175',\n",
              "  'parent': '5152'},\n",
              " {'Abstract': \"Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.\",\n",
              "  'AuthorKeywords': ['Tag',\n",
              "   'clouds,',\n",
              "   'trend',\n",
              "   'visualization,',\n",
              "   'multiple',\n",
              "   'line',\n",
              "   'graphs,',\n",
              "   'stacked',\n",
              "   'bar',\n",
              "   'charts,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.22378653413209768, 'word': 'tag'},\n",
              "   {'score': 0.22378653413209768, 'word': 'clouds'},\n",
              "   {'score': 0.08221078484317515, 'word': 'trends'},\n",
              "   {'score': 0.048076924207359026, 'word': 'time'},\n",
              "   {'score': 0.04503197122967109, 'word': 'sparkclouds'},\n",
              "   {'score': 0.035484670693775554, 'word': 'interesting'},\n",
              "   {'score': 0.035484670693775554, 'word': 'discussions'}],\n",
              "  'Title': 'SparkClouds: Visualizing Trends in Tag Clouds',\n",
              "  'distance': 0,\n",
              "  'no': '176',\n",
              "  'parent': '4624'},\n",
              " {'Abstract': 'We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.',\n",
              "  'AuthorKeywords': ['Evaluation,',\n",
              "   'validation,',\n",
              "   'systematic',\n",
              "   'review,',\n",
              "   'visualization,',\n",
              "   'scientific',\n",
              "   'visualization,',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.14951147787652663, 'word': 'evaluation'},\n",
              "   {'score': 0.09817072992601486, 'word': 'practices'},\n",
              "   {'score': 0.05111422063940951, 'word': 'ieee'},\n",
              "   {'score': 0.05111422063940951, 'word': 'visualization'},\n",
              "   {'score': 0.05111422063940951, 'word': 'conference'},\n",
              "   {'score': 0.04671140695233413, 'word': 'papers'},\n",
              "   {'score': 0.03816010659853946, 'word': 'goal'}],\n",
              "  'Title': 'A Systematic Review on the Practice of Evaluating Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '177',\n",
              "  'parent': '5979'},\n",
              " {'Abstract': 'Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.',\n",
              "  'AuthorKeywords': ['multi-valued',\n",
              "   'visualization,',\n",
              "   'tensor',\n",
              "   'field',\n",
              "   'visualization,oil',\n",
              "   'painting'],\n",
              "  'MultipartiteRank': [{'score': 0.06775233917092038, 'word': 'new'},\n",
              "   {'score': 0.06775233917092038, 'word': 'methods'},\n",
              "   {'score': 0.0433533564823395, 'word': 'ellipsoids'},\n",
              "   {'score': 0.043078156108513954, 'word': 'diffusion'},\n",
              "   {'score': 0.043078156108513954, 'word': 'rate'},\n",
              "   {'score': 0.04082193869918137, 'word': 'dti'},\n",
              "   {'score': 0.03547602716697829, 'word': 'values'}],\n",
              "  'Title': 'Visualizing diffusion tensor images of the mouse spinal cord',\n",
              "  'distance': 0,\n",
              "  'no': '178',\n",
              "  'parent': '5944'},\n",
              " {'Abstract': 'Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.',\n",
              "  'AuthorKeywords': ['Ranking',\n",
              "   'visualization,',\n",
              "   'ranking,',\n",
              "   'scoring,',\n",
              "   'multi-attribute,',\n",
              "   'multifactorial,',\n",
              "   'multi-faceted,',\n",
              "   'stacked',\n",
              "   'bar',\n",
              "   'charts'],\n",
              "  'MultipartiteRank': [{'score': 0.11397313646454166, 'word': 'rankings'},\n",
              "   {'score': 0.09898519962132286, 'word': 'attributes'},\n",
              "   {'score': 0.06402528236360013, 'word': 'items'},\n",
              "   {'score': 0.036497138334900266, 'word': 'visualization'},\n",
              "   {'score': 0.02600464321807348, 'word': 'multiple'},\n",
              "   {'score': 0.02600464321807348, 'word': 'heterogeneous'}],\n",
              "  'Title': 'LineUp: Visual Analysis of Multi-Attribute Rankings',\n",
              "  'distance': 0,\n",
              "  'no': '179',\n",
              "  'parent': '4905'},\n",
              " {'Abstract': 'Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.',\n",
              "  'AuthorKeywords': ['Latent',\n",
              "   'Dirichlet',\n",
              "   'allocation,',\n",
              "   'nonnegative',\n",
              "   'matrix',\n",
              "   'factorization,',\n",
              "   'topic',\n",
              "   'modeling,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'interactive',\n",
              "   'clustering,',\n",
              "   'text',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.1473975894305235, 'word': 'modeling'},\n",
              "   {'score': 0.1127619196896843, 'word': 'user'},\n",
              "   {'score': 0.10602188343053268, 'word': 'topic'},\n",
              "   {'score': 0.06743094380153765, 'word': 'feedback'},\n",
              "   {'score': 0.052963088636282005, 'word': 'utopian'},\n",
              "   {'score': 0.04137570599999083, 'word': 'probabilistic'},\n",
              "   {'score': 0.04137570599999083, 'word': 'graphical'}],\n",
              "  'Title': 'UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization',\n",
              "  'distance': 0,\n",
              "  'no': '180',\n",
              "  'parent': '4971'},\n",
              " {'Abstract': 'We present a novel out-of-core technique for the interactive computation of isosurfaces from volume data. Our algorithm minimizes the main memory and disk space requirements on the visualization workstation, while speeding up isosurface extraction queries. Our overall approach is a two-level indexing scheme. First, by our meta-cell technique, we partition the original dataset into clusters of cells, called meta-cells. Secondly, we produce meta-intervals associated with the meta-cells, and build an indexing data structure on the meta-intervals. We separate the cell information, kept only in meta-cells on disk, from the indexing structure, which is also on disk and only contains pointers to meta-cells. Our meta-cell technique is an I/O-efficient approach for computing a k-d-tree-like partition of the dataset. Our indexing data structure, the binary blocked I/O interval tree, is a new I/O-optimal data structure to perform stabbing queries that report from a set of meta-intervals (or intervals) those containing a query value q. Our tree is simpler to implement, and is also more space-efficient in practice than existing structures. To perform an isosurface query, we first query the indexing structure, and then use the reported meta-cell pointers to read from disk the active meta-cells intersected by the isosurface. The isosurface itself can then be generated from active meta-cells. Rather than being a single cost indexing approach, our technique exhibits a smooth trade-off between query time and disk space.',\n",
              "  'AuthorKeywords': ['Isosurface',\n",
              "   'Extraction,',\n",
              "   'Marching',\n",
              "   'Cubes,',\n",
              "   'Out-Of-Core',\n",
              "   'Computation,',\n",
              "   'Interval',\n",
              "   'Tree,',\n",
              "   'Scientific',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.11184027722028657, 'word': 'meta'},\n",
              "   {'score': 0.0768589381099639, 'word': 'cells'},\n",
              "   {'score': 0.05300132868888664, 'word': 'disk'},\n",
              "   {'score': 0.05300132868888664, 'word': 'space'},\n",
              "   {'score': 0.05300132868888664, 'word': 'requirements'},\n",
              "   {'score': 0.05241455704858026, 'word': 'isosurfaces'},\n",
              "   {'score': 0.051130617118797746, 'word': 'indexing'},\n",
              "   {'score': 0.051130617118797746, 'word': 'data'},\n",
              "   {'score': 0.051130617118797746, 'word': 'structure'}],\n",
              "  'Title': 'Interactive out-of-core isosurface extraction',\n",
              "  'distance': 0,\n",
              "  'no': '181',\n",
              "  'parent': '5961'},\n",
              " {'Abstract': 'An association rule in data mining is an implication of the form X/spl rarr/Y where X is a set of antecedent items and Y is the consequent item. For years researchers have developed many tools to visualize association rules. However, few of these tools can handle more than dozens of rules, and none of them can effectively manage rules with multiple antecedents. Thus, it is extremely difficult to visualize and understand the association information of a large data set even when all the rules are available. This paper presents a novel visualization technique to tackle many of these problems. We apply the technology to a text mining study on large corpora. The results indicate that our design can easily handle hundreds of multiple antecedent association rules in a three-dimensional display with minimum human interaction, low occlusion percentage, and no screen swapping.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15263075536681128, 'word': 'association'},\n",
              "   {'score': 0.15263075536681128, 'word': 'rule'},\n",
              "   {'score': 0.06330398744851516, 'word': 'data'},\n",
              "   {'score': 0.06330398744851516, 'word': 'mining'},\n",
              "   {'score': 0.055221645111548374, 'word': 'many'},\n",
              "   {'score': 0.055221645111548374, 'word': 'tools'},\n",
              "   {'score': 0.0551445030679749, 'word': 'antecedent'},\n",
              "   {'score': 0.0551445030679749, 'word': 'items'},\n",
              "   {'score': 0.047026865922301764, 'word': 'rules'}],\n",
              "  'Title': 'Visualizing association rules for text mining',\n",
              "  'distance': 0,\n",
              "  'no': '182',\n",
              "  'parent': '4132'},\n",
              " {'Abstract': 'One of the reasons that topological methods have a limited popularity for the visualization of complex 3D flow fields is the fact that such topological structures contain a number of separating stream surfaces. Since these stream surfaces tend to hide each other as well as other topological features, for complex 3D topologies the visualizations become cluttered and hardly interpretable. This paper proposes to use particular stream lines called saddle connectors instead of separating stream surfaces and to depict single surfaces only on user demand. We discuss properties and computational issues of saddle connectors and apply these methods to complex flow data. We show that the use of saddle connectors makes topological skeletons available as a valuable visualization tool even for topologically complex 3D flow data.',\n",
              "  'AuthorKeywords': ['3D',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'topology,',\n",
              "   'critical',\n",
              "   'points,',\n",
              "   'separatrices'],\n",
              "  'MultipartiteRank': [{'score': 0.10610068460110476, 'word': 'complex'},\n",
              "   {'score': 0.10610068460110476, 'word': '3d'},\n",
              "   {'score': 0.10610068460110476, 'word': 'flow'},\n",
              "   {'score': 0.10610068460110476, 'word': 'fields'},\n",
              "   {'score': 0.10313409898647341, 'word': 'visualization'},\n",
              "   {'score': 0.08054130175452726, 'word': 'stream'},\n",
              "   {'score': 0.08054130175452726, 'word': 'surfaces'},\n",
              "   {'score': 0.07102575789211195, 'word': 'saddle'},\n",
              "   {'score': 0.07102575789211195, 'word': 'connectors'},\n",
              "   {'score': 0.06680417014944329, 'word': 'topological'},\n",
              "   {'score': 0.06680417014944329, 'word': 'methods'}],\n",
              "  'Title': 'Saddle connectors - an approach to visualizing the topological skeleton of complex 3D vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '183',\n",
              "  'parent': '4399'},\n",
              " {'Abstract': 'We present the first implementation of a volume ray casting algorithm for tetrahedral meshes running on off-the-shelf programmable graphics hardware. Our implementation avoids the memory transfer bottleneck of the graphics bus since the complete mesh data is stored in the local memory of the graphics adapter and all computations, in particular ray traversal and ray integration, are performed by the graphics processing unit. Analogously to other ray casting algorithms, our algorithm does not require an expensive cell sorting. Provided that the graphics adapter offers enough texture memory, our implementation performs comparable to the fastest published volume rendering algorithms for unstructured meshes. Our approach works with cyclic and/or non-convex meshes and supports early ray termination. Accurate ray integration is guaranteed by applying pre-integrated volume rendering. In order to achieve almost interactive modifications of transfer functions, we propose a new method for computing three-dimensional pre-integration tables.',\n",
              "  'AuthorKeywords': ['ray',\n",
              "   'casting,',\n",
              "   'pixel',\n",
              "   'shading,',\n",
              "   'programmable',\n",
              "   'graphics',\n",
              "   'hardware,',\n",
              "   'cell',\n",
              "   'projection,',\n",
              "   'tetrahedral',\n",
              "   'meshes,',\n",
              "   'unstructured',\n",
              "   'meshes,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'pre-integrated',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.09967106840259002, 'word': 'algorithm'},\n",
              "   {'score': 0.08467387231044218, 'word': 'first'},\n",
              "   {'score': 0.08467387231044218, 'word': 'implementation'},\n",
              "   {'score': 0.06989123119803735, 'word': 'graphics'},\n",
              "   {'score': 0.06989123119803735, 'word': 'bus'},\n",
              "   {'score': 0.06973829775258399, 'word': 'volume'},\n",
              "   {'score': 0.06973829775258399, 'word': 'ray'},\n",
              "   {'score': 0.05937766706616409, 'word': 'tetrahedral'},\n",
              "   {'score': 0.05937766706616409, 'word': 'meshes'}],\n",
              "  'Title': 'Hardware-based ray casting for tetrahedral meshes',\n",
              "  'distance': 0,\n",
              "  'no': '184',\n",
              "  'parent': '3842'},\n",
              " {'Abstract': 'Fiber tracking is a standard approach for the visualization of the results of diffusion tensor imaging (DTI). If fibers are reconstructed and visualized individually through the complete white matter, the display gets easily cluttered making it difficult to get insight in the data. Various clustering techniques have been proposed to automatically obtain bundles that should represent anatomical structures, but it is unclear which clustering methods and parameter settings give the best results. We propose a framework to validate clustering methods for white-matter fibers. Clusters are compared with a manual classification which is used as a ground truth. For the quantitative evaluation of the methods, we developed a new measure to assess the difference between the ground truth and the clusterings. The measure was validated and calibrated by presenting different clusterings to physicians and asking them for their judgement. We found that the values of our new measure for different clusterings match well with the opinions of physicians. Using this framework, we have evaluated different clustering algorithms, including shared nearest neighbor clustering, which has not been used before for this purpose. We found that the use of hierarchical clustering using single-link and a fiber similarity measure based on the mean distance between fibers gave the best results.',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'Tensor',\n",
              "   'Imaging,',\n",
              "   'Fiber',\n",
              "   'tracking,',\n",
              "   'Clustering,Clustering',\n",
              "   'Validation,',\n",
              "   'External',\n",
              "   'Indices'],\n",
              "  'MultipartiteRank': [{'score': 0.11062562952366371, 'word': 'fiber'},\n",
              "   {'score': 0.11062562952366371, 'word': 'tracking'},\n",
              "   {'score': 0.053317064788870626, 'word': 'clustering'},\n",
              "   {'score': 0.053317064788870626, 'word': 'methods'},\n",
              "   {'score': 0.04796589197294787, 'word': 'results'},\n",
              "   {'score': 0.04111664602612249, 'word': 'new'},\n",
              "   {'score': 0.04111664602612249, 'word': 'measure'},\n",
              "   {'score': 0.040243208101920606, 'word': 'difference'}],\n",
              "  'Title': 'Evaluation of fiber clustering methods for diffusion tensor imaging',\n",
              "  'distance': 0,\n",
              "  'no': '185',\n",
              "  'parent': '4689'},\n",
              " {'Abstract': 'We present a novel method to extract iso-surfaces from distance volumes. It generates high quality semi-regular multiresolution meshes of arbitrary topology. Our technique proceeds in two stages. First, a very coarse mesh with guaranteed topology is extracted. Subsequently an iterative multi-scale force-based solver refines the initial mesh into a semi-regular mesh with geometrically adaptive sampling rate and good aspect ratio triangles. The coarse mesh extraction is performed using a new approach we call surface wavefront propagation. A set of discrete iso-distance ribbons are rapidly built and connected while respecting the topology of the iso-surface implied by the data. Subsequent multi-scale refinement is driven by a simple force-based solver designed to combine good iso-surface fit and high quality sampling through reparameterization. In contrast to the Marching Cubes technique our output meshes adapt gracefully to the iso-surface geometry, have a natural multiresolution structure and good aspect ratio triangles, as demonstrated with a number of examples.',\n",
              "  'AuthorKeywords': ['Semi-regular',\n",
              "   'meshes,',\n",
              "   'subdivision,',\n",
              "   'volumes,',\n",
              "   'surface',\n",
              "   'extraction,',\n",
              "   'implicit',\n",
              "   'functions,',\n",
              "   'level',\n",
              "   'set',\n",
              "   'methods'],\n",
              "  'MultipartiteRank': [{'score': 0.10588532653445716, 'word': 'iso'},\n",
              "   {'score': 0.10506693390629268, 'word': 'surfaces'},\n",
              "   {'score': 0.06924558268189253, 'word': 'arbitrary'},\n",
              "   {'score': 0.06924558268189253, 'word': 'topology'},\n",
              "   {'score': 0.06512844758480295, 'word': 'coarse'},\n",
              "   {'score': 0.06512844758480295, 'word': 'mesh'},\n",
              "   {'score': 0.05158932259363143, 'word': 'technique'}],\n",
              "  'Title': 'Semi-regular mesh extraction from volumes',\n",
              "  'distance': 0,\n",
              "  'no': '186',\n",
              "  'parent': '4220'},\n",
              " {'Abstract': 'We present a system that allows users to interactively explore complex flow scenarios represented as Sankey diagrams. Our system provides an overview of the flow graph and allows users to zoom in and explore details on demand. The support for quantitative flow tracing across the flow graph as well as representations at different levels of detail facilitate the understanding of complex flow situations. The energy flow in a city serves as a sample scenario for our system. Different forms of energy are distributed within the city and they are transformed into heat, electricity, or other forms of energy. These processes are visualized and interactively explored. In addition our system can be used as a planning tool for the exploration of alternative scenarios by interactively manipulating different parameters in the energy flow network.',\n",
              "  'AuthorKeywords': ['Sankey', 'diagram,', 'flow', 'diagram'],\n",
              "  'MultipartiteRank': [{'score': 0.13653153248946806, 'word': 'flow'},\n",
              "   {'score': 0.07834710979209931, 'word': 'system'},\n",
              "   {'score': 0.06894090337569132, 'word': 'different'},\n",
              "   {'score': 0.06894090337569132, 'word': 'levels'},\n",
              "   {'score': 0.06878524994809256, 'word': 'energy'},\n",
              "   {'score': 0.0677462825413755, 'word': 'graph'},\n",
              "   {'score': 0.05768835920661848, 'word': 'details'}],\n",
              "  'Title': 'Interactive Sankey diagrams',\n",
              "  'distance': 0,\n",
              "  'no': '187',\n",
              "  'parent': '4605'},\n",
              " {'Abstract': 'This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.',\n",
              "  'AuthorKeywords': ['Ridge',\n",
              "   'extraction,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'coherent',\n",
              "   'structures,',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'topology,',\n",
              "   'unsteady',\n",
              "   'vector',\n",
              "   'fields'],\n",
              "  'MultipartiteRank': [{'score': 0.09355096885128977, 'word': 'ridge'},\n",
              "   {'score': 0.09355096885128977, 'word': 'extraction'},\n",
              "   {'score': 0.07853007492438561, 'word': 'trajectories'},\n",
              "   {'score': 0.06967776754105857, 'word': 'underlying'},\n",
              "   {'score': 0.06967776754105857, 'word': 'scalar'},\n",
              "   {'score': 0.06967776754105857, 'word': 'field'},\n",
              "   {'score': 0.06292832167943052, 'word': 'finite'},\n",
              "   {'score': 0.06292832167943052, 'word': 'lyapunov'},\n",
              "   {'score': 0.06292832167943052, 'word': 'exponent'},\n",
              "   {'score': 0.06292832167943052, 'word': 'fields'},\n",
              "   {'score': 0.06027090006558756, 'word': 'method'}],\n",
              "  'Title': 'Efficient Visualization of Lagrangian Coherent Structures by filtered AMR Ridge Extraction',\n",
              "  'distance': 0,\n",
              "  'no': '188',\n",
              "  'parent': '4919'},\n",
              " {'Abstract': 'The Morse-Smale (MS) complex has proven to be a useful tool in extracting and visualizing features from scalar-valued data. However, efficient computation of the MS complex for large scale data remains a challenging problem. We describe a new algorithm and easily extensible framework for computing MS complexes for large scale data of any dimension where scalar values are given at the vertices of a closure-finite and weak topology (CW) complex, therefore enabling computation on a wide variety of meshes such as regular grids, simplicial meshes, and adaptive multiresolution (AMR) meshes. A new divide-and-conquer strategy allows for memory-efficient computation of the MS complex and simplification on-the-fly to control the size of the output. In addition to being able to handle various data formats, the framework supports implementation-specific optimizations, for example, for regular data. We present the complete characterization of critical point cancellations in all dimensions. This technique enables the topology based analysis of large data on off-the-shelf computers. In particular we demonstrate the first full computation of the MS complex for a 1 billion/1024<sup>3</sup>node grid on a laptop computer with 2 Gb memory.',\n",
              "  'AuthorKeywords': ['Topology-based',\n",
              "   'analysis,',\n",
              "   'Morse-Smale',\n",
              "   'complex,',\n",
              "   'large',\n",
              "   'scale',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.12965275486008931, 'word': 'complex'},\n",
              "   {'score': 0.06584146859403654, 'word': 'efficient'},\n",
              "   {'score': 0.06584146859403654, 'word': 'computation'},\n",
              "   {'score': 0.05892529039516045, 'word': 'data'},\n",
              "   {'score': 0.04842856882219611, 'word': 'ms'},\n",
              "   {'score': 0.029293154229830632, 'word': 'simplicial'},\n",
              "   {'score': 0.029293154229830632, 'word': 'meshes'}],\n",
              "  'Title': 'A Practical Approach to Morse-Smale Complex Computation: Scalability and Generality',\n",
              "  'distance': 0,\n",
              "  'no': '189',\n",
              "  'parent': '4895'},\n",
              " {'Abstract': 'An algorithm is presented which describes an application independent method for reducing the number of polygonal primitives required to faithfully represent an object. Reducing polygon count without a corresponding reduction in object detail is important for: achieving interactive frame rates in scientific visualization, reducing mass storage requirements, and facilitating the transmission of large, multi-timestep geometric data sets. This paper shows how coplanar and nearly coplanar polygons can be merged into larger complex polygons and re-triangulated into fewer simple polygons than originally required. The notable contributions of this paper are: (1) a method for quickly grouping polygons into nearly coplanar sets, (2) a fast approach for merging coplanar polygon sets and, (3) a simple, robust triangulation method for polygons created by 1 and 2. The central idea of the algorithm is the notion of treating polygonal data as a collection of segments and removing redundant segments to quickly form polygon hulls which represent the merged coplanar sets.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12409735858251238, 'word': 'polygonal'},\n",
              "   {'score': 0.12409735858251238, 'word': 'primitives'},\n",
              "   {'score': 0.06142916797135632, 'word': 'object'},\n",
              "   {'score': 0.05964283351596973, 'word': 'application'},\n",
              "   {'score': 0.05964283351596973, 'word': 'independent'},\n",
              "   {'score': 0.05964283351596973, 'word': 'method'},\n",
              "   {'score': 0.055823003104037906, 'word': 'number'},\n",
              "   {'score': 0.05312093309305065, 'word': 'coplanar'}],\n",
              "  'Title': 'Geometric optimization',\n",
              "  'distance': 0,\n",
              "  'no': '190',\n",
              "  'parent': '4893'},\n",
              " {'Abstract': 'The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.',\n",
              "  'AuthorKeywords': ['opinion',\n",
              "   'visualization,',\n",
              "   'radial',\n",
              "   'visualization,',\n",
              "   'uncertainty',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.10808646281030279, 'word': 'opinions'},\n",
              "   {'score': 0.06459510963856549, 'word': 'hotel'},\n",
              "   {'score': 0.06459510963856549, 'word': 'customers'},\n",
              "   {'score': 0.04878667000838876, 'word': 'effective'},\n",
              "   {'score': 0.04878667000838876, 'word': 'visual'},\n",
              "   {'score': 0.04878667000838876, 'word': 'analysis'},\n",
              "   {'score': 0.0487142402824072, 'word': 'opinionseer'},\n",
              "   {'score': 0.04087655568103516, 'word': 'new'},\n",
              "   {'score': 0.04087655568103516, 'word': 'visualization'}],\n",
              "  'Title': 'OpinionSeer: Interactive Visualization of Hotel Customer Feedback',\n",
              "  'distance': 0,\n",
              "  'no': '191',\n",
              "  'parent': '4246'},\n",
              " {'Abstract': 'Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.',\n",
              "  'AuthorKeywords': ['Deep',\n",
              "   'convolutional',\n",
              "   'neural',\n",
              "   'networks;rectangle',\n",
              "   'packing;matrix',\n",
              "   'reordering;edge',\n",
              "   'bundling;biclustering'],\n",
              "  'MultipartiteRank': [{'score': 0.07162728668078334, 'word': 'cnns'},\n",
              "   {'score': 0.058274564077691084, 'word': 'neuron'},\n",
              "   {'score': 0.041431892264493196, 'word': 'edge'},\n",
              "   {'score': 0.041431892264493196, 'word': 'bundling'},\n",
              "   {'score': 0.041431892264493196, 'word': 'method'},\n",
              "   {'score': 0.04141965577069839, 'word': 'quality'},\n",
              "   {'score': 0.04141965577069839, 'word': 'deep'},\n",
              "   {'score': 0.04141965577069839, 'word': 'models'},\n",
              "   {'score': 0.04047045726825289, 'word': 'hybrid'},\n",
              "   {'score': 0.04047045726825289, 'word': 'visualization'}],\n",
              "  'Title': 'Towards Better Analysis of Deep Convolutional Neural Networks',\n",
              "  'distance': 0,\n",
              "  'no': '192',\n",
              "  'parent': '4013'},\n",
              " {'Abstract': 'The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17004047729262523, 'word': 'visualization'},\n",
              "   {'score': 0.16292396692683922, 'word': 'data'},\n",
              "   {'score': 0.16292396692683922, 'word': 'explorer'},\n",
              "   {'score': 0.09284298380404342, 'word': 'modules'},\n",
              "   {'score': 0.07719749348858179, 'word': 'scientific'},\n",
              "   {'score': 0.07719749348858179, 'word': 'system'},\n",
              "   {'score': 0.05943527020681349, 'word': 'wide'},\n",
              "   {'score': 0.05943527020681349, 'word': 'variety'},\n",
              "   {'score': 0.04925582119503671, 'word': 'execution'},\n",
              "   {'score': 0.04925582119503671, 'word': 'model'}],\n",
              "  'Title': 'An architecture for a scientific visualization system',\n",
              "  'distance': 0,\n",
              "  'no': '193',\n",
              "  'parent': '3754'},\n",
              " {'Abstract': 'We describe an algorithm for repairing polyhedral CAD models that have errors in their B-REP. Errors like cracks, degeneracies, duplication, holes and overlaps are usually introduced in solid models due to imprecise arithmetic, model transformations, designer errors, programming bugs, etc. Such errors often hamper further processing such as finite element analysis, radiosity computation and rapid prototyping. Our fault-repair algorithm converts an unordered collection of polygons to a shared-vertex representation to help eliminate errors. This is done by choosing, for each polygon edge, the most appropriate edge to unify it with. The two edges are then geometrically merged into one, by moving vertices. At the end of this process, each polygon edge is either coincident with another or is a boundary edge for a polygonal hole or a dangling wall and may be appropriately repaired. Finally, in order to allow user-inspection of the automatic corrections, we produce a visualization of the repair and let the user mark the corrections that conflict with the original design intent. A second iteration of the correction algorithm then produces a repair that is commensurate with the intent. This, by involving the users in a feedback loop, we are able to refine the correction to their satisfaction.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06555046896729642, 'word': 'errors'},\n",
              "   {'score': 0.044103086951179066, 'word': 'polygons'},\n",
              "   {'score': 0.04300646218160271, 'word': 'repair'},\n",
              "   {'score': 0.04300646218160271, 'word': 'algorithm'},\n",
              "   {'score': 0.035382151140285444, 'word': 'holes'},\n",
              "   {'score': 0.034706886791311446, 'word': 'solid'},\n",
              "   {'score': 0.034706886791311446, 'word': 'models'}],\n",
              "  'Title': 'Repairing CAD models',\n",
              "  'distance': 0,\n",
              "  'no': '194',\n",
              "  'parent': '5167'},\n",
              " {'Abstract': 'Volume rendered imagery often includes a barrage of 3D information like shape, appearance and topology of complex structures, and it thus quickly overwhelms the user. In particular, when focusing on a specific region a user cannot observe the relationship between various structures unless he has a mental picture of the entire data. In this paper we present ClearView, a GPU-based, interactive framework for texture-based volume ray-casting that allows users which do not have the visualization skills for this mental exercise to quickly obtain a picture of the data in a very intuitive and user-friendly way. ClearView is designed to enable the user to focus on particular areas in the data while preserving context information without visual clutter. ClearView does not require additional feature volumes as it derives any features in the data from image information only. A simple point-and-click interface enables the user to interactively highlight structures in the data. ClearView provides an easy to use interface to complex volumetric data as it only uses transparency in combination with a few specific shaders to convey focus and context information',\n",
              "  'AuthorKeywords': ['Focus',\n",
              "   '&',\n",
              "   'Context,',\n",
              "   'GPU',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'raycasting'],\n",
              "  'MultipartiteRank': [{'score': 0.06940147082462203, 'word': 'user'},\n",
              "   {'score': 0.061337620585139425, 'word': 'entire'},\n",
              "   {'score': 0.061337620585139425, 'word': 'data'},\n",
              "   {'score': 0.05706835491541412, 'word': '3d'},\n",
              "   {'score': 0.05706835491541412, 'word': 'information'},\n",
              "   {'score': 0.05688810776566693, 'word': 'volume'},\n",
              "   {'score': 0.04934734942486052, 'word': 'complex'},\n",
              "   {'score': 0.04934734942486052, 'word': 'structures'}],\n",
              "  'Title': 'ClearView: An Interactive Context Preserving Hotspot Visualization Technique',\n",
              "  'distance': 0,\n",
              "  'no': '195',\n",
              "  'parent': '4897'},\n",
              " {'Abstract': \"Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.\",\n",
              "  'AuthorKeywords': ['Outflow,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'temporal',\n",
              "   'event',\n",
              "   'sequences,',\n",
              "   'state',\n",
              "   'diagram,',\n",
              "   'state',\n",
              "   'transition'],\n",
              "  'MultipartiteRank': [{'score': 0.21222718931984946, 'word': 'event'},\n",
              "   {'score': 0.16507979198132514, 'word': 'sequence'},\n",
              "   {'score': 0.16507979198132514, 'word': 'data'},\n",
              "   {'score': 0.06766675489625679, 'word': 'common'},\n",
              "   {'score': 0.0490983579186799, 'word': 'many'},\n",
              "   {'score': 0.0490983579186799, 'word': 'domains'},\n",
              "   {'score': 0.04714739733852434, 'word': 'progression'},\n",
              "   {'score': 0.04714739733852434, 'word': 'pathways'},\n",
              "   {'score': 0.044126664589489974, 'word': 'measurable'},\n",
              "   {'score': 0.044126664589489974, 'word': 'outcomes'}],\n",
              "  'Title': 'Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '196',\n",
              "  'parent': '4045'},\n",
              " {'Abstract': \"An increasing number of tasks require people to explore, navigate and search extremely complex data sets visualized as graphs. Examples include electrical and telecommunication networks, Web structures, and airline routes. The problem is that graphs of these real world data sets have many interconnected nodes, ultimately leading to edge congestion: the density of edges is so great that they obscure nodes, individual edges, and even the visual information beneath the graph. To address this problem we developed an interactive technique called EdgeLens. An EdgeLens interactively curves graph edges away for a person's focus attention without changing the node positions. This opens up sufficient space to disambiguate node and edge relationships and to see underlying information while still preserving node layout. Initially two methods of creating this interaction were developed and compared in a user study. The results of this study were used in the selection of a basic approach and the subsequent development of the EdgeLens. We then improved the EdgeLens through use of transparency and colour and by allowing multiple lenses to appear on the graph.\",\n",
              "  'AuthorKeywords': ['Navigation,',\n",
              "   'graph',\n",
              "   'layout,',\n",
              "   'distortion',\n",
              "   'lens,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'edge',\n",
              "   'congestion,',\n",
              "   'interactive',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.07600467064012457, 'word': 'graphs'},\n",
              "   {'score': 0.060926558823987655, 'word': 'nodes'},\n",
              "   {'score': 0.05321177773779527, 'word': 'edgelens'},\n",
              "   {'score': 0.0512948692579487, 'word': 'edges'},\n",
              "   {'score': 0.040030726179126966, 'word': 'complex'},\n",
              "   {'score': 0.040030726179126966, 'word': 'data'},\n",
              "   {'score': 0.040030726179126966, 'word': 'sets'}],\n",
              "  'Title': 'Edgelens: an interactive method for managing edge congestion in graphs',\n",
              "  'distance': 0,\n",
              "  'no': '197',\n",
              "  'parent': '5119'},\n",
              " {'Abstract': 'This paper is aimed at the exploratory visualization of networks where there is a strength or weight associated with each link, and makes use of any hierarchy present on the nodes to aid the investigation of large networks. It describes a method of placing nodes on the plane that gives meaning to their relative positions. The paper discusses how linking and interaction principles aid the user in the exploration. Two examples are given; one of electronic mail communication over eight months within a department, another concerned with changes to a large section of a computer program.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07180419270137361, 'word': 'networks'},\n",
              "   {'score': 0.07127774411218854, 'word': 'link'},\n",
              "   {'score': 0.06564015207563816, 'word': 'nodes'},\n",
              "   {'score': 0.05873142555298839, 'word': 'paper'},\n",
              "   {'score': 0.04324983076541312, 'word': 'exploratory'},\n",
              "   {'score': 0.04324983076541312, 'word': 'visualization'}],\n",
              "  'Title': 'Navigating large networks with hierarchies',\n",
              "  'distance': 0,\n",
              "  'no': '198',\n",
              "  'parent': '3531'},\n",
              " {'Abstract': 'Network evolution is an ubiquitous phenomenon in a wide variety of complex systems. There is an increasing interest in statistically modeling the evolution of complex networks such as small-world networks and scale-free networks. In this article, we address a practical issue concerning the visualizations of co-citation networks of scientific publications derived by two widely known link reduction algorithms, namely minimum spanning trees (MSTs) and pathfinder networks (PFNETs). Our primary goal is to identify the strengths and weaknesses of the two methods in fulfilling the need for visualizing evolving networks. Two criteria are derived for assessing visualizations of evolving networks in terms of topological properties and dynamical properties. We examine the animated visualization models of the evolution of botulinum toxin research in terms of its co-citation structure across a 58-year span (1945-2002). The results suggest that although high-degree nodes dominate the structure of MST models, such structures can be inadequate in depicting the essence of how the network evolves because MST removes potentially significant links from high-order shortest paths. In contrast, PFNET models clearly demonstrate their superiority in maintaining the cohesiveness of some of the most pivotal paths, which in turn make the growth animation more predictable and interpretable. We suggest that the design of visualization and modeling tools for network evolution should take the cohesiveness of critical paths into account.',\n",
              "  'AuthorKeywords': ['Network',\n",
              "   'evolution,',\n",
              "   'network',\n",
              "   'visualization,',\n",
              "   'co-citation',\n",
              "   'networks,',\n",
              "   'Pathfinder',\n",
              "   'networks,',\n",
              "   'minimum',\n",
              "   'spanning',\n",
              "   'trees'],\n",
              "  'MultipartiteRank': [{'score': 0.10057802305909222, 'word': 'networks'},\n",
              "   {'score': 0.07469193665754979, 'word': 'network'},\n",
              "   {'score': 0.07469193665754979, 'word': 'evolution'},\n",
              "   {'score': 0.0707462549699005, 'word': 'world'},\n",
              "   {'score': 0.045087560044399455, 'word': 'visualizations'},\n",
              "   {'score': 0.03360379828136004, 'word': 'msts'}],\n",
              "  'Title': 'Visualizing evolving networks: minimum spanning trees versus pathfinder networks',\n",
              "  'distance': 0,\n",
              "  'no': '199',\n",
              "  'parent': '5383'},\n",
              " {'Abstract': 'We describe an efficient technique for out-of-core management and interactive rendering of planet sized textured terrain surfaces. The technique, called planet-sized batched dynamic adaptive meshes (P-BDAM), extends the BDAM approach by using as basic primitive a general triangulation of points on a displaced triangle. The proposed framework introduces several advances with respect to the state of the art: thanks to a batched host-to-graphics communication model, we outperform current adaptive tessellation solutions in terms of rendering speed; we guarantee overall geometric continuity, exploiting programmable graphics hardware to cope with the accuracy issues introduced by single precision floating points; we exploit a compressed out of core representation and speculative prefetching for hiding disk latency during rendering of out-of-core data; we efficiently construct high quality simplified representations with a novel distributed out of core simplification algorithm working on a standard PC network.',\n",
              "  'AuthorKeywords': ['Multiresolution,', 'terrains,', 'huge', 'dataset'],\n",
              "  'MultipartiteRank': [{'score': 0.0784578466174049, 'word': 'core'},\n",
              "   {'score': 0.04491414029067907, 'word': 'points'},\n",
              "   {'score': 0.04266187191320733, 'word': 'efficient'},\n",
              "   {'score': 0.04266187191320733, 'word': 'technique'},\n",
              "   {'score': 0.040988632129875704, 'word': 'management'},\n",
              "   {'score': 0.037825334400245283, 'word': 'bdam'},\n",
              "   {'score': 0.037469214487529205, 'word': 'representation'}],\n",
              "  'Title': 'Planet-sized batched dynamic adaptive meshes (P-BDAM)',\n",
              "  'distance': 0,\n",
              "  'no': '200',\n",
              "  'parent': '4215'},\n",
              " {'Abstract': 'Treemaps are a well known method for the visualization of attributed hierarchical data. Previously proposed treemap layout algorithms are limited to rectangular shapes, which cause problems with the aspect ratio of the rectangles as well as with identifying the visualized hierarchical structure. The approach of Voronoi treemaps presented in this paper eliminates these problems through enabling subdivisions of and in polygons. Additionally, this allows for creating treemap visualizations within areas of arbitrary shape, such as triangles and circles, thereby enabling a more flexible adaptation of treemaps for a wider range of applications.',\n",
              "  'AuthorKeywords': ['Voronoi',\n",
              "   'Treemaps,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Hierarchies,',\n",
              "   'Trees,',\n",
              "   'Treemaps,',\n",
              "   'Voronoi',\n",
              "   'Tessellations'],\n",
              "  'MultipartiteRank': [{'score': 0.17450245342666926, 'word': 'treemaps'},\n",
              "   {'score': 0.06158748933008139, 'word': 'rectangular'},\n",
              "   {'score': 0.06158748933008139, 'word': 'shapes'},\n",
              "   {'score': 0.058585348234816426, 'word': 'problems'},\n",
              "   {'score': 0.05488310087082712, 'word': 'flexible'},\n",
              "   {'score': 0.05488310087082712, 'word': 'adaptation'},\n",
              "   {'score': 0.050026555671867215, 'word': 'wider'},\n",
              "   {'score': 0.050026555671867215, 'word': 'range'}],\n",
              "  'Title': 'Voronoi treemaps',\n",
              "  'distance': 0,\n",
              "  'no': '201',\n",
              "  'parent': '3565'},\n",
              " {'Abstract': 'In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high precision textures to represent them. We also use transfer functions that operate on the high precision textures in order to highlight different aspects of the cluster characteristics. Providing predefined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient.',\n",
              "  'AuthorKeywords': ['Parallel',\n",
              "   'coordinates,',\n",
              "   'clustering,',\n",
              "   'transfer',\n",
              "   'function,',\n",
              "   'feature',\n",
              "   'animation'],\n",
              "  'MultipartiteRank': [{'score': 0.09872177963664686, 'word': 'multivariate'},\n",
              "   {'score': 0.09872177963664686, 'word': 'data'},\n",
              "   {'score': 0.06930354968935608, 'word': 'clusters'},\n",
              "   {'score': 0.05816736855782524, 'word': 'complex'},\n",
              "   {'score': 0.05816736855782524, 'word': 'structures'},\n",
              "   {'score': 0.048256953574822695, 'word': 'transfer'},\n",
              "   {'score': 0.048256953574822695, 'word': 'functions'},\n",
              "   {'score': 0.047885332316690093, 'word': 'order'}],\n",
              "  'Title': 'Revealing structure within clustered parallel coordinates displays',\n",
              "  'distance': 0,\n",
              "  'no': '202',\n",
              "  'parent': '3831'},\n",
              " {'Abstract': 'Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.',\n",
              "  'AuthorKeywords': ['Mental',\n",
              "   'model,',\n",
              "   'model-based',\n",
              "   'reasoning,',\n",
              "   'distributed',\n",
              "   'cognition,',\n",
              "   'interaction,',\n",
              "   'theory,',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.0852077664556641, 'word': 'internal'},\n",
              "   {'score': 0.07082100557551757, 'word': 'mental'},\n",
              "   {'score': 0.07082100557551757, 'word': 'models'},\n",
              "   {'score': 0.06151861553389362, 'word': 'external'},\n",
              "   {'score': 0.06151861553389362, 'word': 'representations'},\n",
              "   {'score': 0.05824317135418884, 'word': 'information'},\n",
              "   {'score': 0.05824317135418884, 'word': 'visualization'},\n",
              "   {'score': 0.04563771050600089, 'word': 'relationship'}],\n",
              "  'Title': 'Mental Models; Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective',\n",
              "  'distance': 0,\n",
              "  'no': '203',\n",
              "  'parent': '4171'},\n",
              " {'Abstract': 'Navigation through 3D spaces is required in many interactive graphics and virtual reality applications. The authors consider the subclass of situations in which a 2D device such as a mouse controls smooth movements among viewpoints for a \"through the screen\" display of a 3D world. Frequently, there is a poor match between the goal of such a navigation activity, the control device, and the skills of the average user. They propose a unified mathematical framework for incorporating context-dependent constraints into the generalized viewpoint generation problem. These designer-supplied constraint modes provide a middle ground between the triviality of a single camera animation path and the confusing excess freedom of common unconstrained control paradigms. They illustrate the approach with a variety of examples, including terrain models, interior architectural spaces, and complex molecules.',\n",
              "  'AuthorKeywords': ['Navigation,',\n",
              "   'Constrained',\n",
              "   'Navigation,',\n",
              "   'Viewing',\n",
              "   'Control,',\n",
              "   'Camera',\n",
              "   'Control'],\n",
              "  'MultipartiteRank': [{'score': 0.0786201067158097, 'word': 'navigation'},\n",
              "   {'score': 0.06803419179188411, 'word': '3d'},\n",
              "   {'score': 0.06803419179188411, 'word': 'spaces'},\n",
              "   {'score': 0.04738614839935664, 'word': 'viewpoints'},\n",
              "   {'score': 0.040363922296102014, 'word': 'dependent'},\n",
              "   {'score': 0.040363922296102014, 'word': 'constraints'},\n",
              "   {'score': 0.037253074172254284, 'word': 'many'},\n",
              "   {'score': 0.037253074172254284, 'word': 'interactive'},\n",
              "   {'score': 0.037253074172254284, 'word': 'graphics'}],\n",
              "  'Title': 'Constrained 3D navigation with 2D controllers',\n",
              "  'distance': 0,\n",
              "  'no': '204',\n",
              "  'parent': '4346'},\n",
              " {'Abstract': 'For high quality rendering of objects segmented from tomographic volume data the precise location of the boundaries of adjacent objects in subvoxel resolution is required. We describe a new method that determines the membership of a given sample point to an object by reclassifying the sample point using interpolation of the original intensity values and searching for the best fitting object in the neighbourhood. Using a ray-casting approach we then compute the surface location between successive sample points along the viewing-ray by interpolation or bisection. The accurate calculation of the object boundary enables a much more precise computation of the gray-level-gradient yielding the surface normal. Our new approach significantly improves the quality of reconstructed and shaded surfaces and reduces aliasing artifacts for animations and magnified views. We illustrate the results on different cases including the Visible-Human-Data, where we achieve nearly photo-realistic images.',\n",
              "  'AuthorKeywords': ['partial-volume-effect,',\n",
              "   'ray-casting,',\n",
              "   'tomographic',\n",
              "   'data,Visible-Human-Project'],\n",
              "  'MultipartiteRank': [{'score': 0.08955527506786727, 'word': 'objects'},\n",
              "   {'score': 0.0609591115919224, 'word': 'sample'},\n",
              "   {'score': 0.0609591115919224, 'word': 'point'},\n",
              "   {'score': 0.04527475745271139, 'word': 'high'},\n",
              "   {'score': 0.04527475745271139, 'word': 'quality'},\n",
              "   {'score': 0.04527475745271139, 'word': 'rendering'},\n",
              "   {'score': 0.04401323663802335, 'word': 'tomographic'},\n",
              "   {'score': 0.04401323663802335, 'word': 'volume'},\n",
              "   {'score': 0.04401323663802335, 'word': 'data'},\n",
              "   {'score': 0.043457619706286324, 'word': 'precise'},\n",
              "   {'score': 0.043457619706286324, 'word': 'location'}],\n",
              "  'Title': 'High quality rendering of attributed volume data',\n",
              "  'distance': 0,\n",
              "  'no': '205',\n",
              "  'parent': '3908'},\n",
              " {'Abstract': 'Level-of-detail rendering is essential for rendering very large, detailed worlds in real-time. Unfortunately, level-of-detail computations can be expensive, creating a bottleneck at the CPU. This paper presents the CABTT algorithm, an extension to existing binary-triangle-tree-based level-of-detail algorithms. Instead of manipulating triangles, the CABTT algorithm instead operates on clusters of geometry called aggregate triangles. This reduces CPU overhead, eliminating a bottleneck common to level-of-detail algorithms. Since aggregate triangles stay fixed over several frames, they may be cached on the video card. This further reduces CPU load and fully utilizes the hardware accelerated rendering pipeline on modern video cards. These improvements result in a fourfold increase in frame rate over ROAM at high detail levels. Our implementation renders an approximation of an 8 million triangle height field at 42 frames per second with an maximum error of 1 pixel on consumer hardware.',\n",
              "  'AuthorKeywords': ['view-dependent',\n",
              "   'mesh,',\n",
              "   'level',\n",
              "   'of',\n",
              "   'detail,',\n",
              "   'height',\n",
              "   'fields,',\n",
              "   'terrain,',\n",
              "   'binary',\n",
              "   'triangle',\n",
              "   'trees,',\n",
              "   'triangle',\n",
              "   'bintree,',\n",
              "   'multiresolution',\n",
              "   'meshes,',\n",
              "   'displacement',\n",
              "   'maps,',\n",
              "   'frame-to-frame',\n",
              "   'coherence'],\n",
              "  'MultipartiteRank': [{'score': 0.08689098902203136, 'word': 'level'},\n",
              "   {'score': 0.07336233134814886, 'word': 'triangle'},\n",
              "   {'score': 0.06390716378857837, 'word': 'cabtt'},\n",
              "   {'score': 0.06390716378857837, 'word': 'algorithm'},\n",
              "   {'score': 0.05557285826115426, 'word': 'detail'},\n",
              "   {'score': 0.05557285826115426, 'word': 'rendering'},\n",
              "   {'score': 0.04494710552820729, 'word': 'cpu'}],\n",
              "  'Title': 'Fast view-dependent level-of-detail rendering using cached geometry',\n",
              "  'distance': 0,\n",
              "  'no': '206',\n",
              "  'parent': '4656'},\n",
              " {'Abstract': 'Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, LeadLine, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, LeadLine integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, LeadLine allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, LeadLine provides a concise summary of the corpora. LeadLine also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of LeadLine in identifying events and supporting exploration, two case studies were conducted using news and social media data.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.20913619302485215, 'word': 'events'},\n",
              "   {'score': 0.13979921986066338, 'word': 'important'},\n",
              "   {'score': 0.055540003415757, 'word': 'leadline'},\n",
              "   {'score': 0.05052986601296764, 'word': 'valuable'},\n",
              "   {'score': 0.05052986601296764, 'word': 'insights'},\n",
              "   {'score': 0.0481102543502359, 'word': 'online'},\n",
              "   {'score': 0.0481102543502359, 'word': 'news'}],\n",
              "  'Title': 'LeadLine: Interactive visual analysis of text data through event identification and exploration',\n",
              "  'distance': 0,\n",
              "  'no': '207',\n",
              "  'parent': '5013'},\n",
              " {'Abstract': 'To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.',\n",
              "  'AuthorKeywords': ['Interaction,',\n",
              "   'latency,',\n",
              "   'exploratory',\n",
              "   'analysis,',\n",
              "   'interactive',\n",
              "   'visualization,',\n",
              "   'scalability,',\n",
              "   'user',\n",
              "   'performance,',\n",
              "   'verbal',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.1490592645630943, 'word': 'interactive'},\n",
              "   {'score': 0.09753678506672737, 'word': 'latency'},\n",
              "   {'score': 0.07515140564319527, 'word': 'user'},\n",
              "   {'score': 0.07515140564319527, 'word': 'behavior'},\n",
              "   {'score': 0.071032595737413, 'word': 'effective'},\n",
              "   {'score': 0.071032595737413, 'word': 'exploration'},\n",
              "   {'score': 0.05152247949636691, 'word': 'visualizations'},\n",
              "   {'score': 0.03554647496336202, 'word': 'knowledge'},\n",
              "   {'score': 0.03554647496336202, 'word': 'discovery'}],\n",
              "  'Title': 'The Effects of Interactive Latency on Exploratory Visual Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '208',\n",
              "  'parent': '4980'},\n",
              " {'Abstract': \"Current visualization systems are designed around a single user model, making it awkward for large research teams to collectively analyse large data sets. The paper shows how the popular data flow approach to visualization can be extended to allow multiple users to collaborate-each running their own visualization pipeline but with the opportunity to connect in data generated by a colleague, Thus collaborative visualizations are 'programmed' in exactly the same 'plug-and-play' style as is now customary for single-user mode. The paper describes a system architecture that can act as a basis for the collaborative extension of any data flow visualization system, and the ideas are demonstrated through a particular implementation in terms of IRIS Explorer.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.13587103299940456, 'word': 'visualization'},\n",
              "   {'score': 0.09264072223132064, 'word': 'large'},\n",
              "   {'score': 0.09264072223132064, 'word': 'data'},\n",
              "   {'score': 0.09264072223132064, 'word': 'sets'},\n",
              "   {'score': 0.07439119997386037, 'word': 'current'},\n",
              "   {'score': 0.07439119997386037, 'word': 'systems'},\n",
              "   {'score': 0.06952460361201385, 'word': 'paper'},\n",
              "   {'score': 0.06659588708675662, 'word': 'single'},\n",
              "   {'score': 0.06659588708675662, 'word': 'user'},\n",
              "   {'score': 0.06659588708675662, 'word': 'model'}],\n",
              "  'Title': 'Collaborative visualization',\n",
              "  'distance': 0,\n",
              "  'no': '209',\n",
              "  'parent': '4002'},\n",
              " {'Abstract': 'Direct volume rendering is a commonly used technique in visualization applications. Many of these applications require sophisticated shading models to capture subtle lighting effects and characteristics of volumetric data and materials. Many common objects and natural phenomena exhibit visual quality that cannot be captured using simple lighting models or cannot be solved at interactive rates using more sophisticated methods. We present a simple yet effective interactive shading model which captures volumetric light attenuation effects to produce volumetric shadows and the subtle appearance of translucency. We also present a technique for volume displacement or perturbation that allows realistic interactive modeling of high frequency detail for real and synthetic volumetric data.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'rendering,',\n",
              "   'shading',\n",
              "   'model,',\n",
              "   'volume',\n",
              "   'modeling,',\n",
              "   'procedural',\n",
              "   'modeling'],\n",
              "  'MultipartiteRank': [{'score': 0.07687147361772635, 'word': 'visualization'},\n",
              "   {'score': 0.07687147361772635, 'word': 'applications'},\n",
              "   {'score': 0.07477809518270695, 'word': 'many'},\n",
              "   {'score': 0.06265539561476524, 'word': 'direct'},\n",
              "   {'score': 0.06265539561476524, 'word': 'volume'},\n",
              "   {'score': 0.06171082052079181, 'word': 'volumetric'},\n",
              "   {'score': 0.06171082052079181, 'word': 'data'},\n",
              "   {'score': 0.05957754280823983, 'word': 'sophisticated'}],\n",
              "  'Title': 'Interactive translucent volume rendering and procedural modeling',\n",
              "  'distance': 0,\n",
              "  'no': '210',\n",
              "  'parent': '4044'},\n",
              " {'Abstract': 'Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.',\n",
              "  'AuthorKeywords': ['viewpoint',\n",
              "   'selection,',\n",
              "   'viewpoint',\n",
              "   'entropy,',\n",
              "   'direct',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'interval',\n",
              "   'volumes,',\n",
              "   'level-set',\n",
              "   'graphs'],\n",
              "  'MultipartiteRank': [{'score': 0.1679377734599571, 'word': 'optimal'},\n",
              "   {'score': 0.12840799404272962, 'word': 'viewpoint'},\n",
              "   {'score': 0.12840799404272962, 'word': 'selection'},\n",
              "   {'score': 0.07323148060924929, 'word': 'volumes'},\n",
              "   {'score': 0.05878340755732408, 'word': 'several'},\n",
              "   {'score': 0.05878340755732408, 'word': 'methods'},\n",
              "   {'score': 0.042036879216846346, 'word': 'important'},\n",
              "   {'score': 0.042036879216846346, 'word': 'task'},\n",
              "   {'score': 0.0395297794172275, 'word': 'positions'}],\n",
              "  'Title': 'A feature-driven approach to locating optimal viewpoints for volume visualization',\n",
              "  'distance': 0,\n",
              "  'no': '211',\n",
              "  'parent': '4953'},\n",
              " {'Abstract': 'The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more “natural” interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more “natural,” interaction techniques for InfoVis.',\n",
              "  'AuthorKeywords': ['Design',\n",
              "   'considerations,',\n",
              "   'interaction,',\n",
              "   'post-WIMP,',\n",
              "   'NUI',\n",
              "   '(Natural',\n",
              "   'User',\n",
              "   'Interface)'],\n",
              "  'MultipartiteRank': [{'score': 0.1704727650395992, 'word': 'interaction'},\n",
              "   {'score': 0.09853393202616176, 'word': 'infovis'},\n",
              "   {'score': 0.030487979237487646, 'word': 'natural'},\n",
              "   {'score': 0.028016377713509663, 'word': 'new'},\n",
              "   {'score': 0.028016377713509663, 'word': 'possibilities'},\n",
              "   {'score': 0.0269040549857144, 'word': 'technologies'}],\n",
              "  'Title': 'Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions',\n",
              "  'distance': 0,\n",
              "  'no': '212',\n",
              "  'parent': '4337'},\n",
              " {'Abstract': 'We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization;interaction;systems;toolkits;declarative',\n",
              "   'specification'],\n",
              "  'MultipartiteRank': [{'score': 0.08615393092053596, 'word': 'vega'},\n",
              "   {'score': 0.0767368148721146, 'word': 'lite'},\n",
              "   {'score': 0.062348093865351804, 'word': 'level'},\n",
              "   {'score': 0.062348093865351804, 'word': 'grammar'},\n",
              "   {'score': 0.062032908092473776, 'word': 'selections'},\n",
              "   {'score': 0.05333813349036618, 'word': 'interaction'}],\n",
              "  'Title': 'Vega-Lite: A Grammar of Interactive Graphics',\n",
              "  'distance': 0,\n",
              "  'no': '213',\n",
              "  'parent': '4607'},\n",
              " {'Abstract': 'In this work we present a method for speeding the process of volume animation. It exploits coherency between consecutive images to shorten the path rays take through the volume. Rays are provided with the information needed to leap over the empty space and commence volume traversal at the vicinity of meaningful data. The algorithm starts by projecting the volume onto a C-buffer (coordinates-buffer) which stores the object-space coordinates of the first non-empty voxel visible from a pixel. Following a change in the viewing parameters, the C-buffer is transformed accordingly. Next, coordinates that possibly became hidden are discarded. The remaining values serve as an estimate of the point where the new rays should start their volume traversal. This method does not require 3-D preprocessing and does not suffer from any image degradation. It can be combined with existing acceleration techniques and can support any ray traversal algorithm and material modeling scheme.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1191340309851797, 'word': 'volume'},\n",
              "   {'score': 0.1191340309851797, 'word': 'animation'},\n",
              "   {'score': 0.06738529846891507, 'word': 'path'},\n",
              "   {'score': 0.06738529846891507, 'word': 'rays'},\n",
              "   {'score': 0.05830687314729484, 'word': 'buffer'},\n",
              "   {'score': 0.05040080986626727, 'word': 'consecutive'},\n",
              "   {'score': 0.05040080986626727, 'word': 'images'},\n",
              "   {'score': 0.048773184681743645, 'word': 'process'}],\n",
              "  'Title': 'Accelerating volume animation by space-leaping',\n",
              "  'distance': 0,\n",
              "  'no': '214',\n",
              "  'parent': '4076'},\n",
              " {'Abstract': 'There are many applications that can benefit from the simultaneous display of multiple layers of data. The objective in these cases is to render the layered surfaces in a such way that the outer structures can be seen and seen through at the same time. The paper focuses on the particular application of radiation therapy treatment planning, in which physicians need to understand the three dimensional distribution of radiation dose in the context of patient anatomy. We describe a promising technique for communicating the shape and position of the transparent skin surface while at the same time minimally occluding underlying isointensity dose surfaces and anatomical objects: adding a sparse, opaque texture comprised of a small set of carefully chosen lines. We explain the perceptual motivation for explicitly drawing ridge and valley curves on a transparent surface, describe straightforward mathematical techniques for detecting and rendering these lines, and propose a small number of reasonably effective methods for selectively emphasizing the most perceptually relevant lines in the display.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06455186167633757, 'word': 'multiple'},\n",
              "   {'score': 0.06455186167633757, 'word': 'layers'},\n",
              "   {'score': 0.056965019067670083, 'word': 'objective'},\n",
              "   {'score': 0.05021599723422525, 'word': 'simultaneous'},\n",
              "   {'score': 0.05021599723422525, 'word': 'display'},\n",
              "   {'score': 0.04753967150194347, 'word': 'many'},\n",
              "   {'score': 0.04753967150194347, 'word': 'applications'},\n",
              "   {'score': 0.04454381029956021, 'word': 'data'}],\n",
              "  'Title': 'Enhancing transparent skin surfaces with ridge and valley lines',\n",
              "  'distance': 0,\n",
              "  'no': '215',\n",
              "  'parent': '3914'},\n",
              " {'Abstract': 'The paper presents a seed placement strategy for streamlines based on flow features in the dataset. The primary goal of our seeding strategy is to capture flow patterns in the vicinity of critical points in the flow field, even as the density of streamlines is reduced. Secondary goals are to place streamlines such that there is sufficient coverage in non-critical regions, and to vary the streamline placements and lengths so that the overall presentation is aesthetically pleasing (avoid clustering of streamlines, avoid sharp discontinuities across several streamlines, etc.). The procedure is straightforward and non-iterative. First, critical points are identified. Next, the flow field is segmented into regions, each containing a single critical point. The critical point in each region is then seeded with a template depending on the type of critical point. Finally, additional seed points are randomly distributed around the field using a Poisson disk distribution to minimize closely spaced seed points. The main advantage of this approach is that it does not miss the features around critical points. Since the strategy is not image-guided, and hence not view dependent, significant savings are possible when examining flow fields from different viewpoints, especially for 3D flow fields.',\n",
              "  'AuthorKeywords': ['seed',\n",
              "   'placement,',\n",
              "   'streamline,',\n",
              "   'critical',\n",
              "   'point,',\n",
              "   'Voronoi',\n",
              "   'diagram,',\n",
              "   'Poisson',\n",
              "   'disk',\n",
              "   'distribution'],\n",
              "  'MultipartiteRank': [{'score': 0.10152327803852614, 'word': 'flow'},\n",
              "   {'score': 0.09136247404087697, 'word': 'streamlines'},\n",
              "   {'score': 0.07850961744482908, 'word': 'critical'},\n",
              "   {'score': 0.07850961744482908, 'word': 'points'},\n",
              "   {'score': 0.06128284526835318, 'word': 'field'},\n",
              "   {'score': 0.060458535768772935, 'word': 'seed'},\n",
              "   {'score': 0.060458535768772935, 'word': 'placement'},\n",
              "   {'score': 0.060458535768772935, 'word': 'strategy'},\n",
              "   {'score': 0.04024043277017295, 'word': 'features'}],\n",
              "  'Title': 'A flow-guided streamline seeding strategy',\n",
              "  'distance': 0,\n",
              "  'no': '216',\n",
              "  'parent': '4099'},\n",
              " {'Abstract': \"Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'analytics,',\n",
              "   'eye',\n",
              "   'tracking,',\n",
              "   'movement',\n",
              "   'data,',\n",
              "   'trajectory',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.08550876276580112, 'word': 'large'},\n",
              "   {'score': 0.08550876276580112, 'word': 'data'},\n",
              "   {'score': 0.08336861434710971, 'word': 'methods'},\n",
              "   {'score': 0.08225652014957678, 'word': 'eye'},\n",
              "   {'score': 0.08225652014957678, 'word': 'movement'},\n",
              "   {'score': 0.08225652014957678, 'word': 'analysis'},\n",
              "   {'score': 0.059313054515442346, 'word': 'tasks'},\n",
              "   {'score': 0.05783310000771662, 'word': 'tool'}],\n",
              "  'Title': 'Visual Analytics Methodology for Eye Movement Studies',\n",
              "  'distance': 0,\n",
              "  'no': '217',\n",
              "  'parent': '4334'},\n",
              " {'Abstract': 'We present a framework to extract mesh features from unstructured two-manifold surfaces. Our method computes a collection of piecewise linear curves describing the salient features of surfaces, such as edges and ridge lines. We extend these basic techniques to a multiresolution setting which improves the quality of the results and accelerates the extraction process. The extraction process is semi-automatic, that is, the user is required to input a few control parameters and to select the operators to be applied to the input surface. Our mesh feature extraction algorithm can be used as a preprocessor for a variety of applications in geometric modeling including mesh fairing, subdivision and simplification.',\n",
              "  'AuthorKeywords': ['Surface',\n",
              "   'Representations,',\n",
              "   'Geometric',\n",
              "   'Modeling,',\n",
              "   'Triangle',\n",
              "   'Decimation,',\n",
              "   'Multiresolution',\n",
              "   'Models,',\n",
              "   'Feature',\n",
              "   'Extraction'],\n",
              "  'MultipartiteRank': [{'score': 0.09733637944783997, 'word': 'manifold'},\n",
              "   {'score': 0.09733637944783997, 'word': 'surfaces'},\n",
              "   {'score': 0.09210931192914122, 'word': 'mesh'},\n",
              "   {'score': 0.09210931192914122, 'word': 'features'},\n",
              "   {'score': 0.060309309846280586, 'word': 'unstructured'},\n",
              "   {'score': 0.04999097711090307, 'word': 'method'},\n",
              "   {'score': 0.047079411190837195, 'word': 'collection'}],\n",
              "  'Title': 'Multiresolution feature extraction for unstructured meshes',\n",
              "  'distance': 0,\n",
              "  'no': '218',\n",
              "  'parent': '3363'},\n",
              " {'Abstract': 'Radial, space-filling (RSF) techniques for hierarchy visualization have several advantages over traditional node-link diagrams, including the ability to efficiently use the display space while effectively conveying the hierarchy structure. Several RSF systems and tools have been developed to date, each with varying degrees of support for interactive operations such as selection and navigation. We describe what we believe to be a complete set of desirable operations on hierarchical structures. We then present InterRing, an RSF hierarchy visualization system that supports a significantly more extensive set of these operations than prior systems. In particular, InterRing supports multi-focus distortions, interactive hierarchy reconfiguration, and both semi-automated and manual selection. We show the power and utility of these and other operations, and describe our on-going efforts to evaluate their effectiveness and usability.',\n",
              "  'AuthorKeywords': ['radial',\n",
              "   'space-filling',\n",
              "   'hierarchy',\n",
              "   'visualizations,',\n",
              "   'multi-focus',\n",
              "   'distortion,',\n",
              "   'structure-based',\n",
              "   'brushing'],\n",
              "  'MultipartiteRank': [{'score': 0.10011238386131426, 'word': 'hierarchy'},\n",
              "   {'score': 0.06676894072258137, 'word': 'rsf'},\n",
              "   {'score': 0.06534813353907508, 'word': 'space'},\n",
              "   {'score': 0.0527263690587302, 'word': 'visualization'},\n",
              "   {'score': 0.04738601480258405, 'word': 'structure'},\n",
              "   {'score': 0.04696432729172028, 'word': 'filling'}],\n",
              "  'Title': 'InterRing: an interactive tool for visually navigating and manipulating hierarchical structures',\n",
              "  'distance': 0,\n",
              "  'no': '219',\n",
              "  'parent': '4181'},\n",
              " {'Abstract': 'Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.',\n",
              "  'AuthorKeywords': ['Geovisualization,',\n",
              "   'treemaps,',\n",
              "   'cartograms,',\n",
              "   'CIELab,',\n",
              "   'geographic',\n",
              "   'information,',\n",
              "   'tree',\n",
              "   'structures'],\n",
              "  'MultipartiteRank': [{'score': 0.11859093880278433, 'word': 'treemap'},\n",
              "   {'score': 0.11859093880278433, 'word': 'layout'},\n",
              "   {'score': 0.11859093880278433, 'word': 'algorithms'},\n",
              "   {'score': 0.065071862277218, 'word': 'inconsistent'},\n",
              "   {'score': 0.065071862277218, 'word': 'mappings'},\n",
              "   {'score': 0.05913925656356075, 'word': 'data'},\n",
              "   {'score': 0.05913925656356075, 'word': 'order'},\n",
              "   {'score': 0.05183711737128261, 'word': 'visual'},\n",
              "   {'score': 0.05183711737128261, 'word': 'ordering'},\n",
              "   {'score': 0.04924156936391767, 'word': 'poor'}],\n",
              "  'Title': 'Spatially Ordered Treemaps',\n",
              "  'distance': 0,\n",
              "  'no': '220',\n",
              "  'parent': '4621'},\n",
              " {'Abstract': 'Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Knowledge',\n",
              "   'Generation,',\n",
              "   'Reasoning,',\n",
              "   'Visualization',\n",
              "   'Taxonomies',\n",
              "   'and',\n",
              "   'Models,',\n",
              "   'Interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.10030671580114538, 'word': 'visual'},\n",
              "   {'score': 0.10030671580114538, 'word': 'analytics'},\n",
              "   {'score': 0.06308605180549352, 'word': 'knowledge'},\n",
              "   {'score': 0.053079117384212206, 'word': 'prior'},\n",
              "   {'score': 0.053079117384212206, 'word': 'research'},\n",
              "   {'score': 0.04654928872398644, 'word': 'frameworks'},\n",
              "   {'score': 0.046008874211165326, 'word': 'models'}],\n",
              "  'Title': 'Knowledge Generation Model for Visual Analytics',\n",
              "  'distance': 0,\n",
              "  'no': '221',\n",
              "  'parent': '4420'},\n",
              " {'Abstract': 'Vector field visualization remains a difficult task. Many local and global visualization methods for vector fields such as flow data exist, but they usually require extensive user experience on setting the visualization parameters in order to produce images communicating the desired insight. We present a visualization method that produces simplified but suggestive images of the vector field automatically, based on a hierarchical clustering of the input data. The resulting clusters are then visualized with straight or curved arrow icons. The presented method has a few parameters with which users can produce various simplified vector field visualizations that communicate different insights on the vector data.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'Visualization,',\n",
              "   'Simplification,',\n",
              "   'Clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.21966292158305872, 'word': 'visualization'},\n",
              "   {'score': 0.12413226009800016, 'word': 'vector'},\n",
              "   {'score': 0.12413226009800016, 'word': 'field'},\n",
              "   {'score': 0.09553066148505855, 'word': 'global'},\n",
              "   {'score': 0.09553066148505855, 'word': 'methods'},\n",
              "   {'score': 0.07509388074608704, 'word': 'many'},\n",
              "   {'score': 0.07509388074608704, 'word': 'local'},\n",
              "   {'score': 0.07279072176940689, 'word': 'difficult'},\n",
              "   {'score': 0.07279072176940689, 'word': 'task'},\n",
              "   {'score': 0.06641741924734565, 'word': 'flow'},\n",
              "   {'score': 0.06641741924734565, 'word': 'data'}],\n",
              "  'Title': 'Simplified representation of vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '222',\n",
              "  'parent': '4354'},\n",
              " {'Abstract': 'We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.',\n",
              "  'AuthorKeywords': ['Text',\n",
              "   'visualization,',\n",
              "   'tag',\n",
              "   'cloud,',\n",
              "   'natural',\n",
              "   'language',\n",
              "   'processing,',\n",
              "   'semantic',\n",
              "   'net'],\n",
              "  'MultipartiteRank': [{'score': 0.11820508185132776, 'word': 'relation'},\n",
              "   {'score': 0.07616101527751193, 'word': 'phrase'},\n",
              "   {'score': 0.07616101527751193, 'word': 'net'},\n",
              "   {'score': 0.07488258244375122, 'word': 'visual'},\n",
              "   {'score': 0.07488258244375122, 'word': 'overviews'},\n",
              "   {'score': 0.07230494614246524, 'word': 'words'},\n",
              "   {'score': 0.06266319771030295, 'word': 'document'}],\n",
              "  'Title': 'Mapping Text with Phrase Nets',\n",
              "  'distance': 0,\n",
              "  'no': '223',\n",
              "  'parent': '3430'},\n",
              " {'Abstract': \"Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.\",\n",
              "  'AuthorKeywords': ['Multidimensional',\n",
              "   'Projection,',\n",
              "   'High',\n",
              "   'Dimensional',\n",
              "   'Data,',\n",
              "   'Visual',\n",
              "   'Data',\n",
              "   'Mining'],\n",
              "  'MultipartiteRank': [{'score': 0.1270412088129585,\n",
              "    'word': 'multidimensional'},\n",
              "   {'score': 0.1270412088129585, 'word': 'projection'},\n",
              "   {'score': 0.1270412088129585, 'word': 'techniques'},\n",
              "   {'score': 0.07902141718376213, 'word': 'flexible'},\n",
              "   {'score': 0.07902141718376213, 'word': 'enough'},\n",
              "   {'score': 0.07902141718376213, 'word': 'mechanisms'},\n",
              "   {'score': 0.06222933407859054, 'word': 'accuracy'},\n",
              "   {'score': 0.06152426328046537, 'word': 'computational'},\n",
              "   {'score': 0.06152426328046537, 'word': 'times'},\n",
              "   {'score': 0.05687849506700788, 'word': 'lamp'}],\n",
              "  'Title': 'Local Affine Multidimensional Projection',\n",
              "  'distance': 0,\n",
              "  'no': '224',\n",
              "  'parent': '3592'},\n",
              " {'Abstract': 'We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.',\n",
              "  'AuthorKeywords': ['Dynamic',\n",
              "   'graph',\n",
              "   'visualization,',\n",
              "   'graph',\n",
              "   'splatting,',\n",
              "   'software',\n",
              "   'visualization,',\n",
              "   'software',\n",
              "   'evolution'],\n",
              "  'MultipartiteRank': [{'score': 0.07488071967345598, 'word': 'graphs'},\n",
              "   {'score': 0.061228077213886976, 'word': 'edges'},\n",
              "   {'score': 0.052926794351475306, 'word': 'organized'},\n",
              "   {'score': 0.052926794351475306, 'word': 'vertices'},\n",
              "   {'score': 0.03783313770779006, 'word': 'narrow'},\n",
              "   {'score': 0.03783313770779006, 'word': 'stripes'},\n",
              "   {'score': 0.033268992968255015, 'word': 'vertical'}],\n",
              "  'Title': 'Parallel Edge Splatting for Scalable Dynamic Graph Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '225',\n",
              "  'parent': '5240'},\n",
              " {'Abstract': 'This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.',\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'uncertainty',\n",
              "   'categories,',\n",
              "   'visual',\n",
              "   'variables,',\n",
              "   'semiotics'],\n",
              "  'MultipartiteRank': [{'score': 0.18478494058831718, 'word': 'uncertainty'},\n",
              "   {'score': 0.10851315442723261, 'word': 'visualization'},\n",
              "   {'score': 0.05955114404200289, 'word': 'visual'},\n",
              "   {'score': 0.05955114404200289, 'word': 'semiotics'},\n",
              "   {'score': 0.050385155666363604, 'word': 'experiments'},\n",
              "   {'score': 0.041513469454060085, 'word': 'kinds'}],\n",
              "  'Title': 'Visual Semiotics & Uncertainty Visualization: An Empirical Study',\n",
              "  'distance': 0,\n",
              "  'no': '226',\n",
              "  'parent': '4570'},\n",
              " {'Abstract': 'A probe for the interactive visualization of flow fields is presented. The probe can be used to visualize many characteristics of the flow in detail for a small region in the data set. The velocity and the local change of velocity (the velocity gradient tensor) are visualized by a set of geometric primitives. To this end, the velocity gradient tensor is transformed to a local coordinate frame, and decomposed into components parallel with and perpendicular to the flow. These components are visualized as geometric objects with an intuitively meaningful interpretation. An implementation is presented which shows that this probe is a useful tool for flow visualization.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15650979344583998, 'word': 'flow'},\n",
              "   {'score': 0.10088696111687454, 'word': 'velocity'},\n",
              "   {'score': 0.09852731732217733, 'word': 'fields'},\n",
              "   {'score': 0.07509411672671065, 'word': 'probe'},\n",
              "   {'score': 0.05707130797117497, 'word': 'geometric'},\n",
              "   {'score': 0.05707130797117497, 'word': 'primitives'}],\n",
              "  'Title': 'A probe for local flow field visualization',\n",
              "  'distance': 0,\n",
              "  'no': '227',\n",
              "  'parent': '3527'},\n",
              " {'Abstract': 'Presents a new method for adaptive surface meshing and triangulation which controls the local level-of-detail of the surface approximation by local spectral estimates. These estimates are determined by a wavelet representation of the surface data. The basic idea is to decompose the initial data set by means of an orthogonal or semi-orthogonal tensor product wavelet transform (WT) and to analyze the resulting coefficients. In surface regions where the partial energy of the resulting coefficients is low, the polygonal approximation of the surface can be performed with larger triangles without losing too much fine-grain detail. However, since the localization of the WT is bound by the Heisenberg principle, the meshing method has to be controlled by the detail signals rather than directly by the coefficients. The dyadic scaling of the WT stimulated us to build a hierarchical meshing algorithm which transforms the initially regular data grid into a quadtree representation by rejection of unimportant mesh vertices. The optimum triangulation of the resulting quadtree cells is carried out by selection from a look-up table. The tree grows recursively, as controlled by the detail signals, which are computed from a modified inverse WT. In order to control the local level-of-detail, we introduce a new class of wavelet space filters acting as \"magnifying glasses\" on the data.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14055279581977964, 'word': 'surface'},\n",
              "   {'score': 0.08832949436511678, 'word': 'adaptive'},\n",
              "   {'score': 0.08832949436511678, 'word': 'meshing'},\n",
              "   {'score': 0.06252508455068223, 'word': 'detail'},\n",
              "   {'score': 0.05222330145466286, 'word': 'data'},\n",
              "   {'score': 0.05079266312613163, 'word': 'new'},\n",
              "   {'score': 0.05079266312613163, 'word': 'method'},\n",
              "   {'score': 0.04875112356344901, 'word': 'local'},\n",
              "   {'score': 0.04875112356344901, 'word': 'level'}],\n",
              "  'Title': 'Fast multiresolution surface meshing',\n",
              "  'distance': 0,\n",
              "  'no': '228',\n",
              "  'parent': '4877'},\n",
              " {'Abstract': 'Presents a conceptual framework and a process model for feature extraction and iconic visualization. Feature extraction is viewed as a process of data abstraction, which can proceed in multiple stages, and corresponding data abstraction levels. The features are represented by attribute sets, which play a key role in the visualization process. Icons are symbolic parametric objects, designed as visual representations of features. The attributes are mapped to the parameters (or degrees of freedom) of an icon. We describe some generic techniques to generate attribute sets, such as volume integrals and medial axis transforms. A simple but powerful modeling language was developed to create icons, and to link the attributes to the icon parameters. We present illustrative examples of iconic visualization created with the techniques described, showing the effectiveness of this approach.',\n",
              "  'AuthorKeywords': ['scientific',\n",
              "   'visualization,',\n",
              "   'feature',\n",
              "   'extraction,',\n",
              "   'iconic',\n",
              "   'visualization,',\n",
              "   'attribute',\n",
              "   'calculation'],\n",
              "  'MultipartiteRank': [{'score': 0.1118896694945046, 'word': 'iconic'},\n",
              "   {'score': 0.1118896694945046, 'word': 'visualization'},\n",
              "   {'score': 0.10306437659229406, 'word': 'feature'},\n",
              "   {'score': 0.10306437659229406, 'word': 'extraction'},\n",
              "   {'score': 0.08135993813786287, 'word': 'process'},\n",
              "   {'score': 0.08135993813786287, 'word': 'model'},\n",
              "   {'score': 0.06223909712873467, 'word': 'attribute'},\n",
              "   {'score': 0.06223909712873467, 'word': 'sets'},\n",
              "   {'score': 0.04383231049699461, 'word': 'data'},\n",
              "   {'score': 0.04383231049699461, 'word': 'abstraction'}],\n",
              "  'Title': 'Iconic techniques for feature visualization',\n",
              "  'distance': 0,\n",
              "  'no': '229',\n",
              "  'parent': '3667'},\n",
              " {'Abstract': 'Multi-triangulation (MT) is a general framework for managing the level-of-detail in large triangle meshes, which we have introduced in our previous work. In this paper, we describe an efficient implementation of an MT based on vertex decimation. We present general techniques for querying an MT, which are independent of a specific application, and which can be applied for solving problems, such as selective refinement, windowing, point location, and other spatial interference queries. We describe alternative data structures for encoding an MT, which achieve different trade-offs between space and performance. Experimental results are discussed.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.070753363081998, 'word': 'general'},\n",
              "   {'score': 0.070753363081998, 'word': 'framework'},\n",
              "   {'score': 0.05238355287982538, 'word': 'space'},\n",
              "   {'score': 0.05119911777452002, 'word': 'offs'},\n",
              "   {'score': 0.05109343799926068, 'word': 'detail'},\n",
              "   {'score': 0.04987139802349061, 'word': 'performance'}],\n",
              "  'Title': 'Efficient implementation of multi-triangulations',\n",
              "  'distance': 0,\n",
              "  'no': '230',\n",
              "  'parent': '3819'},\n",
              " {'Abstract': 'We present an algorithm for haptic display of moderately complex polygonal models with a six degree of freedom (DOF) force feedback device. We make use of incremental algorithms for contact determination between convex primitives. The resulting contact information is used for calculating the restoring forces and torques and thereby used to generate a sense of virtual touch. To speed up the computation, our approach exploits a combination of geometric locality, temporal coherence, and predictive methods to compute object-object contacts at kHz rates. The algorithm has been implemented and interfaced with a 6-DOF PHANToM Premium 1.5. We demonstrate its performance on force display of the mechanical interaction between moderately complex geometric structures that can be decomposed into convex primitives.',\n",
              "  'AuthorKeywords': ['haptics,',\n",
              "   'virtual',\n",
              "   'reality,',\n",
              "   'forcefeedback',\n",
              "   'devices,',\n",
              "   'interactive',\n",
              "   'computer',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.08120438651628907, 'word': 'algorithm'},\n",
              "   {'score': 0.0731176652134093, 'word': 'force'},\n",
              "   {'score': 0.0731176652134093, 'word': 'feedback'},\n",
              "   {'score': 0.0731176652134093, 'word': 'device'},\n",
              "   {'score': 0.04928742709403651, 'word': 'contact'},\n",
              "   {'score': 0.04928742709403651, 'word': 'determination'},\n",
              "   {'score': 0.048227691870268846, 'word': 'object'},\n",
              "   {'score': 0.03968720856638809, 'word': 'dof'}],\n",
              "  'Title': 'Six degree-of-freedom haptic display of polygonal models',\n",
              "  'distance': 0,\n",
              "  'no': '231',\n",
              "  'parent': '3966'},\n",
              " {'Abstract': 'We present an extremely fast graph drawing algorithm for very large graphs, which we term ACE (for Algebraic multigrid Computation of Eigenvectors). ACE exhibits an improvement of something like two orders of magnitude over the fastest algorithms we are aware of; it draws graphs of millions of nodes in less than a minute. ACE finds an optimal drawing by minimizing a quadratic energy function. The minimization problem is expressed as a generalized eigenvalue problem, which is rapidly solved using a novel algebraic multigrid technique. The same generalized eigenvalue problem seems to come up also in other fields, hence ACE appears to be applicable outside of graph drawing too.',\n",
              "  'AuthorKeywords': ['algebraic',\n",
              "   'multigrid,',\n",
              "   'multiscale/multilevel',\n",
              "   'optimization,',\n",
              "   'graph',\n",
              "   'drawing,',\n",
              "   'generalized',\n",
              "   'eigenvalue',\n",
              "   'problem,',\n",
              "   'Fiedler',\n",
              "   'vector,',\n",
              "   'force',\n",
              "   'directed',\n",
              "   'layout,',\n",
              "   'the',\n",
              "   'Hall',\n",
              "   'energy'],\n",
              "  'MultipartiteRank': [{'score': 0.123941564657417, 'word': 'ace'},\n",
              "   {'score': 0.09577619353157886, 'word': 'fast'},\n",
              "   {'score': 0.09577619353157886, 'word': 'graph'},\n",
              "   {'score': 0.09577619353157886, 'word': 'drawing'},\n",
              "   {'score': 0.09577619353157886, 'word': 'algorithm'},\n",
              "   {'score': 0.06513300799934864, 'word': 'algebraic'},\n",
              "   {'score': 0.06513300799934864, 'word': 'multigrid'},\n",
              "   {'score': 0.06513300799934864, 'word': 'computation'},\n",
              "   {'score': 0.0558555002544348, 'word': 'minimization'},\n",
              "   {'score': 0.0558555002544348, 'word': 'problem'},\n",
              "   {'score': 0.047353979857283075, 'word': 'eigenvectors'}],\n",
              "  'Title': 'ACE: a fast multiscale eigenvectors computation for drawing huge graphs',\n",
              "  'distance': 0,\n",
              "  'no': '232',\n",
              "  'parent': '3719'},\n",
              " {'Abstract': 'We present a 3-D antialiasing algorithm for voxel-based geometric models. The technique band-limits the continuous object before sampling it at the desired 3-D raster resolution. By precomputing tables of filter values for different types and sizes of geometric objects, the algorithm is very efficient and has a complexity that is linear with the number of voxels generated. The algorithm not only creates voxel models which are free from object space aliasing, but it also incorporates the image space antialiasing information as part of the view independent voxel model. The resulting alias-free voxel models have been used to model synthetic scenes, for discrete ray tracing applications. The discrete ray-traced image is superior in quality to the image generated with a conventional surface-based ray tracer, since silhouettes of objects, shadows, and reflections appear smooth (jaggy-less). In addition, the alias-free models are also suitable for intermixing with sampled datasets, since they can be treated uniformly as one common data representation.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': ['voxelization,',\n",
              "   'volume',\n",
              "   'sampling,',\n",
              "   'discrete',\n",
              "   'ray',\n",
              "   'tracing,',\n",
              "   'filtering'],\n",
              "  'MultipartiteRank': [{'score': 0.07708747489363255, 'word': 'geometric'},\n",
              "   {'score': 0.07708747489363255, 'word': 'models'},\n",
              "   {'score': 0.06866500568472866, 'word': 'continuous'},\n",
              "   {'score': 0.06866500568472866, 'word': 'object'},\n",
              "   {'score': 0.05419655464773747, 'word': 'algorithm'},\n",
              "   {'score': 0.045147944282302316, 'word': 'voxel'},\n",
              "   {'score': 0.04334860304175056, 'word': 'image'},\n",
              "   {'score': 0.04334860304175056, 'word': 'space'}],\n",
              "  'Title': 'Volume sampled voxelization of geometric primitives',\n",
              "  'distance': 0,\n",
              "  'no': '233',\n",
              "  'parent': '4743'},\n",
              " {'Abstract': 'We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.',\n",
              "  'AuthorKeywords': ['Incremental',\n",
              "   'Visualization,',\n",
              "   'Event-based',\n",
              "   'Data,',\n",
              "   'Lens',\n",
              "   'Distortion'],\n",
              "  'MultipartiteRank': [{'score': 0.12964118454582688, 'word': 'incremental'},\n",
              "   {'score': 0.07170858573845672, 'word': 'logarithmic'},\n",
              "   {'score': 0.07170858573845672, 'word': 'time'},\n",
              "   {'score': 0.06703367568173905, 'word': 'series'},\n",
              "   {'score': 0.06703367568173905, 'word': 'technique'},\n",
              "   {'score': 0.05793259880737015, 'word': 'data'},\n",
              "   {'score': 0.04148251720477549, 'word': 'visual'},\n",
              "   {'score': 0.04148251720477549, 'word': 'analysis'},\n",
              "   {'score': 0.03518541079679981, 'word': 'representations'}],\n",
              "  'Title': 'CloudLines: Compact Display of Event Episodes in Multiple Time-Series',\n",
              "  'distance': 0,\n",
              "  'no': '234',\n",
              "  'parent': '6017'},\n",
              " {'Abstract': 'This paper presents a technique for performing volume morphing between two volumetric datasets in the wavelet domain. The idea is to decompose the volumetric datasets into a set of frequency bands, apply smooth interpolation to each band, and reconstruct to form the morphed model. In addition, a technique for establishing a suitable correspondence among object voxels is presented. The combination of these two techniques results in a smooth transition between the two datasets and produces morphed volume with fewer high frequency distortions than those obtained from spatial domain volume morphing.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1000880191786903, 'word': 'volumetric'},\n",
              "   {'score': 0.1000880191786903, 'word': 'datasets'},\n",
              "   {'score': 0.09710777415858313, 'word': 'technique'},\n",
              "   {'score': 0.08671766571559215, 'word': 'frequency'},\n",
              "   {'score': 0.08671766571559215, 'word': 'bands'},\n",
              "   {'score': 0.07199399266286617, 'word': 'smooth'},\n",
              "   {'score': 0.07199399266286617, 'word': 'interpolation'},\n",
              "   {'score': 0.0633848746700441, 'word': 'volume'}],\n",
              "  'Title': 'Wavelet-based volume morphing',\n",
              "  'distance': 0,\n",
              "  'no': '235',\n",
              "  'parent': '3891'},\n",
              " {'Abstract': 'The Name Voyager, a Web based visualization of historical trends in baby naming, has proven remarkably popular. This paper discusses the interaction techniques it uses for smooth visual exploration of thousands of time series. We also describe design decisions behind the application and lessons learned in creating an application that makes do-it-yourself data mining popular. The prime lesson, it is hypothesized, is that an information visualization tool may be fruitfully viewed not as a tool but as part of an online social environment. In other words, to design a successful exploratory data analysis tool, one good strategy is to create a system that enables \"social\" data analysis',\n",
              "  'AuthorKeywords': ['Design',\n",
              "   'Study,',\n",
              "   'Time-Varying',\n",
              "   'Data',\n",
              "   'Visualization,',\n",
              "   'Human-Computer',\n",
              "   'Interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.08315542584078268, 'word': 'name'},\n",
              "   {'score': 0.08315542584078268, 'word': 'voyager'},\n",
              "   {'score': 0.08211432083540034, 'word': 'visualization'},\n",
              "   {'score': 0.05613030728095812, 'word': 'popular'},\n",
              "   {'score': 0.05481446159663884, 'word': 'application'},\n",
              "   {'score': 0.05371110371733909, 'word': 'web'}],\n",
              "  'Title': 'Baby names, visualization, and social data analysis',\n",
              "  'distance': 0,\n",
              "  'no': '236',\n",
              "  'parent': '3657'},\n",
              " {'Abstract': 'Visual-interactive cluster analysis provides valuable tools for effectively analyzing large and complex data sets. Due to desirable properties and an inherent predisposition for visualization, the Kohonen Feature Map (or self-organizing map, or SOM) algorithm is among the most popular and widely used visual clustering techniques. However, the unsupervised nature of the algorithm may be disadvantageous in certain applications. Depending on initialization and data characteristics, cluster maps (cluster layouts) may emerge that do not comply with user preferences, expectations, or the application context. Considering SOM-based analysis of trajectory data, we propose a comprehensive visual-interactive monitoring and control framework extending the basic SOM algorithm. The framework implements the general Visual Analytics idea to effectively combine automatic data analysis with human expert supervision. It provides simple, yet effective facilities for visually monitoring and interactively controlling the trajectory clustering process at arbitrary levels of detail. The approach allows the user to leverage existing domain knowledge and user preferences, arriving at improved cluster maps. We apply the framework on a trajectory clustering problem, demonstrating its potential in combining both unsupervised (machine) and supervised (human expert) processing, in producing appropriate cluster results.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10100441493345191, 'word': 'visual'},\n",
              "   {'score': 0.0584820670338865, 'word': 'kohonen'},\n",
              "   {'score': 0.0584820670338865, 'word': 'feature'},\n",
              "   {'score': 0.0584820670338865, 'word': 'map'},\n",
              "   {'score': 0.055694825847857184, 'word': 'interactive'},\n",
              "   {'score': 0.055694825847857184, 'word': 'cluster'},\n",
              "   {'score': 0.055694825847857184, 'word': 'analysis'},\n",
              "   {'score': 0.040547098136003386, 'word': 'algorithm'},\n",
              "   {'score': 0.029771942358025123, 'word': 'som'}],\n",
              "  'Title': 'Visual cluster analysis of trajectory data with interactive Kohonen Maps',\n",
              "  'distance': 0,\n",
              "  'no': '237',\n",
              "  'parent': '4690'},\n",
              " {'Abstract': \"The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12240672638248398, 'word': 'data'},\n",
              "   {'score': 0.05791137570980665, 'word': 'appropriate'},\n",
              "   {'score': 0.05791137570980665, 'word': 'distance'},\n",
              "   {'score': 0.05791137570980665, 'word': 'function'},\n",
              "   {'score': 0.053920367504046156, 'word': 'system'},\n",
              "   {'score': 0.043873713411058425, 'word': 'experts'},\n",
              "   {'score': 0.03500489549286995, 'word': 'user'}],\n",
              "  'Title': 'Dis-function: Learning distance functions interactively',\n",
              "  'distance': 0,\n",
              "  'no': '238',\n",
              "  'parent': '5531'},\n",
              " {'Abstract': 'We study the topology of symmetric, second-order tensor fields. The goal is to represent their complex structure by a simple set of carefully chosen points and lines analogous to vector field topology. We extract topological skeletons of the eigenvector fields, and we track their evolution over time. We study tensor topological transitions and correlate tensor and vector data. The basic constituents of tensor topology are the degenerate points, or points where eigenvalues are equal to each other. Degenerate points play a similar role as critical points in vector fields. We identify two kinds of elementary degenerate points, which we call wedges and trisectors. They can combine to form more familiar singularities-such as saddles, nodes, centers, or foci. However, these are generally unstable structures in tensor fields. Finally, we show a topological rule that puts a constraint on the topology of tensor fields defined across surfaces, extending to tensor fields the Poincare-Hopf theorem for vector fields.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12642031296908124, 'word': 'tensor'},\n",
              "   {'score': 0.12642031296908124, 'word': 'fields'},\n",
              "   {'score': 0.10901355704957714, 'word': 'topology'},\n",
              "   {'score': 0.08721197196564173, 'word': 'order'},\n",
              "   {'score': 0.07294030089585984, 'word': 'points'},\n",
              "   {'score': 0.037833760774916264, 'word': 'vector'},\n",
              "   {'score': 0.037833760774916264, 'word': 'data'}],\n",
              "  'Title': 'The topology of symmetric, second-order tensor fields',\n",
              "  'distance': 0,\n",
              "  'no': '239',\n",
              "  'parent': '4845'},\n",
              " {'Abstract': 'Triangle decimation techniques reduce the number of triangles in a mesh, typically to improve interactive rendering performance or reduce data storage and transmission requirements. Most of these algorithms are designed to preserve the original topology of the mesh. Unfortunately, this characteristic is a strong limiting factor in overall reduction capability, since objects with a large number of holes or other topological constraints cannot be effectively reduced. The author presents an algorithm that yields a guaranteed reduction level, modifying topology as necessary to achieve the desired result. In addition, the algorithm is based on a fast local decimation technique, and its operations can be encoded for progressive storage, transmission, and reconstruction. He describes the new progressive decimation algorithm, introduces mesh splitting operations and shows how they can be encoded as a progressive mesh. He also demonstrates the utility of the algorithm on models ranging in size from 1,132 to 1.68 million triangles and reduction ratios of up to 200:1.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07062177163653724, 'word': 'algorithms'},\n",
              "   {'score': 0.06279691459801799, 'word': 'mesh'},\n",
              "   {'score': 0.05691475907143183, 'word': 'number'},\n",
              "   {'score': 0.051877573414971484, 'word': 'triangles'},\n",
              "   {'score': 0.050984517028283514, 'word': 'decimation'},\n",
              "   {'score': 0.050984517028283514, 'word': 'techniques'}],\n",
              "  'Title': 'A topology modifying progressive decimation algorithm',\n",
              "  'distance': 0,\n",
              "  'no': '240',\n",
              "  'parent': '4893'},\n",
              " {'Abstract': 'This paper discusses strategies for effectively portraying 3D flow using volume line integral convolution. Issues include defining an appropriate input texture, clarifying the distinct identities and relative depths of the advected texture elements, and selectively highlighting regions of interest in both the input and output volumes. Apart from offering insights into the greater potential of 3D LIC as a method for effectively representing flow in a volume, a principal contribution of this work is the suggestion of a technique for generating and rendering 3D visibility-impeding \"halos\" that can help to intuitively indicate the presence of depth discontinuities between contiguous elements in a projection and thereby clarify the 3D spatial organization of elements in the flow. The proposed techniques are applied to the visualization of a hot, supersonic, laminar jet exiting into a colder, subsonic coflow.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10834000687552564, 'word': 'texture'},\n",
              "   {'score': 0.06362901808527034, 'word': '3d'},\n",
              "   {'score': 0.06362901808527034, 'word': 'flow'},\n",
              "   {'score': 0.05434237364859746, 'word': 'elements'},\n",
              "   {'score': 0.05399763322692819, 'word': 'appropriate'},\n",
              "   {'score': 0.05399763322692819, 'word': 'input'},\n",
              "   {'score': 0.047760021249422996, 'word': 'relative'},\n",
              "   {'score': 0.047760021249422996, 'word': 'depths'},\n",
              "   {'score': 0.04366100681345524, 'word': 'output'},\n",
              "   {'score': 0.04366100681345524, 'word': 'volumes'}],\n",
              "  'Title': 'Strategies for effectively visualizing 3D flow with volume LIC',\n",
              "  'distance': 0,\n",
              "  'no': '241',\n",
              "  'parent': '3984'},\n",
              " {'Abstract': 'Large area tiled displays are gaining popularity for use in collaborative immersive virtual environments and scientific visualization. While recent work has addressed the issues of geometric registration, rendering architectures, and human interfaces, there has been relatively little work on photometric calibration in general, and photometric non-uniformity in particular. For example, as a result of differences in the photometric characteristics of projectors, the color and intensity of a large area display varies from place to place. Further, the imagery typically appears brighter at the regions of overlap between adjacent projectors. We analyze and classify the causes of photometric non-uniformity in a tiled display. We then propose a methodology for determining corrections designed to achieve uniformity, that can correct for the photometric variations across a tiled projector display in real time using per channel color look-up-tables (LUT).',\n",
              "  'AuthorKeywords': ['large',\n",
              "   'area',\n",
              "   'display,',\n",
              "   'tiled',\n",
              "   'displays,',\n",
              "   'projector',\n",
              "   'graphics,',\n",
              "   'color',\n",
              "   'calibration'],\n",
              "  'MultipartiteRank': [{'score': 0.06996789668004542, 'word': 'large'},\n",
              "   {'score': 0.06996789668004542, 'word': 'area'},\n",
              "   {'score': 0.059699077246703064, 'word': 'displays'},\n",
              "   {'score': 0.05634382884473474, 'word': 'photometric'},\n",
              "   {'score': 0.05634382884473474, 'word': 'calibration'},\n",
              "   {'score': 0.04851331469034907, 'word': 'recent'},\n",
              "   {'score': 0.04851331469034907, 'word': 'work'},\n",
              "   {'score': 0.03715858643022495, 'word': 'projectors'}],\n",
              "  'Title': 'Achieving color uniformity across multi-projector displays',\n",
              "  'distance': 0,\n",
              "  'no': '242',\n",
              "  'parent': '4262'},\n",
              " {'Abstract': 'Surface texturing aids the visualization of polygonal meshes by providing additional surface orientation cues and feature annotations. Such texturing is usually implemented via texture mapping, which is easier and more effective when the distortion of the mapping from the surface to the texture map is kept small. We have previously shown that distortion occurs when areas of high surface curvature are flattened into the texture map. By cutting the surface in these areas one can reduce texture map distortion at the expense of additional seam artifacts. This paper describes a faster technique for guiding a texture map seam through high distortion regions, while restricting the seam to regions of low visibility. This results in distortion reducing seams that are less visually distracting and take less time to compute. We have also observed that visibility considerations improve the speed of a recent method that adds cuts to reduce a surface genus.',\n",
              "  'AuthorKeywords': ['Texture', 'Mapping,', 'Visibility', 'Classification'],\n",
              "  'MultipartiteRank': [{'score': 0.1313985620546543, 'word': 'surface'},\n",
              "   {'score': 0.1116654370026247, 'word': 'texture'},\n",
              "   {'score': 0.1116654370026247, 'word': 'mapping'},\n",
              "   {'score': 0.07548506698338707, 'word': 'distortion'},\n",
              "   {'score': 0.054858476271303844, 'word': 'additional'},\n",
              "   {'score': 0.054858476271303844, 'word': 'seam'},\n",
              "   {'score': 0.054858476271303844, 'word': 'artifacts'},\n",
              "   {'score': 0.04685584551103916, 'word': 'areas'}],\n",
              "  'Title': 'Seamster: inconspicuous low-distortion texture seam layout',\n",
              "  'distance': 0,\n",
              "  'no': '243',\n",
              "  'parent': '4513'},\n",
              " {'Abstract': \"When displaying thousands of aircraft trajectories on a screen, the visualization is spoiled by a tangle of trails. The visual analysis is therefore difficult, especially if a specific class of trajectories in an erroneous dataset has to be studied. We designed FromDaDy, a trajectory visualization tool that tackles the difficulties of exploring the visualization of multiple trails. This multidimensional data exploration is based on scatterplots, brushing, pick and drop, juxtaposed views and rapid visual design. Users can organize the workspace composed of multiple juxtaposed views. They can define the visual configuration of the views by connecting data dimensions from the dataset to Bertin's visual variables. They can then brush trajectories, and with a pick and drop operation they can spread the brushed information across views. They can then repeat these interactions, until they extract a set of relevant data, thus formulating complex queries. Through two real-world scenarios, we show how FromDaDy supports iterative queries and the extraction of trajectories in a dataset that contains up to 5 million data.\",\n",
              "  'AuthorKeywords': ['visualization,',\n",
              "   'iterative',\n",
              "   'exploration,',\n",
              "   'direct',\n",
              "   'manipulation,',\n",
              "   'trajectories'],\n",
              "  'MultipartiteRank': [{'score': 0.11362781146668433, 'word': 'visualization'},\n",
              "   {'score': 0.07009400382484884, 'word': 'aircraft'},\n",
              "   {'score': 0.07009400382484884, 'word': 'trajectories'},\n",
              "   {'score': 0.05463511983327354, 'word': 'trails'},\n",
              "   {'score': 0.04773240511390324, 'word': 'multidimensional'},\n",
              "   {'score': 0.04773240511390324, 'word': 'data'},\n",
              "   {'score': 0.04773240511390324, 'word': 'exploration'},\n",
              "   {'score': 0.04754348228874428, 'word': 'juxtaposed'},\n",
              "   {'score': 0.04754348228874428, 'word': 'views'}],\n",
              "  'Title': 'FromDaDy: Spreading Aircraft Trajectories Across Views to Support Iterative Queries',\n",
              "  'distance': 0,\n",
              "  'no': '244',\n",
              "  'parent': '4251'},\n",
              " {'Abstract': 'In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.',\n",
              "  'AuthorKeywords': ['Parallel',\n",
              "   'Coordinates,',\n",
              "   'Scatterplots,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Multidimensional',\n",
              "   'Scaling'],\n",
              "  'MultipartiteRank': [{'score': 0.15788641174473617, 'word': 'parallel'},\n",
              "   {'score': 0.15788641174473617, 'word': 'coordinates'},\n",
              "   {'score': 0.10375656264433265, 'word': 'novel'},\n",
              "   {'score': 0.10375656264433265, 'word': 'design'},\n",
              "   {'score': 0.08162133720137996, 'word': 'points'},\n",
              "   {'score': 0.04805492037764801, 'word': 'scatterplots'},\n",
              "   {'score': 0.04294417324354468, 'word': 'interaction'},\n",
              "   {'score': 0.04294417324354468, 'word': 'tools'}],\n",
              "  'Title': 'Scattering Points in Parallel Coordinates',\n",
              "  'distance': 0,\n",
              "  'no': '245',\n",
              "  'parent': '5184'},\n",
              " {'Abstract': 'In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'Visualization,',\n",
              "   'Euler',\n",
              "   'diagrams,',\n",
              "   'Set',\n",
              "   'Visualization,',\n",
              "   'Graph',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.09671645116270339, 'word': 'sets'},\n",
              "   {'score': 0.05030224096186578, 'word': 'several'},\n",
              "   {'score': 0.05030224096186578, 'word': 'approaches'},\n",
              "   {'score': 0.04573490549342458, 'word': 'data'},\n",
              "   {'score': 0.04573490549342458, 'word': 'elements'},\n",
              "   {'score': 0.03704614193665865, 'word': 'euler'},\n",
              "   {'score': 0.03704614193665865, 'word': 'style'},\n",
              "   {'score': 0.03704614193665865, 'word': 'diagrams'},\n",
              "   {'score': 0.034416694555190475, 'word': 'common'},\n",
              "   {'score': 0.034416694555190475, 'word': 'visual'},\n",
              "   {'score': 0.034416694555190475, 'word': 'representation'}],\n",
              "  'Title': 'Untangling Euler Diagrams',\n",
              "  'distance': 0,\n",
              "  'no': '246',\n",
              "  'parent': '6367'},\n",
              " {'Abstract': 'In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'layouts,',\n",
              "   'edge',\n",
              "   'bundles,',\n",
              "   'image-based',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08252254706527452, 'word': 'layouts'},\n",
              "   {'score': 0.0645590055891589, 'word': 'edges'},\n",
              "   {'score': 0.06194130844465527, 'word': 'general'},\n",
              "   {'score': 0.06194130844465527, 'word': 'graphs'},\n",
              "   {'score': 0.04538633172490661, 'word': 'efficient'},\n",
              "   {'score': 0.04538633172490661, 'word': 'implementation'},\n",
              "   {'score': 0.043800614936379975, 'word': 'skeletons'}],\n",
              "  'Title': 'Skeleton-Based Edge Bundling for Graph Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '247',\n",
              "  'parent': '3916'},\n",
              " {'Abstract': 'The paper describes an implementation of a tool for visualizing and interacting with huge information hierarchies, and some preliminary empirical evaluation of the tool\\'s efficacy. Existing systems for visualizing huge hierarchies using cone trees \"break down\" once the hierarchy to be displayed exceeds roughly 1000 nodes, due to increasing visual clutter. The paper describes a system called fsviz which visualizes arbitrarily large hierarchies while retaining user control. This is accomplished by augmenting cone trees with several graphical and interaction techniques: usage-based filtering, animated zooming, hand-coupled rotation, fish-eye zooming, coalescing of distant nodes, texturing, effective use of colour for depth cueing, and the applications of dynamic queries. The fsviz system also improves upon earlier cone tree visualization systems through a more elaborate node layout algorithm. This algorithm enhances the usefulness of cone tree visualization for large hierarchies by all but eliminating clutter.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08142008091469732, 'word': 'huge'},\n",
              "   {'score': 0.08142008091469732, 'word': 'information'},\n",
              "   {'score': 0.08142008091469732, 'word': 'hierarchies'},\n",
              "   {'score': 0.0637789374025297, 'word': 'cone'},\n",
              "   {'score': 0.0637789374025297, 'word': 'trees'},\n",
              "   {'score': 0.047438410510033724, 'word': 'tool'},\n",
              "   {'score': 0.04672100033465486, 'word': 'systems'},\n",
              "   {'score': 0.04007591155256438, 'word': 'zooming'}],\n",
              "  'Title': 'Research report. Interacting with huge hierarchies: beyond cone trees',\n",
              "  'distance': 0,\n",
              "  'no': '248',\n",
              "  'parent': '4863'},\n",
              " {'Abstract': 'This paper presents a novel method to extract vortical structures from 3D CFD (computational fluid dynamics) vector fields automatically. It discusses the underlying theory and some aspects of the implementation. Making use of higher-order derivatives, the method is able to locate bent vortices. In order to structure the recognition procedure, we distinguish locating the core line from calculating attributes of strength and quality. Results are presented on several flow fields from the field of turbomachinery.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07963678402628331, 'word': 'vortical'},\n",
              "   {'score': 0.07963678402628331, 'word': 'structures'},\n",
              "   {'score': 0.07868127749267785, 'word': 'novel'},\n",
              "   {'score': 0.07868127749267785, 'word': 'method'},\n",
              "   {'score': 0.0730938050324194, 'word': 'vector'},\n",
              "   {'score': 0.0730938050324194, 'word': 'fields'},\n",
              "   {'score': 0.05982193993975221, 'word': 'order'},\n",
              "   {'score': 0.05982193993975221, 'word': 'derivatives'},\n",
              "   {'score': 0.05761138530097923, 'word': '3d'},\n",
              "   {'score': 0.05761138530097923, 'word': 'cfd'}],\n",
              "  'Title': 'A higher-order method for finding vortex core lines',\n",
              "  'distance': 0,\n",
              "  'no': '249',\n",
              "  'parent': '3344'},\n",
              " {'Abstract': 'The paper describes some fundamental issues for robust implementations of progressively refined tetrahedralizations generated through sequences of edge collapses. We address the definition of appropriate cost functions and explain on various tests which are necessary to preserve the consistency of the mesh when collapsing edges. Although considered a special case of progressive simplicial complexes (J. Popovic and H. Hoppe, 1997), the results of our method are of high practical importance and can be used in many different applications, such as finite element meshing, scattered data interpolation, or rendering of unstructured volume data.',\n",
              "  'AuthorKeywords': ['mesh',\n",
              "   'simplification,',\n",
              "   'multiresolution,',\n",
              "   'level-of-detail,',\n",
              "   'unstructured',\n",
              "   'meshes,',\n",
              "   'mesh',\n",
              "   'generation'],\n",
              "  'MultipartiteRank': [{'score': 0.0875777565561492, 'word': 'edge'},\n",
              "   {'score': 0.0875777565561492, 'word': 'collapses'},\n",
              "   {'score': 0.06988290371367657, 'word': 'mesh'},\n",
              "   {'score': 0.05807096884044233, 'word': 'sequences'},\n",
              "   {'score': 0.050656004826414094, 'word': 'appropriate'},\n",
              "   {'score': 0.050656004826414094, 'word': 'cost'},\n",
              "   {'score': 0.050656004826414094, 'word': 'functions'},\n",
              "   {'score': 0.04893048264782157, 'word': 'definition'}],\n",
              "  'Title': 'Progressive tetrahedralizations',\n",
              "  'distance': 0,\n",
              "  'no': '250',\n",
              "  'parent': '3968'},\n",
              " {'Abstract': 'The compression of geometric structures is a relatively new field of data compression. Since about 1995, several articles have dealt with the coding of meshes, using for most of them the following approach: the vertices of the mesh are coded in an order that partially contains the topology of the mesh. In the same time, some simple rules attempt to predict the position of each vertex from the positions of its neighbors that have been previously coded. We describe a compression algorithm whose principle is completely different: the coding order of the vertices is used to compress their coordinates, and then the topology of the mesh is reconstructed from the vertices. This algorithm achieves compression ratios that are slightly better than those of the currently available algorithms, and moreover, it allows progressive and interactive transmission of the meshes.',\n",
              "  'AuthorKeywords': ['geometry,',\n",
              "   'compression,',\n",
              "   'coding,',\n",
              "   'interactivity,',\n",
              "   'mesh,',\n",
              "   'reconstruction,',\n",
              "   'terrain',\n",
              "   'models'],\n",
              "  'MultipartiteRank': [{'score': 0.1403692385593276, 'word': 'compression'},\n",
              "   {'score': 0.0968641756422904, 'word': 'meshes'},\n",
              "   {'score': 0.0715859942017404, 'word': 'geometric'},\n",
              "   {'score': 0.0715859942017404, 'word': 'structures'},\n",
              "   {'score': 0.06601410008054898, 'word': 'vertices'},\n",
              "   {'score': 0.046246444174338416, 'word': 'new'},\n",
              "   {'score': 0.046246444174338416, 'word': 'field'}],\n",
              "  'Title': 'Geometric compression for interactive transmission',\n",
              "  'distance': 0,\n",
              "  'no': '251',\n",
              "  'parent': '3843'},\n",
              " {'Abstract': 'We describe a pipeline of image processing steps for deriving symbolic models of vascular structures from radiological data which reflect the branching pattern and diameter of vessels. For the visualization of these symbolic models, concatenated truncated cones are smoothly blended at branching points. We put emphasis on the quality of the visualizations which is achieved by anti-aliasing operations in different stages of the visualization. The methods presented are referred to as HQVV (high quality vessel visualization). Scalable techniques are provided to explore vascular structures of different orders of magnitude. The hierarchy as well as the diameter of the branches of vascular systems are used to restrict visualizations to relevant subtrees and to emphasize parts of vascular systems. Our research is inspired by clear visualizations in textbooks and is targeted toward medical education and therapy planning. We describe the application of vessel visualization techniques for liver surgery planning. For this application it is crucial to recognize the morphology and branching pattern of vascular systems as well as the basic spatial relations between vessels and other anatomic structures.',\n",
              "  'AuthorKeywords': ['vessel',\n",
              "   'visualization,',\n",
              "   'medical',\n",
              "   'visualization,',\n",
              "   'computer-assisted',\n",
              "   'surgery'],\n",
              "  'MultipartiteRank': [{'score': 0.13194954335894968, 'word': 'vascular'},\n",
              "   {'score': 0.08641499705006968, 'word': 'structures'},\n",
              "   {'score': 0.07658222365542668, 'word': 'visualization'},\n",
              "   {'score': 0.06920916660290022, 'word': 'branching'},\n",
              "   {'score': 0.06920916660290022, 'word': 'pattern'},\n",
              "   {'score': 0.0645122641309304, 'word': 'vessels'},\n",
              "   {'score': 0.04553454630888001, 'word': 'systems'}],\n",
              "  'Title': 'Visualization and interaction techniques for the exploration of vascular structures',\n",
              "  'distance': 0,\n",
              "  'no': '252',\n",
              "  'parent': '4575'},\n",
              " {'Abstract': 'A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.',\n",
              "  'AuthorKeywords': ['human',\n",
              "   'information',\n",
              "   'interaction,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'sense-making,',\n",
              "   'narrative,',\n",
              "   'pattern',\n",
              "   'detection,',\n",
              "   'story',\n",
              "   'making,',\n",
              "   'story',\n",
              "   'telling'],\n",
              "  'MultipartiteRank': [{'score': 0.08003676593352632, 'word': 'story'},\n",
              "   {'score': 0.07169387150238873, 'word': 'patterns'},\n",
              "   {'score': 0.06308438120520872, 'word': 'system'},\n",
              "   {'score': 0.06283497762475174, 'word': 'analytical'},\n",
              "   {'score': 0.06283497762475174, 'word': 'process'},\n",
              "   {'score': 0.062410500012978716, 'word': 'intelligence'},\n",
              "   {'score': 0.062410500012978716, 'word': 'analysts'}],\n",
              "  'Title': 'Stories in GeoTime',\n",
              "  'distance': 0,\n",
              "  'no': '253',\n",
              "  'parent': '4186'},\n",
              " {'Abstract': \"Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.\",\n",
              "  'AuthorKeywords': ['Set',\n",
              "   'visualization,',\n",
              "   'clustering,',\n",
              "   'faceted',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'graph',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.07992677071137079, 'word': 'common'},\n",
              "   {'score': 0.051812139808456906, 'word': 'sets'},\n",
              "   {'score': 0.051531617800213696, 'word': 'elements'},\n",
              "   {'score': 0.04280219910179459, 'word': 'linesets'},\n",
              "   {'score': 0.04108609640517999, 'word': 'tasks'},\n",
              "   {'score': 0.0388406743061908, 'word': 'representations'}],\n",
              "  'Title': 'Design Study of LineSets, a Novel Set Visualization Technique',\n",
              "  'distance': 0,\n",
              "  'no': '254',\n",
              "  'parent': '4659'},\n",
              " {'Abstract': 'HyperSlice is a new method for the visualization of scalar functions of many variables. With this method the multi-dimensional function is presented in a simple and easy to understand way in which all dimensions are treated identically. The central concept is the representation of a multi-dimensional function as a matrix of orthogonal two-dimensional slices. These two-dimensional slices lend themselves very well to interaction via direct manipulation, due to a one to one relation between screen space and variable space. Several interaction techniques, for navigation, the location of maxima, and the use of user-defined paths, are presented.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07191655232880055, 'word': 'many'},\n",
              "   {'score': 0.07191655232880055, 'word': 'variables'},\n",
              "   {'score': 0.06856216165713025, 'word': 'new'},\n",
              "   {'score': 0.06856216165713025, 'word': 'method'},\n",
              "   {'score': 0.05693735468307512, 'word': 'interaction'},\n",
              "   {'score': 0.05247298009018841, 'word': 'scalar'},\n",
              "   {'score': 0.05247298009018841, 'word': 'functions'},\n",
              "   {'score': 0.048682520882364785, 'word': 'dimensional'},\n",
              "   {'score': 0.048682520882364785, 'word': 'slices'}],\n",
              "  'Title': 'HyperSlice - Visualization of Scalar Functions of Many Variables',\n",
              "  'distance': 0,\n",
              "  'no': '255',\n",
              "  'parent': '3762'},\n",
              " {'Abstract': 'A scalable, high-resolution display may be constructed by tiling many projected images over a single display surface. One fundamental challenge for such a display is to avoid visible seams due to misalignment among the projectors. Traditional methods for avoiding seams involve sophisticated mechanical devices and expensive CRT projectors, coupled with extensive human effort for fine-tuning the projectors. The paper describes an automatic alignment method that relies on an inexpensive, uncalibrated camera to measure the relative mismatches between neighboring projectors, and then correct the projected imagery to avoid seams without significant human effort.',\n",
              "  'AuthorKeywords': ['seamless',\n",
              "   'tiling,',\n",
              "   'automatic',\n",
              "   'alignment,',\n",
              "   'projective',\n",
              "   'mapping,',\n",
              "   'simulated',\n",
              "   'annealing'],\n",
              "  'MultipartiteRank': [{'score': 0.1334498892217633, 'word': 'seams'},\n",
              "   {'score': 0.09964485009445187, 'word': 'projectors'},\n",
              "   {'score': 0.09488799521942827, 'word': 'resolution'},\n",
              "   {'score': 0.09488799521942827, 'word': 'display'},\n",
              "   {'score': 0.08490965916194085, 'word': 'visible'},\n",
              "   {'score': 0.08490965916194085, 'word': 'due'},\n",
              "   {'score': 0.05317216286951591, 'word': 'high'}],\n",
              "  'Title': 'Automatic alignment of high-resolution multi-projector displays using an uncalibrated camera',\n",
              "  'distance': 0,\n",
              "  'no': '256',\n",
              "  'parent': '3585'},\n",
              " {'Abstract': 'The growing availability of massive polygonal models, and the inability of most existing visualization tools to work with such data, has created a pressing need for memory-efficient methods capable of simplifying very large meshes. In this paper, we present a method for performing adaptive simplification of polygonal meshes that are too large to fit in-core. Our algorithm performs two passes over an input mesh. In the first pass, the model is quantized using a uniform grid, and surface information is accumulated in the form of quadrics and dual quadrics. This sampling is then used to construct a BSP-tree in which the partitioning planes are determined by the dual quadrics. In the final pass, the original vertices are clustered using the BSP-tree, yielding an adaptive approximation of the original mesh. The BSP-tree describes a natural simplification hierarchy, making it possible to generate a progressive transmission and construct level-of-detail representations. In this way, the algorithm provides some of the features associated with more expensive edge contraction methods while maintaining greater computational efficiency. In addition to performing adaptive simplification, our algorithm exhibits output-sensitive memory requirements and allows fine control over the size of the simplified mesh.',\n",
              "  'AuthorKeywords': ['surface',\n",
              "   'simplification,',\n",
              "   'massive',\n",
              "   'meshes,',\n",
              "   'quadric',\n",
              "   'error',\n",
              "   'metric,',\n",
              "   'recursive',\n",
              "   'partitioning,',\n",
              "   'out-of-core',\n",
              "   'simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.05471867393853245, 'word': 'polygonal'},\n",
              "   {'score': 0.05471867393853245, 'word': 'meshes'},\n",
              "   {'score': 0.04731681222648561, 'word': 'adaptive'},\n",
              "   {'score': 0.04731681222648561, 'word': 'simplification'},\n",
              "   {'score': 0.0420431347799477, 'word': 'efficient'},\n",
              "   {'score': 0.0420431347799477, 'word': 'methods'},\n",
              "   {'score': 0.0420431347799477, 'word': 'capable'},\n",
              "   {'score': 0.041814455835071665, 'word': 'algorithm'},\n",
              "   {'score': 0.04039385397098104, 'word': 'passes'}],\n",
              "  'Title': 'Efficient Adaptive Simplification of Massive Meshes',\n",
              "  'distance': 0,\n",
              "  'no': '257',\n",
              "  'parent': '4627'},\n",
              " {'Abstract': 'The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.',\n",
              "  'AuthorKeywords': ['Focus+Context',\n",
              "   'Techniques,Lens,Volume',\n",
              "   'Rendering,',\n",
              "   'Hardware-assisted',\n",
              "   'Volume',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.06361555258595218, 'word': 'resolution'},\n",
              "   {'score': 0.06104037468790416, 'word': 'user'},\n",
              "   {'score': 0.06104037468790416, 'word': 'views'},\n",
              "   {'score': 0.05614367953349071, 'word': 'volume'},\n",
              "   {'score': 0.05614367953349071, 'word': 'datasets'},\n",
              "   {'score': 0.05508736920698034, 'word': 'data'},\n",
              "   {'score': 0.05438842126576444, 'word': 'features'}],\n",
              "  'Title': 'The magic volume lens: an interactive focus+context technique for volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '258',\n",
              "  'parent': '4257'},\n",
              " {'Abstract': 'Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second',\n",
              "  'AuthorKeywords': ['Illustrative',\n",
              "   'visualization,',\n",
              "   'exploded',\n",
              "   'views,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.10650376425231944, 'word': 'exploded'},\n",
              "   {'score': 0.10650376425231944, 'word': 'views'},\n",
              "   {'score': 0.06187643456341278, 'word': 'object'},\n",
              "   {'score': 0.04209378603683702, 'word': 'force'},\n",
              "   {'score': 0.04044824969775703, 'word': 'parts'},\n",
              "   {'score': 0.03664330307199551, 'word': 'illustration'},\n",
              "   {'score': 0.03664330307199551, 'word': 'technique'}],\n",
              "  'Title': 'Exploded Views for Volume Data',\n",
              "  'distance': 0,\n",
              "  'no': '259',\n",
              "  'parent': '4984'},\n",
              " {'Abstract': 'In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'design',\n",
              "   'study,',\n",
              "   'bioinformatics,',\n",
              "   'synteny'],\n",
              "  'MultipartiteRank': [{'score': 0.06925810657961251, 'word': 'comparative'},\n",
              "   {'score': 0.06925810657961251, 'word': 'genomics'},\n",
              "   {'score': 0.0660832689086364, 'word': 'multiple'},\n",
              "   {'score': 0.04428687337429156, 'word': 'relationships'},\n",
              "   {'score': 0.03666845254283353, 'word': 'scales'},\n",
              "   {'score': 0.031058140926825822, 'word': 'questions'},\n",
              "   {'score': 0.02941481636580287, 'word': 'types'}],\n",
              "  'Title': 'MizBee: A Multiscale Synteny Browser',\n",
              "  'distance': 0,\n",
              "  'no': '260',\n",
              "  'parent': '4590'},\n",
              " {'Abstract': 'Presents a simple, robust and practical method for object simplification for applications where gradual elimination of high-frequency details is desired. This is accomplished by sampling and low-pass filtering the object into multi-resolution volume buffers and applying the marching cubes algorithm to generate a multi-resolution triangle-mesh hierarchy. Our method simplifies the genus of objects and can also help existing object simplification algorithms achieve better results. At each level of detail, a multi-layered mesh can be used for an optional and efficient antialiased rendering.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11811602882009616, 'word': 'object'},\n",
              "   {'score': 0.11811602882009616, 'word': 'simplification'},\n",
              "   {'score': 0.08557374159310414, 'word': 'practical'},\n",
              "   {'score': 0.08557374159310414, 'word': 'method'},\n",
              "   {'score': 0.06292196300963697, 'word': 'applications'},\n",
              "   {'score': 0.06044472158018602, 'word': 'frequency'},\n",
              "   {'score': 0.06044472158018602, 'word': 'details'},\n",
              "   {'score': 0.05947564975499704, 'word': 'gradual'},\n",
              "   {'score': 0.05947564975499704, 'word': 'elimination'}],\n",
              "  'Title': 'Voxel based object simplification',\n",
              "  'distance': 0,\n",
              "  'no': '261',\n",
              "  'parent': '3486'},\n",
              " {'Abstract': 'The recent growth in the size and availability of large triangular surface models has generated interest in compact multi-resolution progressive representation and data transmission. An ongoing challenge is to design an efficient data structure that encompasses both compactness of geometric representations and visual quality of progressive representations. We introduce a topological layering based data structure and an encoding scheme to build a compact progressive representation of an arbitrary triangular mesh (a 2D simplicial complex in 3D) with attached attribute data. This compact representation is composed of multiple levels of detail that can be progressively transmitted and displayed. The global topology, which is the number of holes and connected components, can be flexibly changed among successive levels while still achieving guaranteed size of the coarsest level mesh for very complex models. The flexibility in our encoding scheme also allows topology preserving progressivity.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09233553402201031, 'word': 'geometric'},\n",
              "   {'score': 0.09233553402201031, 'word': 'representations'},\n",
              "   {'score': 0.08970026853418865, 'word': 'data'},\n",
              "   {'score': 0.08970026853418865, 'word': 'transmission'},\n",
              "   {'score': 0.05756717312007539, 'word': 'topological'},\n",
              "   {'score': 0.05756717312007539, 'word': 'layering'},\n",
              "   {'score': 0.04459002661235835, 'word': 'visual'},\n",
              "   {'score': 0.04459002661235835, 'word': 'quality'},\n",
              "   {'score': 0.04286078063160009, 'word': 'size'}],\n",
              "  'Title': 'Progressive compression and transmission of arbitrary triangular meshes',\n",
              "  'distance': 0,\n",
              "  'no': '262',\n",
              "  'parent': '3923'},\n",
              " {'Abstract': 'When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications',\n",
              "  'AuthorKeywords': ['topology,', 'multi-resolution,', 'Morse', 'theory'],\n",
              "  'MultipartiteRank': [{'score': 0.07569888103991163, 'word': 'bubbles'},\n",
              "   {'score': 0.04484312991192333, 'word': 'rayleigh'},\n",
              "   {'score': 0.0445851254691199, 'word': 'taylor'},\n",
              "   {'score': 0.0445851254691199, 'word': 'instability'},\n",
              "   {'score': 0.03761375234340856, 'word': 'interface'},\n",
              "   {'score': 0.034526920493522, 'word': 'hierarchical'},\n",
              "   {'score': 0.034526920493522, 'word': 'segmentation'}],\n",
              "  'Title': 'Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities',\n",
              "  'distance': 0,\n",
              "  'no': '263',\n",
              "  'parent': '4620'},\n",
              " {'Abstract': 'While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.',\n",
              "  'AuthorKeywords': ['visualization',\n",
              "   'systems,',\n",
              "   'query-by-example,',\n",
              "   'analogy'],\n",
              "  'MultipartiteRank': [{'score': 0.10230109598228856, 'word': 'visual'},\n",
              "   {'score': 0.10230109598228856, 'word': 'exploration'},\n",
              "   {'score': 0.07517185685812601, 'word': 'visualization'},\n",
              "   {'score': 0.07517185685812601, 'word': 'systems'},\n",
              "   {'score': 0.05163646326632231, 'word': 'process'},\n",
              "   {'score': 0.041557968573043065, 'word': 'advances'},\n",
              "   {'score': 0.0394284215602435, 'word': 'major'},\n",
              "   {'score': 0.0394284215602435, 'word': 'bottleneck'}],\n",
              "  'Title': 'Querying and Creating Visualizations by Analogy',\n",
              "  'distance': 0,\n",
              "  'no': '264',\n",
              "  'parent': '3679'},\n",
              " {'Abstract': 'A survey of graphics developers on the issue of texture mapping hardware for volume rendering would most likely find that the vast majority of them view limited texture memory as one of the most serious drawbacks of an otherwise fine technology. In this paper, we propose a compression scheme for static and time-varying volumetric data sets based on vector quantization that allows us to circumvent this limitation. We describe a hierarchical quantization scheme that is based on a multiresolution covariance analysis of the original field. This allows for the efficient encoding of large-scale data sets, yet providing a mechanism to exploit temporal coherence in non-stationary fields. We show, that decoding and rendering the compressed data stream can be done on the graphics chip using programmable hardware. In this way, data transfer between the CPU and the graphics processing unit (GPU) can be minimized thus enabling flexible and memory efficient real-time rendering options. We demonstrate the effectiveness of our approach by demonstrating interactive renditions of Gigabyte data sets at reasonable fidelity on commodity graphics hardware.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   'Vector',\n",
              "   'Quantization,',\n",
              "   'Texture',\n",
              "   'Compression,',\n",
              "   'Graphics',\n",
              "   'Hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.06239642824738416, 'word': 'volumetric'},\n",
              "   {'score': 0.06239642824738416, 'word': 'data'},\n",
              "   {'score': 0.06239642824738416, 'word': 'sets'},\n",
              "   {'score': 0.0489518657451339, 'word': 'time'},\n",
              "   {'score': 0.048207136850832284, 'word': 'graphics'},\n",
              "   {'score': 0.048207136850832284, 'word': 'developers'},\n",
              "   {'score': 0.03980674556724468, 'word': 'limited'},\n",
              "   {'score': 0.03980674556724468, 'word': 'texture'},\n",
              "   {'score': 0.03980674556724468, 'word': 'memory'},\n",
              "   {'score': 0.037044869654305305, 'word': 'static'}],\n",
              "  'Title': 'Compression domain volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '265',\n",
              "  'parent': '3802'},\n",
              " {'Abstract': 'Diffusion weighted magnetic resonance imaging is a unique tool for non-invasive investigation of major nerve fiber tracts. Since the popular diffusion tensor (DT-MRI) model is limited to voxels with a single fiber direction, a number of high angular resolution techniques have been proposed to provide information about more diverse fiber distributions. Two such approaches are Q-Ball imaging and spherical deconvolution, which produce orientation distribution functions (ODFs) on the sphere. For analysis and visualization, the maxima of these functions have been used as principal directions, even though the results are known to be biased in case of crossing fiber tracts. In this paper, we present a more reliable technique for extracting discrete orientations from continuous ODFs, which is based on decomposing their higher-order tensor representation into an isotropic component, several rank-1 terms, and a small residual. Comparing to ground truth in synthetic data shows that the novel method reduces bias and reliably reconstructs crossing fibers which are not resolved as individual maxima in the ODF We present results on both Q-Ball and spherical deconvolution data and demonstrate that the estimated directions allow for plausible fiber tracking in a real data set.',\n",
              "  'AuthorKeywords': ['DW-MRI,',\n",
              "   'Q-Ball,',\n",
              "   'spherical',\n",
              "   'deconvolution,',\n",
              "   'fiber',\n",
              "   'tracking,',\n",
              "   'higher-order',\n",
              "   'tensor,',\n",
              "   'tensor',\n",
              "   'decomposition'],\n",
              "  'MultipartiteRank': [{'score': 0.09279919511324361, 'word': 'fiber'},\n",
              "   {'score': 0.06774777053853355, 'word': 'diffusion'},\n",
              "   {'score': 0.04999917595841934, 'word': 'major'},\n",
              "   {'score': 0.04999917595841934, 'word': 'nerve'},\n",
              "   {'score': 0.04999917595841934, 'word': 'tracts'},\n",
              "   {'score': 0.04516042878550302, 'word': 'odfs'},\n",
              "   {'score': 0.04280001915482427, 'word': 'single'},\n",
              "   {'score': 0.04280001915482427, 'word': 'direction'},\n",
              "   {'score': 0.03731632451603767, 'word': 'orientation'},\n",
              "   {'score': 0.03731632451603767, 'word': 'distribution'},\n",
              "   {'score': 0.03731632451603767, 'word': 'functions'}],\n",
              "  'Title': 'Estimating Crossing fibers: A Tensor Decomposition Approach',\n",
              "  'distance': 0,\n",
              "  'no': '266',\n",
              "  'parent': '4447'},\n",
              " {'Abstract': 'The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.',\n",
              "  'AuthorKeywords': ['Time-varying',\n",
              "   'data,',\n",
              "   'conditional',\n",
              "   'entropy,',\n",
              "   'joint',\n",
              "   'feature-temporal',\n",
              "   'space,',\n",
              "   'clustering,',\n",
              "   'highlighting,',\n",
              "   'transfer',\n",
              "   'function'],\n",
              "  'MultipartiteRank': [{'score': 0.09693609216561672, 'word': 'data'},\n",
              "   {'score': 0.07159474719100659, 'word': 'importance'},\n",
              "   {'score': 0.07159474719100659, 'word': 'curve'},\n",
              "   {'score': 0.06816901492207236, 'word': 'important'},\n",
              "   {'score': 0.06729843042199314, 'word': 'time'},\n",
              "   {'score': 0.06360587525746311, 'word': 'block'}],\n",
              "  'Title': 'Importance-Driven Time-Varying Data Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '267',\n",
              "  'parent': '3658'},\n",
              " {'Abstract': 'In information visualization, as the volume and complexity of the data increases, researchers require more powerful visualization tools that enable them to more effectively explore multidimensional datasets. We discuss the general utility of a novel visualization spreadsheet framework. Just as a numerical spreadsheet enables exploration of numbers, a visualization spreadsheet enables exploration of visual forms of information. We show that the spreadsheet approach facilitates certain information visualization tasks that are more difficult using other approaches. Unlike traditional spreadsheets, which store only simple data elements and formulas in each cell, a visualization spreadsheet cell can hold an entire complex data set, selection criteria, viewing specifications, and other information needed for a full-fledged information visualization. Similarly, inter-cell operations are far more complex, stretching beyond simple arithmetic and string operations to encompass a range of domain-specific operators. We have built two prototype systems that illustrate some of these research issues. The underlying approach in our work allows domain experts to define new data types and data operations, and enables visualization experts to incorporate new visualizations, viewing parameters, and view operations.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15707184073367825, 'word': 'visualization'},\n",
              "   {'score': 0.08258987262115722, 'word': 'information'},\n",
              "   {'score': 0.07448196811252103, 'word': 'novel'},\n",
              "   {'score': 0.07448196811252103, 'word': 'spreadsheet'},\n",
              "   {'score': 0.07448196811252103, 'word': 'framework'},\n",
              "   {'score': 0.04516922326922532, 'word': 'complexity'},\n",
              "   {'score': 0.040181354356822095, 'word': 'researchers'},\n",
              "   {'score': 0.03845922226140835, 'word': 'visual'},\n",
              "   {'score': 0.03845922226140835, 'word': 'forms'}],\n",
              "  'Title': 'A spreadsheet approach to information visualization',\n",
              "  'distance': 0,\n",
              "  'no': '268',\n",
              "  'parent': '5437'},\n",
              " {'Abstract': 'Deformable isosurfaces, implemented with level-set methods, have demonstrated a great potential in visualization for applications such as segmentation, surface processing, and surface reconstruction. Their usefulness has been limited, however, by their high computational cost and reliance on significant parameter tuning. This paper presents a solution to these challenges by describing graphics processor (GPU) based on algorithms for solving and visualizing level-set solutions at interactive rates. Our efficient GPU-based solution relies on packing the level-set isosurface data into a dynamic, sparse texture format. As the level set moves, this sparse data structure is updated via a novel GPU to CPU message passing scheme. When the level-set solver is integrated with a real-time volume renderer operating on the same packed format, a user can visualize and steer the deformable level-set surface as it evolves. In addition, the resulting isosurface can serve as a region-of-interest specifier for the volume renderer. This paper demonstrates the capabilities of this technology for interactive volume visualization and segmentation.',\n",
              "  'AuthorKeywords': ['Deformable',\n",
              "   'Models,',\n",
              "   'Image',\n",
              "   'Segmentation,',\n",
              "   'Volume',\n",
              "   'Visualization,',\n",
              "   'GPU,',\n",
              "   'Level',\n",
              "   'Sets,',\n",
              "   'Streaming',\n",
              "   'Computation'],\n",
              "  'MultipartiteRank': [{'score': 0.08880708194006914, 'word': 'level'},\n",
              "   {'score': 0.07695627791587137, 'word': 'deformable'},\n",
              "   {'score': 0.07695627791587137, 'word': 'isosurfaces'},\n",
              "   {'score': 0.04828846310434814, 'word': 'solution'},\n",
              "   {'score': 0.046747901022269306, 'word': 'gpu'},\n",
              "   {'score': 0.04472482221574632, 'word': 'surface'},\n",
              "   {'score': 0.04472482221574632, 'word': 'processing'}],\n",
              "  'Title': 'Interactive deformation and visualization of level set surfaces using graphics hardware',\n",
              "  'distance': 0,\n",
              "  'no': '269',\n",
              "  'parent': '4917'},\n",
              " {'Abstract': 'This paper presents a signed distance transform algorithm using graphics hardware, which computes the scalar valued function of the Euclidean distance to a given manifold of co-dimension one. If the manifold is closed and orientable, the distance has a negative sign on one side of the manifold and a positive sign on the other. Triangle meshes are considered for the representation of a two-dimensional manifold and the distance function is sampled on a regular Cartesian grid. In order to achieve linear complexity in the number of grid points, to each primitive we assign a simple polyhedron enclosing its Voronoi cell. Voronoi cells are known to contain exactly all points that lay closest to its corresponding primitive. Thus, the distance to the primitive only has to be computed for grid points inside its polyhedron. Although Voronoi cells partition space, the polyhedrons enclosing these cells do overlap. In regions where these overlaps occur, the minimum of all computed distances is assigned to a grid point. In order to speed up computations, points inside each polyhedron are determined by scan conversion of grid slices using graphics hardware. For this task, a fragment program is used to perform the nonlinear interpolation and minimization of distance values.',\n",
              "  'AuthorKeywords': ['Distance',\n",
              "   'field,',\n",
              "   'distance',\n",
              "   'transform,',\n",
              "   'Voronoi',\n",
              "   'diagram,',\n",
              "   'fragment',\n",
              "   'program,',\n",
              "   'scan',\n",
              "   'conversion'],\n",
              "  'MultipartiteRank': [{'score': 0.0942358461404383, 'word': 'distance'},\n",
              "   {'score': 0.0942358461404383, 'word': 'transform'},\n",
              "   {'score': 0.0942358461404383, 'word': 'algorithm'},\n",
              "   {'score': 0.05854706040804166, 'word': 'grid'},\n",
              "   {'score': 0.05854706040804166, 'word': 'points'},\n",
              "   {'score': 0.05199154464305206, 'word': 'manifold'},\n",
              "   {'score': 0.04911859939853381, 'word': 'simple'},\n",
              "   {'score': 0.04911859939853381, 'word': 'polyhedron'},\n",
              "   {'score': 0.04716677144487087, 'word': 'graphics'},\n",
              "   {'score': 0.04716677144487087, 'word': 'hardware'}],\n",
              "  'Title': 'Signed distance transform using graphics hardware',\n",
              "  'distance': 0,\n",
              "  'no': '270',\n",
              "  'parent': '5151'},\n",
              " {'Abstract': 'In many domains, increased collaboration has lead to more innovation by fostering the sharing of knowledge, skills, and ideas. Shared analysis of information visualizations does not only lead to increased information processing power, but team members can also share, negotiate, and discuss their views and interpretations on a dataset and contribute unique perspectives on a given problem. Designing technologies to support collaboration around information visualizations poses special challenges and relatively few systems have been designed. We focus on supporting small groups collaborating around information visualizations in a co-located setting, using a shared interactive tabletop display. We introduce an analysis of challenges and requirements for the design of co-located collaborative information visualization systems. We then present a new system that facilitates hierarchical data comparison tasks for this type of collaborative work. Our system supports multi-user input, shared and individual views on the hierarchical data visualization, flexible use of representations, and flexible workspace organization to facilitate group work around visualizations.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'collaboration,',\n",
              "   'co-located',\n",
              "   'work,',\n",
              "   'hierarchical',\n",
              "   'data',\n",
              "   'comparison'],\n",
              "  'MultipartiteRank': [{'score': 0.09530170373322891, 'word': 'information'},\n",
              "   {'score': 0.09530170373322891, 'word': 'visualizations'},\n",
              "   {'score': 0.06419153509573686, 'word': 'collaboration'},\n",
              "   {'score': 0.04786860725558443, 'word': 'special'},\n",
              "   {'score': 0.04786860725558443, 'word': 'challenges'},\n",
              "   {'score': 0.04493157638982346, 'word': 'analysis'},\n",
              "   {'score': 0.04083009565048415, 'word': 'views'}],\n",
              "  'Title': 'Interactive Tree Comparison for Co-located Collaborative Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '271',\n",
              "  'parent': '4752'},\n",
              " {'Abstract': \"We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.\",\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'interactivity,',\n",
              "   'node-link',\n",
              "   'diagrams,',\n",
              "   'animation,',\n",
              "   'information',\n",
              "   'seeking,',\n",
              "   'exploratory',\n",
              "   'search'],\n",
              "  'MultipartiteRank': [{'score': 0.0633280940248153, 'word': 'faceted'},\n",
              "   {'score': 0.0633280940248153, 'word': 'information'},\n",
              "   {'score': 0.0633280940248153, 'word': 'resources'},\n",
              "   {'score': 0.0424655011664198, 'word': 'pivotpaths'},\n",
              "   {'score': 0.0407129081252881, 'word': 'interactive'},\n",
              "   {'score': 0.0407129081252881, 'word': 'visualization'},\n",
              "   {'score': 0.033318570102636884, 'word': 'relations'},\n",
              "   {'score': 0.03308581722057769, 'word': 'filter'},\n",
              "   {'score': 0.03308581722057769, 'word': 'operations'}],\n",
              "  'Title': 'PivotPaths: Strolling through Faceted Information Spaces',\n",
              "  'distance': 0,\n",
              "  'no': '272',\n",
              "  'parent': '4477'},\n",
              " {'Abstract': 'Streamlines and stream surfaces are well known techniques for the visualization of fluid flow. For steady velocity fields, a streamline is the trace of a particle, and a stream surface is the trace of a curve. Here a new method is presented for the construction of stream surfaces. The central concept is the representation of a stream surface as an implicit surface f (x) = C. After the initial calculation of f a family of stream surfaces can be generated efficiently by varying C. The shapes of the originating curves are defined by the value of f at the boundary. Two techniques are presented for the calculation of f: one based on solving the convection equation, the other on backward tracing of the trajectories of grid points. The flow around objects is discussed separately. With this method irregular topologies of the originating curves and of the stream surfaces can be handled easily. Further, it can also be used for other visualization techniques, such as time surfaces and stream volumes. Finally, an effective method for the automatic placement of originating curves is presented.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1348171840940449, 'word': 'stream'},\n",
              "   {'score': 0.1348171840940449, 'word': 'surfaces'},\n",
              "   {'score': 0.06826086248716146, 'word': 'curve'},\n",
              "   {'score': 0.06807590989664926, 'word': 'trace'},\n",
              "   {'score': 0.04979735266827373, 'word': 'fluid'},\n",
              "   {'score': 0.04979735266827373, 'word': 'flow'},\n",
              "   {'score': 0.047460586319219865, 'word': 'streamlines'}],\n",
              "  'Title': 'Implicit stream surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '273',\n",
              "  'parent': '5054'},\n",
              " {'Abstract': 'The authors present a multiresolution framework, called Multi-Tetra framework, that approximates volume data with different levels-of-detail tetrahedra. The framework is generated through a recursive subdivision of the volume data and is represented by binary trees. Instead of using a certain level of the Multi-Tetra framework for approximation, an error-based model (EBM) is generated by recursively fusing a sequence of tetrahedra from different levels of the Multi-Tetra framework. The EBM significantly reduces the number of voxels required to model an object, while preserving the original topology. The approach provides continuous distribution of rendered intensity or generated isosurfaces along boundaries of different levels-of-detail thus solving the crack problem. The model supports typical rendering approaches, such as marching cubes, direct volume projection, and splatting. Experimental results demonstrate the strengths of the approach.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'visualization,',\n",
              "   'multiresolution',\n",
              "   'volume,',\n",
              "   'level',\n",
              "   'of',\n",
              "   'detail,',\n",
              "   'isosurface',\n",
              "   'extraction,',\n",
              "   'volume',\n",
              "   'subdivision,',\n",
              "   'polygon',\n",
              "   'simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.08480213943385216, 'word': 'different'},\n",
              "   {'score': 0.08480213943385216, 'word': 'levels'},\n",
              "   {'score': 0.06216412060202943, 'word': 'approach'},\n",
              "   {'score': 0.04694357913889316, 'word': 'model'},\n",
              "   {'score': 0.04559580135734412, 'word': 'detail'},\n",
              "   {'score': 0.04559580135734412, 'word': 'tetrahedra'},\n",
              "   {'score': 0.04353943982258281, 'word': 'multiresolution'},\n",
              "   {'score': 0.04353943982258281, 'word': 'framework'}],\n",
              "  'Title': 'Multiresolution tetrahedral framework for visualizing regular volume data',\n",
              "  'distance': 0,\n",
              "  'no': '274',\n",
              "  'parent': '3875'},\n",
              " {'Abstract': 'Since the introduction of graphical user interfaces (GUI) and two-dimensional (2D) displays, the concept of space has entered the information technology (IT) domain. Interactions with computers were re-encoded in terms of fidelity to the interactions with real environment and consequently in terms of fitness to cognitive and spatial abilities. A further step in this direction was the creation of three-dimensional (3D) displays which have amplified the fidelity of digital representations. However, there are no systematic results evaluating the extent to which 3D displays better support cognitive spatial abilities. The aim of this research is to empirically investigate spatial memory performance across different instances of 2D and 3D displays. Two experiments were performed. The displays used in the experimental situation represented hierarchical information structures. The results of the test show that the 3D display does improve performances in the designed spatial memory task.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09228808101542983, 'word': 'displays'},\n",
              "   {'score': 0.04863824247339052, 'word': 'interactions'},\n",
              "   {'score': 0.04718799188221917, 'word': 'terms'},\n",
              "   {'score': 0.045096512068629004, 'word': 'spatial'},\n",
              "   {'score': 0.045096512068629004, 'word': 'abilities'},\n",
              "   {'score': 0.0450168480404025, 'word': 'fidelity'}],\n",
              "  'Title': '2D vs 3D, implications on spatial memory',\n",
              "  'distance': 0,\n",
              "  'no': '275',\n",
              "  'parent': '5074'},\n",
              " {'Abstract': 'We introduce a new algorithm for fitting a Catmull-Clark subdivision surface to a given shape within a prescribed tolerance, based on the method of quasi-interpolation. The fitting algorithm is fast, local and scales well since it does not require the solution of linear systems. Its convergence rate is optimal for regular meshes and our experiments show that it behaves very well for irregular meshes. We demonstrate the power and versatility of our method with examples from interactive modeling, surface fitting, and scientific visualization.',\n",
              "  'AuthorKeywords': ['Animation,',\n",
              "   'CAD,',\n",
              "   'Curves',\n",
              "   '&',\n",
              "   'Surfaces,',\n",
              "   'Geometric',\n",
              "   'Modeling,',\n",
              "   'Digital',\n",
              "   'Geometry',\n",
              "   'Processing,',\n",
              "   'Subdivision',\n",
              "   'Schemes,',\n",
              "   'Approximation,',\n",
              "   'Quasi-Interpolation,',\n",
              "   'Catmull-Clark'],\n",
              "  'MultipartiteRank': [{'score': 0.07501881376824086, 'word': 'fitting'},\n",
              "   {'score': 0.07501881376824086, 'word': 'algorithm'},\n",
              "   {'score': 0.07192307139463111, 'word': 'regular'},\n",
              "   {'score': 0.07192307139463111, 'word': 'meshes'},\n",
              "   {'score': 0.06909765868883516, 'word': 'method'},\n",
              "   {'score': 0.05561554376475068, 'word': 'fast'},\n",
              "   {'score': 0.05546321228687983, 'word': 'optimal'}],\n",
              "  'Title': 'Fitting Subdivision Surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '276',\n",
              "  'parent': '3573'},\n",
              " {'Abstract': \"Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder's query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)\",\n",
              "  'AuthorKeywords': ['Temporal',\n",
              "   'query,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'interface'],\n",
              "  'MultipartiteRank': [{'score': 0.09356446570238709, 'word': 'patterns'},\n",
              "   {'score': 0.09083259777383673, 'word': 'events'},\n",
              "   {'score': 0.06393877888985774, 'word': 'time'},\n",
              "   {'score': 0.05780727421116737, 'word': 'query'},\n",
              "   {'score': 0.03872686207822152, 'word': 'patient'},\n",
              "   {'score': 0.03872686207822152, 'word': 'histories'}],\n",
              "  'Title': 'A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories',\n",
              "  'distance': 0,\n",
              "  'no': '277',\n",
              "  'parent': '4045'},\n",
              " {'Abstract': \"While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap's stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.\",\n",
              "  'AuthorKeywords': ['Treemap,',\n",
              "   'tree',\n",
              "   'comparison,',\n",
              "   'visualize',\n",
              "   'changes,',\n",
              "   'treemap',\n",
              "   'layout',\n",
              "   'algorithm'],\n",
              "  'MultipartiteRank': [{'score': 0.06851561755305235, 'word': 'treemap'},\n",
              "   {'score': 0.0672099287241002, 'word': 'changes'},\n",
              "   {'score': 0.05603745154027623, 'word': 'hierarchical'},\n",
              "   {'score': 0.05603745154027623, 'word': 'data'},\n",
              "   {'score': 0.04187529953587195, 'word': 'prominent'},\n",
              "   {'score': 0.04187529953587195, 'word': 'visual'},\n",
              "   {'score': 0.04187529953587195, 'word': 'patterns'},\n",
              "   {'score': 0.041682670966313486, 'word': 'layout'}],\n",
              "  'Title': 'Visualizing Changes of Hierarchical Data using Treemaps',\n",
              "  'distance': 0,\n",
              "  'no': '278',\n",
              "  'parent': '5492'},\n",
              " {'Abstract': 'As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records.',\n",
              "  'AuthorKeywords': ['Progressive',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'interactive',\n",
              "   'machine',\n",
              "   'learning,',\n",
              "   'electronic',\n",
              "   'medical',\n",
              "   'records'],\n",
              "  'MultipartiteRank': [{'score': 0.07423484463619595, 'word': 'analysts'},\n",
              "   {'score': 0.07377882209949096, 'word': 'analytic'},\n",
              "   {'score': 0.07377882209949096, 'word': 'algorithms'},\n",
              "   {'score': 0.0705261433808303, 'word': 'progressive'},\n",
              "   {'score': 0.0705261433808303, 'word': 'visual'},\n",
              "   {'score': 0.0705261433808303, 'word': 'analytics'},\n",
              "   {'score': 0.05818040654416918, 'word': 'results'},\n",
              "   {'score': 0.041755016834727494, 'word': 'typical'},\n",
              "   {'score': 0.041755016834727494, 'word': 'workflow'}],\n",
              "  'Title': 'Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics',\n",
              "  'distance': 0,\n",
              "  'no': '279',\n",
              "  'parent': '5555'},\n",
              " {'Abstract': 'Topology analysis of plane, turbulent vector fields results in visual clutter caused by critical points indicating vortices of finer and finer scales. A simplification can be achieved by merging critical points within a prescribed radius into higher order critical points. After building clusters containing the singularities to merge, the method generates a piecewise linear representation of the vector field in each cluster containing only one (higher order) singularity. Any visualization method can be applied to the result after this process. Using different maximal distances for the critical points to be merged results in a hierarchy of simplified vector fields that can be used for analysis on different scales.',\n",
              "  'AuthorKeywords': ['vector',\n",
              "   'field',\n",
              "   'topology,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'clustering,simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.1040202846019724, 'word': 'critical'},\n",
              "   {'score': 0.1040202846019724, 'word': 'points'},\n",
              "   {'score': 0.09664147065438922, 'word': 'turbulent'},\n",
              "   {'score': 0.09664147065438922, 'word': 'vector'},\n",
              "   {'score': 0.09664147065438922, 'word': 'fields'},\n",
              "   {'score': 0.09664147065438922, 'word': 'results'},\n",
              "   {'score': 0.07318973488349576, 'word': 'topology'},\n",
              "   {'score': 0.07318973488349576, 'word': 'analysis'},\n",
              "   {'score': 0.06124337122169942, 'word': 'finer'},\n",
              "   {'score': 0.056465751402912774, 'word': 'plane'}],\n",
              "  'Title': 'A topology simplification method for 2D vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '280',\n",
              "  'parent': '4349'},\n",
              " {'Abstract': 'In the traditional volume visualization paradigm, the user specifies a transfer function that assigns each scalar value to a color and opacity by defining an opacity and a color map function. The transfer function has two limitations. First, the user must define curves based on histogram and value rather than seeing and working with the volume itself. Second, the transfer function is inflexible in classifying regions of interest, where values at a voxel such as intensity and gradient are used to differentiate material, not talking into account additional properties such as texture and position. We describe an intuitive user interface for specifying the classification functions that consists of the users painting directly on sample slices of the volume. These painted regions are used to automatically define high-dimensional classification functions that can be implemented in hardware for interactive rendering. The classification of the volume is iteratively improved as the user paints samples, allowing intuitive and efficient viewing of materials of interest.',\n",
              "  'AuthorKeywords': ['classification,',\n",
              "   'graphics',\n",
              "   'hardware,',\n",
              "   'interactive',\n",
              "   'visualization,',\n",
              "   'multidimensional',\n",
              "   'transfer',\n",
              "   'function,',\n",
              "   'neural',\n",
              "   'network,',\n",
              "   'user',\n",
              "   'interface',\n",
              "   'design,',\n",
              "   'volume',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.07230389574608082, 'word': 'user'},\n",
              "   {'score': 0.06036408321000877, 'word': 'scalar'},\n",
              "   {'score': 0.06036408321000877, 'word': 'value'},\n",
              "   {'score': 0.06020465019292376, 'word': 'transfer'},\n",
              "   {'score': 0.06020465019292376, 'word': 'function'},\n",
              "   {'score': 0.051711884918720086, 'word': 'classification'},\n",
              "   {'score': 0.051711884918720086, 'word': 'functions'},\n",
              "   {'score': 0.0505511859905747, 'word': 'volume'}],\n",
              "  'Title': 'A novel interface for higher-dimensional classification of volume data',\n",
              "  'distance': 0,\n",
              "  'no': '281',\n",
              "  'parent': '4102'},\n",
              " {'Abstract': \"Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system's imagery pyramid to superpose a heatmap of the log files over the original maps. Users' behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces.\",\n",
              "  'AuthorKeywords': ['Geographical',\n",
              "   'visualization,',\n",
              "   'GIS,',\n",
              "   'heatmap,',\n",
              "   'server',\n",
              "   'log',\n",
              "   'analysis,',\n",
              "   'online',\n",
              "   'mapping',\n",
              "   'systems,',\n",
              "   'social',\n",
              "   'navigation'],\n",
              "  'MultipartiteRank': [{'score': 0.12254503139381145, 'word': 'online'},\n",
              "   {'score': 0.12254503139381145, 'word': 'maps'},\n",
              "   {'score': 0.08308139821875904, 'word': 'hotmap'},\n",
              "   {'score': 0.05685450577838977, 'word': 'users'},\n",
              "   {'score': 0.045579362451008645, 'word': 'design'},\n",
              "   {'score': 0.03472974550584891, 'word': 'data'},\n",
              "   {'score': 0.03472974550584891, 'word': 'acquisition'},\n",
              "   {'score': 0.03472974550584891, 'word': 'teams'}],\n",
              "  'Title': 'Hotmap: Looking at Geographic Attention',\n",
              "  'distance': 0,\n",
              "  'no': '282',\n",
              "  'parent': '3909'},\n",
              " {'Abstract': 'Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1463159371546216, 'word': 'visual'},\n",
              "   {'score': 0.1463159371546216, 'word': 'exploration'},\n",
              "   {'score': 0.07024402818155964, 'word': 'number'},\n",
              "   {'score': 0.06440122076662229, 'word': 'dimensional'},\n",
              "   {'score': 0.06440122076662229, 'word': 'representations'},\n",
              "   {'score': 0.060412849051237935, 'word': 'multivariate'},\n",
              "   {'score': 0.060412849051237935, 'word': 'data'},\n",
              "   {'score': 0.04625947562455552, 'word': 'lower'}],\n",
              "  'Title': 'Combining automated analysis and visualization techniques for effective exploration of high-dimensional data',\n",
              "  'distance': 0,\n",
              "  'no': '283',\n",
              "  'parent': '4046'},\n",
              " {'Abstract': 'Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4&lt;sup&gt;d&lt;/sup&gt; values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation.',\n",
              "  'AuthorKeywords': ['Data',\n",
              "   'compression,',\n",
              "   'floating-point',\n",
              "   'arrays,',\n",
              "   'orthogonal',\n",
              "   'block',\n",
              "   'transform,',\n",
              "   'embedded',\n",
              "   'coding'],\n",
              "  'MultipartiteRank': [{'score': 0.11357420872243973, 'word': 'current'},\n",
              "   {'score': 0.11357420872243973, 'word': 'compression'},\n",
              "   {'score': 0.11357420872243973, 'word': 'schemes'},\n",
              "   {'score': 0.06616687663883936, 'word': 'small'},\n",
              "   {'score': 0.06616687663883936, 'word': 'blocks'},\n",
              "   {'score': 0.06495655562980505, 'word': 'point'},\n",
              "   {'score': 0.06495655562980505, 'word': 'data'},\n",
              "   {'score': 0.058735985103974375, 'word': 'length'},\n",
              "   {'score': 0.058735985103974375, 'word': 'bit'},\n",
              "   {'score': 0.058735985103974375, 'word': 'stream'},\n",
              "   {'score': 0.04683608983876616, 'word': 'precision'},\n",
              "   {'score': 0.04683608983876616, 'word': 'values'}],\n",
              "  'Title': 'Fixed-Rate Compressed Floating-Point Arrays',\n",
              "  'distance': 0,\n",
              "  'no': '284',\n",
              "  'parent': '4628'},\n",
              " {'Abstract': 'Multiresolution methods are becoming increasingly important tools for the interactive visualization of very large data sets. Multiresolution isosurface visualization allows the user to explore volume data using simplified and coarse representations of the isosurface for overview images, and finer resolution in areas of high interest or when zooming into the data. Ideally, a coarse isosurface should have the same topological structure as the original. The topological genus of the isosurface is one important property which is often neglected in multiresolution algorithms. This results in uncontrolled topological changes which can occur whenever the level-of-detail is changed. The scope of this paper is to propose an efficient technique which allows preservation of topology as well as controlled topology simplification in multiresolution isosurface extraction.',\n",
              "  'AuthorKeywords': ['tetrahedral',\n",
              "   'grid',\n",
              "   'refinement,',\n",
              "   'implicit',\n",
              "   'surface',\n",
              "   'approximation,',\n",
              "   'level-of-detail,',\n",
              "   'topological',\n",
              "   'genus,',\n",
              "   'critical',\n",
              "   'points'],\n",
              "  'MultipartiteRank': [{'score': 0.17733627456378825,\n",
              "    'word': 'multiresolution'},\n",
              "   {'score': 0.11655409987005616, 'word': 'isosurface'},\n",
              "   {'score': 0.11655409987005616, 'word': 'visualization'},\n",
              "   {'score': 0.10020399445214391, 'word': 'large'},\n",
              "   {'score': 0.10020399445214391, 'word': 'data'},\n",
              "   {'score': 0.10020399445214391, 'word': 'sets'},\n",
              "   {'score': 0.06078217469373211, 'word': 'methods'},\n",
              "   {'score': 0.0575986528500675, 'word': 'important'},\n",
              "   {'score': 0.0575986528500675, 'word': 'tools'},\n",
              "   {'score': 0.05329755870650704, 'word': 'topological'},\n",
              "   {'score': 0.05329755870650704, 'word': 'genus'}],\n",
              "  'Title': 'Topology preserving and controlled topology simplifying multiresolution isosurface extraction',\n",
              "  'distance': 0,\n",
              "  'no': '285',\n",
              "  'parent': '4109'},\n",
              " {'Abstract': 'A new method for the synthesis of dense, vector-field aligned textures on curved surfaces is presented, called IBFVS. The method is based on image based flow visualization (IBFV). In IBFV two-dimensional animated textures are produced by defining each frame of a flow animation as a blend between a warped version of the previous image and a number of filtered white noise images. We produce flow aligned texture on arbitrary three-dimensional triangular meshes in the same spirit as the original method: texture is generated directly in image space. We show that IBFVS is efficient and effective. High performance (typically fifty frames or more per second) is achieved by exploiting graphics hardware. Also, IBFVS can easily be implemented and a variety of effects can be achieved. Applications are flow visualization and surface rendering. Specifically, we show how to visualize the wind field on the earth and how to render a dirty bronze bunny.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'visualization,',\n",
              "   'texture',\n",
              "   'mapping,',\n",
              "   'line',\n",
              "   'integral',\n",
              "   'convolution,',\n",
              "   'surface',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.07756516242800274, 'word': 'textures'},\n",
              "   {'score': 0.07486257002800802, 'word': 'flow'},\n",
              "   {'score': 0.07486257002800802, 'word': 'visualization'},\n",
              "   {'score': 0.0744473695589977, 'word': 'new'},\n",
              "   {'score': 0.0744473695589977, 'word': 'method'},\n",
              "   {'score': 0.06811512824454422, 'word': 'ibfvs'},\n",
              "   {'score': 0.06369508159953399, 'word': 'image'}],\n",
              "  'Title': 'Image based flow visualization for curved surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '286',\n",
              "  'parent': '4639'},\n",
              " {'Abstract': 'Many sophisticated techniques for the visualization of volumetric data such as medical data have been published. While existing techniques are mature from a technical point of view, managing the complexity of visual parameters is still difficult for nonexpert users. To this end, this paper presents new ideas to facilitate the specification of optical properties for direct volume rendering. We introduce an additional level of abstraction for parametric models of transfer functions. The proposed framework allows visualization experts to design high-level transfer function models which can intuitively be used by non-expert users. The results are user interfaces which provide semantic information for specialized visualization problems. The proposed method is based on principal component analysis as well as on concepts borrowed from computer animation',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'rendering,',\n",
              "   'transfer',\n",
              "   'function',\n",
              "   'design,',\n",
              "   'semantic',\n",
              "   'models'],\n",
              "  'MultipartiteRank': [{'score': 0.10726233476540634, 'word': 'visualization'},\n",
              "   {'score': 0.09278923715917681, 'word': 'many'},\n",
              "   {'score': 0.09278923715917681, 'word': 'sophisticated'},\n",
              "   {'score': 0.09278923715917681, 'word': 'techniques'},\n",
              "   {'score': 0.044566413505235006, 'word': 'nonexpert'},\n",
              "   {'score': 0.044566413505235006, 'word': 'users'},\n",
              "   {'score': 0.040733196974424145, 'word': 'transfer'},\n",
              "   {'score': 0.040733196974424145, 'word': 'functions'},\n",
              "   {'score': 0.03233414539523894, 'word': 'medical'},\n",
              "   {'score': 0.03233414539523894, 'word': 'data'}],\n",
              "  'Title': 'High-Level User Interfaces for Transfer Function Design with Semantics',\n",
              "  'distance': 0,\n",
              "  'no': '287',\n",
              "  'parent': '3764'},\n",
              " {'Abstract': 'Direct volume rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a \"sensitivity lens\" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy.',\n",
              "  'AuthorKeywords': ['Uncertainty,',\n",
              "   'probability,',\n",
              "   'medical',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'transfer',\n",
              "   'function'],\n",
              "  'MultipartiteRank': [{'score': 0.104846686725463, 'word': 'direct'},\n",
              "   {'score': 0.104846686725463, 'word': 'volume'},\n",
              "   {'score': 0.104846686725463, 'word': 'rendering'},\n",
              "   {'score': 0.06713986114588462, 'word': 'effective'},\n",
              "   {'score': 0.06713986114588462, 'word': 'visualization'},\n",
              "   {'score': 0.06713986114588462, 'word': 'method'},\n",
              "   {'score': 0.05306448415365356, 'word': 'medical'},\n",
              "   {'score': 0.05306448415365356, 'word': 'data'},\n",
              "   {'score': 0.05306448415365356, 'word': 'sets'},\n",
              "   {'score': 0.05085861935641342, 'word': 'tissue'},\n",
              "   {'score': 0.05085861935641342, 'word': 'classification'},\n",
              "   {'score': 0.05085861935641342, 'word': 'task'},\n",
              "   {'score': 0.037324406064954324, 'word': 'time'}],\n",
              "  'Title': 'Uncertainty Visualization in Medical Volume Rendering Using Probabilistic Animation',\n",
              "  'distance': 0,\n",
              "  'no': '288',\n",
              "  'parent': '5166'},\n",
              " {'Abstract': 'Controlled experiments with novice treemap users and real data highlight the strengths of treemaps and provide direction for improvement. Issues discussed include experimental results, layout algorithms, nesting offsets, labeling, animation, and small multiple displays. Treemaps prove to be a potent tool for hierarchy display. The principles discussed are applicable to many information visualization situations.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14316630686072493, 'word': 'novice'},\n",
              "   {'score': 0.14316630686072493, 'word': 'treemap'},\n",
              "   {'score': 0.14316630686072493, 'word': 'users'},\n",
              "   {'score': 0.07333169115080147, 'word': 'treemaps'},\n",
              "   {'score': 0.07063460051724112, 'word': 'real'},\n",
              "   {'score': 0.07063460051724112, 'word': 'data'},\n",
              "   {'score': 0.05958705715575763, 'word': 'experiments'},\n",
              "   {'score': 0.056828549058063976, 'word': 'strengths'}],\n",
              "  'Title': 'Improving the visualization of hierarchies with treemaps: design issues and experimentation',\n",
              "  'distance': 0,\n",
              "  'no': '289',\n",
              "  'parent': '3411'},\n",
              " {'Abstract': 'Graph drawing is a basic visualization tool. For graphs of up to hundreds of nodes and edges, there are many effective techniques available. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, and multiscale and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we describe a topological zooming method. It is based on the precomputation of a hierarchy of coarsened graphs, which are combined on the fly into renderings with the level of detail dependent on the distance from one or more foci. We also discuss a related distortion method that allows our technique to achieve constant information density displays',\n",
              "  'AuthorKeywords': ['topological', 'fisheye,large', 'graph', 'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.12271205431942063, 'word': 'graph'},\n",
              "   {'score': 0.12271205431942063, 'word': 'drawing'},\n",
              "   {'score': 0.05628166129000835, 'word': 'occlusion'},\n",
              "   {'score': 0.05628166129000835, 'word': 'problems'},\n",
              "   {'score': 0.053425000162296274, 'word': 'basic'},\n",
              "   {'score': 0.053425000162296274, 'word': 'visualization'},\n",
              "   {'score': 0.053425000162296274, 'word': 'tool'},\n",
              "   {'score': 0.047424839955377635, 'word': 'zoom'},\n",
              "   {'score': 0.041078350879171104, 'word': 'data'},\n",
              "   {'score': 0.041078350879171104, 'word': 'density'}],\n",
              "  'Title': 'Topological Fisheye Views for Visualizing Large Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '290',\n",
              "  'parent': '3865'},\n",
              " {'Abstract': \"This paper describes a comparative experiment with five well-known tree visualization systems, and Windows Explorer as a baseline system. Subjects performed tasks relating to the structure of a directory hierarchy, and to attributes of files and directories. Task completion times, correctness and user satisfaction were measured, and video recordings of subjects' interaction with the systems were made. Significant system and task type effects and an interaction between system and task type were found. Qualitative analyses of the video recordings were thereupon conducted to determine reasons for the observed differences, resulting in several findings and design recommendations as well as implications for future experiments with tree visualization systems\",\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'experimental',\n",
              "   'comparison,',\n",
              "   'task',\n",
              "   'performance,',\n",
              "   'accuracy,',\n",
              "   'user',\n",
              "   'satisfaction,',\n",
              "   'user',\n",
              "   'interaction,',\n",
              "   'design',\n",
              "   'recommendations'],\n",
              "  'MultipartiteRank': [{'score': 0.11739458952794835, 'word': 'tree'},\n",
              "   {'score': 0.11739458952794835, 'word': 'visualization'},\n",
              "   {'score': 0.11739458952794835, 'word': 'systems'},\n",
              "   {'score': 0.0881715972931855, 'word': 'tasks'},\n",
              "   {'score': 0.06048397859198481, 'word': 'subjects'},\n",
              "   {'score': 0.05812473079393708, 'word': 'comparative'},\n",
              "   {'score': 0.05812473079393708, 'word': 'experiment'},\n",
              "   {'score': 0.05161427528923425, 'word': 'directory'},\n",
              "   {'score': 0.05161427528923425, 'word': 'hierarchy'}],\n",
              "  'Title': 'User Experiments with Tree Visualization Systems',\n",
              "  'distance': 0,\n",
              "  'no': '291',\n",
              "  'parent': '4223'},\n",
              " {'Abstract': 'Simulating hand-drawn illustration techniques can succinctly express information in a manner that is communicative and informative. We present a framework for an interactive direct volume illustration system that simulates traditional stipple drawing. By combining the principles of artistic and scientific illustration, we explore several feature enhancement techniques to create effective, interactive visualizations of scientific and medical datasets. We also introduce a rendering mechanism that generates appropriate point lists at all resolutions during an automatic preprocess, and modifies rendering styles through different combinations of these feature enhancements. The new system is an effective way to interactively preview large, complex volume datasets in a concise, meaningful, and illustrative manner. Volume stippling is effective for many applications and provides a quick and efficient method to investigate volume models.',\n",
              "  'AuthorKeywords': ['non-photorealistic',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'scientific',\n",
              "   'visualization,',\n",
              "   'medical',\n",
              "   'imaging'],\n",
              "  'MultipartiteRank': [{'score': 0.06615270201938706, 'word': 'effective'},\n",
              "   {'score': 0.054111378187405586, 'word': 'scientific'},\n",
              "   {'score': 0.054111378187405586, 'word': 'illustration'},\n",
              "   {'score': 0.05012780051864051, 'word': 'manner'},\n",
              "   {'score': 0.04925042722896212, 'word': 'information'},\n",
              "   {'score': 0.046770872489987805, 'word': 'several'},\n",
              "   {'score': 0.046770872489987805, 'word': 'feature'},\n",
              "   {'score': 0.046770872489987805, 'word': 'enhancement'},\n",
              "   {'score': 0.046770872489987805, 'word': 'techniques'}],\n",
              "  'Title': 'Non-photorealistic volume rendering using stippling techniques',\n",
              "  'distance': 0,\n",
              "  'no': '292',\n",
              "  'parent': '4307'},\n",
              " {'Abstract': 'Volume rendering is a flexible technique for visualizing dense 3D volumetric datasets. A central element of volume rendering is the conversion between data values and observable quantities such as color and opacity. This process is usually realized through the use of transfer functions that are precomputed and stored in lookup tables. For multidimensional transfer functions applied to multivariate data, these lookup tables become prohibitively large. We propose the direct evaluation of a particular type of transfer functions based on a sum of Gaussians. Because of their simple form (in terms of number of parameters), these functions and their analytic integrals along line segments can be evaluated efficiently on current graphics hardware, obviating the need for precomputed lookup tables. We have adopted these transfer functions because they are well suited for classification based on a unique combination of multiple data values that localize features in the transfer function domain. We apply this technique to the visualization of several multivariate datasets (CT, cryosection) that are difficult to classify and render accurately at interactive rates using traditional approaches.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   'Transfer',\n",
              "   'Functions,',\n",
              "   'Multi-field',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.09254045626758947, 'word': 'transfer'},\n",
              "   {'score': 0.09254045626758947, 'word': 'functions'},\n",
              "   {'score': 0.05889938595806714, 'word': 'data'},\n",
              "   {'score': 0.05889938595806714, 'word': 'values'},\n",
              "   {'score': 0.04901077312846181, 'word': 'lookup'},\n",
              "   {'score': 0.04901077312846181, 'word': 'tables'},\n",
              "   {'score': 0.043305844367187304, 'word': 'volume'},\n",
              "   {'score': 0.043305844367187304, 'word': 'rendering'},\n",
              "   {'score': 0.03561010393111748, 'word': 'flexible'},\n",
              "   {'score': 0.03561010393111748, 'word': 'technique'}],\n",
              "  'Title': 'Gaussian transfer functions for multi-field volume visualization',\n",
              "  'distance': 0,\n",
              "  'no': '293',\n",
              "  'parent': '4321'},\n",
              " {'Abstract': 'Exploratory analysis of multidimensional data sets is challenging because of the difficulty in comprehending more than three dimensions. Two fundamental statistical principles for the exploratory analysis are (1) to examine each dimension first and then find relationships among dimensions, and (2) to try graphical displays first and then find numerical summaries (D.S. Moore, (1999). We implement these principles in a novel conceptual framework called the rank-by-feature framework. In the framework, users can choose a ranking criterion interesting to them and sort 1D or 2D axis-parallel projections according to the criterion. We introduce the rank-by-feature prism that is a color-coded lower-triangular matrix that guides users to desired features. Statistical graphs (histogram, boxplot, and scatterplot) and information visualization techniques (overview, coordination, and dynamic query) are combined to help users effectively traverse 1D and 2D axis-parallel projections, and finally to help them interactively find interesting features',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'exploratory',\n",
              "   'data',\n",
              "   'analysis,',\n",
              "   'dynamic',\n",
              "   'query,',\n",
              "   'feature',\n",
              "   'detection/selection,',\n",
              "   'statistical',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.1337259881017632, 'word': 'framework'},\n",
              "   {'score': 0.07634913723467686, 'word': 'feature'},\n",
              "   {'score': 0.0678850097736097, 'word': 'users'},\n",
              "   {'score': 0.06165706419878529, 'word': 'dimensions'},\n",
              "   {'score': 0.05737685086708634, 'word': 'novel'},\n",
              "   {'score': 0.05737685086708634, 'word': 'conceptual'},\n",
              "   {'score': 0.05199935614673226, 'word': 'rank'}],\n",
              "  'Title': 'A Rank-by-Feature Framework for Unsupervised Multidimensional Data Exploration Using Low Dimensional Projections',\n",
              "  'distance': 0,\n",
              "  'no': '294',\n",
              "  'parent': '4087'},\n",
              " {'Abstract': 'Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.',\n",
              "  'AuthorKeywords': ['Scatterplot,',\n",
              "   'histogram,',\n",
              "   'continuous',\n",
              "   'frequency',\n",
              "   'plot,',\n",
              "   'interpolation'],\n",
              "  'MultipartiteRank': [{'score': 0.19788268246233853, 'word': 'data'},\n",
              "   {'score': 0.13768247947318862, 'word': 'scatterplots'},\n",
              "   {'score': 0.07323493056789973, 'word': 'variables'},\n",
              "   {'score': 0.04032584854757862, 'word': 'continuous'},\n",
              "   {'score': 0.04032584854757862, 'word': 'input'},\n",
              "   {'score': 0.03992040514333055, 'word': 'discrete'},\n",
              "   {'score': 0.03992040514333055, 'word': 'values'}],\n",
              "  'Title': 'Continuous Scatterplots',\n",
              "  'distance': 0,\n",
              "  'no': '295',\n",
              "  'parent': '5957'},\n",
              " {'Abstract': 'The paper describes a general formulation of the \"detail-in-context\" problem, which is a central issue of fundamental importance to a wide variety of nonlinear magnification systems. A number of tools are described for dealing with this problem effectively. These tools can be applied to any continuous nonlinear magnification system, and are not tied to specific implementation features of the system that produced the original transformation. Of particular interest is the development of \"seamless multi level views\", which allow multiple global views of an information space (each having different information content) to be integrated into a single view without discontinuity.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10065234878304409, 'word': 'nonlinear'},\n",
              "   {'score': 0.10065234878304409, 'word': 'magnification'},\n",
              "   {'score': 0.10065234878304409, 'word': 'systems'},\n",
              "   {'score': 0.0722556754825434, 'word': 'problem'},\n",
              "   {'score': 0.07174138306931738, 'word': 'tools'},\n",
              "   {'score': 0.05944592776551104, 'word': 'wide'},\n",
              "   {'score': 0.05944592776551104, 'word': 'variety'},\n",
              "   {'score': 0.05254091128784125, 'word': 'number'}],\n",
              "  'Title': 'The generalized detail in-context problem',\n",
              "  'distance': 0,\n",
              "  'no': '296',\n",
              "  'parent': '3524'},\n",
              " {'Abstract': 'In 1998 we introduced the idea for a project we call the Office of the Future. Our long-term vision is to provide a better every-day working environment, with high-fidelity scene reconstruction for life-sized 3D tele-collaboration. In particular, we want a true sense of presence with our remote collaborator and their real surroundings. The challenges related to this vision are enormous and involve many technical tradeoffs. This is true in particular for scene reconstruction. Researchers have been striving to achieve real-time approaches, and while they have made respectable progress, the limitations of conventional technologies relegate them to relatively low resolution in a restricted volume. We present a significant step toward our ultimate goal, via a slightly different path. In lieu of low-fidelity dynamic scene modeling we present an exceedingly high fidelity reconstruction of a real but static office. By assembling the best of available hardware and software technologies in static scene acquisition, modeling algorithms, rendering, tracking and stereo projective display, we are able to demonstrate a portal to a real office, occupied today by a mannequin, and in the future by a real remote collaborator. We now have both a compelling sense of just how good it could be, and a framework into which we will later incorporate dynamic scene modeling, as we continue to head toward our ultimate goal of 3D collaborative telepresence.',\n",
              "  'AuthorKeywords': ['telepresence,',\n",
              "   'tele-immersion,',\n",
              "   'virtual',\n",
              "   'reality,',\n",
              "   'collaborative',\n",
              "   'visualization,',\n",
              "   'immersive',\n",
              "   'display,',\n",
              "   'augmented',\n",
              "   'reality,',\n",
              "   'human-computer',\n",
              "   'interface'],\n",
              "  'MultipartiteRank': [{'score': 0.0463266896879089, 'word': 'collaboration'},\n",
              "   {'score': 0.04387326300802778, 'word': 'fidelity'},\n",
              "   {'score': 0.04387326300802778, 'word': 'scene'},\n",
              "   {'score': 0.04387326300802778, 'word': 'reconstruction'},\n",
              "   {'score': 0.04251149242372052, 'word': 'real'},\n",
              "   {'score': 0.04251149242372052, 'word': 'surroundings'},\n",
              "   {'score': 0.03199204152688271, 'word': 'term'},\n",
              "   {'score': 0.03199204152688271, 'word': 'vision'},\n",
              "   {'score': 0.03167974472032373, 'word': 'particular'}],\n",
              "  'Title': 'Toward a compelling sensation of telepresence: demonstrating a portal to a distant (static) office',\n",
              "  'distance': 0,\n",
              "  'no': '297',\n",
              "  'parent': '6297'},\n",
              " {'Abstract': 'We present a generic method for rapid flight planning, virtual navigation and effective camera control in a volumetric environment. Directly derived from an accurate distance from boundary (DFB) field, our automatic path planning algorithm rapidly generates centered flight paths, a skeleton, in the navigable region of the virtual environment. Based on precomputed flight paths and the DFB field, our dual-mode physically based camera control model supports a smooth, safe, and sticking-free virtual navigation with six degrees of freedom. By using these techniques, combined with accelerated volume rendering, we have successfully developed a real-time virtual colonoscopy system on low-cost PCs and confirmed the high speed, high accuracy and robustness of our techniques on more than 40 patient datasets.',\n",
              "  'AuthorKeywords': ['Distance',\n",
              "   'fields,',\n",
              "   'path',\n",
              "   'planning,',\n",
              "   'centerline,',\n",
              "   'camera',\n",
              "   'control,',\n",
              "   'virtual',\n",
              "   'navigation,',\n",
              "   'volumetric',\n",
              "   'environment,',\n",
              "   'physically',\n",
              "   'based',\n",
              "   'modeling,',\n",
              "   'virtual',\n",
              "   'colonoscopy'],\n",
              "  'MultipartiteRank': [{'score': 0.0784878991921752, 'word': 'virtual'},\n",
              "   {'score': 0.0784878991921752, 'word': 'navigation'},\n",
              "   {'score': 0.06105802014215629, 'word': 'effective'},\n",
              "   {'score': 0.06105802014215629, 'word': 'camera'},\n",
              "   {'score': 0.06105802014215629, 'word': 'control'},\n",
              "   {'score': 0.05114768191562965, 'word': 'dfb'},\n",
              "   {'score': 0.04869842418107685, 'word': 'volumetric'},\n",
              "   {'score': 0.04869842418107685, 'word': 'environment'},\n",
              "   {'score': 0.04199960367433878, 'word': 'rapid'},\n",
              "   {'score': 0.04199960367433878, 'word': 'flight'},\n",
              "   {'score': 0.04199960367433878, 'word': 'planning'}],\n",
              "  'Title': 'Distance-field based skeletons for virtual navigation',\n",
              "  'distance': 0,\n",
              "  'no': '298',\n",
              "  'parent': '3889'},\n",
              " {'Abstract': \"The dominant paradigm for searching and browsing large data stores is text-based: presenting a scrollable list of search results in response to textual search term input. While this works well for the Web, there is opportunity for improvement in the domain of personal information stores, which tend to have more heterogeneous data and richer metadata. In this paper, we introduce FacetMap, an interactive, query-driven visualization, generalizable to a wide range of metadata-rich data stores. FacetMap uses a visual metaphor for both input (selection of metadata facets as filters) and output. Results of a user study provide insight into tradeoffs between FacetMap's graphical approach and the traditional text-oriented approach\",\n",
              "  'AuthorKeywords': ['Graphical',\n",
              "   'visualization,',\n",
              "   'interactive',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'faceted',\n",
              "   'metadata'],\n",
              "  'MultipartiteRank': [{'score': 0.06086977121158996, 'word': 'richer'},\n",
              "   {'score': 0.06086977121158996, 'word': 'metadata'},\n",
              "   {'score': 0.05655772371088418, 'word': 'facetmap'},\n",
              "   {'score': 0.05175251772511077, 'word': 'large'},\n",
              "   {'score': 0.05175251772511077, 'word': 'data'},\n",
              "   {'score': 0.05175251772511077, 'word': 'stores'},\n",
              "   {'score': 0.049728385344043384, 'word': 'search'},\n",
              "   {'score': 0.049728385344043384, 'word': 'results'},\n",
              "   {'score': 0.0449465483326908, 'word': 'text'}],\n",
              "  'Title': 'FacetMap: A Scalable Search and Browse Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '299',\n",
              "  'parent': '3599'},\n",
              " {'Abstract': \"Surgical approaches tailored to an individual patient's anatomy and pathology have become standard in neurosurgery. Precise preoperative planning of these procedures, however, is necessary to achieve an optimal therapeutic effect. Therefore, multiple radiological imaging modalities are used prior to surgery to delineate the patient's anatomy, neurological function, and metabolic processes. Developing a three-dimensional perception of the surgical approach, however, is traditionally still done by mentally fusing multiple modalities. Concurrent 3D visualization of these datasets can, therefore, improve the planning process significantly. In this paper we introduce an application for planning of individual neurosurgical approaches with high-quality interactive multimodal volume rendering. The application consists of three main modules which allow to (1) plan the optimal skin incision and opening of the skull tailored to the underlying pathology; (2) visualize superficial brain anatomy, function and metabolism; and (3) plan the patient-specific approach for surgery of deep-seated lesions. The visualization is based on direct multi-volume raycasting on graphics hardware, where multiple volumes from different modalities can be displayed concurrently at interactive frame rates. Graphics memory limitations are avoided by performing raycasting on bricked volumes. For preprocessing tasks such as registration or segmentation, the visualization modules are integrated into a larger framework, thus supporting the entire workflow of preoperative planning.\",\n",
              "  'AuthorKeywords': ['Multimodal',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   'Hardware',\n",
              "   'Assisted',\n",
              "   'Raycasting,',\n",
              "   'Surgery',\n",
              "   'Planning'],\n",
              "  'MultipartiteRank': [{'score': 0.06339331006023358, 'word': 'anatomy'},\n",
              "   {'score': 0.05730127410185298, 'word': 'precise'},\n",
              "   {'score': 0.05730127410185298, 'word': 'preoperative'},\n",
              "   {'score': 0.05730127410185298, 'word': 'planning'},\n",
              "   {'score': 0.05460610606184094, 'word': 'surgical'},\n",
              "   {'score': 0.05460610606184094, 'word': 'approaches'},\n",
              "   {'score': 0.04860250100693141, 'word': 'individual'},\n",
              "   {'score': 0.04860250100693141, 'word': 'patient'},\n",
              "   {'score': 0.04203843918189074, 'word': 'multiple'},\n",
              "   {'score': 0.04203843918189074, 'word': 'radiological'},\n",
              "   {'score': 0.04203843918189074, 'word': 'imaging'},\n",
              "   {'score': 0.04203843918189074, 'word': 'modalities'}],\n",
              "  'Title': 'High-Quality Multimodal Volume Rendering for Preoperative Planning of Neurosurgical Interventions',\n",
              "  'distance': 0,\n",
              "  'no': '300',\n",
              "  'parent': '5228'},\n",
              " {'Abstract': 'Digital information displays are becoming more common in public spaces such as museums, galleries, and libraries. However, the public nature of these locations requires special considerations concerning the design of information visualization in terms of visual representations and interaction techniques. We discuss the potential for, and challenges of, information visualization in the museum context based on our practical experience with EMDialog, an interactive information presentation that was part of the Emily Carr exhibition at the Glenbow Museum in Calgary. EMDialog visualizes the diverse and multi-faceted discourse about this Canadian artist with the goal to both inform and provoke discussion. It provides a visual exploration environment that offers interplay between two integrated visualizations, one for information access along temporal, and the other along contextual dimensions. We describe the results of an observational study we conducted at the museum that revealed the different ways visitors approached and interacted with EMDialog, as well as how they perceived this form of information presentation in the museum context. Our results include the need to present information in a manner sufficiently attractive to draw attention and the importance of rewarding passive observation as well as both short- and longer term information exploration.',\n",
              "  'AuthorKeywords': ['artistic',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'interactive',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'walk-up-and-use',\n",
              "   'interaction,',\n",
              "   'public',\n",
              "   'displays'],\n",
              "  'MultipartiteRank': [{'score': 0.09068509475418932, 'word': 'information'},\n",
              "   {'score': 0.09068509475418932, 'word': 'visualization'},\n",
              "   {'score': 0.07534518977967852, 'word': 'museums'},\n",
              "   {'score': 0.041087900495792765, 'word': 'emdialog'},\n",
              "   {'score': 0.03903777375692858, 'word': 'visual'},\n",
              "   {'score': 0.03903777375692858, 'word': 'representations'},\n",
              "   {'score': 0.029647365706965644, 'word': 'museum'},\n",
              "   {'score': 0.029647365706965644, 'word': 'context'}],\n",
              "  'Title': 'EMDialog: Bringing Information Visualization into the Museum',\n",
              "  'distance': 0,\n",
              "  'no': '301',\n",
              "  'parent': '4927'},\n",
              " {'Abstract': 'When analyzing thousands of event histories, analysts often want to see the events as an aggregate to detect insights and generate new hypotheses about the data. An analysis tool must emphasize both the prevalence and the temporal ordering of these events. Additionally, the analysis tool must also support flexible comparisons to allow analysts to gather visual evidence. In a previous work, we introduced align, rank, and filter (ARF) to accentuate temporal ordering. In this paper, we present temporal summaries, an interactive visualization technique that highlights the prevalence of event occurrences. Temporal summaries dynamically aggregate events in multiple granularities (year, month, week, day, hour, etc.) for the purpose of spotting trends over time and comparing several groups of records. They provide affordances for analysts to perform temporal range filters. We demonstrate the applicability of this approach in two extensive case studies with analysts who applied temporal summaries to search, filter, and look for patterns in electronic health records and academic records.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'Visualization,',\n",
              "   'Interaction',\n",
              "   'design,',\n",
              "   'Human-computer',\n",
              "   'interaction,',\n",
              "   'temporal',\n",
              "   'categorical',\n",
              "   'data',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.104437806776099, 'word': 'temporal'},\n",
              "   {'score': 0.08562849511950352, 'word': 'event'},\n",
              "   {'score': 0.08562849511950352, 'word': 'histories'},\n",
              "   {'score': 0.07062724060941561, 'word': 'analysts'},\n",
              "   {'score': 0.06681446373775625, 'word': 'ordering'},\n",
              "   {'score': 0.04008224750658684, 'word': 'events'},\n",
              "   {'score': 0.03762334303834275, 'word': 'summaries'}],\n",
              "  'Title': 'Temporal Summaries: Supporting Temporal Categorical Searching, Aggregation and Comparison',\n",
              "  'distance': 0,\n",
              "  'no': '302',\n",
              "  'parent': '4849'},\n",
              " {'Abstract': 'The explosive growth of information systems on the Internet has clearly demonstrated the need to organise, filter, and present information in ways which allow users to cope with the sheer quantities of information available. The scope for visualisation of Gopher and WWW spaces is restricted by the limitations of their respective data models. The far richer data model supported by the Hyper-G Internet information system is exploited by its Harmony client to provide a number of tightly-coupled, two- and three-dimensional visualisation and navigational facilities, which help provide location feedback and alleviate user disorientation.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12848672211311615, 'word': 'information'},\n",
              "   {'score': 0.12848672211311615, 'word': 'systems'},\n",
              "   {'score': 0.0686414616450245, 'word': 'visualisation'},\n",
              "   {'score': 0.060550628221620814, 'word': 'explosive'},\n",
              "   {'score': 0.060550628221620814, 'word': 'growth'},\n",
              "   {'score': 0.053181239458494414, 'word': 'internet'},\n",
              "   {'score': 0.052521423482257176, 'word': 'respective'},\n",
              "   {'score': 0.052521423482257176, 'word': 'data'},\n",
              "   {'score': 0.052521423482257176, 'word': 'models'}],\n",
              "  'Title': 'Case study. Visualising cyberspace: information visualisation in the Harmony Internet browser',\n",
              "  'distance': 0,\n",
              "  'no': '303',\n",
              "  'parent': '3605'},\n",
              " {'Abstract': 'The authors consider the multi-triangulation, a general model for representing surfaces at variable resolution based on triangle meshes. They analyse characteristics of the model that make it effective for supporting basic operations such as extraction of a surface approximation, and point location. An interruptible algorithm for extracting a representation at a resolution variable over the surface is presented. Different heuristics for building the model are considered and compared. Results on both the construction and the extraction algorithm are presented.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1748215473810451, 'word': 'model'},\n",
              "   {'score': 0.14073811642585343, 'word': 'surfaces'},\n",
              "   {'score': 0.11090283944296724, 'word': 'general'},\n",
              "   {'score': 0.10414511275387948, 'word': 'variable'},\n",
              "   {'score': 0.10414511275387948, 'word': 'resolution'},\n",
              "   {'score': 0.06011944069927953, 'word': 'extraction'}],\n",
              "  'Title': 'Building and traversing a surface at variable resolution',\n",
              "  'distance': 0,\n",
              "  'no': '304',\n",
              "  'parent': '3529'},\n",
              " {'Abstract': 'In this paper, we present a topological approach for simplifying continuous functions defined on volumetric domains. We introduce two atomic operations that remove pairs of critical points of the function and design a combinatorial algorithm that simplifies the Morse-Smale complex by repeated application of these operations. The Morse-Smale complex is a topological data structure that provides a compact representation of gradient flow between critical points of a function. Critical points paired by the Morse-Smale complex identify topological features and their importance. The simplification procedure leaves important critical points untouched, and is therefore useful for extracting desirable features. We also present a visualization of the simplified topology.',\n",
              "  'AuthorKeywords': ['Morse',\n",
              "   'theory,',\n",
              "   'Morse-Smale',\n",
              "   'complexes,',\n",
              "   'computational',\n",
              "   'topology,',\n",
              "   'multiresolution,',\n",
              "   'simplification,',\n",
              "   'feature',\n",
              "   'detection,',\n",
              "   '3D',\n",
              "   'scalar',\n",
              "   'fields'],\n",
              "  'MultipartiteRank': [{'score': 0.10159864220487462, 'word': 'critical'},\n",
              "   {'score': 0.10159864220487462, 'word': 'points'},\n",
              "   {'score': 0.09008521394109052, 'word': 'continuous'},\n",
              "   {'score': 0.09008521394109052, 'word': 'functions'},\n",
              "   {'score': 0.08109134454018332, 'word': 'smale'},\n",
              "   {'score': 0.08109134454018332, 'word': 'complex'},\n",
              "   {'score': 0.07639451605551642, 'word': 'morse'},\n",
              "   {'score': 0.05885521061036067, 'word': 'atomic'},\n",
              "   {'score': 0.05885521061036067, 'word': 'operations'}],\n",
              "  'Title': 'Topology-based simplification for feature extraction from 3D scalar fields',\n",
              "  'distance': 0,\n",
              "  'no': '305',\n",
              "  'parent': '3858'},\n",
              " {'Abstract': 'Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.',\n",
              "  'AuthorKeywords': ['Multi-facet',\n",
              "   'visualization,',\n",
              "   'Text',\n",
              "   'visualization,',\n",
              "   'Multi-relational',\n",
              "   'Graph,',\n",
              "   'Search',\n",
              "   'UI'],\n",
              "  'MultipartiteRank': [{'score': 0.0936945096077848, 'word': 'documents'},\n",
              "   {'score': 0.051981895881750936, 'word': 'multiple'},\n",
              "   {'score': 0.051981895881750936, 'word': 'facets'},\n",
              "   {'score': 0.045851108183403017, 'word': 'facetatlas'},\n",
              "   {'score': 0.04584966366759572, 'word': 'different'},\n",
              "   {'score': 0.04584966366759572, 'word': 'relations'},\n",
              "   {'score': 0.035065642246150386, 'word': 'rich'},\n",
              "   {'score': 0.035065642246150386, 'word': 'text'},\n",
              "   {'score': 0.035065642246150386, 'word': 'corpora'}],\n",
              "  'Title': 'FacetAtlas: Multifaceted Visualization for Rich Text Corpora',\n",
              "  'distance': 0,\n",
              "  'no': '306',\n",
              "  'parent': '4700'},\n",
              " {'Abstract': 'The author presents a simple and flexible method of sharp coding for higher dimensional data sets that allows the database operator or the scientist quick access to promising patterns within and among records or samples. The example used is a 13-parameter set of solar wind, magnetosphere, and ground observation data collected hourly for 21 days in 1976. The software system is a prototype developed to demonstrate the glyph approach to depicting higher-dimensional data sets. The experiment was to depict all parameters simultaneously, to see if any global or local patterns emerged. This experiment proves that much more complex data can be presented for visual pattern extraction than standard methods allow.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10656981437116057, 'word': 'higher'},\n",
              "   {'score': 0.10656981437116057, 'word': 'dimensional'},\n",
              "   {'score': 0.10656981437116057, 'word': 'data'},\n",
              "   {'score': 0.10656981437116057, 'word': 'sets'},\n",
              "   {'score': 0.06532882504830755, 'word': 'promising'},\n",
              "   {'score': 0.06532882504830755, 'word': 'patterns'},\n",
              "   {'score': 0.062161916305655804, 'word': 'sharp'},\n",
              "   {'score': 0.062161916305655804, 'word': 'coding'},\n",
              "   {'score': 0.05521150433840731, 'word': 'flexible'},\n",
              "   {'score': 0.05521150433840731, 'word': 'method'},\n",
              "   {'score': 0.05120606723160214, 'word': 'scientist'},\n",
              "   {'score': 0.05120606723160214, 'word': 'quick'},\n",
              "   {'score': 0.05120606723160214, 'word': 'access'}],\n",
              "  'Title': 'Shape coding of multidimensional data on a microcomputer display',\n",
              "  'distance': 0,\n",
              "  'no': '307',\n",
              "  'parent': '3814'},\n",
              " {'Abstract': 'Swept surfaces and volumes are generated by moving a geometric model through space. Swept surfaces and volumes are important in many computer-aided design applications including geometric modeling, numerical cutter path generation, and spatial path planning. In this paper we describe a numerical algorithm to generate swept surfaces and volumes using implicit modeling techniques. The algorithm is applicable to any geometric representation for which a distance function can be computed. The algorithm also treats degenerate trajectories such as self-intersection and surface singularity. We show applications of this algorithm to maintainability design and robot path planning.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15678066341580266, 'word': 'swept'},\n",
              "   {'score': 0.15678066341580266, 'word': 'surfaces'},\n",
              "   {'score': 0.10858808758140188, 'word': 'volumes'},\n",
              "   {'score': 0.0943035642133566, 'word': 'geometric'},\n",
              "   {'score': 0.0943035642133566, 'word': 'model'},\n",
              "   {'score': 0.07190559146902648, 'word': 'design'},\n",
              "   {'score': 0.07190559146902648, 'word': 'applications'},\n",
              "   {'score': 0.06686351834446395, 'word': 'numerical'},\n",
              "   {'score': 0.06686351834446395, 'word': 'algorithm'}],\n",
              "  'Title': 'Implicit modeling of swept surfaces and volumes',\n",
              "  'distance': 0,\n",
              "  'no': '308',\n",
              "  'parent': '3854'},\n",
              " {'Abstract': 'Vector fields can present complex structural behavior, especially in turbulent computational fluid dynamics. The topological analysis of these data sets reduces the information, but one is usually still left with too many details for interpretation. In this paper, we present a simplification approach that removes pairs of critical points from the data set, based on relevance measures. In contrast to earlier methods, no grid changes are necessary, since the whole method uses small local changes of the vector values defining the vector field. An interpretation in terms of bifurcations underlines the continuous, natural flavor of the algorithm.',\n",
              "  'AuthorKeywords': ['vector',\n",
              "   'field',\n",
              "   'topology,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'unstructured',\n",
              "   'grid,',\n",
              "   'simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.10017738014400487, 'word': 'vector'},\n",
              "   {'score': 0.10017738014400487, 'word': 'fields'},\n",
              "   {'score': 0.06536181351656253, 'word': 'interpretation'},\n",
              "   {'score': 0.06025005698788386, 'word': 'earlier'},\n",
              "   {'score': 0.06025005698788386, 'word': 'methods'},\n",
              "   {'score': 0.05938228297884842, 'word': 'data'},\n",
              "   {'score': 0.05938228297884842, 'word': 'sets'},\n",
              "   {'score': 0.0385658071550211, 'word': 'terms'}],\n",
              "  'Title': 'Continuous topology simplification of planar vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '309',\n",
              "  'parent': '3781'},\n",
              " {'Abstract': \"Current implementations of multidimensional scaling (MDS), an approach that attempts to best represent data point similarity in a low-dimensional representation, are not suited for many of today's large-scale datasets. We propose an extension to the spring model approach that allows the user to interactively explore datasets that are far beyond the scale of previous implementations of MDS. We present MDSteer, a steerable MDS computation engine and visualization tool that progressively computes an MDS layout and handles datasets of over one million points. Our technique employs hierarchical data structures and progressive layouts to allow the user to steer the computation of the algorithm to the interesting areas of the dataset. The algorithm iteratively alternates between a layout stage in which a subselection of points are added to the set of active points affected by the MDS iteration, and a binning stage which increases the depth of the bin hierarchy and organizes the currently unplaced points into separate spatial regions. This binning strategy allows the user to select onscreen regions of the layout to focus the MDS computation into the areas of the dataset that are assigned to the selected bins. We show both real and common synthetic benchmark datasets with dimensionalities ranging from 3 to 300 and cardinalities of over one million points\",\n",
              "  'AuthorKeywords': ['dimensionality',\n",
              "   'reduction,',\n",
              "   'multidimensional',\n",
              "   'scaling'],\n",
              "  'MultipartiteRank': [{'score': 0.06176795336998056, 'word': 'mds'},\n",
              "   {'score': 0.061694352683556095, 'word': 'current'},\n",
              "   {'score': 0.061694352683556095, 'word': 'implementations'},\n",
              "   {'score': 0.05977752543827809, 'word': 'data'},\n",
              "   {'score': 0.05977752543827809, 'word': 'point'},\n",
              "   {'score': 0.05977752543827809, 'word': 'similarity'},\n",
              "   {'score': 0.055259650996762034, 'word': 'scale'},\n",
              "   {'score': 0.055259650996762034, 'word': 'datasets'},\n",
              "   {'score': 0.04750095250670485, 'word': 'multidimensional'},\n",
              "   {'score': 0.04750095250670485, 'word': 'scaling'}],\n",
              "  'Title': 'Steerable, Progressive Multidimensional Scaling',\n",
              "  'distance': 0,\n",
              "  'no': '310',\n",
              "  'parent': '4341'},\n",
              " {'Abstract': \"The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten &amp;amp; van Wijk's force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns.\",\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'aggregation,',\n",
              "   'node-link',\n",
              "   'diagrams,',\n",
              "   'edge',\n",
              "   'bundling,',\n",
              "   'physical',\n",
              "   'simulation'],\n",
              "  'MultipartiteRank': [{'score': 0.07793355234712905, 'word': 'graph'},\n",
              "   {'score': 0.07054462354094795, 'word': 'edge'},\n",
              "   {'score': 0.07054462354094795, 'word': 'bundling'},\n",
              "   {'score': 0.0561419870415919, 'word': 'direction'},\n",
              "   {'score': 0.048507169901368635, 'word': 'weight'},\n",
              "   {'score': 0.042534932776338304, 'word': 'force'}],\n",
              "  'Title': 'Divided Edge Bundling for Directional Network Data',\n",
              "  'distance': 0,\n",
              "  'no': '311',\n",
              "  'parent': '4663'},\n",
              " {'Abstract': 'Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.',\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'boxplots,',\n",
              "   'band',\n",
              "   'depth,',\n",
              "   'ensemble',\n",
              "   'visualization,',\n",
              "   'order',\n",
              "   'statistics'],\n",
              "  'MultipartiteRank': [{'score': 0.07828412408888344, 'word': 'boxplots'},\n",
              "   {'score': 0.06685380158367325, 'word': 'ensembles'},\n",
              "   {'score': 0.05154484295620805, 'word': 'numerical'},\n",
              "   {'score': 0.05154484295620805, 'word': 'simulations'},\n",
              "   {'score': 0.04148958087300694, 'word': 'contour'},\n",
              "   {'score': 0.03179386625379316, 'word': 'data'},\n",
              "   {'score': 0.03179386625379316, 'word': 'analysis'}],\n",
              "  'Title': 'Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles',\n",
              "  'distance': 0,\n",
              "  'no': '312',\n",
              "  'parent': '5104'},\n",
              " {'Abstract': 'It is becoming increasingly important that support is provided for users who are dealing with complex information spaces. The need is driven by the growing number of domains where there is a requirement for users to understand, navigate and manipulate large sets of computer based data; by the increasing size and complexity of this information and by the pressures to use this information efficiently. The paradigmatic example is the World Wide Web, but other domains include software systems, information systems and concurrent engineering. One approach to providing this support is to provide sophisticated visualisation tools which lead the users to form an intuitive understanding of the structure and behaviour of their domain and which provide mechanisms which allow them to manipulate objects within their system. The paper describes such a tool and a number of visualisation techniques that it implements.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1220783678368958, 'word': 'information'},\n",
              "   {'score': 0.06377811121299476, 'word': 'users'},\n",
              "   {'score': 0.051106299169628666, 'word': 'complex'},\n",
              "   {'score': 0.051106299169628666, 'word': 'spaces'},\n",
              "   {'score': 0.045551183711712434, 'word': 'domains'},\n",
              "   {'score': 0.045534719028833645, 'word': 'software'},\n",
              "   {'score': 0.045534719028833645, 'word': 'systems'}],\n",
              "  'Title': 'Case study. Narcissus: visualising information',\n",
              "  'distance': 0,\n",
              "  'no': '313',\n",
              "  'parent': '4791'},\n",
              " {'Abstract': 'Segmentation of structures from measured volume data, such as anatomy in medical imaging, is a challenging data-dependent task. In this paper, we present a segmentation method that leverages the parallel processing capabilities of modern programmable graphics hardware in order to run significantly faster than previous methods. In addition, collocating the algorithm computation with the visualization on the graphics hardware circumvents the need to transfer data across the system bus, allowing for faster visualization and interaction. This algorithm is unique in that it utilizes sophisticated graphics hardware functionality (i.e., floating point precision, render to texture, computational masking, and fragment programs) to enable fast segmentation and interactive visualization.',\n",
              "  'AuthorKeywords': ['region',\n",
              "   'growing,',\n",
              "   'diffusion,',\n",
              "   'segmentation,',\n",
              "   'graphics',\n",
              "   'processor,',\n",
              "   'streaming',\n",
              "   'computation'],\n",
              "  'MultipartiteRank': [{'score': 0.11399542808527552, 'word': 'segmentation'},\n",
              "   {'score': 0.08670368613514155, 'word': 'volume'},\n",
              "   {'score': 0.08670368613514155, 'word': 'data'},\n",
              "   {'score': 0.06414447879088415, 'word': 'modern'},\n",
              "   {'score': 0.06414447879088415, 'word': 'programmable'},\n",
              "   {'score': 0.06414447879088415, 'word': 'graphics'},\n",
              "   {'score': 0.06414447879088415, 'word': 'hardware'},\n",
              "   {'score': 0.06025402766904804, 'word': 'structures'},\n",
              "   {'score': 0.043878301112451654, 'word': 'visualization'}],\n",
              "  'Title': 'Fast volume segmentation with simultaneous visualization using programmable graphics hardware',\n",
              "  'distance': 0,\n",
              "  'no': '314',\n",
              "  'parent': '3504'},\n",
              " {'Abstract': 'We investigate the use of elastic hierarchies for representing trees, where a single graphical depiction uses a hybrid mixture, or \"interleaving\", of more basic forms at different nodes of the tree. In particular, we explore combinations of node link and treemap forms, to combine the space efficiency of treemaps with the structural clarity of node link diagrams. A taxonomy is developed to characterize the design space of such hybrid combinations. A software prototype is described, which we used to explore various techniques for visualizing, browsing and interacting with elastic hierarchies, such as side by side overview and detail views, highlighting and rubber banding across views, visualization of multiple foci, and smooth animations across transitions. The paper concludes with a discussion of the characteristics of elastic hierarchies and suggestions for research on their properties and uses.',\n",
              "  'AuthorKeywords': ['Elastic',\n",
              "   'Hierarchies,',\n",
              "   'Treemaps,',\n",
              "   'node-link',\n",
              "   'diagrams,',\n",
              "   'hybrids,',\n",
              "   'combinations,',\n",
              "   'overview+detail,',\n",
              "   'multiple',\n",
              "   'views,',\n",
              "   'trees,',\n",
              "   'interaction',\n",
              "   'techniques,',\n",
              "   'interactive',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.06146354679455445, 'word': 'different'},\n",
              "   {'score': 0.06146354679455445, 'word': 'nodes'},\n",
              "   {'score': 0.0597322328258973, 'word': 'elastic'},\n",
              "   {'score': 0.0597322328258973, 'word': 'hierarchies'},\n",
              "   {'score': 0.049370302695504596, 'word': 'detail'},\n",
              "   {'score': 0.049370302695504596, 'word': 'views'},\n",
              "   {'score': 0.04358262974732865, 'word': 'treemap'},\n",
              "   {'score': 0.04358262974732865, 'word': 'forms'},\n",
              "   {'score': 0.04244678753403374, 'word': 'trees'}],\n",
              "  'Title': 'Elastic hierarchies: combining treemaps and node-link diagrams',\n",
              "  'distance': 0,\n",
              "  'no': '315',\n",
              "  'parent': '4143'},\n",
              " {'Abstract': 'Flow volumes are the volumetric equivalent of stream lines. They provide more information about the vector field being visualized than do stream lines or ribbons. Presented is an efficient method for producing flow volumes, composed of transparently rendered tetrahedra, for use in an interactive system. The problems of rendering, subdivision, sorting, composing artifacts, and user interaction are dealt with. Efficiency comes from rendering only the volume of the smoke, and using hardware texturing and compositing.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1259494524937314, 'word': 'flow'},\n",
              "   {'score': 0.1259494524937314, 'word': 'volumes'},\n",
              "   {'score': 0.08301617922151688, 'word': 'stream'},\n",
              "   {'score': 0.08301617922151688, 'word': 'lines'},\n",
              "   {'score': 0.07926235491158469, 'word': 'interactive'},\n",
              "   {'score': 0.07926235491158469, 'word': 'system'},\n",
              "   {'score': 0.07339398597592611, 'word': 'efficient'},\n",
              "   {'score': 0.07339398597592611, 'word': 'method'},\n",
              "   {'score': 0.05617025269814098, 'word': 'rendering'}],\n",
              "  'Title': 'Flow volumes for interactive vector field visualization',\n",
              "  'distance': 0,\n",
              "  'no': '316',\n",
              "  'parent': '3612'},\n",
              " {'Abstract': 'Uncertainty or errors are introduced in fluid flow data as the data is acquired, transformed and rendered. Although researchers are aware of these uncertainties, little has been done to incorporate them in the existing visualization systems for fluid flow. In the absence of integrated presentation of data and its associated uncertainty, the analysis of the visualization is incomplete at best and may lead to inaccurate or incorrect conclusions. The article presents UFLOW-a system for visualizing uncertainty in fluid flow. Although there are several sources of uncertainties in fluid flow data, in this work, we focus on uncertainty arising from the use of different numerical algorithms for computing particle traces in a fluid flow. The techniques that we have employed to visualize uncertainty in fluid flow include uncertainty glyphs, flow envelopes, animations, priority sequences, twirling batons of trace viewpoints, and rakes. These techniques are effective in making the users aware of the effects of different integration methods and their sensitivity, especially near critical points in the flow field.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'uncertainty',\n",
              "   'glyphs,',\n",
              "   'streamlines,',\n",
              "   'rakes,',\n",
              "   'flow',\n",
              "   'envelopes,',\n",
              "   'animation'],\n",
              "  'MultipartiteRank': [{'score': 0.1766164660500864, 'word': 'fluid'},\n",
              "   {'score': 0.1766164660500864, 'word': 'flow'},\n",
              "   {'score': 0.16223843528372842, 'word': 'uncertainty'},\n",
              "   {'score': 0.15519081545073388, 'word': 'data'},\n",
              "   {'score': 0.03294227138660542, 'word': 'visualization'},\n",
              "   {'score': 0.03294227138660542, 'word': 'systems'}],\n",
              "  'Title': 'UFLOW: visualizing uncertainty in fluid flow',\n",
              "  'distance': 0,\n",
              "  'no': '317',\n",
              "  'parent': '4851'},\n",
              " {'Abstract': 'Many sophisticated solutions have been proposed to reduce the geometric complexity of 3D meshes. A problem studied less often is how to preserve on a simplified mesh the detail (e.g., color, high frequency shape detail, scalar fields, etc.) which is encoded in the original mesh. We present a general approach for preserving detail on simplified meshes. The detail (or high frequency information) lost after simplification is encoded through texture or bump maps. The original contribution is that preservation is performed after simplification, by building set of triangular texture patches that are then packed in a single texture map. Each simplified mesh face is sampled to build the associated triangular texture patch; a new method for storing this set of texture patches into a standard rectangular texture is presented and discussed. Our detail preserving approach makes no assumptions about the simplification process adopted to reduce mesh complexity and allows highly efficient rendering. The solution is very general, allowing preservation of any attribute value defined on the high resolution mesh. We also describe an alternative application: the conversion of 3D models with 3D static procedural textures into standard 3D models with 2D textures.',\n",
              "  'AuthorKeywords': ['surface',\n",
              "   'simplification,',\n",
              "   'detail',\n",
              "   'preservation,texture',\n",
              "   'mapping'],\n",
              "  'MultipartiteRank': [{'score': 0.11255590256801885, 'word': 'detail'},\n",
              "   {'score': 0.10105739207537481, 'word': '3d'},\n",
              "   {'score': 0.10105739207537481, 'word': 'meshes'},\n",
              "   {'score': 0.060553154616496706, 'word': 'texture'},\n",
              "   {'score': 0.04507062613800546, 'word': 'high'},\n",
              "   {'score': 0.04507062613800546, 'word': 'frequency'},\n",
              "   {'score': 0.04507062613800546, 'word': 'shape'},\n",
              "   {'score': 0.044717040984725315, 'word': 'many'},\n",
              "   {'score': 0.044717040984725315, 'word': 'sophisticated'},\n",
              "   {'score': 0.044717040984725315, 'word': 'solutions'}],\n",
              "  'Title': 'A general method for preserving attribute values on simplified meshes',\n",
              "  'distance': 0,\n",
              "  'no': '318',\n",
              "  'parent': '4877'},\n",
              " {'Abstract': 'High-throughput experiments such as gene expression microarrays in the life sciences result in large datasets. In response, a wide variety of visualization tools have been created to facilitate data analysis. Biologists often face a dilemma in choosing the best tool for their situation. The tool that works best for one biologist may not work well for another due to differences in the type of insight they seek from their data. A primary purpose of a visualization tool is to provide domain-relevant insight into the data. Ideally, any user wants maximum information in the least possible time. In this paper we identify several distinct characteristics of insight that enable us to recognize and quantify it. Based on this, we empirically evaluate five popular microarray visualization tools. Our conclusions can guide biologists in selecting the best tool for their data, and computer scientists in developing and evaluating visualizations',\n",
              "  'AuthorKeywords': ['Data',\n",
              "   'visualization,',\n",
              "   'empirical',\n",
              "   'evaluation,',\n",
              "   'insight,',\n",
              "   'high',\n",
              "   'throughput',\n",
              "   'experiments,',\n",
              "   'microarray',\n",
              "   'data,',\n",
              "   'bioinformatics'],\n",
              "  'MultipartiteRank': [{'score': 0.0842022086698742, 'word': 'data'},\n",
              "   {'score': 0.0842022086698742, 'word': 'analysis'},\n",
              "   {'score': 0.07338362812234588, 'word': 'visualization'},\n",
              "   {'score': 0.07338362812234588, 'word': 'tools'},\n",
              "   {'score': 0.07217828499497533, 'word': 'biologists'},\n",
              "   {'score': 0.06362245498080436, 'word': 'insight'},\n",
              "   {'score': 0.0609560622369565, 'word': 'best'},\n",
              "   {'score': 0.0609560622369565, 'word': 'tool'}],\n",
              "  'Title': 'An Evaluation of Microarray Visualization Tools for Biological Insight',\n",
              "  'distance': 0,\n",
              "  'no': '319',\n",
              "  'parent': '4345'},\n",
              " {'Abstract': 'We present the definition and computational algorithms for a new class of surfaces which are dual to the isosurface produced by the widely used marching cubes (MC) algorithm. These new isosurfaces have the same separating properties as the MC surfaces but they are comprised of quad patches that tend to eliminate the common negative aspect of poorly shaped triangles of the MC isosurfaces. Based upon the concept of this new dual operator, we describe a simple, but rather effective iterative scheme for producing smooth separating surfaces for binary, enumerated volumes which are often produced by segmentation algorithms. Both the dual surface algorithm and the iterative smoothing scheme are easily implemented.',\n",
              "  'AuthorKeywords': ['Marching',\n",
              "   'Cubes,',\n",
              "   'isosurfaces,',\n",
              "   'triangular',\n",
              "   'mesh,',\n",
              "   'dual',\n",
              "   'graph,',\n",
              "   'segmented',\n",
              "   'data,',\n",
              "   'smoothing'],\n",
              "  'MultipartiteRank': [{'score': 0.10722895608850669, 'word': 'computational'},\n",
              "   {'score': 0.10722895608850669, 'word': 'algorithms'},\n",
              "   {'score': 0.09823175918467587, 'word': 'dual'},\n",
              "   {'score': 0.09366465454324466, 'word': 'isosurface'},\n",
              "   {'score': 0.09214058856783094, 'word': 'surfaces'},\n",
              "   {'score': 0.07332766237055288, 'word': 'new'},\n",
              "   {'score': 0.07332766237055288, 'word': 'class'}],\n",
              "  'Title': 'Dual marching cubes',\n",
              "  'distance': 0,\n",
              "  'no': '320',\n",
              "  'parent': '3964'},\n",
              " {'Abstract': 'Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'treemap,',\n",
              "   'business',\n",
              "   'graphics,',\n",
              "   'hierarchical',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.09767539623255438, 'word': 'use'},\n",
              "   {'score': 0.06514480856551412, 'word': 'simple'},\n",
              "   {'score': 0.06514480856551412, 'word': 'business'},\n",
              "   {'score': 0.06514480856551412, 'word': 'graphics'},\n",
              "   {'score': 0.05770380467295592, 'word': 'treemaps'},\n",
              "   {'score': 0.051184004042481274, 'word': 'detailed'},\n",
              "   {'score': 0.051184004042481274, 'word': 'information'},\n",
              "   {'score': 0.04937361124949964, 'word': 'large'},\n",
              "   {'score': 0.04937361124949964, 'word': 'amounts'}],\n",
              "  'Title': 'Visualizing Business Data with Generalized Treemaps',\n",
              "  'distance': 0,\n",
              "  'no': '321',\n",
              "  'parent': '4282'},\n",
              " {'Abstract': 'This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented.',\n",
              "  'AuthorKeywords': ['Graph', 'layout,', 'GPU,', 'graph', 'partitioning'],\n",
              "  'MultipartiteRank': [{'score': 0.1681924303142594, 'word': 'algorithm'},\n",
              "   {'score': 0.10953079558657719, 'word': 'new'},\n",
              "   {'score': 0.09550606803539598, 'word': 'graph'},\n",
              "   {'score': 0.09550606803539598, 'word': 'layout'},\n",
              "   {'score': 0.07774129778991325, 'word': 'gpu'},\n",
              "   {'score': 0.05878870162179823, 'word': 'force'}],\n",
              "  'Title': 'Multi-Level Graph Layout on the GPU',\n",
              "  'distance': 0,\n",
              "  'no': '322',\n",
              "  'parent': '5424'},\n",
              " {'Abstract': \"Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework's use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.\",\n",
              "  'AuthorKeywords': ['Color',\n",
              "   'design,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'transparency,',\n",
              "   'user',\n",
              "   'study',\n",
              "   'evaluation,',\n",
              "   'conjoint',\n",
              "   'analysis,',\n",
              "   'illustrative',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.13266372091940323, 'word': 'professional'},\n",
              "   {'score': 0.13266372091940323, 'word': 'designers'},\n",
              "   {'score': 0.05774210530736885, 'word': 'effective'},\n",
              "   {'score': 0.05774210530736885, 'word': 'color'},\n",
              "   {'score': 0.05774210530736885, 'word': 'palettes'},\n",
              "   {'score': 0.04303241955785084, 'word': 'artists'},\n",
              "   {'score': 0.03491533187444587, 'word': 'rules'},\n",
              "   {'score': 0.02911824465509784, 'word': 'attention'}],\n",
              "  'Title': 'Color Design for Illustrative Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '323',\n",
              "  'parent': '5626'},\n",
              " {'Abstract': 'Today, online stores collect a lot of customer feedback in the form of surveys, reviews, and comments. This feedback is categorized and in some cases responded to, but in general it is underutilized - even though customer satisfaction is essential to the success of their business. In this paper, we introduce several new techniques to interactively analyze customer comments and ratings to determine the positive and negative opinions expressed by the customers. First, we introduce a new discrimination-based technique to automatically extract the terms that are the subject of the positive or negative opinion (such as price or customer service) and that are frequently commented on. Second, we derive a Reverse-Distance-Weighting method to map the attributes to the related positive and negative opinions in the text. Third, the resulting high-dimensional feature vectors are visualized in a new summary representation that provides a quick overview. We also cluster the reviews according to the similarity of the comments. Special thumbnails are used to provide insight into the composition of the clusters and their relationship. In addition, an interactive circular correlation map is provided to allow analysts to detect the relationships of the comments to other important attributes and the scores. We have applied these techniques to customer comments from real-world online stores and product reviews from web sites to identify the strength and problems of different products and services, and show the potential of our technique.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Opinion',\n",
              "   'Analysis,',\n",
              "   'Visual',\n",
              "   'Sentiment',\n",
              "   'Analysis,',\n",
              "   'Visual',\n",
              "   'Document',\n",
              "   'Analysis,',\n",
              "   'Attribute',\n",
              "   'Extraction'],\n",
              "  'MultipartiteRank': [{'score': 0.06076872764287063, 'word': 'comments'},\n",
              "   {'score': 0.04475336791997524, 'word': 'customer'},\n",
              "   {'score': 0.04475336791997524, 'word': 'feedback'},\n",
              "   {'score': 0.039462489490863895, 'word': 'reviews'},\n",
              "   {'score': 0.03813174953469874, 'word': 'negative'},\n",
              "   {'score': 0.03813174953469874, 'word': 'opinions'},\n",
              "   {'score': 0.037611586192581835, 'word': 'several'},\n",
              "   {'score': 0.037611586192581835, 'word': 'new'},\n",
              "   {'score': 0.037611586192581835, 'word': 'techniques'}],\n",
              "  'Title': 'Visual opinion analysis of customer feedback data',\n",
              "  'distance': 0,\n",
              "  'no': '324',\n",
              "  'parent': '5296'},\n",
              " {'Abstract': 'We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.',\n",
              "  'AuthorKeywords': ['Illustrative',\n",
              "   'rendering',\n",
              "   'and',\n",
              "   'visualization,',\n",
              "   'NPR,',\n",
              "   'dense',\n",
              "   'line',\n",
              "   'data,',\n",
              "   'DTI,',\n",
              "   'black-and-white',\n",
              "   'rendering,',\n",
              "   'GPU',\n",
              "   'technique'],\n",
              "  'MultipartiteRank': [{'score': 0.07926422096905077, 'word': '3d'},\n",
              "   {'score': 0.07926422096905077, 'word': 'line'},\n",
              "   {'score': 0.07926422096905077, 'word': 'data'},\n",
              "   {'score': 0.07606592855895099, 'word': 'technique'},\n",
              "   {'score': 0.07579564897094118, 'word': 'lines'},\n",
              "   {'score': 0.07379424943213574, 'word': 'depth'},\n",
              "   {'score': 0.07138464470621082, 'word': 'dependent'},\n",
              "   {'score': 0.07138464470621082, 'word': 'halos'}],\n",
              "  'Title': 'Depth-Dependent Halos: Illustrative Rendering of Dense Line Data',\n",
              "  'distance': 0,\n",
              "  'no': '325',\n",
              "  'parent': '3841'},\n",
              " {'Abstract': \"When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, “Whisper”, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.\",\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'Information',\n",
              "   'diffusion,',\n",
              "   'Contagion,',\n",
              "   'Social',\n",
              "   'media,',\n",
              "   'Microblogging,',\n",
              "   'Spatiotemporal',\n",
              "   'patterns'],\n",
              "  'MultipartiteRank': [{'score': 0.06851723258059216, 'word': 'social'},\n",
              "   {'score': 0.06851723258059216, 'word': 'media'},\n",
              "   {'score': 0.0542783302751598, 'word': 'information'},\n",
              "   {'score': 0.0370979669674467, 'word': 'novel'},\n",
              "   {'score': 0.0370979669674467, 'word': 'visualization'},\n",
              "   {'score': 0.0370979669674467, 'word': 'design'},\n",
              "   {'score': 0.03551160752046101, 'word': 'events'},\n",
              "   {'score': 0.031245597774581274, 'word': 'diffusion'}],\n",
              "  'Title': 'Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time',\n",
              "  'distance': 0,\n",
              "  'no': '326',\n",
              "  'parent': '5813'},\n",
              " {'Abstract': 'Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.',\n",
              "  'AuthorKeywords': ['Storylines,',\n",
              "   'story-telling',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'interactions,',\n",
              "   'level-of-detail,',\n",
              "   'optimization'],\n",
              "  'MultipartiteRank': [{'score': 0.10161200223156422, 'word': 'approaches'},\n",
              "   {'score': 0.06881461937749381, 'word': 'entities'},\n",
              "   {'score': 0.05971931761017612, 'word': 'storyline'},\n",
              "   {'score': 0.05971931761017612, 'word': 'layout'},\n",
              "   {'score': 0.05622274339558147, 'word': 'story'},\n",
              "   {'score': 0.0441357959340336, 'word': 'dynamic'},\n",
              "   {'score': 0.0441357959340336, 'word': 'relationships'}],\n",
              "  'Title': 'StoryFlow: Tracking the Evolution of Stories',\n",
              "  'distance': 0,\n",
              "  'no': '327',\n",
              "  'parent': '3797'},\n",
              " {'Abstract': 'Anatomy-based facial tissue modeling for surgical simulation is a field whose time has come. Real-time facial animation has been created in the last few years using models based on the anatomical structure of the human skin. Anatomy-based models are also under development in the field of medical visualization, with which facial surgery can be realistically simulated. In this article, we present an anatomy-based 3D finite element tissue model. Integrated into a computer-aided surgical planning system, this model allows the precise prediction of soft tissue changes resulting from the realignment of the underlying bone structure. The model has already been used in our Department of Oral and Maxillofacial Surgery and has improved craniofacial surgical planning procedures. The model is described in detail, and surgical simulation results are shown and discussed.',\n",
              "  'AuthorKeywords': ['human',\n",
              "   'facial',\n",
              "   'modeling,',\n",
              "   'finite',\n",
              "   'element',\n",
              "   'method,',\n",
              "   'computer-aided',\n",
              "   'surgery,',\n",
              "   'surgery',\n",
              "   'planning',\n",
              "   'and',\n",
              "   'simulation'],\n",
              "  'MultipartiteRank': [{'score': 0.1468757831574358, 'word': 'facial'},\n",
              "   {'score': 0.1468757831574358, 'word': 'tissue'},\n",
              "   {'score': 0.1468757831574358, 'word': 'modeling'},\n",
              "   {'score': 0.07845172745809856, 'word': 'anatomy'},\n",
              "   {'score': 0.07149484934645277, 'word': 'models'},\n",
              "   {'score': 0.07083615405314285, 'word': 'field'},\n",
              "   {'score': 0.06967330123724275, 'word': 'surgical'},\n",
              "   {'score': 0.06967330123724275, 'word': 'simulation'}],\n",
              "  'Title': 'Anatomy-based facial tissue modeling using the finite element method',\n",
              "  'distance': 0,\n",
              "  'no': '328',\n",
              "  'parent': '4116'},\n",
              " {'Abstract': 'We present a practical and general-purpose approach to large and complex visual data analysis where visualization processing, rendering and subsequent human interpretation is constrained to the subset of data deemed interesting by the user. In many scientific data analysis applications, \"interesting\" data can be defined by compound Boolean range queries of the form (temperature&gt;1000) AND (70&lt;pressure&lt;90). As data sizes grow larger, a central challenge is to answer such queries as efficiently as possible. Prior work in the visualization community has focused on answering range queries for scalar fields within the context of accelerating the search phase of isosurface algorithms. In contrast, our work describes an approach that leverages state-of-the-art indexing technology from the scientific data management community called \"bitmap indexing\". Our implementation, which we call \"DEX\" (short for dextrous data explorer), uses bitmap indexing to efficiently answer multivariate, multidimensional data queries to provide input to a visualization pipeline. We present an analysis overview and benchmark results that show bitmap indexing offers significant storage and performance improvements when compared to previous approaches for accelerating the search phase of isosurface algorithms. More importantly, since bitmap indexing supports complex multidimensional, multivariate range queries, it is more generally applicable to scientific data visualization and analysis problems. In addition to benchmark performance and analysis, we apply DEX to a typical scientific visualization problem encountered in combustion simulation data analysis.',\n",
              "  'AuthorKeywords': ['query-driven',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'bitmap',\n",
              "   'index,',\n",
              "   'multivariate',\n",
              "   'visualization,',\n",
              "   'large',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'data',\n",
              "   'analysis,',\n",
              "   'scientific',\n",
              "   'data',\n",
              "   'management'],\n",
              "  'MultipartiteRank': [{'score': 0.12965796894104661, 'word': 'data'},\n",
              "   {'score': 0.06617273189700593, 'word': 'complex'},\n",
              "   {'score': 0.06617273189700593, 'word': 'visual'},\n",
              "   {'score': 0.06617273189700593, 'word': 'analysis'},\n",
              "   {'score': 0.048415967643406776, 'word': 'visualization'},\n",
              "   {'score': 0.048415967643406776, 'word': 'processing'},\n",
              "   {'score': 0.0465702405852402, 'word': 'purpose'},\n",
              "   {'score': 0.0465702405852402, 'word': 'approach'},\n",
              "   {'score': 0.03899638782792696, 'word': 'interesting'}],\n",
              "  'Title': 'Query-driven visualization of large data sets',\n",
              "  'distance': 0,\n",
              "  'no': '329',\n",
              "  'parent': '5960'},\n",
              " {'Abstract': 'Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.',\n",
              "  'AuthorKeywords': ['Taxonomy,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Analytic',\n",
              "   'Activity,',\n",
              "   'Visual',\n",
              "   'Analytics,',\n",
              "   'Insight',\n",
              "   'Provenance'],\n",
              "  'MultipartiteRank': [{'score': 0.11134097571043439, 'word': 'insight'},\n",
              "   {'score': 0.11134097571043439, 'word': 'provenance'},\n",
              "   {'score': 0.07118317167874472, 'word': 'many'},\n",
              "   {'score': 0.07118317167874472, 'word': 'visual'},\n",
              "   {'score': 0.07118317167874472, 'word': 'analytics'},\n",
              "   {'score': 0.07118317167874472, 'word': 'applications'},\n",
              "   {'score': 0.058516785152139615, 'word': 'actions'},\n",
              "   {'score': 0.03920335879426759, 'word': 'approaches'},\n",
              "   {'score': 0.02934447487411041, 'word': 'multiple'},\n",
              "   {'score': 0.02934447487411041, 'word': 'levels'}],\n",
              "  'Title': \"Characterizing users' visual analytic activity for insight provenance\",\n",
              "  'distance': 0,\n",
              "  'no': '330',\n",
              "  'parent': '5346'},\n",
              " {'Abstract': \"Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization design. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.\",\n",
              "  'AuthorKeywords': ['User', 'study,', 'uncertainty', 'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.13375730142153214, 'word': 'techniques'},\n",
              "   {'score': 0.10064089742509656, 'word': 'many'},\n",
              "   {'score': 0.07826072097890287, 'word': 'uncertainty'},\n",
              "   {'score': 0.045688662887253706, 'word': 'search'},\n",
              "   {'score': 0.045688662887253706, 'word': 'tasks'},\n",
              "   {'score': 0.04133846568247309, 'word': 'data'},\n",
              "   {'score': 0.04133846568247309, 'word': 'visualizations'}],\n",
              "  'Title': 'A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets',\n",
              "  'distance': 0,\n",
              "  'no': '331',\n",
              "  'parent': '6161'},\n",
              " {'Abstract': \"Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's “Movie Narrative Charts” [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.\",\n",
              "  'AuthorKeywords': ['Layout',\n",
              "   'algorithm,',\n",
              "   'timeline',\n",
              "   'visualization,',\n",
              "   'storyline',\n",
              "   'visualization,',\n",
              "   'design',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.20292761914289592, 'word': 'storyline'},\n",
              "   {'score': 0.20292761914289592, 'word': 'visualization'},\n",
              "   {'score': 0.0626659892900088, 'word': 'social'},\n",
              "   {'score': 0.0626659892900088, 'word': 'interactions'},\n",
              "   {'score': 0.05450862767191685, 'word': 'illustration'},\n",
              "   {'score': 0.04870163116131806, 'word': 'technique'},\n",
              "   {'score': 0.04228918900870731, 'word': 'previous'},\n",
              "   {'score': 0.04228918900870731, 'word': 'methods'}],\n",
              "  'Title': 'Design Considerations for Optimizing Storyline Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '332',\n",
              "  'parent': '3806'},\n",
              " {'Abstract': 'This paper describes the SHriMP visualization technique for seamlessly exploring software structure and browsing source code, with a focus on effectively assisting hybrid program comprehension strategies. The technique integrates both pan+zoom and fisheye-view visualization approaches for exploring a nested graph view of software structure. The fisheye-view approach handles multiple focal points, which are necessary when examining several subsystems and their mutual interconnections. Source code is presented by embedding code fragments within the nodes of the nested graph. Finer connections among these fragments are represented by a network that is navigated using a hypertext link-following metaphor. SHriMP combines this hypertext metaphor with animated panning and zooming motions over the nested graph to provide continuous orientation and contextual cues for the user. The SHriMP tool is being evaluated in several user studies. Observations of users performing program understanding tasks with the tool are discussed.',\n",
              "  'AuthorKeywords': ['Nested',\n",
              "   'graphs,',\n",
              "   'pan',\n",
              "   'and',\n",
              "   'zoom,',\n",
              "   'fisheye',\n",
              "   'views,',\n",
              "   'hypertext,',\n",
              "   'mental',\n",
              "   'map,',\n",
              "   'software',\n",
              "   'visualization,',\n",
              "   'program',\n",
              "   'understanding'],\n",
              "  'MultipartiteRank': [{'score': 0.10900360064275044, 'word': 'view'},\n",
              "   {'score': 0.06010955262188024, 'word': 'graph'},\n",
              "   {'score': 0.056825463972333984, 'word': 'software'},\n",
              "   {'score': 0.056825463972333984, 'word': 'structure'},\n",
              "   {'score': 0.050474300250070776, 'word': 'fisheye'},\n",
              "   {'score': 0.0488940480208702, 'word': 'visualization'},\n",
              "   {'score': 0.0488940480208702, 'word': 'approaches'},\n",
              "   {'score': 0.045180145911029354, 'word': 'browsing'},\n",
              "   {'score': 0.045180145911029354, 'word': 'source'},\n",
              "   {'score': 0.045180145911029354, 'word': 'code'}],\n",
              "  'Title': 'On integrating visualization techniques for effective software exploration',\n",
              "  'distance': 0,\n",
              "  'no': '333',\n",
              "  'parent': '4494'},\n",
              " {'Abstract': \"We propose a new approach to polygonal isosurface extraction that is based on extracting only the visible portion of the isosurface. The visibility tests are done in two phases. First, coarse visibility tests are performed in software to determine the visible cells. These tests are based on hierarchical tiles and shear-warp factorization. The second phase resolves the visible portions of the extracted triangles and is accomplished by the graphics hardware. While the latest isosurface extraction methods have effectively eliminated the search phase bottleneck, the cost of constructing and rendering the isosurface remains high. Many of today's large datasets contain very large and complex isosurfaces that can easily overwhelm even state-of-the-art graphics hardware. The proposed approach is output sensitive and is thus well suited for remote visualization applications where the extraction and rendering phases are done on a separate machines.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1337502212263495, 'word': 'isosurface'},\n",
              "   {'score': 0.07616757394083182, 'word': 'phases'},\n",
              "   {'score': 0.06978143648544327, 'word': 'visibility'},\n",
              "   {'score': 0.06978143648544327, 'word': 'tests'},\n",
              "   {'score': 0.06858345601867541, 'word': 'visible'},\n",
              "   {'score': 0.06858345601867541, 'word': 'portion'},\n",
              "   {'score': 0.06373997488112011, 'word': 'polygonal'},\n",
              "   {'score': 0.06373997488112011, 'word': 'extraction'}],\n",
              "  'Title': 'View dependent isosurface extraction',\n",
              "  'distance': 0,\n",
              "  'no': '334',\n",
              "  'parent': '4407'},\n",
              " {'Abstract': 'In this paper we develop a new technique for tracing anatomical fibers from 3D tensor fields. The technique extracts salient tensor features using a local regularization technique that allows the algorithm to cross noisy regions and bridge gaps in the data. We applied the method to human brain DT-MRI data and recovered identifiable anatomical structures that correspond to the white matter brain-fiber pathways. The images in this paper are derived from a dataset having 121/spl times/88/spl times/60 resolution. We were able to recover fibers with less than the voxel size resolution by applying the regularization technique, i.e., using a priori assumptions about fiber smoothness. The regularization procedure is done through a moving least squares filter directly incorporated in the tracing algorithm.',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'tensors,',\n",
              "   'adaptive',\n",
              "   'filtering,',\n",
              "   'moving',\n",
              "   'least',\n",
              "   'squares,',\n",
              "   'streamlines,',\n",
              "   'fiber',\n",
              "   'tracing,',\n",
              "   'pathways,',\n",
              "   'salient',\n",
              "   'features'],\n",
              "  'MultipartiteRank': [{'score': 0.11219345972231369, 'word': 'anatomical'},\n",
              "   {'score': 0.11219345972231369, 'word': 'fibers'},\n",
              "   {'score': 0.10964084787583163, 'word': 'new'},\n",
              "   {'score': 0.10964084787583163, 'word': 'technique'},\n",
              "   {'score': 0.05734273739280777, 'word': '3d'},\n",
              "   {'score': 0.05734273739280777, 'word': 'tensor'},\n",
              "   {'score': 0.05734273739280777, 'word': 'fields'},\n",
              "   {'score': 0.0549040275549406, 'word': 'paper'},\n",
              "   {'score': 0.05237960656996189, 'word': 'data'}],\n",
              "  'Title': 'Oriented tensor reconstruction: tracing neural pathways from diffusion tensor MRI',\n",
              "  'distance': 0,\n",
              "  'no': '335',\n",
              "  'parent': '4208'},\n",
              " {'Abstract': 'We present a technique for direct visualization of unsteady flow on surfaces from computational fluid dynamics. The method generates dense representations of time-dependent vector fields with high spatio-temporal correlation using both Lagrangian-Eulerian advection and image based flow visualization as its foundation. While the 3D vector fields are associated with arbitrary triangular surface meshes, the generation and advection of texture properties is confined to image space. Frame rates of up to 20 frames per second are realized by exploiting graphics card hardware. We apply this algorithm to unsteady flow on boundary surfaces of, large, complex meshes from computational fluid dynamics composed of more than 250,000 polygons, dynamic meshes with time-dependent geometry and topology, as well as medical data.',\n",
              "  'AuthorKeywords': ['Unsteady',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'computational',\n",
              "   'fluid',\n",
              "   'dynamics',\n",
              "   '(CFD),',\n",
              "   'surface',\n",
              "   'representation,',\n",
              "   'texture',\n",
              "   'mapping'],\n",
              "  'MultipartiteRank': [{'score': 0.054110865393052175, 'word': 'unsteady'},\n",
              "   {'score': 0.054110865393052175, 'word': 'flow'},\n",
              "   {'score': 0.051306649459416376, 'word': 'direct'},\n",
              "   {'score': 0.051306649459416376, 'word': 'visualization'},\n",
              "   {'score': 0.04976923081666696, 'word': 'computational'},\n",
              "   {'score': 0.04976923081666696, 'word': 'fluid'},\n",
              "   {'score': 0.04976923081666696, 'word': 'dynamics'},\n",
              "   {'score': 0.049204400553170484, 'word': 'surfaces'},\n",
              "   {'score': 0.046863491628224736, 'word': 'time'}],\n",
              "  'Title': 'Image space based visualization of unsteady flow on surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '336',\n",
              "  'parent': '3779'},\n",
              " {'Abstract': 'In this paper we show how out-of-core mesh processing techniques can be adapted to perform their computations based on the new processing sequence paradigm (Isenburg, et al., 2003), using mesh simplification as an example. We believe that this processing concept will also prove useful for other tasks, such a parameterization, remeshing, or smoothing, for which currently only in-core solutions exist. A processing sequence represents a mesh as a particular interleaved ordering of indexed triangles and vertices. This representation allows streaming very large meshes through main memory while maintaining information about the visitation status of edges and vertices. At any time, only a small portion of the mesh is kept in-core, with the bulk of the mesh data residing on disk. Mesh access is restricted to a fixed traversal order, but full connectivity and geometry information is available for the active elements of the traversal. This provides seamless and highly efficient out-of-core access to very large meshes for algorithms that can adapt their computations to this fixed ordering. The two abstractions that are naturally supported by this representation are boundary-based and buffer-based processing. We illustrate both abstractions by adapting two different simplification methods to perform their computation using a prototype of our mesh processing sequence API. Both algorithms benefit from using processing sequences in terms of improved quality, more efficient execution, and smaller memory footprints.',\n",
              "  'AuthorKeywords': ['Out-of-core',\n",
              "   'algorithms,',\n",
              "   'processing',\n",
              "   'sequences,',\n",
              "   'mesh',\n",
              "   'simplification,',\n",
              "   'large',\n",
              "   'meshes'],\n",
              "  'MultipartiteRank': [{'score': 0.08416915077307831, 'word': 'mesh'},\n",
              "   {'score': 0.08416915077307831, 'word': 'simplification'},\n",
              "   {'score': 0.07801225099024289, 'word': 'new'},\n",
              "   {'score': 0.07801225099024289, 'word': 'processing'},\n",
              "   {'score': 0.07801225099024289, 'word': 'sequence'},\n",
              "   {'score': 0.07801225099024289, 'word': 'paradigm'},\n",
              "   {'score': 0.03867357412683538, 'word': 'computations'},\n",
              "   {'score': 0.0360312871970739, 'word': 'particular'},\n",
              "   {'score': 0.0360312871970739, 'word': 'interleaved'},\n",
              "   {'score': 0.0360312871970739, 'word': 'ordering'},\n",
              "   {'score': 0.03390682871736991, 'word': 'core'},\n",
              "   {'score': 0.03390682871736991, 'word': 'solutions'}],\n",
              "  'Title': 'Large mesh simplification using processing sequences',\n",
              "  'distance': 0,\n",
              "  'no': '337',\n",
              "  'parent': '5305'},\n",
              " {'Abstract': 'Even though information visualization (InfoVis) research has matured in recent years, it is generally acknowledged that the field still lacks supporting, encompassing theories. In this paper, we argue that the distributed cognition framework can be used to substantiate the theoretical foundation of InfoVis. We highlight fundamental assumptions and theoretical constructs of the distributed cognition approach, based on the cognitive science literature and a real life scenario. We then discuss how the distributed cognition framework can have an impact on the research directions and methodologies we take as InfoVis researchers. Our contributions are as follows. First, we highlight the view that cognition is more an emergent property of interaction than a property of the human mind. Second, we argue that a reductionist approach to study the abstract properties of isolated human minds may not be useful in informing InfoVis design. Finally we propose to make cognition an explicit research agenda, and discuss the implications on how we perform evaluation and theory building.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'distributed',\n",
              "   'cognition,',\n",
              "   'interaction,',\n",
              "   'representation,',\n",
              "   'theory',\n",
              "   'and',\n",
              "   'methods'],\n",
              "  'MultipartiteRank': [{'score': 0.09336693508361452, 'word': 'cognition'},\n",
              "   {'score': 0.09336693508361452, 'word': 'framework'},\n",
              "   {'score': 0.08603636447067035, 'word': 'infovis'},\n",
              "   {'score': 0.08468860982809234, 'word': 'research'},\n",
              "   {'score': 0.051588933462447764, 'word': 'theoretical'},\n",
              "   {'score': 0.051588933462447764, 'word': 'foundation'},\n",
              "   {'score': 0.04855803069924061, 'word': 'emergent'},\n",
              "   {'score': 0.04855803069924061, 'word': 'property'}],\n",
              "  'Title': 'Distributed Cognition as a Theoretical Framework for Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '338',\n",
              "  'parent': '4171'},\n",
              " {'Abstract': 'We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.',\n",
              "  'AuthorKeywords': ['Trajectories,',\n",
              "   'Kernel',\n",
              "   'Density',\n",
              "   'Estimation,',\n",
              "   'Multivariate',\n",
              "   'Data,',\n",
              "   'Geographical',\n",
              "   'Information',\n",
              "   'Systems,',\n",
              "   'Raster',\n",
              "   'Maps'],\n",
              "  'MultipartiteRank': [{'score': 0.08812748472399941, 'word': 'density'},\n",
              "   {'score': 0.08812748472399941, 'word': 'maps'},\n",
              "   {'score': 0.0442735332460117, 'word': 'block'},\n",
              "   {'score': 0.0442735332460117, 'word': 'diagram'},\n",
              "   {'score': 0.04284265611912976, 'word': 'domain'},\n",
              "   {'score': 0.04284265611912976, 'word': 'knowledge'},\n",
              "   {'score': 0.041137668145170475, 'word': 'versatile'},\n",
              "   {'score': 0.041137668145170475, 'word': 'exploration'},\n",
              "   {'score': 0.03976004380182436, 'word': 'means'}],\n",
              "  'Title': 'Composite Density Maps for Multivariate Trajectories',\n",
              "  'distance': 0,\n",
              "  'no': '339',\n",
              "  'parent': '3866'},\n",
              " {'Abstract': 'In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus “observation”) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.',\n",
              "  'AuthorKeywords': ['observation-level',\n",
              "   'interaction,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'statistical',\n",
              "   'models'],\n",
              "  'MultipartiteRank': [{'score': 0.09513550463707944, 'word': 'visual'},\n",
              "   {'score': 0.09513550463707944, 'word': 'analytics'},\n",
              "   {'score': 0.06229652316119113, 'word': 'sensemaking'},\n",
              "   {'score': 0.056623977412865296, 'word': 'observations'},\n",
              "   {'score': 0.05255827620474687, 'word': 'data'},\n",
              "   {'score': 0.04340009245041332, 'word': 'users'}],\n",
              "  'Title': 'Observation-level interaction with statistical models for visual analytics',\n",
              "  'distance': 0,\n",
              "  'no': '340',\n",
              "  'parent': '5345'},\n",
              " {'Abstract': 'Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.',\n",
              "  'AuthorKeywords': ['Hierarchical',\n",
              "   'topic',\n",
              "   'representation,',\n",
              "   'topic',\n",
              "   'modeling,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'rose',\n",
              "   'tree'],\n",
              "  'MultipartiteRank': [{'score': 0.12636905996887413, 'word': 'topic'},\n",
              "   {'score': 0.09039850247908812, 'word': 'large'},\n",
              "   {'score': 0.06236381013590128, 'word': 'interactive'},\n",
              "   {'score': 0.06236381013590128, 'word': 'visualizations'},\n",
              "   {'score': 0.05059259400563973, 'word': 'number'},\n",
              "   {'score': 0.039805908473448386, 'word': 'text'},\n",
              "   {'score': 0.039805908473448386, 'word': 'corpora'},\n",
              "   {'score': 0.037375525857581506, 'word': 'user'},\n",
              "   {'score': 0.037375525857581506, 'word': 'interactions'}],\n",
              "  'Title': 'HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies',\n",
              "  'distance': 0,\n",
              "  'no': '341',\n",
              "  'parent': '5364'},\n",
              " {'Abstract': 'A technique that harnesses color and texture perception to create integrated displays of 2D image-like multiparameter distributions is presented. The power of the technique is demonstrated by an example of a synthesized dataset and compared with several other proposed techniques. The nature of studies that are required to measure objectively and accurately the effectiveness of such displays is discussed.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.16873407760075565, 'word': 'technique'},\n",
              "   {'score': 0.09774892987189687, 'word': '2d'},\n",
              "   {'score': 0.09774892987189687, 'word': 'image'},\n",
              "   {'score': 0.08705530520617383, 'word': 'like'},\n",
              "   {'score': 0.08705530520617383, 'word': 'multiparameter'},\n",
              "   {'score': 0.08705530520617383, 'word': 'distributions'},\n",
              "   {'score': 0.08599702202609188, 'word': 'displays'},\n",
              "   {'score': 0.08482236667754876, 'word': 'texture'},\n",
              "   {'score': 0.08482236667754876, 'word': 'perception'}],\n",
              "  'Title': 'Color icons: merging color and texture perception for integrated visualization of multiple parameters',\n",
              "  'distance': 0,\n",
              "  'no': '342',\n",
              "  'parent': '3353'},\n",
              " {'Abstract': 'It is shown how data visualization fits into the broader process of scientific data analysis. Scientists from several disciplines were observed while they analyzed their own data. Examination of the observations exposed process elements outside conventional image viewing. For example, analysts queried for quantitative information, made a variety of comparisons, applied math, managed data, and kept records. The characterization of scientific data analysis reveals activity beyond that traditionally supported by computer. It offers an understanding which has the potential to be applied to many future designs, and suggests specific recommendations for improving the support of this important aspect of scientific computing.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.19250183994527104, 'word': 'data'},\n",
              "   {'score': 0.12814915689222006, 'word': 'visualization'},\n",
              "   {'score': 0.09039750637988592, 'word': 'broader'},\n",
              "   {'score': 0.09039750637988592, 'word': 'process'},\n",
              "   {'score': 0.06435268305305096, 'word': 'scientific'},\n",
              "   {'score': 0.06435268305305096, 'word': 'analysis'},\n",
              "   {'score': 0.04512577089093694, 'word': 'scientists'},\n",
              "   {'score': 0.038975900197665884, 'word': 'several'},\n",
              "   {'score': 0.038975900197665884, 'word': 'disciplines'}],\n",
              "  'Title': 'A characterization of the scientific data analysis process',\n",
              "  'distance': 0,\n",
              "  'no': '343',\n",
              "  'parent': '4299'},\n",
              " {'Abstract': 'Geographic visualization, sometimes called cartographic visualization, is a form of information visualization in which principles from cartography, geographic information systems (GIS), exploratory data analysis (EDA), and information visualization more generally are integrated in the development and assessment of visual methods that facilitate the exploration, analysis, synthesis, and presentation of georeferenced information. The authors report on development and use of one component of a prototype GVis environment designed to facilitate exploration, by domain experts, of time series multivariate georeferenced health statistics. Emphasis is on how manipulable dynamic GVis tools may facilitate visual thinking, pattern noticing, and hypothesis generation. The prototype facilitates the highlighting of data extremes, examination of change in geographic patterns over time, and exploration of similarity among georeferenced variables. A qualitative exploratory analysis of verbal protocols and transaction logs is used to characterize system use. Evidence produced through the characterization highlights differences among experts in data analysis strategies (particularly in relation to the use of attribute \"focusing\" combined with time series animation) and corresponding differences in success at noticing spatiotemporal patterns.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15820564066714787, 'word': 'visualization'},\n",
              "   {'score': 0.0941094023410211, 'word': 'geographic'},\n",
              "   {'score': 0.06409623832612676, 'word': 'information'},\n",
              "   {'score': 0.05047460815826578, 'word': 'exploratory'},\n",
              "   {'score': 0.05047460815826578, 'word': 'data'},\n",
              "   {'score': 0.05047460815826578, 'word': 'analysis'},\n",
              "   {'score': 0.03592283842051169, 'word': 'exploration'},\n",
              "   {'score': 0.03135694186623513, 'word': 'time'},\n",
              "   {'score': 0.03135694186623513, 'word': 'series'},\n",
              "   {'score': 0.03135694186623513, 'word': 'multivariate'}],\n",
              "  'Title': 'Geographic visualization: designing manipulable maps for exploring temporally varying georeferenced statistics',\n",
              "  'distance': 0,\n",
              "  'no': '344',\n",
              "  'parent': '4888'},\n",
              " {'Abstract': 'We propose methods to accelerate texture-based volume rendering by skipping invisible voxels. We partition the volume into sub-volumes, each containing voxels with similar properties. Sub-volumes composed of only voxels mapped to empty by the transfer function are skipped. To render the adaptively partitioned sub-volumes in visibility order, we reorganize them into an orthogonal BSP tree. We also present an algorithm that computes incrementally the intersection of the volume with the slicing planes, which avoids the overhead of the intersection and texture coordinates computation introduced by the partitioning. Rendering with empty space skipping is 2 to 5 times faster than without it. To skip occluded voxels, we introduce the concept of orthogonal opacity map, that simplifies the transformation between the volume coordinates and the opacity map coordinates, which is intensively used for occlusion detection. The map is updated efficiently by the GPU. The sub-volumes are then culled and clipped against the opacity map. We also present a method that adaptively adjusts the optimal number of the opacity map updates. With occlusion clipping, about 60% of non-empty voxels can be skipped and an additional 80% speedup on average is gained for iso-surface-like rendering.',\n",
              "  'AuthorKeywords': ['Graphics',\n",
              "   'hardware,',\n",
              "   'texture-based',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'empty',\n",
              "   'space',\n",
              "   'skipping,',\n",
              "   'occlusion',\n",
              "   'clipping,',\n",
              "   'orthogonal',\n",
              "   'opacity',\n",
              "   'map'],\n",
              "  'MultipartiteRank': [{'score': 0.11466943971644172, 'word': 'volume'},\n",
              "   {'score': 0.07019609932321763, 'word': 'orthogonal'},\n",
              "   {'score': 0.07019609932321763, 'word': 'opacity'},\n",
              "   {'score': 0.07019609932321763, 'word': 'map'},\n",
              "   {'score': 0.05667061974156723, 'word': 'invisible'},\n",
              "   {'score': 0.05667061974156723, 'word': 'voxels'},\n",
              "   {'score': 0.04673773954756172, 'word': 'texture'},\n",
              "   {'score': 0.045600501354419225, 'word': 'sub'}],\n",
              "  'Title': 'Empty space skipping and occlusion clipping for texture-based volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '345',\n",
              "  'parent': '4930'},\n",
              " {'Abstract': 'Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for \"summarizing\" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing \"relative\" and \"absolute\" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.',\n",
              "  'AuthorKeywords': ['Video',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'video',\n",
              "   'surveillance,',\n",
              "   'change',\n",
              "   'detection,',\n",
              "   'image-swept',\n",
              "   'volume'],\n",
              "  'MultipartiteRank': [{'score': 0.23873933877872594, 'word': 'video'},\n",
              "   {'score': 0.23873933877872594, 'word': 'data'},\n",
              "   {'score': 0.08200884760861332, 'word': 'volume'},\n",
              "   {'score': 0.04776916534542319, 'word': 'real'},\n",
              "   {'score': 0.04776916534542319, 'word': 'time'},\n",
              "   {'score': 0.04414896190169767, 'word': 'process'},\n",
              "   {'score': 0.04124621876358739, 'word': 'visualization'},\n",
              "   {'score': 0.04124621876358739, 'word': 'techniques'}],\n",
              "  'Title': 'Video visualization',\n",
              "  'distance': 0,\n",
              "  'no': '346',\n",
              "  'parent': '5059'},\n",
              " {'Abstract': 'All orientable metric surfaces are Riemann surfaces and admit global conformal parameterizations. Riemann surface structure is a fundamental structure and governs many natural physical phenomena, such as heat diffusion and electro-magnetic fields on the surface. A good parameterization is crucial for simulation and visualization. This paper provides an explicit method for finding optimal global conformal parameterizations of arbitrary surfaces. It relies on certain holomorphic differential forms and conformal mappings from differential geometry and Riemann surface theories. Algorithms are developed to modify topology, locate zero points, and determine cohomology types of differential forms. The implementation is based on a finite dimensional optimization method. The optimal parameterization is intrinsic to the geometry, preserves angular structure, and can play an important role in various applications including texture mapping, remeshing, morphing and simulation. The method is demonstrated by visualizing the Riemann surface structure of real surfaces represented as triangle meshes.',\n",
              "  'AuthorKeywords': ['Computational',\n",
              "   'geometry',\n",
              "   'and',\n",
              "   'object',\n",
              "   'modeling,',\n",
              "   'Curve',\n",
              "   '/',\n",
              "   'surface',\n",
              "   '/',\n",
              "   'solid',\n",
              "   'and',\n",
              "   'object',\n",
              "   'representations,',\n",
              "   'Surface',\n",
              "   'parameterization'],\n",
              "  'MultipartiteRank': [{'score': 0.1763342836686761, 'word': 'surfaces'},\n",
              "   {'score': 0.16333001125020363, 'word': 'riemann'},\n",
              "   {'score': 0.08988171178494778, 'word': 'global'},\n",
              "   {'score': 0.08988171178494778, 'word': 'conformal'},\n",
              "   {'score': 0.08988171178494778, 'word': 'parameterizations'},\n",
              "   {'score': 0.07071643814060746, 'word': 'structure'},\n",
              "   {'score': 0.04777152243715667, 'word': 'orientable'},\n",
              "   {'score': 0.04777152243715667, 'word': 'metric'},\n",
              "   {'score': 0.035949188121923235, 'word': 'fundamental'},\n",
              "   {'score': 0.03476725001868422, 'word': 'surface'}],\n",
              "  'Title': 'Optimal global conformal surface parameterization',\n",
              "  'distance': 0,\n",
              "  'no': '347',\n",
              "  'parent': '4785'},\n",
              " {'Abstract': \"Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.\",\n",
              "  'AuthorKeywords': ['Parallel',\n",
              "   'coordinates,',\n",
              "   'metrics,',\n",
              "   'display',\n",
              "   'optimization,',\n",
              "   'visualization',\n",
              "   'models'],\n",
              "  'MultipartiteRank': [{'score': 0.0634187853328614, 'word': 'space'},\n",
              "   {'score': 0.04506374979297355, 'word': 'adjacent'},\n",
              "   {'score': 0.04506374979297355, 'word': 'axes'},\n",
              "   {'score': 0.04492108836344397, 'word': 'number'},\n",
              "   {'score': 0.032872469078951035, 'word': 'dimensions'},\n",
              "   {'score': 0.032688086835524495, 'word': 'metrics'},\n",
              "   {'score': 0.030730698497336905, 'word': 'screen'}],\n",
              "  'Title': 'Pargnostics: Screen-Space Metrics for Parallel Coordinates',\n",
              "  'distance': 0,\n",
              "  'no': '348',\n",
              "  'parent': '4974'},\n",
              " {'Abstract': 'In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'theory,',\n",
              "   'theory',\n",
              "   'of',\n",
              "   'visualization,',\n",
              "   'quantitative',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.11050244916384463, 'word': 'information'},\n",
              "   {'score': 0.11050244916384463, 'word': 'theory'},\n",
              "   {'score': 0.10350587942593449, 'word': 'visualization'},\n",
              "   {'score': 0.040179369980925896, 'word': 'major'},\n",
              "   {'score': 0.040179369980925896, 'word': 'applications'},\n",
              "   {'score': 0.039619441633506385, 'word': 'data'},\n",
              "   {'score': 0.039619441633506385, 'word': 'compression'},\n",
              "   {'score': 0.03640342603261609, 'word': 'emphasis'}],\n",
              "  'Title': 'An Information-theoretic Framework for Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '349',\n",
              "  'parent': '5021'},\n",
              " {'Abstract': 'Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'maps,',\n",
              "   'Automated',\n",
              "   'Cartography,',\n",
              "   'Spiral',\n",
              "   'Trees'],\n",
              "  'MultipartiteRank': [{'score': 0.23922716402263983, 'word': 'maps'},\n",
              "   {'score': 0.16587716741695688, 'word': 'flow'},\n",
              "   {'score': 0.07334999660568294, 'word': 'thematic'},\n",
              "   {'score': 0.05046280425460781, 'word': 'several'},\n",
              "   {'score': 0.05046280425460781, 'word': 'targets'},\n",
              "   {'score': 0.04600371397428069, 'word': 'lines'},\n",
              "   {'score': 0.03958584227954145, 'word': 'movement'}],\n",
              "  'Title': 'Flow Map Layout via Spiral Trees',\n",
              "  'distance': 0,\n",
              "  'no': '350',\n",
              "  'parent': '3979'},\n",
              " {'Abstract': 'Interactive techniques are powerful tools for manipulating visualizations to analyze, communicate and acquire information. This is especially true for large data sets or complex 3D visualizations. Although many new types of interaction have been introduced recently, very little work has been done on understanding what their components are, how they are related and how they can be combined. This paper begins to address these issues with a framework for classifying interactive visualizations. Our goal is a framework that will enable us to develop toolkits for assembling visualization interfaces both interactively and automatically.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'interactive',\n",
              "   'techniques,',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'automatic',\n",
              "   'presentation',\n",
              "   'systems,',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.1500993706153166, 'word': 'visualizations'},\n",
              "   {'score': 0.14698141619163682, 'word': 'interactive'},\n",
              "   {'score': 0.14698141619163682, 'word': 'techniques'},\n",
              "   {'score': 0.11085238391797123, 'word': 'powerful'},\n",
              "   {'score': 0.11085238391797123, 'word': 'tools'},\n",
              "   {'score': 0.05914179194339156, 'word': 'large'},\n",
              "   {'score': 0.05914179194339156, 'word': 'data'},\n",
              "   {'score': 0.05914179194339156, 'word': 'sets'},\n",
              "   {'score': 0.05800579465477505, 'word': 'framework'}],\n",
              "  'Title': 'On the semantics of interactive visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '351',\n",
              "  'parent': '3785'},\n",
              " {'Abstract': 'Transfer function design is an integrated component in volume visualization and data exploration. The common trial-and-error approach for transfer function searching is a very difficult and time consuming process. A goal oriented and parameterized transfer function model is therefore crucial in guiding the transfer function searching process for better and more meaningful visualization results. The paper presents an image based transfer function model that integrates 3D image processing tools into the volume visualization pipeline to facilitate the search for an image based transfer function in volume data visualization and exploration. The model defines a transfer function as a sequence of 3D image processing procedures, and allows the users to adjust a set of qualitative and descriptive parameters to achieve their subjective visualization goals. 3D image enhancement and boundary detection tools, and their integration methods with volume visualization algorithms are described. The application of this approach for 3D microscopy data exploration and analysis is also discussed.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'visualization,',\n",
              "   '3D',\n",
              "   'image',\n",
              "   'processing,',\n",
              "   'transfer',\n",
              "   'function,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'data',\n",
              "   'exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.18973968912287603, 'word': 'transfer'},\n",
              "   {'score': 0.18973968912287603, 'word': 'function'},\n",
              "   {'score': 0.18973968912287603, 'word': 'design'},\n",
              "   {'score': 0.08232235749763513, 'word': 'volume'},\n",
              "   {'score': 0.08232235749763513, 'word': 'visualization'},\n",
              "   {'score': 0.07429523612732848, 'word': 'integrated'},\n",
              "   {'score': 0.07429523612732848, 'word': 'component'},\n",
              "   {'score': 0.061203019838686, 'word': 'data'},\n",
              "   {'score': 0.061203019838686, 'word': 'exploration'},\n",
              "   {'score': 0.05021971525617755, 'word': 'image'}],\n",
              "  'Title': 'Image-based transfer function design for data exploration in volume visualization',\n",
              "  'distance': 0,\n",
              "  'no': '352',\n",
              "  'parent': '4886'},\n",
              " {'Abstract': 'The discrete nature of categorical data makes it a particular challenge for visualization. Methods that work very well for continuous data are often hardly usable with categorical dimensions. Only few methods deal properly with such data, mostly because of the discrete nature of categorical data, which does not translate well into the continuous domains of space and color. Parallel sets is a new visualization method that adopts the layout of parallel coordinates, but substitutes the individual data points by a frequency based representation. This abstracted view, combined with a set of carefully designed interactions, supports visual data analysis of large and complex data sets. The technique allows efficient work with meta data, which is particularly important when dealing with categorical datasets. By creating new dimensions from existing ones, for example, the user can filter the data according to his or her current needs. We also present the results from an interactive analysis of CRM data using parallel sets. We demonstrate how the flexible layout eases the process of knowledge crystallization, especially when combined with a sophisticated interaction scheme.',\n",
              "  'AuthorKeywords': ['categorical',\n",
              "   'data,',\n",
              "   'meta',\n",
              "   'information,',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.11649577781367186, 'word': 'categorical'},\n",
              "   {'score': 0.11649577781367186, 'word': 'data'},\n",
              "   {'score': 0.05960137347764298, 'word': 'parallel'},\n",
              "   {'score': 0.05960137347764298, 'word': 'sets'},\n",
              "   {'score': 0.0542358906687555, 'word': 'discrete'},\n",
              "   {'score': 0.0542358906687555, 'word': 'nature'},\n",
              "   {'score': 0.050801511064787176, 'word': 'visualization'},\n",
              "   {'score': 0.048793359437002276, 'word': 'methods'}],\n",
              "  'Title': 'Parallel sets: visual analysis of categorical data',\n",
              "  'distance': 0,\n",
              "  'no': '353',\n",
              "  'parent': '5803'},\n",
              " {'Abstract': 'Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.',\n",
              "  'AuthorKeywords': ['Gender',\n",
              "   'differences,',\n",
              "   'orthogonal',\n",
              "   'projections,',\n",
              "   'spatial',\n",
              "   'ability,',\n",
              "   'standardized',\n",
              "   'testing'],\n",
              "  'MultipartiteRank': [{'score': 0.0901840661460203, 'word': 'spatial'},\n",
              "   {'score': 0.0901840661460203, 'word': 'ability'},\n",
              "   {'score': 0.0901840661460203, 'word': 'differences'},\n",
              "   {'score': 0.08130046621847209, 'word': 'information'},\n",
              "   {'score': 0.08130046621847209, 'word': 'visualizations'},\n",
              "   {'score': 0.06634717630603633, 'word': 'comprehension'},\n",
              "   {'score': 0.04842538568188826, 'word': 'paper'},\n",
              "   {'score': 0.045932336281242596, 'word': 'goal'}],\n",
              "  'Title': 'Understanding visualization through spatial ability differences',\n",
              "  'distance': 0,\n",
              "  'no': '354',\n",
              "  'parent': '5683'},\n",
              " {'Abstract': 'A common goal of multivariate visualization is to enable data inspection at discrete points, while also illustrating larger-scale continuous structures. In diffusion tensor visualization, glyphs are typically used to meet the first goal, and methods such as texture synthesis or fiber tractography can address the second. We adapt particle systems originally developed for surface modeling and anisotropic mesh generation to enhance the utility of glyph-based tensor visualizations. By carefully distributing glyphs throughout the field (either on a slice, or in the volume) into a dense packing, using potential energy profiles shaped by the local tensor value, we remove undue visual emphasis of the regular sampling grid of the data, and the underlying continuous features become more apparent. The method is demonstrated on a DT-MRI scan of a patient with a brain tumor',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'tensor,',\n",
              "   'glyphs,',\n",
              "   'particle',\n",
              "   'systems,',\n",
              "   'anisotropic',\n",
              "   'sampling,',\n",
              "   'fiber',\n",
              "   'tractography'],\n",
              "  'MultipartiteRank': [{'score': 0.09934278365929988, 'word': 'multivariate'},\n",
              "   {'score': 0.09934278365929988, 'word': 'visualization'},\n",
              "   {'score': 0.07460228514762647, 'word': 'common'},\n",
              "   {'score': 0.07460228514762647, 'word': 'goal'},\n",
              "   {'score': 0.06698152677233614, 'word': 'glyphs'},\n",
              "   {'score': 0.06431377586978802, 'word': 'data'},\n",
              "   {'score': 0.06431377586978802, 'word': 'inspection'},\n",
              "   {'score': 0.043143257148682265, 'word': 'discrete'},\n",
              "   {'score': 0.043143257148682265, 'word': 'points'}],\n",
              "  'Title': 'Diffusion Tensor Visualization with Glyph Packing',\n",
              "  'distance': 0,\n",
              "  'no': '355',\n",
              "  'parent': '4189'},\n",
              " {'Abstract': 'Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eye-tracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator',\n",
              "  'AuthorKeywords': ['Saliency,',\n",
              "   'visual',\n",
              "   'attention,',\n",
              "   'perceptual',\n",
              "   'enhancement,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'non-photorealistic',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.17609691011505263, 'word': 'saliency'},\n",
              "   {'score': 0.10790595273218605, 'word': 'visual'},\n",
              "   {'score': 0.0636977324924775, 'word': 'operator'},\n",
              "   {'score': 0.05903825477653229, 'word': 'regions'},\n",
              "   {'score': 0.052025938997514905, 'word': 'user'}],\n",
              "  'Title': 'Saliency-guided Enhancement for Volume Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '356',\n",
              "  'parent': '4148'},\n",
              " {'Abstract': \"People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.\",\n",
              "  'AuthorKeywords': ['Bayesian',\n",
              "   'reasoning,',\n",
              "   'base',\n",
              "   'rate',\n",
              "   'fallacy,',\n",
              "   'probabilistic',\n",
              "   'judgment,',\n",
              "   'Euler',\n",
              "   'diagrams,',\n",
              "   'glyphs,',\n",
              "   'crowdsourcing'],\n",
              "  'MultipartiteRank': [{'score': 0.08905365987722541, 'word': 'visual'},\n",
              "   {'score': 0.08905365987722541, 'word': 'representations'},\n",
              "   {'score': 0.06664879179583544, 'word': 'psychology'},\n",
              "   {'score': 0.06664879179583544, 'word': 'studies'},\n",
              "   {'score': 0.06366165449830098, 'word': 'visualizations'},\n",
              "   {'score': 0.042869679214014515, 'word': 'diverse'},\n",
              "   {'score': 0.042869679214014515, 'word': 'subject'},\n",
              "   {'score': 0.042869679214014515, 'word': 'pool'},\n",
              "   {'score': 0.03901913635942047, 'word': 'way'},\n",
              "   {'score': 0.03901913635942047, 'word': 'bayesian'},\n",
              "   {'score': 0.03901913635942047, 'word': 'problems'}],\n",
              "  'Title': 'Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing',\n",
              "  'distance': 0,\n",
              "  'no': '357',\n",
              "  'parent': '4646'},\n",
              " {'Abstract': 'Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure \"data-flow\". This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15680593979857585, 'word': 'flow'},\n",
              "   {'score': 0.14378564964077883, 'word': 'execution'},\n",
              "   {'score': 0.14378564964077883, 'word': 'model'},\n",
              "   {'score': 0.11429310401461464, 'word': 'data'},\n",
              "   {'score': 0.06551027732225245, 'word': 'systems'},\n",
              "   {'score': 0.052772039983442445, 'word': 'simplistic'},\n",
              "   {'score': 0.052772039983442445, 'word': 'implementations'}],\n",
              "  'Title': 'An extended data-flow architecture for data analysis and visualization',\n",
              "  'distance': 0,\n",
              "  'no': '358',\n",
              "  'parent': '3895'},\n",
              " {'Abstract': 'Multilevel representations and mesh reduction techniques have been used for accelerating the processing and the rendering of large datasets representing scalar- or vector-valued functions defined on complex 2D or 3D meshes. We present a method based on finite element approximations which combines these two approaches in a new and unique way that is conceptually simple and theoretically sound. The main idea is to consider mesh reduction as an approximation problem in appropriate finite element spaces. Starting with a very coarse triangulation of the functional domain, a hierarchy of highly non-uniform tetrahedral (or triangular in 2D) meshes is generated adaptively by local refinement. This process is driven by controlling the local error of the piecewise linear finite element approximation of the function on each mesh element. A reliable and efficient computation of the global approximation error and a multilevel preconditioned conjugate gradient solver are the key components of the implementation. In order to analyze the properties and advantages of the adaptively generated tetrahedral meshes, we implemented two volume visualization algorithms: an iso-surface extractor and a ray-caster. Both algorithms, while conceptually simple, show significant speedups over conventional methods delivering comparable rendering quality from adaptively compressed datasets.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06745982427153205, 'word': '3d'},\n",
              "   {'score': 0.06745982427153205, 'word': 'meshes'},\n",
              "   {'score': 0.04721280536108221, 'word': 'functions'},\n",
              "   {'score': 0.046662153534852376, 'word': 'finite'},\n",
              "   {'score': 0.046662153534852376, 'word': 'element'},\n",
              "   {'score': 0.046662153534852376, 'word': 'approximations'},\n",
              "   {'score': 0.04241529199106539, 'word': 'multilevel'},\n",
              "   {'score': 0.04241529199106539, 'word': 'representations'},\n",
              "   {'score': 0.03401609861409026, 'word': 'method'}],\n",
              "  'Title': 'The multilevel finite element method for adaptive mesh optimization and visualization of volume data',\n",
              "  'distance': 0,\n",
              "  'no': '359',\n",
              "  'parent': '4178'},\n",
              " {'Abstract': 'Unlike traditional information visualization, ambient information visualizations reside in the environment of the user rather than on the screen of a desktop computer. Currently, most dynamic information that is displayed in public places consists of text and numbers. We argue that information visualization can be employed to make such dynamic data more useful and appealing. However, visualizations intended for non-desktop spaces will have to both provide valuable information and present an attractive addition to the environment - they must strike a balance between aesthetical appeal and usefulness. To explore this, we designed a real-time visualization of bus departure times and deployed it in a public space, with about 300 potential users. To make the presentation more visually appealing, we took inspiration from a modern abstract artist. The visualization was designed in two passes. First, we did a preliminary version that was presented to and discussed with prospective users. Based on their input, we did a final design. We discuss the lessons learned in designing this and previous ambient information visualizations, including how visual art can be used as a design constraint, and how the choice of information and the placement of the display affect the visualization.',\n",
              "  'AuthorKeywords': ['Ambient',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'informative',\n",
              "   'art,',\n",
              "   'ambient',\n",
              "   'displays,',\n",
              "   'calm',\n",
              "   'technology'],\n",
              "  'MultipartiteRank': [{'score': 0.11475498516752072, 'word': 'traditional'},\n",
              "   {'score': 0.11475498516752072, 'word': 'information'},\n",
              "   {'score': 0.11475498516752072, 'word': 'visualization'},\n",
              "   {'score': 0.06849240971853947, 'word': 'visualizations'},\n",
              "   {'score': 0.05918375330391051, 'word': 'user'},\n",
              "   {'score': 0.055563013748582475, 'word': 'appealing'},\n",
              "   {'score': 0.055255514857726125, 'word': 'environment'}],\n",
              "  'Title': 'Between aesthetics and utility: designing ambient information visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '360',\n",
              "  'parent': '4488'},\n",
              " {'Abstract': 'Large financial institutions such as Bank of America handle hundreds of thousands of wire transactions per day. Although most transactions are legitimate, these institutions have legal and financial obligations in discovering those that are suspicious. With the methods of fraudulent activities ever changing, searching on predefined patterns is often insufficient in detecting previously undiscovered methods. In this paper, we present a set of coordinated visualizations based on identifying specific keywords within the wire transactions. The different views used in our system depict relationships among keywords and accounts over time. Furthermore, we introduce a search-by-example technique which extracts accounts that show similar transaction patterns. In collaboration with the Anti-Money Laundering division at Bank of America, we demonstrate that using our tool, investigators are able to detect accounts and transactions that exhibit suspicious behaviors.',\n",
              "  'AuthorKeywords': ['Fraud',\n",
              "   'detection,',\n",
              "   'financial',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'categorial',\n",
              "   'and',\n",
              "   'time-varying',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.08666227100455445, 'word': 'wire'},\n",
              "   {'score': 0.08666227100455445, 'word': 'transactions'},\n",
              "   {'score': 0.04881907565319525, 'word': 'methods'},\n",
              "   {'score': 0.04469483123933658, 'word': 'specific'},\n",
              "   {'score': 0.04469483123933658, 'word': 'keywords'},\n",
              "   {'score': 0.04347613011608046, 'word': 'america'},\n",
              "   {'score': 0.0382904293022813, 'word': 'bank'}],\n",
              "  'Title': 'WireVis: Visualization of Categorical, Time-Varying Data From Financial Transactions',\n",
              "  'distance': 0,\n",
              "  'no': '361',\n",
              "  'parent': '4098'},\n",
              " {'Abstract': \"The process of visualization can be seen as a visual communication channel where the input to the channel is the raw data, and the output is the result of a visualization algorithm. From this point of view, we can evaluate the effectiveness of visualization by measuring how much information in the original data is being communicated through the visual communication channel. In this paper, we present an information-theoretic framework for flow visualization with a special focus on streamline generation. In our framework, a vector field is modeled as a distribution of directions from which Shannon's entropy is used to measure the information content in the field. The effectiveness of the streamlines displayed in visualization can be measured by first constructing a new distribution of vectors derived from the existing streamlines, and then comparing this distribution with that of the original data set using the conditional entropy. The conditional entropy between these two distributions indicates how much information in the original data remains hidden after the selected streamlines are displayed. The quality of the visualization can be improved by progressively introducing new streamlines until the conditional entropy converges to a small value. We describe the key components of our framework with detailed analysis, and show that the framework can effectively visualize 2D and 3D flow data.\",\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'information',\n",
              "   'theory,',\n",
              "   'streamline',\n",
              "   'generation'],\n",
              "  'MultipartiteRank': [{'score': 0.08439142960684022, 'word': 'visualization'},\n",
              "   {'score': 0.055986544268958945, 'word': 'streamline'},\n",
              "   {'score': 0.055986544268958945, 'word': 'generation'},\n",
              "   {'score': 0.05565356979487632, 'word': 'much'},\n",
              "   {'score': 0.05565356979487632, 'word': 'information'},\n",
              "   {'score': 0.05082115844843242, 'word': 'raw'},\n",
              "   {'score': 0.05082115844843242, 'word': 'data'},\n",
              "   {'score': 0.05032783022307739, 'word': 'theoretic'},\n",
              "   {'score': 0.05032783022307739, 'word': 'framework'}],\n",
              "  'Title': 'An Information-Theoretic Framework for Flow Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '362',\n",
              "  'parent': '5787'},\n",
              " {'Abstract': 'In this paper we address the difficult problem of parameter-finding in image segmentation. We replace a tedious manual process that is often based on guess-work and luck by a principled approach that systematically explores the parameter space. Our core idea is the following two-stage technique: We start with a sparse sampling of the parameter space and apply a statistical model to estimate the response of the segmentation algorithm. The statistical model incorporates a model of uncertainty of the estimation which we use in conjunction with the actual estimate in (visually) guiding the user towards areas that need refinement by placing additional sample points. In the second stage the user navigates through the parameter space in order to determine areas where the response value (goodness of segmentation) is high. In our exploration we rely on existing ground-truth images in order to evaluate the \"goodness\" of an image segmentation technique. We evaluate its usefulness by demonstrating this technique on two image segmentation algorithms: a three parameter model to detect microtubules in electron tomograms and an eight parameter model to identify functional regions in dynamic Positron Emission Tomography scans.',\n",
              "  'AuthorKeywords': ['Parameter',\n",
              "   'exploration,',\n",
              "   'Image',\n",
              "   'segmentation,',\n",
              "   'Gaussian',\n",
              "   'Process',\n",
              "   'Model'],\n",
              "  'MultipartiteRank': [{'score': 0.12024467060958897, 'word': 'parameter'},\n",
              "   {'score': 0.0779256334874608, 'word': 'image'},\n",
              "   {'score': 0.0779256334874608, 'word': 'segmentation'},\n",
              "   {'score': 0.05681529029591022, 'word': 'statistical'},\n",
              "   {'score': 0.05681529029591022, 'word': 'model'},\n",
              "   {'score': 0.04602747400644089, 'word': 'finding'},\n",
              "   {'score': 0.04071655919633044, 'word': 'space'}],\n",
              "  'Title': 'Tuner: Principled Parameter finding for Image Segmentation Algorithms Using Visual Response Surface Exploration',\n",
              "  'distance': 0,\n",
              "  'no': '363',\n",
              "  'parent': '4762'},\n",
              " {'Abstract': 'Visualization has proved an efficient tool in the understanding of large data sets in computational science and engineering. There is growing interest today in the development of problem solving environments which integrate both visualization and the computational process which generates the data. The GRASPARC project has looked at some of the issues involved in creating such an environment. An architecture is proposed in which tools for computation and visualization can be embedded in a framework which assists in the management of the problem solving process. This framework has an integral data management facility which allows an audit trail of the experiments to be recorded. This design therefore allows not only steering but also backtracking and more complicated problem solving strategies. A number of demonstrator case studies have been implemented.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09101925544273755, 'word': 'computational'},\n",
              "   {'score': 0.09101925544273755, 'word': 'science'},\n",
              "   {'score': 0.07263404069102707, 'word': 'large'},\n",
              "   {'score': 0.07263404069102707, 'word': 'data'},\n",
              "   {'score': 0.07263404069102707, 'word': 'sets'},\n",
              "   {'score': 0.07243267606741624, 'word': 'problem'},\n",
              "   {'score': 0.06758963289231756, 'word': 'visualization'},\n",
              "   {'score': 0.05660816872211959, 'word': 'efficient'},\n",
              "   {'score': 0.05660816872211959, 'word': 'tool'}],\n",
              "  'Title': 'GRASPARC-A problem solving environment integrating computation and visualization',\n",
              "  'distance': 0,\n",
              "  'no': '364',\n",
              "  'parent': '3897'},\n",
              " {'Abstract': 'This paper describes initial results of a 3D field topology analysis for automating transfer function design aiming at comprehensible volume rendering. The conventional Reeb graph-based approach to describing topological features of 3D surfaces is extended to capture the topological skeleton of a volumetric field. Based on the analysis result, which is represented in the form of a hyper Reeb graph, a procedure is proposed for designing appropriate color/opacity transfer functions. Two analytic volume datasets are used to preliminarily prove the feasibility of the present design methodology.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08916330125000513, 'word': 'initial'},\n",
              "   {'score': 0.08916330125000513, 'word': 'results'},\n",
              "   {'score': 0.08659200919592425, 'word': 'transfer'},\n",
              "   {'score': 0.08659200919592425, 'word': 'function'},\n",
              "   {'score': 0.08659200919592425, 'word': 'design'},\n",
              "   {'score': 0.08603583534551296, 'word': 'topological'},\n",
              "   {'score': 0.08603583534551296, 'word': 'features'},\n",
              "   {'score': 0.0844376185679058, 'word': 'conventional'},\n",
              "   {'score': 0.0844376185679058, 'word': 'reeb'},\n",
              "   {'score': 0.0844376185679058, 'word': 'graph'},\n",
              "   {'score': 0.06390437628798624, 'word': '3d'},\n",
              "   {'score': 0.06390437628798624, 'word': 'field'},\n",
              "   {'score': 0.06390437628798624, 'word': 'topology'},\n",
              "   {'score': 0.06390437628798624, 'word': 'analysis'}],\n",
              "  'Title': 'Automating transfer function design for comprehensible volume rendering based on 3D field topology analysis',\n",
              "  'distance': 0,\n",
              "  'no': '365',\n",
              "  'parent': '3715'},\n",
              " {'Abstract': 'In Web data, telecommunications traffic and in epidemiological studies, dense subgraphs correspond to subsets of subjects (i.e. users, patients) that share a collection of attributes values (i.e. accessed Web pages, email-calling patterns or disease diagnostic profiles). Visual and computational identification of these \"clusters\" becomes useful when domain experts desire to determine those factors of major influence in the formation of access and communication clusters or in the detection and contention of disease spread. With the current increases in graphic hardware capabilities and RAM sizes, it is more useful to relate graph sizes to the available screen real estate S and the amount of available RAM M, instead of the number of edges or nodes in the graph. We offer a visual interface that is parameterized by M and S and is particularly suited for navigation tasks that require the identification of subgraphs whose edge density is above certain threshold. This is achieved by providing a zoomable matrix view of the underlying data. This view is strongly coupled to a hierarchical view of the essential information elements present in the data domain. We illustrate the applicability of this work to the visual navigation of cancer incidence data and to an aggregated sample of phone call traffic',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'Visualization,',\n",
              "   'Hierarchy',\n",
              "   'Trees,',\n",
              "   'Clustering,',\n",
              "   'External',\n",
              "   'Memory',\n",
              "   'Algorithms,',\n",
              "   'Cancer',\n",
              "   'Data,',\n",
              "   'Phone',\n",
              "   'Traffic'],\n",
              "  'MultipartiteRank': [{'score': 0.051431020471564316, 'word': 'web'},\n",
              "   {'score': 0.051431020471564316, 'word': 'data'},\n",
              "   {'score': 0.03858030721842234, 'word': 'visual'},\n",
              "   {'score': 0.03585801804462537, 'word': 'clusters'},\n",
              "   {'score': 0.033802873153255794, 'word': 'useful'},\n",
              "   {'score': 0.03375856774347099, 'word': 'dense'},\n",
              "   {'score': 0.03375856774347099, 'word': 'subgraphs'}],\n",
              "  'Title': 'Matrix Zoom: A Visual Interface to Semi-External Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '366',\n",
              "  'parent': '4952'},\n",
              " {'Abstract': 'Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.',\n",
              "  'AuthorKeywords': ['Parameter',\n",
              "   'space',\n",
              "   'analysis,',\n",
              "   'input-output',\n",
              "   'model,',\n",
              "   'simulation,',\n",
              "   'task',\n",
              "   'characterization,',\n",
              "   'literature',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.13615007958195774, 'word': 'framework'},\n",
              "   {'score': 0.1159535959604501, 'word': 'visual'},\n",
              "   {'score': 0.1159535959604501, 'word': 'parameter'},\n",
              "   {'score': 0.1159535959604501, 'word': 'space'},\n",
              "   {'score': 0.1159535959604501, 'word': 'analysis'},\n",
              "   {'score': 0.08369590157642866, 'word': 'conceptual'},\n",
              "   {'score': 0.06985108977418693, 'word': 'research'},\n",
              "   {'score': 0.06985108977418693, 'word': 'endeavors'},\n",
              "   {'score': 0.04536519223588788, 'word': 'different'},\n",
              "   {'score': 0.04536519223588788, 'word': 'application'},\n",
              "   {'score': 0.04536519223588788, 'word': 'domains'}],\n",
              "  'Title': 'Visual Parameter Space Analysis: A Conceptual Framework',\n",
              "  'distance': 0,\n",
              "  'no': '367',\n",
              "  'parent': '4865'},\n",
              " {'Abstract': 'Spot noise is a technique for texture synthesis, which is very useful for vector field visualization. This paper describes improvements and extensions of the basic principle of spot noise. First, better visualization of highly curved vector fields with spot noise is achieved, by adapting the shape of the spots to the local velocity field. Second, filtering of spots is proposed to eliminate undesired low frequency components from the spot noise texture. Third, methods are described to utilize graphics hardware to generate the texture, and to produce variable viewpoint animations of spot noise on surfaces. Fourth, the synthesis of spot noise on grids with highly irregular cell sizes is described.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.20842635242083898, 'word': 'spot'},\n",
              "   {'score': 0.20842635242083898, 'word': 'noise'},\n",
              "   {'score': 0.0619183693706859, 'word': 'vector'},\n",
              "   {'score': 0.0619183693706859, 'word': 'field'},\n",
              "   {'score': 0.0619183693706859, 'word': 'visualization'},\n",
              "   {'score': 0.05074713849431993, 'word': 'texture'},\n",
              "   {'score': 0.05074713849431993, 'word': 'synthesis'},\n",
              "   {'score': 0.037294901804960076, 'word': 'improvements'},\n",
              "   {'score': 0.03654893107374401, 'word': 'paper'}],\n",
              "  'Title': 'Enhanced spot noise for vector field visualization',\n",
              "  'distance': 0,\n",
              "  'no': '368',\n",
              "  'parent': '3941'},\n",
              " {'Abstract': \"With the development of magnetic resonance imaging techniques for acquiring diffusion tensor data from biological tissue, visualization of tensor data has become a new research focus. The diffusion tensor describes the directional dependence of water molecules' diffusion and can be represented by a three-by-three symmetric matrix. Visualization of second-order tensor fields is difficult because the data values have many degrees of freedom. Existing visualization techniques are best at portraying the tensor's properties over a two-dimensional field, or over a small subset of locations within a three-dimensional field. A means of visualizing the global structure in measured diffusion tensor data is needed. We propose the use of direct volume rendering, with novel approaches for the tensors' coloring, lighting, and opacity assignment. Hue-balls use a two-dimensional colormap on the unit sphere to illustrate the tensor's action as a linear operator. Lit-tensors provide a lighting model for tensors which includes as special cases both lit-lines (from streamline vector visualization) and standard Phong surface lighting. Together with an opacity assignment based on a novel two-dimensional barycentric space of anisotropy, these methods are shown to produce informative renderings of measured diffusion tensor data from the human brain.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.16481196417159175, 'word': 'tensor'},\n",
              "   {'score': 0.11614389711289917, 'word': 'diffusion'},\n",
              "   {'score': 0.11614389711289917, 'word': 'data'},\n",
              "   {'score': 0.05928284921055254, 'word': 'visualization'},\n",
              "   {'score': 0.03600374164290845, 'word': 'dimensional'},\n",
              "   {'score': 0.03600374164290845, 'word': 'field'},\n",
              "   {'score': 0.028413226187576905, 'word': 'biological'},\n",
              "   {'score': 0.028413226187576905, 'word': 'tissue'}],\n",
              "  'Title': 'Hue-balls and lit-tensors for direct volume rendering of diffusion tensor fields',\n",
              "  'distance': 0,\n",
              "  'no': '369',\n",
              "  'parent': '4447'},\n",
              " {'Abstract': 'We present a new technique which enables direct volume rendering based on 3D texture mapping hardware, enabling shading as well as classification of the interpolated data. Our technique supports accurate lighting for a one directional light source, semi-transparent classification, and correct blending. To circumvent the limitations of one general classification, we introduce multiple classification spaces which are very valuable to understand the visualized data, and even mandatory to comprehensively grasp the 3D relationship of different materials present in the volumetric data. Furthermore, we illustrate how multiple classification spaces can be realized using existing graphics hardware. In contrast to previously reported algorithms, our technique is capable of performing all the above mentioned tasks within the graphics pipeline. Therefore, it is very efficient: The three dimensional texture needs to be stored only once and no load is put onto the CPU. Besides using standard OpenGL functionality, we exploit advanced per pixel operations and make use of available OpenGL extensions.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   '3D',\n",
              "   'Texture',\n",
              "   'Mapping,',\n",
              "   'Rectilinear',\n",
              "   'Grid,',\n",
              "   'Shading,',\n",
              "   'Classification,',\n",
              "   'OpenGL'],\n",
              "  'MultipartiteRank': [{'score': 0.14092008941035278, 'word': 'technique'},\n",
              "   {'score': 0.089925295794244, 'word': 'new'},\n",
              "   {'score': 0.07840474006703499, 'word': 'classification'},\n",
              "   {'score': 0.07030656773518507, 'word': 'data'},\n",
              "   {'score': 0.045063652036077775, 'word': 'direct'},\n",
              "   {'score': 0.045063652036077775, 'word': 'volume'}],\n",
              "  'Title': 'Enabling Classification and Shading for 3D Texture Mapping based Volume Rendering using OpenGL and Extensions',\n",
              "  'distance': 0,\n",
              "  'no': '370',\n",
              "  'parent': '4614'},\n",
              " {'Abstract': 'Visualization of topological information of a vector field can provide useful information on the structure of the field. However, in turbulent flows standard critical point visualization will result in a cluttered image which is difficult to interpret. This paper presents a technique for collapsing topologies. The governing idea is to classify the importance of the critical points in the topology. By only displaying the more important critical points, a simplified depiction of the topology can be provided. Flow consistency is maintained when collapsing the topology, resulting in a visualization which is consistent with the original topology. We apply the collapsing topology technique to a turbulent flow field.',\n",
              "  'AuthorKeywords': ['multi-level',\n",
              "   'visualization',\n",
              "   'techniques,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'flow',\n",
              "   'topology'],\n",
              "  'MultipartiteRank': [{'score': 0.15250699977506005, 'word': 'visualization'},\n",
              "   {'score': 0.14827166145312215, 'word': 'topological'},\n",
              "   {'score': 0.14827166145312215, 'word': 'information'},\n",
              "   {'score': 0.09001635334177502, 'word': 'vector'},\n",
              "   {'score': 0.09001635334177502, 'word': 'field'},\n",
              "   {'score': 0.07593530314161004, 'word': 'standard'},\n",
              "   {'score': 0.07593530314161004, 'word': 'critical'},\n",
              "   {'score': 0.07593530314161004, 'word': 'point'},\n",
              "   {'score': 0.064121660196518, 'word': 'topologies'}],\n",
              "  'Title': 'Collapsing Flow Topology Using Area Metrics',\n",
              "  'distance': 0,\n",
              "  'no': '371',\n",
              "  'parent': '3698'},\n",
              " {'Abstract': 'The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.',\n",
              "  'AuthorKeywords': ['Simplicial',\n",
              "   'Complexes,',\n",
              "   'Mesh',\n",
              "   'Simplification,Volume',\n",
              "   'Visualization,',\n",
              "   'Unstructured',\n",
              "   'Grids'],\n",
              "  'MultipartiteRank': [{'score': 0.06739402845516783, 'word': 'techniques'},\n",
              "   {'score': 0.059228446236754176, 'word': 'geometrical'},\n",
              "   {'score': 0.05802657663580689, 'word': 'topological'},\n",
              "   {'score': 0.05802657663580689, 'word': 'shape'},\n",
              "   {'score': 0.05396748239612645, 'word': 'scalar'},\n",
              "   {'score': 0.05396748239612645, 'word': 'field'},\n",
              "   {'score': 0.05157170649938923, 'word': 'volume'}],\n",
              "  'Title': 'Simplification of tetrahedral meshes with accurate error evaluation',\n",
              "  'distance': 0,\n",
              "  'no': '372',\n",
              "  'parent': '4398'},\n",
              " {'Abstract': 'Presents a new rendering technique for processing multiple multi-resolution textures of LOD (level-of-detail) terrain models and describes its application to interactive, animated terrain content design. The approach is based on a multi-resolution model for terrain texture which cooperates with a multi-resolution model for terrain geometry. For each texture layer, an image pyramid and a texture tree are constructed. Multiple texture layers can be associated with one terrain model and can be combined in different ways, e.g. by blending and masking. The rendering algorithm simultaneously traverses the multi-resolution geometry model and the multi-resolution texture model, and takes into account geometric and texture approximation errors. It uses multi-pass rendering and exploits multi-texturing to achieve real-time performance. Applications include interactive texture lenses, texture animation and topographic textures. These techniques offer an enormous potential for developing new visualization applications for presenting, exploring and manipulating spatio-temporal data.',\n",
              "  'AuthorKeywords': ['Terrain',\n",
              "   'Rendering,',\n",
              "   'Texture',\n",
              "   'Mapping,',\n",
              "   'Multiresolution,',\n",
              "   'Level',\n",
              "   'of',\n",
              "   'Detail,',\n",
              "   '3D',\n",
              "   'Maps'],\n",
              "  'MultipartiteRank': [{'score': 0.09844122196551983, 'word': 'texture'},\n",
              "   {'score': 0.09844122196551983, 'word': 'layer'},\n",
              "   {'score': 0.09819112617671297, 'word': 'terrain'},\n",
              "   {'score': 0.09819112617671297, 'word': 'models'},\n",
              "   {'score': 0.06755414568506622, 'word': 'application'},\n",
              "   {'score': 0.05565963906445501, 'word': 'new'},\n",
              "   {'score': 0.05565963906445501, 'word': 'rendering'},\n",
              "   {'score': 0.05565963906445501, 'word': 'technique'},\n",
              "   {'score': 0.043750136051658145, 'word': 'image'},\n",
              "   {'score': 0.043750136051658145, 'word': 'pyramid'}],\n",
              "  'Title': 'Texturing techniques for terrain visualization',\n",
              "  'distance': 0,\n",
              "  'no': '373',\n",
              "  'parent': '4123'},\n",
              " {'Abstract': 'A new method for visualizing the class of incrementally evolving networks is presented. In addition to the intermediate states of the network it conveys the nature of the change between them by unrolling the dynamics of the network. Each modification is shown in a separate layer of a three-dimensional representation, where the stack of layers corresponds to a time line of the evolution. We focus on discourse networks as the driving application, but our method extends to any type of network evolving in similar ways.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.16640590375998274, 'word': 'networks'},\n",
              "   {'score': 0.07593462617696613, 'word': 'new'},\n",
              "   {'score': 0.07593462617696613, 'word': 'method'},\n",
              "   {'score': 0.07008209695386315, 'word': 'separate'},\n",
              "   {'score': 0.07008209695386315, 'word': 'layer'},\n",
              "   {'score': 0.04897393311290836, 'word': 'intermediate'},\n",
              "   {'score': 0.04897393311290836, 'word': 'states'},\n",
              "   {'score': 0.04596031102635572, 'word': 'nature'}],\n",
              "  'Title': 'Visual unrolling of network evolution and the analysis of dynamic discourse',\n",
              "  'distance': 0,\n",
              "  'no': '374',\n",
              "  'parent': '3466'},\n",
              " {'Abstract': 'Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focus+context radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'focus+context,',\n",
              "   'radial',\n",
              "   'graph',\n",
              "   'layout,',\n",
              "   'graph',\n",
              "   'drawing'],\n",
              "  'MultipartiteRank': [{'score': 0.10081111147259637, 'word': 'tree'},\n",
              "   {'score': 0.10081111147259637, 'word': 'visualization'},\n",
              "   {'score': 0.10081111147259637, 'word': 'techniques'},\n",
              "   {'score': 0.0816039581776735, 'word': 'node'},\n",
              "   {'score': 0.07694628346122505, 'word': 'interactive'},\n",
              "   {'score': 0.07694628346122505, 'word': 'exploration'},\n",
              "   {'score': 0.06513497685818984, 'word': 'graph'},\n",
              "   {'score': 0.052976278645140706, 'word': 'moiregraphs'}],\n",
              "  'Title': 'MoireGraphs: radial focus+context visualization and interaction for graphs with visual nodes',\n",
              "  'distance': 0,\n",
              "  'no': '375',\n",
              "  'parent': '3560'},\n",
              " {'Abstract': 'Multiperspective images are a useful way to visualize extended, roughly planar scenes such as landscapes or city blocks. However, constructing effective multiperspective images is something of an art. We describe an interactive system for creating multiperspective images composed of serially blended cross-slits images. Beginning with a sideways-looking video of the scene as might be captured from a moving vehicle, we allow the user to interactively specify a set of cross-slits cameras, possibly with gaps between them. In each camera, one of the slits is defined to be the camera path, which is typically horizontal, and the user is left to choose the second slit, which is typically vertical. The system then generates intermediate views between these cameras using a novel interpolation scheme, thereby producing a multiperspective image with no seams. The user can also choose the picture surface in space onto which viewing rays are projected, thereby establishing a parameterization for the image. We show how the choice of this surface can be used to create interesting visual effects. We demonstrate our system by constructing multiperspective images that summarize city blocks, including corners, blocks with deep plazas and other challenging urban situations.',\n",
              "  'AuthorKeywords': ['cross-slits',\n",
              "   'image,',\n",
              "   'multi-perspective',\n",
              "   'image,',\n",
              "   'city',\n",
              "   'block'],\n",
              "  'MultipartiteRank': [{'score': 0.16273558675462568,\n",
              "    'word': 'multiperspective'},\n",
              "   {'score': 0.16273558675462568, 'word': 'images'},\n",
              "   {'score': 0.060267733403419524, 'word': 'interactive'},\n",
              "   {'score': 0.060267733403419524, 'word': 'system'},\n",
              "   {'score': 0.04965481208070056, 'word': 'user'},\n",
              "   {'score': 0.048520918574416934, 'word': 'camera'},\n",
              "   {'score': 0.03916545498552275, 'word': 'city'},\n",
              "   {'score': 0.03916545498552275, 'word': 'blocks'}],\n",
              "  'Title': 'Interactive design of multi-perspective images for visualizing urban landscapes',\n",
              "  'distance': 0,\n",
              "  'no': '376',\n",
              "  'parent': '4079'},\n",
              " {'Abstract': 'We propose a novel algorithm for placement of streamlines from two-dimensional steady vector or direction fields. Our method consists of placing one streamline at a time by numerical integration starting at the furthest away from all previously placed streamlines. Such a farthest point seeding strategy leads to high quality placements by favoring long streamlines, while retaining uniformity with the increasing density. Our greedy approach generates placements of comparable quality with respect to the optimization approach from Turk and Banks, while being 200 times faster. Simplicity, robustness as well as efficiency is achieved through the use of a Delaunay triangulation to model the streamlines, address proximity queries and determine the biggest voids by exploiting the empty circle property. Our method handles variable density and extends to multiresolution.',\n",
              "  'AuthorKeywords': ['Streamline',\n",
              "   'placement,',\n",
              "   'farthest',\n",
              "   'point',\n",
              "   'seeding,',\n",
              "   'Delaunay',\n",
              "   'triangulation,',\n",
              "   'variable',\n",
              "   'density,',\n",
              "   'multiresolution'],\n",
              "  'MultipartiteRank': [{'score': 0.09761562223782029, 'word': 'streamlines'},\n",
              "   {'score': 0.08085130810800369, 'word': 'placement'},\n",
              "   {'score': 0.05869710688914743, 'word': 'greedy'},\n",
              "   {'score': 0.05869710688914743, 'word': 'approach'},\n",
              "   {'score': 0.04657259588903846, 'word': 'time'},\n",
              "   {'score': 0.04556240211797668, 'word': 'density'}],\n",
              "  'Title': 'Farthest point seeding for efficient placement of streamlines',\n",
              "  'distance': 0,\n",
              "  'no': '377',\n",
              "  'parent': '3959'},\n",
              " {'Abstract': 'Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'layout,',\n",
              "   'systems',\n",
              "   'biology',\n",
              "   'visualization,',\n",
              "   'small',\n",
              "   'multiples,',\n",
              "   'design',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.1108859763964381, 'word': 'interaction'},\n",
              "   {'score': 0.1108859763964381, 'word': 'graphs'},\n",
              "   {'score': 0.09267984456736772, 'word': 'experimental'},\n",
              "   {'score': 0.09030144995575265, 'word': 'systems'},\n",
              "   {'score': 0.05264677113997367, 'word': 'data'},\n",
              "   {'score': 0.046612297384964335, 'word': 'biological'},\n",
              "   {'score': 0.04368915257078832, 'word': 'biologists'},\n",
              "   {'score': 0.04003307342739406, 'word': 'various'},\n",
              "   {'score': 0.04003307342739406, 'word': 'conditions'}],\n",
              "  'Title': 'Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context',\n",
              "  'distance': 0,\n",
              "  'no': '378',\n",
              "  'parent': '5303'},\n",
              " {'Abstract': 'In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.',\n",
              "  'AuthorKeywords': ['Problem',\n",
              "   'solving',\n",
              "   'environment,',\n",
              "   'decision',\n",
              "   'making,',\n",
              "   'simulation',\n",
              "   'steering,',\n",
              "   'parallel',\n",
              "   'worlds,',\n",
              "   'CFD,',\n",
              "   'smoothed',\n",
              "   'particle',\n",
              "   'hydrodynamics'],\n",
              "  'MultipartiteRank': [{'score': 0.08343066799575859, 'word': 'world'},\n",
              "   {'score': 0.08343066799575859, 'word': 'lines'},\n",
              "   {'score': 0.07356562123545293, 'word': 'multiple'},\n",
              "   {'score': 0.07356562123545293, 'word': 'heterogeneous'},\n",
              "   {'score': 0.07356562123545293, 'word': 'simulation'},\n",
              "   {'score': 0.07356562123545293, 'word': 'runs'},\n",
              "   {'score': 0.057881488121240665, 'word': 'novel'},\n",
              "   {'score': 0.057881488121240665, 'word': 'interactive'},\n",
              "   {'score': 0.057881488121240665, 'word': 'visualization'},\n",
              "   {'score': 0.04446621867723427, 'word': 'decisions'},\n",
              "   {'score': 0.03925770238888329, 'word': 'users'}],\n",
              "  'Title': 'World Lines',\n",
              "  'distance': 0,\n",
              "  'no': '379',\n",
              "  'parent': '6078'},\n",
              " {'Abstract': 'The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.',\n",
              "  'AuthorKeywords': ['Microblog',\n",
              "   'analysis,',\n",
              "   'Twitter,',\n",
              "   'text',\n",
              "   'analytics,',\n",
              "   'social',\n",
              "   'media',\n",
              "   'monitoring,',\n",
              "   'live',\n",
              "   'monitoring,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'filter',\n",
              "   'construction,',\n",
              "   'query',\n",
              "   'construction,',\n",
              "   'text',\n",
              "   'classification'],\n",
              "  'MultipartiteRank': [{'score': 0.0670093080663355, 'word': 'relevant'},\n",
              "   {'score': 0.0670093080663355, 'word': 'messages'},\n",
              "   {'score': 0.04778434397761485, 'word': 'microblog'},\n",
              "   {'score': 0.04778434397761485, 'word': 'posts'},\n",
              "   {'score': 0.03258184113320821, 'word': 'critical'},\n",
              "   {'score': 0.03258184113320821, 'word': 'tasks'},\n",
              "   {'score': 0.03256747030368387, 'word': 'topic'},\n",
              "   {'score': 0.032018996148112176, 'word': 'analysts'}],\n",
              "  'Title': 'ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering',\n",
              "  'distance': 0,\n",
              "  'no': '380',\n",
              "  'parent': '5017'},\n",
              " {'Abstract': 'A method is presented for the visualization of 3D vector fields. The stream polygon, which is a regular, n-sided polygon, oriented normal to the local vector, can present local deformations due to rigid body rotation and both normal and shear strain. The effect of translation and scalar functions can be represented by sweeping the stream polygon along the streamline, and by appropriately varying the radius and shading the surface of the resulting streamtube. A mathematical foundation for the stream is developed, and examples with application to velocity field visualization are provided.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11643496955198736, 'word': 'vector'},\n",
              "   {'score': 0.09080463987451035, 'word': 'stream'},\n",
              "   {'score': 0.09080463987451035, 'word': 'polygon'},\n",
              "   {'score': 0.08001828289157473, 'word': 'normal'},\n",
              "   {'score': 0.0649091019242257, 'word': 'local'},\n",
              "   {'score': 0.06468780646648417, 'word': 'visualization'},\n",
              "   {'score': 0.05152586762776165, 'word': '3d'},\n",
              "   {'score': 0.05152586762776165, 'word': 'fields'}],\n",
              "  'Title': 'The stream polygon: A technique for 3D vector field visualization',\n",
              "  'distance': 0,\n",
              "  'no': '381',\n",
              "  'parent': '3408'},\n",
              " {'Abstract': 'Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.',\n",
              "  'AuthorKeywords': ['Time',\n",
              "   'critical',\n",
              "   'Visualization,',\n",
              "   'Compression',\n",
              "   'for',\n",
              "   'Visualization,',\n",
              "   'Volume',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.11072023302551719, 'word': 'volume'},\n",
              "   {'score': 0.06279253302528542, 'word': '3d'},\n",
              "   {'score': 0.06279253302528542, 'word': 'wavelet'},\n",
              "   {'score': 0.06279253302528542, 'word': 'transforms'},\n",
              "   {'score': 0.062425818484391, 'word': 'animated'},\n",
              "   {'score': 0.062425818484391, 'word': 'data'},\n",
              "   {'score': 0.05035573072845213, 'word': 'interactive'},\n",
              "   {'score': 0.05035573072845213, 'word': 'frame'},\n",
              "   {'score': 0.05035573072845213, 'word': 'rates'},\n",
              "   {'score': 0.048294414541126186, 'word': 'reconstructed'},\n",
              "   {'score': 0.04462940565803844, 'word': 'algorithm'}],\n",
              "  'Title': 'Real-time decompression and visualization of animated volume data',\n",
              "  'distance': 0,\n",
              "  'no': '382',\n",
              "  'parent': '4127'},\n",
              " {'Abstract': 'The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.',\n",
              "  'AuthorKeywords': ['Volume', 'Rendering,', 'Virtual', 'Endoscopy'],\n",
              "  'MultipartiteRank': [{'score': 0.09808609933362578, 'word': 'possible'},\n",
              "   {'score': 0.09808609933362578, 'word': 'visualization'},\n",
              "   {'score': 0.09808609933362578, 'word': 'technique'},\n",
              "   {'score': 0.06419236288365424, 'word': 'surface'},\n",
              "   {'score': 0.04599493095505329, 'word': 'colon'},\n",
              "   {'score': 0.0421701167307127, 'word': 'diagnosis'},\n",
              "   {'score': 0.04096008013236966, 'word': 'optimal'},\n",
              "   {'score': 0.04096008013236966, 'word': 'information'}],\n",
              "  'Title': 'Nonlinear virtual colon unfolding',\n",
              "  'distance': 0,\n",
              "  'no': '383',\n",
              "  'parent': '4200'},\n",
              " {'Abstract': 'Many graph drawing and visualization algorithms, such as force-directed layout and line-dot rendering, work very well on relatively small and sparse graphs. However, they often produce extremely tangled results and exhibit impractical running times for highly non-planar graphs with large edge density. And very few graph layout algorithms support dynamic time-varying graphs; applying them independently to each frame produces distracting temporally incoherent visualizations. We have developed a new visualization technique based on a novel approach to hierarchically structuring dense graphs via stratification. Using this structure, we formulate a hierarchical force-directed layout algorithm that is both efficient and produces quality graph layouts. The stratification of the graph also allows us to present views of the data that abstract away many small details of its structure. Rather than displaying all edges and nodes at once, resulting in a convoluted rendering, we present an interactive tool that filters edges and nodes using the graph hierarchy and allows users to drill down into the graph for details. Our layout algorithm also accommodates time-varying graphs in a natural way, producing a temporally coherent animation that can be used to analyze and extract trends from dynamic graph data. For example, we demonstrate the use of our method to explore financial correlation data for the U.S. stock market in the period from 1990 to 2005. The user can easily analyze the time-varying correlation graph of the market, uncovering information such as market sector trends, representative stocks for portfolio construction, and the interrelationship of stocks over time.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'and',\n",
              "   'network',\n",
              "   'visualization,',\n",
              "   'financial',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'hierarchy',\n",
              "   'visualization,',\n",
              "   'time',\n",
              "   'series',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.17475713311103278, 'word': 'many'},\n",
              "   {'score': 0.17475713311103278, 'word': 'graph'},\n",
              "   {'score': 0.17475713311103278, 'word': 'drawing'},\n",
              "   {'score': 0.07605009227258316, 'word': 'visualization'},\n",
              "   {'score': 0.07605009227258316, 'word': 'algorithms'},\n",
              "   {'score': 0.05825893084503842, 'word': 'layout'},\n",
              "   {'score': 0.04705397856822974, 'word': 'force'},\n",
              "   {'score': 0.04062634048510725, 'word': 'impractical'},\n",
              "   {'score': 0.04062634048510725, 'word': 'running'},\n",
              "   {'score': 0.04062634048510725, 'word': 'times'}],\n",
              "  'Title': 'Visual Exploration of Complex Time-Varying Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '384',\n",
              "  'parent': '5320'},\n",
              " {'Abstract': 'Volumetric data commonly has high depth complexity which makes it difficult to judge spatial relationships accurately. There are many different ways to enhance depth perception, such as shading, contours, and shadows. Artists and illustrators frequently employ halos for this purpose. In this technique, regions surrounding the edges of certain structures are darkened or brightened which makes it easier to judge occlusion. Based on this concept, we present a flexible method for enhancing and highlighting structures of interest using GPU-based direct volume rendering. Our approach uses an interactively defined halo transfer function to classify structures of interest based on data value, direction, and position. A feature-preserving spreading algorithm is applied to distribute seed values to neighboring locations, generating a controllably smooth field of halo intensities. These halo intensities are then mapped to colors and opacities using a halo profile function. Our method can be used to annotate features at interactive frame rates.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'rendering,',\n",
              "   'illustrative',\n",
              "   'visualization,',\n",
              "   'halos'],\n",
              "  'MultipartiteRank': [{'score': 0.07189224783940659, 'word': 'halos'},\n",
              "   {'score': 0.06079900166752677, 'word': 'certain'},\n",
              "   {'score': 0.06079900166752677, 'word': 'structures'},\n",
              "   {'score': 0.03953801398799742, 'word': 'interest'},\n",
              "   {'score': 0.03562601194983011, 'word': 'direct'},\n",
              "   {'score': 0.03562601194983011, 'word': 'volume'},\n",
              "   {'score': 0.03399158970798467, 'word': 'illustrators'}],\n",
              "  'Title': 'Enhancing Depth-Perception with Flexible Volumetric Halos',\n",
              "  'distance': 0,\n",
              "  'no': '385',\n",
              "  'parent': '4546'},\n",
              " {'Abstract': 'Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.',\n",
              "  'AuthorKeywords': ['Multivariate',\n",
              "   'data,',\n",
              "   'visualization,',\n",
              "   'scatterplot,',\n",
              "   'Parallel',\n",
              "   'Coordinates',\n",
              "   'Plot'],\n",
              "  'MultipartiteRank': [{'score': 0.14395269489104712, 'word': 'visualization'},\n",
              "   {'score': 0.06985056648490184, 'word': 'flexible'},\n",
              "   {'score': 0.06985056648490184, 'word': 'linked'},\n",
              "   {'score': 0.06985056648490184, 'word': 'axes'},\n",
              "   {'score': 0.06482190463244866, 'word': 'multivariate'},\n",
              "   {'score': 0.06482190463244866, 'word': 'data'},\n",
              "   {'score': 0.05554228605527739, 'word': 'user'},\n",
              "   {'score': 0.048966927532303785, 'word': 'scatter'},\n",
              "   {'score': 0.048966927532303785, 'word': 'plot-'}],\n",
              "  'Title': 'Flexible Linked Axes for Multivariate Data Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '386',\n",
              "  'parent': '4493'},\n",
              " {'Abstract': 'We present a system for the interactive construction and analysis of decision trees that enables domain experts to bring in domain specific knowledge. We identify different user tasks and corresponding requirements, and develop a system incorporating a tight integration of visualization, interaction and algorithmic support. Domain experts are supported in growing, pruning, optimizing and analysing decision trees. Furthermore, we present a scalable decision tree visualization optimized for exploration. We show the effectiveness of our approach by applying the methods to two use cases. The first case illustrates the advantages of interactive construction, the second case demonstrates the effectiveness of analysis of decision trees and exploration of the structure of the data.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09444956897430909, 'word': 'decision'},\n",
              "   {'score': 0.09444956897430909, 'word': 'trees'},\n",
              "   {'score': 0.09146285616150267, 'word': 'interactive'},\n",
              "   {'score': 0.09146285616150267, 'word': 'construction'},\n",
              "   {'score': 0.07733990926941114, 'word': 'use'},\n",
              "   {'score': 0.07733990926941114, 'word': 'cases'},\n",
              "   {'score': 0.06538164269854867, 'word': 'analysis'},\n",
              "   {'score': 0.0610628635482503, 'word': 'effectiveness'}],\n",
              "  'Title': 'BaobabView: Interactive construction and analysis of decision trees',\n",
              "  'distance': 0,\n",
              "  'no': '387',\n",
              "  'parent': '3714'},\n",
              " {'Abstract': 'It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.',\n",
              "  'AuthorKeywords': ['Opinion',\n",
              "   'visualization,',\n",
              "   'opinion',\n",
              "   'diffusion,',\n",
              "   'opinion',\n",
              "   'flow,',\n",
              "   'influence',\n",
              "   'estimation,',\n",
              "   'kernel',\n",
              "   'density',\n",
              "   'estimation,',\n",
              "   'level-of-detail'],\n",
              "  'MultipartiteRank': [{'score': 0.09893333522926885, 'word': 'public'},\n",
              "   {'score': 0.09893333522926885, 'word': 'opinions'},\n",
              "   {'score': 0.0914140199919713, 'word': 'diffusion'},\n",
              "   {'score': 0.05106628887047861, 'word': 'social'},\n",
              "   {'score': 0.05106628887047861, 'word': 'media'},\n",
              "   {'score': 0.049953130750911415, 'word': 'great'},\n",
              "   {'score': 0.049953130750911415, 'word': 'diversity'},\n",
              "   {'score': 0.042720394933108065, 'word': 'twitter'},\n",
              "   {'score': 0.042720394933108065, 'word': 'users'}],\n",
              "  'Title': 'OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media',\n",
              "  'distance': 0,\n",
              "  'no': '388',\n",
              "  'parent': '4623'},\n",
              " {'Abstract': 'The sphere quadtree (SQT), which is based on the recursive subdivision of spherical triangles obtained by projecting the faces of an icosahedron onto a sphere, is discussed. Most databases for spherically distributed data are not structured in a manner consistent with their geometry. As a result, such databases possess undesirable artifacts, including the introduction of tears in the data when they are mapped onto a flat file system. Furthermore, it is difficult to make queries about the topological relationship among the data components without performing real arithmetic. The SQT eliminates some of these problems. The SQT allows the representation of data at multiple levels and arbitrary resolution. Efficient search strategies can be implemented for the selection of data to be rendered or analyzed by a specific technique. Geometric and topological consistency with the data are maintained.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12369678507170481, 'word': 'data'},\n",
              "   {'score': 0.07764947628825147, 'word': 'sqt'},\n",
              "   {'score': 0.050651261915485205, 'word': 'sphere'},\n",
              "   {'score': 0.050651261915485205, 'word': 'quadtree'},\n",
              "   {'score': 0.04773734800984197, 'word': 'manner'},\n",
              "   {'score': 0.04773734800984197, 'word': 'consistent'},\n",
              "   {'score': 0.03573639834554061, 'word': 'multiple'},\n",
              "   {'score': 0.03573639834554061, 'word': 'levels'}],\n",
              "  'Title': 'Rendering and managing spherical data with sphere quadtrees',\n",
              "  'distance': 0,\n",
              "  'no': '389',\n",
              "  'parent': '4228'},\n",
              " {'Abstract': 'Time-dependent (unsteady) flow fields are commonly generated in computational fluid dynamics (CFD) simulations; however, there are very few flow visualization systems that generate particle traces in unsteady flow fields. Most existing systems generate particle traces in time-independent flow fields. A particle tracing system has been developed to generate particle traces in unsteady flow fields. The system was used to visualize several 3D unsteady flow fields from real-world problems, and it has provided useful insights into the time-varying phenomena in the flow fields. The design requirements and the architecture of the system are described. Some examples of particle traces computed by the system are also shown.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15267975082527718, 'word': 'flow'},\n",
              "   {'score': 0.15267975082527718, 'word': 'fields'},\n",
              "   {'score': 0.10911377045124455, 'word': 'particle'},\n",
              "   {'score': 0.10911377045124455, 'word': 'traces'},\n",
              "   {'score': 0.1025561035169114, 'word': 'systems'},\n",
              "   {'score': 0.08633325953415959, 'word': 'time'},\n",
              "   {'score': 0.046642706671490744, 'word': 'unsteady'}],\n",
              "  'Title': 'UFAT-a particle tracer for time-dependent flow fields',\n",
              "  'distance': 0,\n",
              "  'no': '390',\n",
              "  'parent': '3770'},\n",
              " {'Abstract': 'We introduce a simple but effective extension to the existing pure point rendering systems. Rather than using only points, we use both points and polygons to represent and render large mesh models. We start from triangles as leaf nodes and build up a hierarchical tree structure with intermediate nodes as points. During the rendering, the system determines whether to use a point (of a certain intermediate level node) or a triangle (of a leaf node) for display depending on the screen contribution of each node. While points are used to speedup the rendering of distant objects, triangles are used to ensure the quality of close objects. Our method can accelerate the rendering of large models, compromising little in image quality.',\n",
              "  'AuthorKeywords': ['Rendering',\n",
              "   'system,',\n",
              "   'Spatial',\n",
              "   'data',\n",
              "   'structures,',\n",
              "   'Level',\n",
              "   'of',\n",
              "   'detail',\n",
              "   'algorithms,',\n",
              "   'hybrid',\n",
              "   'rendering',\n",
              "   'systems'],\n",
              "  'MultipartiteRank': [{'score': 0.10321084886871076, 'word': 'points'},\n",
              "   {'score': 0.08716954709618531, 'word': 'triangles'},\n",
              "   {'score': 0.08081037967140807, 'word': 'rendering'},\n",
              "   {'score': 0.06379520237299209, 'word': 'intermediate'},\n",
              "   {'score': 0.06379520237299209, 'word': 'nodes'},\n",
              "   {'score': 0.05793717686498137, 'word': 'distant'},\n",
              "   {'score': 0.05793717686498137, 'word': 'objects'}],\n",
              "  'Title': 'POP: A Hybrid Point and Polygon Rendering System for Large Data',\n",
              "  'distance': 0,\n",
              "  'no': '391',\n",
              "  'parent': '3965'},\n",
              " {'Abstract': 'This paper describes the Worldmapper project, which makes use of novel visualization techniques to represent a broad variety of social and economic data about the countries of the world. The goal of the project is to use the map projections known as cartograms to depict comparisons and relations between different territories, and its execution raises many interesting design challenges that were not all apparent at the outset. We discuss the approaches taken towards these challenges, some of which may have considerably broad application. We conclude by commenting on the positive initial response to the Worldmapper images published on the Web, which we believe is due, at least in part, to the particular effectiveness of the cartogram as a tool for communicating quantitative geographic data',\n",
              "  'AuthorKeywords': ['Geographic',\n",
              "   'Visualization,',\n",
              "   'Computer',\n",
              "   'Graphics,',\n",
              "   'Worldmapper,',\n",
              "   'Data',\n",
              "   'Visualization,',\n",
              "   'Social',\n",
              "   'Visualization,',\n",
              "   'Cartogram'],\n",
              "  'MultipartiteRank': [{'score': 0.08084600699262237, 'word': 'worldmapper'},\n",
              "   {'score': 0.08084600699262237, 'word': 'project'},\n",
              "   {'score': 0.05267110040100234, 'word': 'broad'},\n",
              "   {'score': 0.05267110040100234, 'word': 'variety'},\n",
              "   {'score': 0.04985391074614208, 'word': 'cartograms'},\n",
              "   {'score': 0.04035213303718006, 'word': 'social'},\n",
              "   {'score': 0.04014293288489604, 'word': 'novel'},\n",
              "   {'score': 0.04014293288489604, 'word': 'visualization'},\n",
              "   {'score': 0.04014293288489604, 'word': 'techniques'}],\n",
              "  'Title': \"Worldmapper: The World as You've Never Seen it Before\",\n",
              "  'distance': 0,\n",
              "  'no': '392',\n",
              "  'parent': '3756'},\n",
              " {'Abstract': 'Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.',\n",
              "  'AuthorKeywords': ['Task',\n",
              "   'taxonomy,',\n",
              "   'design',\n",
              "   'space,',\n",
              "   'climate',\n",
              "   'impact',\n",
              "   'research,',\n",
              "   'visualization',\n",
              "   'recommendation'],\n",
              "  'MultipartiteRank': [{'score': 0.1563114564562179, 'word': 'visualization'},\n",
              "   {'score': 0.1563114564562179, 'word': 'tasks'},\n",
              "   {'score': 0.14601037069094713, 'word': 'design'},\n",
              "   {'score': 0.14601037069094713, 'word': 'space'},\n",
              "   {'score': 0.1013225019056903, 'word': 'different'},\n",
              "   {'score': 0.0985007437075281, 'word': 'general'},\n",
              "   {'score': 0.0585731358622045, 'word': 'aspects'},\n",
              "   {'score': 0.042749366043485795, 'word': 'user'},\n",
              "   {'score': 0.042749366043485795, 'word': 'roles'}],\n",
              "  'Title': 'A Design Space of Visualization Tasks',\n",
              "  'distance': 0,\n",
              "  'no': '393',\n",
              "  'parent': '4862'},\n",
              " {'Abstract': \"The paper presents an algorithm, UFLIC (Unsteady Flow LIC), to visualize vector data in unsteady flow fields. Using line integral convolution (LIC) as the underlying method, a new convolution algorithm is proposed that can effectively trace the flow's global features over time. The new algorithm consists of a time-accurate value depositing scheme and a successive feedforward method. The value depositing scheme accurately models the flow advection, and the successive feedforward method maintains the coherence between animation frames. The new algorithm can produce time-accurate, highly coherent flow animations to highlight global features in unsteady flow fields. CFD scientists, for the first time, are able to visualize unsteady surface flows using the algorithm.\",\n",
              "  'AuthorKeywords': ['view',\n",
              "   'synthesis,',\n",
              "   'dynamic',\n",
              "   'scene',\n",
              "   'analysis,',\n",
              "   'modeling',\n",
              "   'from',\n",
              "   'image',\n",
              "   'sequences,',\n",
              "   'computer',\n",
              "   'vision',\n",
              "   'and',\n",
              "   'scene',\n",
              "   'understanding,',\n",
              "   'virtual',\n",
              "   'worlds'],\n",
              "  'MultipartiteRank': [{'score': 0.12352711344180488, 'word': 'unsteady'},\n",
              "   {'score': 0.12352711344180488, 'word': 'flow'},\n",
              "   {'score': 0.12352711344180488, 'word': 'lic'},\n",
              "   {'score': 0.11376260067720342, 'word': 'algorithm'},\n",
              "   {'score': 0.06732994039349771, 'word': 'time'},\n",
              "   {'score': 0.05794494605797557, 'word': 'uflic'},\n",
              "   {'score': 0.05393906531980742, 'word': 'method'}],\n",
              "  'Title': 'UFLIC: a line integral convolution algorithm for visualizing unsteady flows',\n",
              "  'distance': 0,\n",
              "  'no': '394',\n",
              "  'parent': '4034'},\n",
              " {'Abstract': 'Many real world polygonal surfaces contain topological singularities that represent a challenge for processes such as simplification, compression, smoothing, etc. We present an algorithm for removing such singularities, thus converting non manifold sets of polygons to manifold polygonal surfaces (orientable if necessary). We identify singular vertices and edges, multiply singular vertices, and cut through singular edges. In an optional stitching phase, we join surface boundary edges that were cut, or whose endpoints are sufficiently close, while guaranteeing that the surface is a manifold. We study two different stitching strategies called \"edge pinching\" and \"edge snapping\"; when snapping, special care is required to avoid re-creating singularities. The algorithm manipulates the polygon vertex indices (surface topology) and essentially ignores vertex coordinates (surface geometry). Except for the optional stitching, the algorithm has a linear complexity in the number of vertices edges and faces, and require no floating point operation.',\n",
              "  'AuthorKeywords': ['Polygonal',\n",
              "   'Surface,',\n",
              "   'Manifold,',\n",
              "   'Cutting,',\n",
              "   'Stitching'],\n",
              "  'MultipartiteRank': [{'score': 0.12081016406677408, 'word': 'many'},\n",
              "   {'score': 0.12081016406677408, 'word': 'real'},\n",
              "   {'score': 0.12081016406677408, 'word': 'world'},\n",
              "   {'score': 0.12081016406677408, 'word': 'polygonal'},\n",
              "   {'score': 0.12081016406677408, 'word': 'surfaces'},\n",
              "   {'score': 0.11341172125212334, 'word': 'edges'},\n",
              "   {'score': 0.10427932851563147, 'word': 'topological'},\n",
              "   {'score': 0.10427932851563147, 'word': 'singularities'},\n",
              "   {'score': 0.05156851274405239, 'word': 'surface'},\n",
              "   {'score': 0.05156851274405239, 'word': 'boundary'},\n",
              "   {'score': 0.04285167455000639, 'word': 'algorithm'}],\n",
              "  'Title': 'Converting sets of polygons to manifold surfaces by cutting and stitching',\n",
              "  'distance': 0,\n",
              "  'no': '395',\n",
              "  'parent': '3892'},\n",
              " {'Abstract': 'Presents a method for the hierarchical representation of vector fields. Our approach is based on iterative refinement using clustering and principal component analysis. The input to our algorithm is a discrete set of points with associated vectors. The algorithm generates a top-down segmentation of the discrete field by splitting clusters of points. We measure the error of the various approximation levels by measuring the discrepancy between streamlines generated by the original discrete field and its approximations based on much smaller discrete data sets. Our method assumes no particular structure of the field, nor does it require any topological connectivity information. It is possible to generate multi-resolution representations of vector fields using this approach.',\n",
              "  'AuthorKeywords': ['vector',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   \"Hardy's\",\n",
              "   'multiquadric',\n",
              "   'method,',\n",
              "   'binary-space',\n",
              "   'partitioning,',\n",
              "   'data',\n",
              "   'simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.10734164993504987, 'word': 'vector'},\n",
              "   {'score': 0.10734164993504987, 'word': 'fields'},\n",
              "   {'score': 0.059983412880243905, 'word': 'points'},\n",
              "   {'score': 0.05963443318109434, 'word': 'clustering'},\n",
              "   {'score': 0.056186573063033964, 'word': 'algorithm'},\n",
              "   {'score': 0.05359789543739206, 'word': 'discrete'},\n",
              "   {'score': 0.05359789543739206, 'word': 'set'}],\n",
              "  'Title': 'Construction of vector field hierarchies',\n",
              "  'distance': 0,\n",
              "  'no': '396',\n",
              "  'parent': '3512'},\n",
              " {'Abstract': 'The classification of volumetric data sets as well as their rendering algorithms are typically based on the representation of the underlying grid. Grid structures based on a Cartesian lattice are the de-facto standard for regular representations of volumetric data. In this paper we introduce a more general concept of regular grids for the representation of volumetric data. We demonstrate that a specific type of regular lattice-the so-called body-centered cubic-is able to represent the same data set as a Cartesian grid to the same accuracy but with 29.3% fewer samples. This speeds up traditional volume rendering algorithms by the same ratio, which we demonstrate by adopting a splatting implementation for these new lattices. We investigate different filtering methods required for computing the normals on this lattice. The lattice representation results also in lossless compression ratios that are better than previously reported. Although other regular grid structures achieve the same sample efficiency, the body-centered cubic is particularly easy to use. The only assumption necessary is that the underlying volume is isotropic and band-limited-an assumption that is valid for most practical data sets.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'data,Cartesiangrid,close',\n",
              "   'packing,hexagonal',\n",
              "   'sampling,',\n",
              "   'body',\n",
              "   'centered',\n",
              "   'cubic'],\n",
              "  'MultipartiteRank': [{'score': 0.09565163906326428,\n",
              "    'word': 'representation'},\n",
              "   {'score': 0.0893700157859046, 'word': 'volumetric'},\n",
              "   {'score': 0.0893700157859046, 'word': 'data'},\n",
              "   {'score': 0.0893700157859046, 'word': 'sets'},\n",
              "   {'score': 0.08359683371580649, 'word': 'underlying'},\n",
              "   {'score': 0.08359683371580649, 'word': 'grid'},\n",
              "   {'score': 0.06994888427441054, 'word': 'cartesian'},\n",
              "   {'score': 0.06994888427441054, 'word': 'lattice'},\n",
              "   {'score': 0.048194836916490874, 'word': 'rendering'},\n",
              "   {'score': 0.048194836916490874, 'word': 'algorithms'}],\n",
              "  'Title': 'Optimal regular volume sampling',\n",
              "  'distance': 0,\n",
              "  'no': '397',\n",
              "  'parent': '4161'},\n",
              " {'Abstract': 'Beamtrees are a new method for the visualization of large hierarchical data sets. Nodes are shown as stacked circular beams, such that both the hierarchical structure as well as the size of nodes are depicted. The dimensions of beams are calculated using a variation of the treemap algorithm. A small user study indicated that beamtrees are significantly more effective than nested treemaps and cushion treemaps for the extraction of global hierarchical information.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10266262808058045, 'word': 'treemap'},\n",
              "   {'score': 0.10266262808058045, 'word': 'algorithm'},\n",
              "   {'score': 0.09136274159335608, 'word': 'nodes'},\n",
              "   {'score': 0.08183598634954706, 'word': 'circular'},\n",
              "   {'score': 0.08183598634954706, 'word': 'beams'},\n",
              "   {'score': 0.07249902676791331, 'word': 'beamtrees'},\n",
              "   {'score': 0.05887599799789786, 'word': 'large'},\n",
              "   {'score': 0.05887599799789786, 'word': 'hierarchical'},\n",
              "   {'score': 0.05887599799789786, 'word': 'data'},\n",
              "   {'score': 0.05887599799789786, 'word': 'sets'}],\n",
              "  'Title': 'Beamtrees: compact visualization of large hierarchies',\n",
              "  'distance': 0,\n",
              "  'no': '398',\n",
              "  'parent': '3441'},\n",
              " {'Abstract': 'Interactive visualization of large digital elevation models is of continuing interest in scientific visualization, GIS, and virtual reality applications. Taking advantage of the regular structure of grid digital elevation models, efficient hierarchical multiresolution triangulation and adaptive level-of-detail (LOD) rendering algorithms have been developed for interactive terrain visualization. Despite the higher triangle count, these approaches generally outperform mesh simplification methods that produce irregular triangulated network (TIN) based LOD representations. In this project we combine the advantage of a TIN based mesh simplification preprocess with high-performance quadtree based LOD triangulation and rendering at run-time. This approach, called QuadTIN, generates an efficient quadtree triangulation hierarchy over any irregular point set that may originate from irregular terrain sampling or from reducing oversampling in high-resolution grid digital elevation models.',\n",
              "  'AuthorKeywords': ['multiresolution',\n",
              "   'triangulation,',\n",
              "   'real-time',\n",
              "   'terrain',\n",
              "   'visualization,',\n",
              "   'triangulated',\n",
              "   'irregular',\n",
              "   'networks,',\n",
              "   'level-of-detail'],\n",
              "  'MultipartiteRank': [{'score': 0.12848470579143695, 'word': 'interactive'},\n",
              "   {'score': 0.12848470579143695, 'word': 'visualization'},\n",
              "   {'score': 0.09403258071820023, 'word': 'large'},\n",
              "   {'score': 0.09403258071820023, 'word': 'digital'},\n",
              "   {'score': 0.09403258071820023, 'word': 'elevation'},\n",
              "   {'score': 0.09403258071820023, 'word': 'models'},\n",
              "   {'score': 0.05479842294050734, 'word': 'lod'},\n",
              "   {'score': 0.039021863013273664, 'word': 'efficient'},\n",
              "   {'score': 0.039021863013273664, 'word': 'hierarchical'},\n",
              "   {'score': 0.039021863013273664, 'word': 'multiresolution'},\n",
              "   {'score': 0.039021863013273664, 'word': 'triangulation'},\n",
              "   {'score': 0.03752597083075994, 'word': 'advantage'}],\n",
              "  'Title': 'QuadTIN: quadtree based triangulated irregular networks',\n",
              "  'distance': 0,\n",
              "  'no': '399',\n",
              "  'parent': '4485'},\n",
              " {'Abstract': \"Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for Personal Digital Assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style.\",\n",
              "  'AuthorKeywords': ['Small',\n",
              "   'screen,',\n",
              "   'PDA,',\n",
              "   'scatterplot,',\n",
              "   'zoom,',\n",
              "   'fisheye,',\n",
              "   'focus+context'],\n",
              "  'MultipartiteRank': [{'score': 0.04630528440334812, 'word': 'visualization'},\n",
              "   {'score': 0.04630528440334812, 'word': 'techniques'},\n",
              "   {'score': 0.038986423917297446, 'word': 'items'},\n",
              "   {'score': 0.03890210128544482, 'word': 'fisheye'},\n",
              "   {'score': 0.03890210128544482, 'word': 'distortion'},\n",
              "   {'score': 0.037244262289764164, 'word': 'users'},\n",
              "   {'score': 0.030448282782668958, 'word': 'scatterplot'},\n",
              "   {'score': 0.030448282782668958, 'word': 'tool'}],\n",
              "  'Title': 'User Interaction with Scatterplots on Small Screens - A Comparative Evaluation of Geometric-Semantic Zoom and Fisheye Distortion',\n",
              "  'distance': 0,\n",
              "  'no': '400',\n",
              "  'parent': '4453'},\n",
              " {'Abstract': 'We propose a visual analytics procedure for analyzing movement data, i.e., recorded tracks of moving objects. It is oriented to a class of problems where it is required to determine significant places on the basis of certain types of events occurring repeatedly in movement data. The procedure consists of four major steps: (1) event extraction from trajectories; (2) event clustering and extraction of relevant places; (3) spatio-temporal aggregation of events or trajectories; (4) analysis of the aggregated data. All steps are scalable with respect to the amount of the data under analysis. We demonstrate the use of the procedure by example of two real-world problems requiring analysis at different spatial scales.',\n",
              "  'AuthorKeywords': ['movement,',\n",
              "   'trajectories,',\n",
              "   'spatio-temporal',\n",
              "   'data,',\n",
              "   'spatial',\n",
              "   'events,',\n",
              "   'spatial',\n",
              "   'clustering,',\n",
              "   'spatio-temporal',\n",
              "   'clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.08638943694712663, 'word': 'movement'},\n",
              "   {'score': 0.08638943694712663, 'word': 'data'},\n",
              "   {'score': 0.06959779911927938, 'word': 'visual'},\n",
              "   {'score': 0.06959779911927938, 'word': 'analytics'},\n",
              "   {'score': 0.06959779911927938, 'word': 'procedure'},\n",
              "   {'score': 0.06725152702791001, 'word': 'events'},\n",
              "   {'score': 0.046101849690560415, 'word': 'significant'},\n",
              "   {'score': 0.046101849690560415, 'word': 'places'},\n",
              "   {'score': 0.045954552049421976, 'word': 'analysis'}],\n",
              "  'Title': 'From movement tracks through events to places: Extracting and characterizing significant places from mobility data',\n",
              "  'distance': 0,\n",
              "  'no': '401',\n",
              "  'parent': '3907'},\n",
              " {'Abstract': 'In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles.',\n",
              "  'AuthorKeywords': ['Artificial',\n",
              "   'neural',\n",
              "   'networks;dimensionality',\n",
              "   'reduction;algorithm',\n",
              "   'understanding'],\n",
              "  'MultipartiteRank': [{'score': 0.06952607948785096, 'word': 'dimensional'},\n",
              "   {'score': 0.06952607948785096, 'word': 'vectors'},\n",
              "   {'score': 0.06847286159477918, 'word': 'observations'},\n",
              "   {'score': 0.05747633811075071, 'word': 'level'},\n",
              "   {'score': 0.05747633811075071, 'word': 'representations'},\n",
              "   {'score': 0.05113390159837424, 'word': 'high'},\n",
              "   {'score': 0.03699158295296434, 'word': 'artificial'},\n",
              "   {'score': 0.03699158295296434, 'word': 'neurons'}],\n",
              "  'Title': 'Visualizing the Hidden Activity of Artificial Neural Networks',\n",
              "  'distance': 0,\n",
              "  'no': '402',\n",
              "  'parent': '4243'},\n",
              " {'Abstract': 'The VolVis system has been developed to satisfy the diverse requirements of the volume visualization community by comfortably housing numerous visualization algorithms and methods within a consistent and well organized framework. The VolVis system is supported by a generalized abstract model which provides for both geometric and volumetric constructs. VolVis contains several rendering algorithms that span the speed versus accuracy continuum. A fast volume rendering algorithm has been developed, which is capable of exploiting existing graphics hardware without placing any viewing restrictions or compromising accuracy. In addition, VolVis includes a volumetric navigation facility, key-frame animation generator, quantitative analysis tools, and a generalized protocol for communicating with 3D input devices.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17650104800548083, 'word': 'volvis'},\n",
              "   {'score': 0.12439582563660871, 'word': 'system'},\n",
              "   {'score': 0.057034936297441025, 'word': 'algorithms'},\n",
              "   {'score': 0.05449765178171666, 'word': 'accuracy'},\n",
              "   {'score': 0.05449765178171666, 'word': 'continuum'},\n",
              "   {'score': 0.04352895881000607, 'word': 'organized'},\n",
              "   {'score': 0.04352895881000607, 'word': 'framework'}],\n",
              "  'Title': 'Towards a comprehensive volume visualization system',\n",
              "  'distance': 0,\n",
              "  'no': '403',\n",
              "  'parent': '3415'},\n",
              " {'Abstract': 'The paper describes major concepts of a scalable information visualization framework. We assume that the exploration of heterogeneous information spaces at arbitrary levels of detail requires a suitable preprocessing of information quantities, the combination of different graphical interfaces and the illustration of the frame of reference of given information sets. The innovative features of our system include: dynamic hierarchy computation and user controlled refinement of those hierarchies for preprocessing unstructured information spaces; a new Focus+Context technique for visualizing complex hierarchy graphs; a new paradigm for visualizing information structures within their frame of reference; and a new graphical interface that utilizes textual similarities to arrange objects of high dimensional information space in 3-dimensional visualization space.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14823510165605788, 'word': 'information'},\n",
              "   {'score': 0.07687377563504248, 'word': 'quantities'},\n",
              "   {'score': 0.0713613260210154, 'word': 'heterogeneous'},\n",
              "   {'score': 0.0713613260210154, 'word': 'spaces'},\n",
              "   {'score': 0.05946597046846934, 'word': 'dynamic'},\n",
              "   {'score': 0.05946597046846934, 'word': 'hierarchy'},\n",
              "   {'score': 0.05946597046846934, 'word': 'computation'},\n",
              "   {'score': 0.052028604939905354, 'word': 'different'},\n",
              "   {'score': 0.052028604939905354, 'word': 'graphical'},\n",
              "   {'score': 0.052028604939905354, 'word': 'interfaces'},\n",
              "   {'score': 0.047556299575632205, 'word': 'frame'}],\n",
              "  'Title': 'A scalable framework for information visualization',\n",
              "  'distance': 0,\n",
              "  'no': '404',\n",
              "  'parent': '4863'},\n",
              " {'Abstract': 'WEAVE (Workbench Environment for Analysis and Visual Exploration) is an environment for creating interactive visualization applications. WEAVE differs from previous systems in that it provides transparent linking between custom 3D visualizations and multidimensional statistical representations, and provides interactive color brushing between all visualizations. The authors demonstrate how WEAVE can be used to rapidly prototype a biomedical application, weaving together simulation data, measurement data, and 3D anatomical data concerning the propagation of excitation in the heart. These linked statistical and custom three-dimensional visualizations of the heart can allow scientists to more effectively study the correspondence of structure and behavior.',\n",
              "  'AuthorKeywords': ['visualization,',\n",
              "   'medical,',\n",
              "   'heart,',\n",
              "   'data',\n",
              "   'synthesis'],\n",
              "  'MultipartiteRank': [{'score': 0.11567550300517299, 'word': 'weave'},\n",
              "   {'score': 0.1060436935230374, 'word': 'visual'},\n",
              "   {'score': 0.1060436935230374, 'word': 'exploration'},\n",
              "   {'score': 0.07942811374925399, 'word': 'workbench'},\n",
              "   {'score': 0.07942811374925399, 'word': 'environment'},\n",
              "   {'score': 0.053058701889540476, 'word': 'analysis'},\n",
              "   {'score': 0.04593411165173709, 'word': 'multidimensional'},\n",
              "   {'score': 0.04593411165173709, 'word': 'statistical'},\n",
              "   {'score': 0.04593411165173709, 'word': 'representations'}],\n",
              "  'Title': 'WEAVE: a system for visually linking 3-D and statistical visualizations applied to cardiac simulation and measurement data',\n",
              "  'distance': 0,\n",
              "  'no': '405',\n",
              "  'parent': '3563'},\n",
              " {'Abstract': 'Artificial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well defined criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more efficient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classification task.',\n",
              "  'AuthorKeywords': ['Artificial',\n",
              "   'Neural',\n",
              "   'Network,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Visualization',\n",
              "   'Application,',\n",
              "   'Classification,',\n",
              "   'Machine',\n",
              "   'Learning'],\n",
              "  'MultipartiteRank': [{'score': 0.2744426016183652, 'word': 'neural'},\n",
              "   {'score': 0.2744426016183652, 'word': 'networks'},\n",
              "   {'score': 0.21535937789561682, 'word': 'artificial'},\n",
              "   {'score': 0.0985943847473503, 'word': 'computer'},\n",
              "   {'score': 0.0985943847473503, 'word': 'software'},\n",
              "   {'score': 0.06696874066395204, 'word': 'hardware'},\n",
              "   {'score': 0.06696874066395204, 'word': 'models'},\n",
              "   {'score': 0.04996537629057933, 'word': 'behavior'}],\n",
              "  'Title': 'Opening the black box - data driven visualization of neural networks',\n",
              "  'distance': 0,\n",
              "  'no': '406',\n",
              "  'parent': '4650'},\n",
              " {'Abstract': 'We address the problem of filtering, selecting and placing labels on a dynamic map, which is characterized by continuous zooming and panning capabilities. This consists of two interrelated issues. The first is to avoid label popping and other artifacts that cause confusion and interrupt navigation, and the second is to label at interactive speed. In most formulations the static map labeling problem is NP-hard, and a fast approximation might have O(n log n) complexity. Even this is too slow during interaction, when the number of labels shown can be several orders of magnitude less than the number in the map. In this paper we introduce a set of desiderata for \"consistent\" dynamic map labeling, which has qualities desirable for navigation. We develop a new framework for dynamic labeling that achieves the desiderata and allows for fast interactive display by moving all of the selection and placement decisions into the preprocessing phase. This framework is general enough to accommodate a variety of selection and placement algorithms. It does not appear possible to achieve our desiderata using previous frameworks. Prior to this paper, there were no formal models of dynamic maps or of dynamic labels; our paper introduces both. We formulate a general optimization problem for dynamic map labeling and give a solution to a simple version of the problem. The simple version is based on label priorities and a versatile and intuitive class of dynamic label placements we call \"invariant point placements\". Despite these restrictions, our approach gives a useful and practical solution. Our implementation is incorporated into the G-Vis system which is a full-detail dynamic map of the continental USA. This demo is available through any browser',\n",
              "  'AuthorKeywords': ['Map',\n",
              "   'labeling,',\n",
              "   'dynamic',\n",
              "   'maps,',\n",
              "   'human-computer',\n",
              "   'interface,',\n",
              "   'label',\n",
              "   'placement,',\n",
              "   'label',\n",
              "   'selection,',\n",
              "   'label',\n",
              "   'filtering,',\n",
              "   'label',\n",
              "   'consistency,computational',\n",
              "   'cartography,',\n",
              "   'GIS,',\n",
              "   'HCI,',\n",
              "   'realtime,',\n",
              "   'preprocessing'],\n",
              "  'MultipartiteRank': [{'score': 0.08814127897671359, 'word': 'labels'},\n",
              "   {'score': 0.04328383640889513, 'word': 'dynamic'},\n",
              "   {'score': 0.04328383640889513, 'word': 'map'},\n",
              "   {'score': 0.033464368453578544, 'word': 'interactive'},\n",
              "   {'score': 0.033464368453578544, 'word': 'speed'},\n",
              "   {'score': 0.030698778815390793, 'word': 'number'},\n",
              "   {'score': 0.030646160055041095, 'word': 'new'},\n",
              "   {'score': 0.030646160055041095, 'word': 'framework'}],\n",
              "  'Title': 'Dynamic Map Labeling',\n",
              "  'distance': 0,\n",
              "  'no': '407',\n",
              "  'parent': '5978'},\n",
              " {'Abstract': 'We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets',\n",
              "  'AuthorKeywords': ['Visualization,', 'multifield,', 'correlation'],\n",
              "  'MultipartiteRank': [{'score': 0.1422331696718306, 'word': 'correlations'},\n",
              "   {'score': 0.07071728839519366, 'word': 'scalar'},\n",
              "   {'score': 0.07071728839519366, 'word': 'fields'},\n",
              "   {'score': 0.06634033642333996, 'word': 'approach'},\n",
              "   {'score': 0.056870145567883154, 'word': 'selection'},\n",
              "   {'score': 0.046683851950957096, 'word': 'huge'},\n",
              "   {'score': 0.046683851950957096, 'word': 'number'}],\n",
              "  'Title': 'Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data',\n",
              "  'distance': 0,\n",
              "  'no': '408',\n",
              "  'parent': '4020'},\n",
              " {'Abstract': 'Scientific visualization and illustration tools are designed to help people understand the structure and complexity of scientific data with images that are as informative and intuitive as possible. In this context the use of metaphors plays an important role since they make complex information easily accessible by using commonly known concepts. In this paper we propose a new metaphor, called \"topological landscapes,\" which facilitates understanding the topological structure of scalar functions. The basic idea is to construct a terrain with the same topology as a given dataset and to display the terrain as an easily understood representation of the actual input data. In this projection from an n-dimensional scalar function to a two-dimensional (2D) model we preserve function values of critical points, the persistence (function span) of topological features, and one possible additional metric property (in our examples volume). By displaying this topologically equivalent landscape together with the original data we harness the natural human proficiency in understanding terrain topography and make complex topological information easily accessible.',\n",
              "  'AuthorKeywords': ['Feature',\n",
              "   'Detection,',\n",
              "   'User',\n",
              "   'Interfaces,',\n",
              "   'Visual',\n",
              "   'Analytics,',\n",
              "   'Contour',\n",
              "   'Tree,',\n",
              "   'Terrain,',\n",
              "   'Topology,',\n",
              "   'SOAR'],\n",
              "  'MultipartiteRank': [{'score': 0.08621604539449544, 'word': 'complexity'},\n",
              "   {'score': 0.057963758038061294, 'word': 'structure'},\n",
              "   {'score': 0.04989244489905152, 'word': 'scientific'},\n",
              "   {'score': 0.04989244489905152, 'word': 'data'},\n",
              "   {'score': 0.045219064233061504, 'word': 'scalar'},\n",
              "   {'score': 0.045219064233061504, 'word': 'functions'},\n",
              "   {'score': 0.04070654788959661, 'word': 'metaphors'}],\n",
              "  'Title': 'Topological Landscapes: A Terrain Metaphor for Scientific Data',\n",
              "  'distance': 0,\n",
              "  'no': '409',\n",
              "  'parent': '4475'},\n",
              " {'Abstract': 'Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation.',\n",
              "  'AuthorKeywords': ['Interaction,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Framework,',\n",
              "   'Interface',\n",
              "   'Evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.10943868335600976, 'word': 'costs'},\n",
              "   {'score': 0.07652445424542276, 'word': 'interaction'},\n",
              "   {'score': 0.07652445424542276, 'word': 'cost'},\n",
              "   {'score': 0.05832057142159074, 'word': 'framework'},\n",
              "   {'score': 0.046145513981629215, 'word': 'visualization'},\n",
              "   {'score': 0.046145513981629215, 'word': 'design'},\n",
              "   {'score': 0.03738026683122066, 'word': 'study'}],\n",
              "  'Title': 'A Framework of Interaction Costs in Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '410',\n",
              "  'parent': '4094'},\n",
              " {'Abstract': 'Typical scientific data is represented on a grid with appropriate interpolation or approximation schemes,defined on a continuous domain. The visualization of such data in parallel coordinates may reveal patterns latently contained in the data and thus can improve the understanding of multidimensional relations. In this paper, we adopt the concept of continuous scatterplots for the visualization of spatially continuous input data to derive a density model for parallel coordinates. Based on the point-line duality between scatterplots and parallel coordinates, we propose a mathematical model that maps density from a continuous scatterplot to parallel coordinates and present different algorithms for both numerical and analytical computation of the resulting density field. In addition, we show how the 2-D model can be used to successively construct continuous parallel coordinates with an arbitrary number of dimensions. Since continuous parallel coordinates interpolate data values within grid cells, a scalable and dense visualization is achieved, which will be demonstrated for typical multi-variate scientific data.',\n",
              "  'AuthorKeywords': ['Parallel',\n",
              "   'coordinates,',\n",
              "   'integrating',\n",
              "   'spatial',\n",
              "   'and',\n",
              "   'non-spatial',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'multi-variate',\n",
              "   'visualization,',\n",
              "   'interpolation'],\n",
              "  'MultipartiteRank': [{'score': 0.12527284072220946, 'word': 'typical'},\n",
              "   {'score': 0.12527284072220946, 'word': 'scientific'},\n",
              "   {'score': 0.12527284072220946, 'word': 'data'},\n",
              "   {'score': 0.0882085369459597, 'word': 'parallel'},\n",
              "   {'score': 0.0882085369459597, 'word': 'coordinates'},\n",
              "   {'score': 0.05774530836357012, 'word': 'continuous'},\n",
              "   {'score': 0.05774530836357012, 'word': 'scatterplots'},\n",
              "   {'score': 0.05160535673352551, 'word': 'grid'},\n",
              "   {'score': 0.049432997488295626, 'word': 'visualization'}],\n",
              "  'Title': 'Continuous Parallel Coordinates',\n",
              "  'distance': 0,\n",
              "  'no': '411',\n",
              "  'parent': '3670'},\n",
              " {'Abstract': \"Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.\",\n",
              "  'AuthorKeywords': ['Hierarchy',\n",
              "   'visualization,',\n",
              "   'node-link',\n",
              "   'layout,',\n",
              "   'eye',\n",
              "   'tracking,',\n",
              "   'user',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.10312334425883218, 'word': 'node'},\n",
              "   {'score': 0.06261370981631706, 'word': 'link'},\n",
              "   {'score': 0.06261370981631706, 'word': 'diagrams'},\n",
              "   {'score': 0.0457385687696214, 'word': 'effective'},\n",
              "   {'score': 0.038765412311801216, 'word': 'eye'},\n",
              "   {'score': 0.038765412311801216, 'word': 'tracking'},\n",
              "   {'score': 0.038765412311801216, 'word': 'experiment'},\n",
              "   {'score': 0.03816576786145925, 'word': 'layouts'}],\n",
              "  'Title': 'Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study',\n",
              "  'distance': 0,\n",
              "  'no': '412',\n",
              "  'parent': '5084'},\n",
              " {'Abstract': \"Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'analytics,',\n",
              "   'human',\n",
              "   'computer',\n",
              "   'interaction,',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'active',\n",
              "   'learning,',\n",
              "   'classification,',\n",
              "   'user',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.07459030844640323, 'word': 'exhaustive'},\n",
              "   {'score': 0.07459030844640323, 'word': 'searches'},\n",
              "   {'score': 0.047606724897666736, 'word': 'machine'},\n",
              "   {'score': 0.047606724897666736, 'word': 'learning'},\n",
              "   {'score': 0.03899927341990373, 'word': 'analyst'},\n",
              "   {'score': 0.035619942796908756, 'word': 'large'},\n",
              "   {'score': 0.035619942796908756, 'word': 'number'},\n",
              "   {'score': 0.032801320012799284, 'word': 'classifier'}],\n",
              "  'Title': 'Visual Classifier Training for Text Document Retrieval',\n",
              "  'distance': 0,\n",
              "  'no': '413',\n",
              "  'parent': '5506'},\n",
              " {'Abstract': 'An empirical comparison of three commercial information visualization systems on three different databases is presented. The systems use different paradigms for visualizing data. Tasks were selected to be \"ecologically relevant\", i.e. meaningful and interesting in the respec- tive domains. Users of one system turned out to solve problems significantly faster than users of the other two, while users of another system would supply significantly more correct answers. Reasons for these results and general observations about the studied systems are discussed.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.19269730165209992, 'word': 'systems'},\n",
              "   {'score': 0.101807470184104, 'word': 'users'},\n",
              "   {'score': 0.08360932666607274, 'word': 'different'},\n",
              "   {'score': 0.08360932666607274, 'word': 'databases'},\n",
              "   {'score': 0.05558017406937729, 'word': 'respec-'},\n",
              "   {'score': 0.05558017406937729, 'word': 'tive'},\n",
              "   {'score': 0.05558017406937729, 'word': 'domains'},\n",
              "   {'score': 0.053545292110308715, 'word': 'commercial'},\n",
              "   {'score': 0.053545292110308715, 'word': 'information'},\n",
              "   {'score': 0.053545292110308715, 'word': 'visualization'}],\n",
              "  'Title': 'An empirical comparison of three commercial information visualization systems',\n",
              "  'distance': 0,\n",
              "  'no': '414',\n",
              "  'parent': '3542'},\n",
              " {'Abstract': 'The authors propose three simple, but significant improvements to the OoCS (Out-of-Core Simplification) algorithm of P. Lindstrom (2000) which increase the quality of approximations and extend the applicability of the algorithm to an even larger class of compute systems. The original OoCS algorithm has memory complexity that depends on the size of the output mesh, but no dependency on the size of the input mesh. That is, it can be used to simplify meshes of arbitrarily large size, but the complexity of the output mesh is limited by the amount of memory available. Our first contribution is a version of OoCS that removes the dependency of having enough memory to hold (even) the simplified mesh. With our new algorithm, the whole process is made essentially independent of the available memory on the host computer. Our new technique uses disk instead of main memory, but it is carefully designed to avoid costly random accesses. Our two other contributions improve the quality of the approximations generated by OoCS. We propose a scheme for preserving surface boundaries which does not use connectivity information, and a scheme for constraining the position of the \"representative vertex\" of a grid cell to an optimal position inside the cell.',\n",
              "  'AuthorKeywords': ['polygonal',\n",
              "   'surface',\n",
              "   'simplification,',\n",
              "   'large',\n",
              "   'data,',\n",
              "   'out-of-core',\n",
              "   'algorithms,',\n",
              "   'external',\n",
              "   'sorting,',\n",
              "   'quadric',\n",
              "   'error',\n",
              "   'metrics'],\n",
              "  'MultipartiteRank': [{'score': 0.06595366449301746, 'word': 'output'},\n",
              "   {'score': 0.06595366449301746, 'word': 'mesh'},\n",
              "   {'score': 0.06501416796780145, 'word': 'oocs'},\n",
              "   {'score': 0.0543469793231553, 'word': 'memory'},\n",
              "   {'score': 0.0543469793231553, 'word': 'available'},\n",
              "   {'score': 0.04737444070186236, 'word': 'size'},\n",
              "   {'score': 0.043015784283718224, 'word': 'algorithm'}],\n",
              "  'Title': 'A memory insensitive technique for large model simplification',\n",
              "  'distance': 0,\n",
              "  'no': '415',\n",
              "  'parent': '5878'},\n",
              " {'Abstract': 'In this paper we present a hardware-assisted rendering technique coupled with a compression scheme for the interactive visual exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3-D graphics card. Using a single PC equipped with a modest amount of memory, a texture capable graphics card, and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 45 millions voxels each time step) at interactive rates, permitting the visual exploration of large scientific data sets in both the temporal and spatial domain.',\n",
              "  'AuthorKeywords': ['Compression,',\n",
              "   'high',\n",
              "   'performance',\n",
              "   'computing,',\n",
              "   'out-of-core',\n",
              "   'processing,',\n",
              "   'PC,',\n",
              "   'scientific',\n",
              "   'visualization,',\n",
              "   'texture',\n",
              "   'hardware,',\n",
              "   'time-varying',\n",
              "   'data,',\n",
              "   'transform',\n",
              "   'encoding,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.08585860094453139, 'word': 'time'},\n",
              "   {'score': 0.07096464540511647, 'word': 'interactive'},\n",
              "   {'score': 0.07096464540511647, 'word': 'visual'},\n",
              "   {'score': 0.07096464540511647, 'word': 'exploration'},\n",
              "   {'score': 0.06779913601646884, 'word': 'rendering'},\n",
              "   {'score': 0.06779913601646884, 'word': 'technique'},\n",
              "   {'score': 0.06263138123170557, 'word': 'scalar'},\n",
              "   {'score': 0.06263138123170557, 'word': 'volume'},\n",
              "   {'score': 0.06263138123170557, 'word': 'data'},\n",
              "   {'score': 0.054651761035788365, 'word': 'graphics'},\n",
              "   {'score': 0.054651761035788365, 'word': 'card'}],\n",
              "  'Title': 'Texture Hardware Assisted Rendering of Time-Varying Volume Data',\n",
              "  'distance': 0,\n",
              "  'no': '416',\n",
              "  'parent': '3958'},\n",
              " {'Abstract': 'Traditionally, node link diagrams are the prime choice when it comes to visualizing software architectures. However, node link diagrams often fall short when used to visualize large graph structures. In this paper we investigate the use of call matrices as visual aids in the management of large software projects. We argue that call matrices have a number of advantages over traditional node link diagrams when the main object of interest is the link instead of the node. Matrix visualizations can provide stable and crisp layouts of large graphs and are inherently well suited for large multilevel visualizations because of their recursive structure. We discuss a number of visualization issues, using a very large software project currently under development at Philips Medical Systems as a running example.',\n",
              "  'AuthorKeywords': ['software',\n",
              "   'visualization,',\n",
              "   'multilevel',\n",
              "   'visualization,',\n",
              "   'call',\n",
              "   'matrix'],\n",
              "  'MultipartiteRank': [{'score': 0.1064070251520153, 'word': 'node'},\n",
              "   {'score': 0.1064070251520153, 'word': 'link'},\n",
              "   {'score': 0.1064070251520153, 'word': 'diagrams'},\n",
              "   {'score': 0.09578264405962723, 'word': 'large'},\n",
              "   {'score': 0.07005717219734033, 'word': 'visual'},\n",
              "   {'score': 0.07005717219734033, 'word': 'aids'},\n",
              "   {'score': 0.061087149119952625, 'word': 'call'},\n",
              "   {'score': 0.061087149119952625, 'word': 'matrices'},\n",
              "   {'score': 0.04812953472114949, 'word': 'graph'},\n",
              "   {'score': 0.04812953472114949, 'word': 'structures'},\n",
              "   {'score': 0.047653109338477745, 'word': 'software'},\n",
              "   {'score': 0.047653109338477745, 'word': 'projects'}],\n",
              "  'Title': 'Using multilevel call matrices in large software projects',\n",
              "  'distance': 0,\n",
              "  'no': '417',\n",
              "  'parent': '4804'},\n",
              " {'Abstract': \"We present an efficient and automatic image-recoloring technique for dichromats that highlights important visual details that would otherwise be unnoticed by these individuals. While previous techniques approach this problem by potentially changing all colors of the original image, causing their results to look unnatural to color vision deficients, our approach preserves, as much as possible, the image's original colors. Our approach is about three orders of magnitude faster than previous ones. The results of a paired-comparison evaluation carried out with fourteen color-vision deficients (CVDs) indicated the preference of our technique over the state-of-the-art automatic recoloring technique for dichromats. When considering information visualization examples, the subjects tend to prefer our results over the original images. An extension of our technique that exaggerates color contrast tends to be preferred when CVDs compared pairs of scientific visualization images. These results provide valuable information for guiding the design of visualizations for color-vision deficients.\",\n",
              "  'AuthorKeywords': ['Color-contrast',\n",
              "   'enhancement,',\n",
              "   'Color-vision',\n",
              "   'deficiency,',\n",
              "   'Recoloring',\n",
              "   'algorithms,',\n",
              "   'Information',\n",
              "   'and',\n",
              "   'Scientific',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08894972626181395, 'word': 'automatic'},\n",
              "   {'score': 0.08894972626181395, 'word': 'image'},\n",
              "   {'score': 0.07610567276809085, 'word': 'technique'},\n",
              "   {'score': 0.07115227588504601, 'word': 'colors'},\n",
              "   {'score': 0.05402307535903882, 'word': 'results'},\n",
              "   {'score': 0.05203498014392384, 'word': 'important'},\n",
              "   {'score': 0.05203498014392384, 'word': 'visual'},\n",
              "   {'score': 0.05203498014392384, 'word': 'details'}],\n",
              "  'Title': 'An Efficient Naturalness-Preserving Image-Recoloring Method for Dichromats',\n",
              "  'distance': 0,\n",
              "  'no': '418',\n",
              "  'parent': '4441'},\n",
              " {'Abstract': 'Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.',\n",
              "  'AuthorKeywords': ['Storytelling,',\n",
              "   'data',\n",
              "   'presentation,',\n",
              "   'sketch,',\n",
              "   'pen',\n",
              "   'and',\n",
              "   'touch,',\n",
              "   'interaction,',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.12071971024130361, 'word': 'data'},\n",
              "   {'score': 0.07150785137413962, 'word': 'exploration'},\n",
              "   {'score': 0.0672086466629659, 'word': 'sketchstory'},\n",
              "   {'score': 0.0600908155436976, 'word': 'presenter'},\n",
              "   {'score': 0.054332456071284764, 'word': 'storytelling'},\n",
              "   {'score': 0.054332456071284764, 'word': 'medium'}],\n",
              "  'Title': 'SketchStory: Telling More Engaging Stories with Data through Freeform Sketching',\n",
              "  'distance': 0,\n",
              "  'no': '419',\n",
              "  'parent': '5258'},\n",
              " {'Abstract': 'How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.',\n",
              "  'AuthorKeywords': ['Social',\n",
              "   'media',\n",
              "   'visuaization,',\n",
              "   'topic',\n",
              "   'competition,',\n",
              "   'information',\n",
              "   'diffusion,',\n",
              "   'information',\n",
              "   'propagation,',\n",
              "   'agenda-setting'],\n",
              "  'MultipartiteRank': [{'score': 0.10251261296418193, 'word': 'various'},\n",
              "   {'score': 0.10251261296418193, 'word': 'topics'},\n",
              "   {'score': 0.07826863834630814, 'word': 'competitiveness'},\n",
              "   {'score': 0.05944237926356301, 'word': 'opinion'},\n",
              "   {'score': 0.05944237926356301, 'word': 'leaders'},\n",
              "   {'score': 0.05223898130253541, 'word': 'social'},\n",
              "   {'score': 0.05223898130253541, 'word': 'media'},\n",
              "   {'score': 0.04029130697727721, 'word': 'public'},\n",
              "   {'score': 0.04029130697727721, 'word': 'attention'}],\n",
              "  'Title': 'Visual Analysis of Topic Competition on Social Media',\n",
              "  'distance': 0,\n",
              "  'no': '420',\n",
              "  'parent': '4482'},\n",
              " {'Abstract': \"We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model's modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.\",\n",
              "  'AuthorKeywords': ['Neural',\n",
              "   'Network,Graph',\n",
              "   'Visualization,Dataflow',\n",
              "   'Graph,Clustered',\n",
              "   'Graph'],\n",
              "  'MultipartiteRank': [{'score': 0.07948151553015717, 'word': 'underlying'},\n",
              "   {'score': 0.07948151553015717, 'word': 'dataflow'},\n",
              "   {'score': 0.07948151553015717, 'word': 'graphs'},\n",
              "   {'score': 0.06364022251715044, 'word': 'hierarchical'},\n",
              "   {'score': 0.06364022251715044, 'word': 'structure'},\n",
              "   {'score': 0.06157056485929252, 'word': 'tensorflow'},\n",
              "   {'score': 0.06157056485929252, 'word': 'graph'},\n",
              "   {'score': 0.06157056485929252, 'word': 'visualizer'},\n",
              "   {'score': 0.05846047253731617, 'word': 'tool'},\n",
              "   {'score': 0.05687004852566063, 'word': 'users'}],\n",
              "  'Title': 'Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow',\n",
              "  'distance': 0,\n",
              "  'no': '421',\n",
              "  'parent': '4875'},\n",
              " {'Abstract': 'We present the use of mapping functions to automatically generate levels of detail with known error bounds for polygonal models. We develop a piece-wise linear mapping function for each simplification operation and use this function to measure deviation of the new surface from both the previous level of detail and from the original surface. In addition, we use the mapping function to compute appropriate texture coordinates if the original map has texture coordinates at its vertices. Our overall algorithm uses edge collapse operations. We present rigorous procedures for the generation of local planar projections as well as for the selection of a new vertex position for the edge collapse operation. As compared to earlier methods, our algorithm is able to compute tight error bounds on surface deviation and produce an entire continuum of levels of detail with mappings between them. We demonstrate the effectiveness of our algorithm on several models: a Ford Bronco consisting of over 300 parts and 70,000 triangles, a textured lion model consisting of 49 parts and 86,000 triangles, and a textured, wrinkled torus consisting of 79,000 triangles.',\n",
              "  'AuthorKeywords': ['model',\n",
              "   'simplification,levels-of-detail,',\n",
              "   'surface',\n",
              "   'approximation,',\n",
              "   'projection,',\n",
              "   'linear',\n",
              "   'programming'],\n",
              "  'MultipartiteRank': [{'score': 0.07088529520324101, 'word': 'mapping'},\n",
              "   {'score': 0.07088529520324101, 'word': 'functions'},\n",
              "   {'score': 0.056812901954365946, 'word': 'appropriate'},\n",
              "   {'score': 0.056812901954365946, 'word': 'texture'},\n",
              "   {'score': 0.056812901954365946, 'word': 'coordinates'},\n",
              "   {'score': 0.05271361555641896, 'word': 'detail'},\n",
              "   {'score': 0.051937094897302236, 'word': 'levels'},\n",
              "   {'score': 0.04371852507552911, 'word': 'overall'},\n",
              "   {'score': 0.04371852507552911, 'word': 'algorithm'}],\n",
              "  'Title': 'Simplifying polygonal models using successive mappings',\n",
              "  'distance': 0,\n",
              "  'no': '422',\n",
              "  'parent': '5365'},\n",
              " {'Abstract': 'Line integral convolution (LIC) is an effective technique for visualizing vector fields. The application of LIC to 3D flow fields has yet been limited by difficulties to efficiently display and animate the resulting 3D-images. Texture-based volume rendering allows interactive visualization and manipulation of 3D-LIC textures. In order to ensure the comprehensive and convenient exploration of flow fields, we suggest interactive functionality including transfer functions and different clipping mechanisms. Thereby, we efficiently substitute the calculation of LIC based on sparse noise textures and show the convenient visual access of interior structures. Further on, we introduce two approaches for animating static 3D-flow fields without the computational expense and the immense memory requirements for pre-computed 3D-textures and without loss of interactivity. This is achieved by using a single 3D-LIC texture and a set of time surfaces as clipping geometries. In our first approach we use the clipping geometry to pre-compute a special 3D-LIC texture that can be animated by time-dependent color tables. Our second approach uses time volumes to actually clip the 3D-LIC volume interactively during rasterization. Additionally, several examples demonstrate the value of our strategy in practice.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'Visualization,',\n",
              "   'Animated',\n",
              "   'LIC,',\n",
              "   'Direct',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   '3D-Textures',\n",
              "   'Mapping,',\n",
              "   'Interactive',\n",
              "   'Volume',\n",
              "   'Exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.10224239524567694, 'word': 'lic'},\n",
              "   {'score': 0.06966454771364672, 'word': 'vector'},\n",
              "   {'score': 0.06966454771364672, 'word': 'fields'},\n",
              "   {'score': 0.04411104328711196, 'word': 'interactive'},\n",
              "   {'score': 0.04411104328711196, 'word': 'visualization'},\n",
              "   {'score': 0.04337452890827722, 'word': 'texture'},\n",
              "   {'score': 0.03630267199499938, 'word': 'static'},\n",
              "   {'score': 0.03630267199499938, 'word': '3d'}],\n",
              "  'Title': 'Interactive exploration of volume line integral convolution based on 3D-texture mapping',\n",
              "  'distance': 0,\n",
              "  'no': '423',\n",
              "  'parent': '4639'},\n",
              " {'Abstract': 'Most analysts start with an overview of the data before gradually refining their view to be more focused and detailed. Multiscale pan-and-zoom systems are effective because they directly support this approach. However generating abstract overviews of large data sets is difficult, and most systems take advantage of only one type of abstraction: visual abstraction. Furthermore, these existing systems limit the analyst to a single zooming path on their data and thus a single set of abstract views. This paper presents: (1) a formalism for describing multiscale visualizations of data cubes with both data and visual abstraction, and (2) a method for independently zooming along one or more dimensions by traversing a zoom graph with nodes at different levels of detail. As an example of how to design multiscale visualizations using our system, we describe four design patterns using our formalism. These design patterns show the effectiveness of multiscale visualization of general relational databases.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09212007759641042, 'word': 'data'},\n",
              "   {'score': 0.07169892311708953, 'word': 'multiscale'},\n",
              "   {'score': 0.07169892311708953, 'word': 'pan'},\n",
              "   {'score': 0.07039673829098106, 'word': 'abstract'},\n",
              "   {'score': 0.07039673829098106, 'word': 'overviews'},\n",
              "   {'score': 0.05579223066114694, 'word': 'zoom'},\n",
              "   {'score': 0.05579223066114694, 'word': 'systems'},\n",
              "   {'score': 0.05246863682389852, 'word': 'detailed'}],\n",
              "  'Title': 'Multiscale visualization using data cubes',\n",
              "  'distance': 0,\n",
              "  'no': '424',\n",
              "  'parent': '4823'},\n",
              " {'Abstract': 'Large 2D information spaces, such as maps, images, or abstract visualizations, require views at various level of detail: close ups to inspect details, overviews to maintain (literally) an overview. Users often switch between these views. We discuss how smooth animations from one view to another can be defined. To this end, a metric on the effect of simultaneous zooming and panning is defined, based on an estimate of the perceived velocity. Optimal is defined as smooth and efficient. Given the metric, these terms can be translated into a computational model, which is used to calculate an analytic solution for optimal animations. The model has two free parameters: animation speed and zoom/pan trade off. A user experiment to find good values for these is described.',\n",
              "  'AuthorKeywords': ['Navigation,',\n",
              "   'zooming,',\n",
              "   'panning,',\n",
              "   'scrolling,',\n",
              "   'scale',\n",
              "   'space'],\n",
              "  'MultipartiteRank': [{'score': 0.07125666739342991, 'word': 'views'},\n",
              "   {'score': 0.0524925146089128, 'word': 'simultaneous'},\n",
              "   {'score': 0.0524925146089128, 'word': 'zooming'},\n",
              "   {'score': 0.05026312001044125, 'word': 'smooth'},\n",
              "   {'score': 0.05026312001044125, 'word': 'animations'},\n",
              "   {'score': 0.04983194936418667, 'word': 'metric'},\n",
              "   {'score': 0.04903112022696905, 'word': 'detail'}],\n",
              "  'Title': 'Smooth and efficient zooming and panning',\n",
              "  'distance': 0,\n",
              "  'no': '425',\n",
              "  'parent': '3773'},\n",
              " {'Abstract': 'In this paper we use advanced tensor visualization techniques to study 3D diffusion tensor MRI data of a heart. We use scalar and tensor glyph visualization methods to investigate the data and apply a moving least squares (MLS) fiber tracing method to recover and visualize the helical structure and the orientation of the heart muscle fibers.',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'tensors,',\n",
              "   'DT-MRI,',\n",
              "   'fiber',\n",
              "   'tracing,',\n",
              "   'adaptive',\n",
              "   'filtering,',\n",
              "   'moving',\n",
              "   'least',\n",
              "   'squares,',\n",
              "   'streamlines'],\n",
              "  'MultipartiteRank': [{'score': 0.20329491058486437, 'word': 'tensor'},\n",
              "   {'score': 0.12416210109806701, 'word': 'advanced'},\n",
              "   {'score': 0.12416210109806701, 'word': 'visualization'},\n",
              "   {'score': 0.12416210109806701, 'word': 'techniques'},\n",
              "   {'score': 0.10813652834525031, 'word': 'fiber'},\n",
              "   {'score': 0.0839733062434475, 'word': 'mls'},\n",
              "   {'score': 0.07913280948679738, 'word': '3d'},\n",
              "   {'score': 0.07913280948679738, 'word': 'diffusion'},\n",
              "   {'score': 0.07913280948679738, 'word': 'mri'},\n",
              "   {'score': 0.07913280948679738, 'word': 'data'},\n",
              "   {'score': 0.07315939379528234, 'word': 'least'},\n",
              "   {'score': 0.07315939379528234, 'word': 'squares'}],\n",
              "  'Title': 'Heart-muscle fiber reconstruction from diffusion tensor MRI',\n",
              "  'distance': 0,\n",
              "  'no': '426',\n",
              "  'parent': '3344'},\n",
              " {'Abstract': 'This paper presents an algorithm for drawing a sequence of graphs that contain an inherent grouping of their vertex set into clusters. It differs from previous work on dynamic graph drawing in the emphasis that is put on maintaining the clustered structure of the graph during incremental layout. The algorithm works online and allows arbitrary modifications to the graph. It is generic and can be implemented using a wide range of static force-directed graph layout tools. The paper introduces several metrics for measuring layout quality of dynamic clustered graphs. The performance of our algorithm is analyzed using these metrics. The algorithm has been successfully applied to visualizing mobile object software',\n",
              "  'AuthorKeywords': ['graph',\n",
              "   'drawing,',\n",
              "   'dynamic',\n",
              "   'layout,',\n",
              "   'mobile',\n",
              "   'objects,',\n",
              "   'software',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.13137188870003186, 'word': 'graphs'},\n",
              "   {'score': 0.08438990545850329, 'word': 'algorithm'},\n",
              "   {'score': 0.06820605384555031, 'word': 'dynamic'},\n",
              "   {'score': 0.06820605384555031, 'word': 'graph'},\n",
              "   {'score': 0.06820605384555031, 'word': 'drawing'},\n",
              "   {'score': 0.06335261900738572, 'word': 'clusters'},\n",
              "   {'score': 0.06279066894266794, 'word': 'incremental'},\n",
              "   {'score': 0.06279066894266794, 'word': 'layout'}],\n",
              "  'Title': 'Dynamic Drawing of Clustered Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '427',\n",
              "  'parent': '3972'},\n",
              " {'Abstract': \"An important task in volume rendering is the visualization of boundaries between materials. This is typically accomplished using transfer functions that increase opacity based on a voxel's value and gradient. Lighting also plays a crucial role in illustrating surfaces. In this paper we present a multi-dimensional transfer function method for enhancing surfaces, not through the variation of opacity, but through the modification of surface shading. The technique uses a lighting transfer function that takes into account the distribution of values along a material boundary and features a novel interface for visualizing and specifying these transfer functions. With our method, the user is given a means of visualizing boundaries without modifying opacity, allowing opacity to be used for illustrating the thickness of homogeneous materials through the absorption of light.\",\n",
              "  'AuthorKeywords': ['direct',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'multi-dimensional',\n",
              "   'transfer',\n",
              "   'functions,',\n",
              "   'shading,',\n",
              "   'transfer',\n",
              "   'functions'],\n",
              "  'MultipartiteRank': [{'score': 0.07985298676166525, 'word': 'opacity'},\n",
              "   {'score': 0.07901201820593241, 'word': 'boundaries'},\n",
              "   {'score': 0.06317323264310329, 'word': 'transfer'},\n",
              "   {'score': 0.06317323264310329, 'word': 'functions'},\n",
              "   {'score': 0.06180300092112523, 'word': 'surfaces'},\n",
              "   {'score': 0.056611685563625995, 'word': 'value'}],\n",
              "  'Title': 'Lighting transfer functions using gradient aligned sampling',\n",
              "  'distance': 0,\n",
              "  'no': '428',\n",
              "  'parent': '4547'},\n",
              " {'Abstract': 'In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics',\n",
              "  'AuthorKeywords': ['Illustrative',\n",
              "   'visualization,',\n",
              "   'Illustrative',\n",
              "   'manipulation,',\n",
              "   'GPU',\n",
              "   'computing,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'deformation,',\n",
              "   'computerassisted',\n",
              "   'medical',\n",
              "   'illustration'],\n",
              "  'MultipartiteRank': [{'score': 0.059125966570274587, 'word': 'technique'},\n",
              "   {'score': 0.035021087891814136, 'word': 'interactive'},\n",
              "   {'score': 0.035021087891814136, 'word': 'manipulation'},\n",
              "   {'score': 0.034191621952735715, 'word': 'illustrative'},\n",
              "   {'score': 0.034191621952735715, 'word': 'visualization'},\n",
              "   {'score': 0.03413084079887611, 'word': 'medical'},\n",
              "   {'score': 0.03413084079887611, 'word': 'illustrations'},\n",
              "   {'score': 0.033411110454319146, 'word': 'alignment'}],\n",
              "  'Title': 'Feature Aligned Volume Manipulation for Illustration and Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '429',\n",
              "  'parent': '4366'},\n",
              " {'Abstract': \"The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.\",\n",
              "  'AuthorKeywords': ['Cognition,',\n",
              "   'visualization',\n",
              "   'theory,',\n",
              "   'metaphors,',\n",
              "   'hierarchies,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.1394450109574611, 'word': 'visual'},\n",
              "   {'score': 0.1394450109574611, 'word': 'metaphors'},\n",
              "   {'score': 0.10106267414160608, 'word': 'visualization'},\n",
              "   {'score': 0.058945489609404475, 'word': 'user'},\n",
              "   {'score': 0.05583269030286384, 'word': 'verbal'},\n",
              "   {'score': 0.05583269030286384, 'word': 'metaphor'},\n",
              "   {'score': 0.054682856597118794, 'word': 'information'}],\n",
              "  'Title': 'The Shaping of Information by Visual Metaphors',\n",
              "  'distance': 0,\n",
              "  'no': '430',\n",
              "  'parent': '5139'},\n",
              " {'Abstract': \"A new algorithm for identifying vortices in complex flows is presented. The scheme uses both the vorticity and pressure fields. A skeleton line along the center of a vortex is produced by a two-step predictor-corrector scheme. The technique uses the vector field to move in the direction of the skeleton line and the scalar field to correct the location in the plane perpendicular to the skeleton line. With an economical description of the vortex tube's cross-section, the skeleton compresses the representation of the flow by a factor of 4000 or more. We show how the reconstructed geometry of vortex tubes can be enhanced to help visualize helical motion.&lt;&lt;ETX&gt;&gt;\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1077214566999746, 'word': 'skeleton'},\n",
              "   {'score': 0.1077214566999746, 'word': 'line'},\n",
              "   {'score': 0.09638703285261992, 'word': 'pressure'},\n",
              "   {'score': 0.09638703285261992, 'word': 'fields'},\n",
              "   {'score': 0.09196672113522036, 'word': 'vortices'},\n",
              "   {'score': 0.071912522256966, 'word': 'scheme'},\n",
              "   {'score': 0.06688274793993863, 'word': 'vortex'}],\n",
              "  'Title': 'Vortex tubes in turbulent flows: identification, representation, reconstruction',\n",
              "  'distance': 0,\n",
              "  'no': '431',\n",
              "  'parent': '3502'},\n",
              " {'Abstract': \"To gain insight and understanding of complex information collections, users must be able to visualize and explore many facets of the information. The paper presents several novel visual methods from an information analyst's perspective. The authors present a sample scenario, using the various methods to gain a variety of insights from a large information collection. They conclude that no single paradigm or visual method is sufficient for many analytical tasks. Often a suite of integrated methods offers a better analytic environment in today's emerging culture of information overload and rapidly changing issues. They also conclude that the interactions among these visual paradigms are equally as important as, if not more important than, the paradigms themselves.\",\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'scenario,information',\n",
              "   'analysis,',\n",
              "   'document',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.13056398068934746, 'word': 'complex'},\n",
              "   {'score': 0.13056398068934746, 'word': 'information'},\n",
              "   {'score': 0.13056398068934746, 'word': 'collections'},\n",
              "   {'score': 0.08786198013634268, 'word': 'several'},\n",
              "   {'score': 0.08786198013634268, 'word': 'novel'},\n",
              "   {'score': 0.08786198013634268, 'word': 'visual'},\n",
              "   {'score': 0.08786198013634268, 'word': 'methods'},\n",
              "   {'score': 0.05623053213705575, 'word': 'insight'},\n",
              "   {'score': 0.048932538549812776, 'word': 'users'},\n",
              "   {'score': 0.04744934489744736, 'word': 'understanding'}],\n",
              "  'Title': 'Multi-faceted insight through interoperable visual information analysis paradigms',\n",
              "  'distance': 0,\n",
              "  'no': '432',\n",
              "  'parent': '4446'},\n",
              " {'Abstract': 'Splatting is a volume rendering algorithm that combines efficient volume projection with a sparse data representation. Only voxels that have values inside the iso-range need to be considered, and these voxels can be projected via efficient rasterization schemes. In splatting, each projected voxel is represented as a radially symmetric interpolation kernel, equivalent to a fuzzy ball. Projecting such a basis function leaves a fuzzy impression, called a footprint or splat, on the screen. Splatting traditionally classifies and shades the voxels prior to projection, and thus each voxel footprint is weighted by the assigned voxel color and opacity. Projecting these fuzzy color balls provides a uniform screen image for homogeneous object regions, but leads to a blurry appearance of object edges. The latter is clearly undesirable, especially when the view is zoomed on the object. In this work, we manipulate the rendering pipeline of splatting by performing the classification and shading process after the voxels have been projected onto the screen. In this way volume contributions outside the iso-range never affect the image. Since shading requires gradients, we not only splat the density volume, using regular splats, but we also project the gradient volume, using gradient splats. However alternative to gradient splats, we can also compute the gradients on the projection plane using central differencing. This latter scheme cuts the number of footprint rasterization by a factor of four since only the voxel densities have to be projected.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10896136839541717, 'word': 'splatting'},\n",
              "   {'score': 0.08086632473787844, 'word': 'voxels'},\n",
              "   {'score': 0.08051911354071463, 'word': 'volume'},\n",
              "   {'score': 0.04127296285813766, 'word': 'fuzzy'},\n",
              "   {'score': 0.04127296285813766, 'word': 'ball'},\n",
              "   {'score': 0.04074732725585254, 'word': 'efficient'},\n",
              "   {'score': 0.04074732725585254, 'word': 'projection'}],\n",
              "  'Title': 'Splatting without the blur',\n",
              "  'distance': 0,\n",
              "  'no': '433',\n",
              "  'parent': '5151'},\n",
              " {'Abstract': \"We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a 'binning' technique is very fast and yet approaches the accuracy of the more expensive 'true' complete measurement\",\n",
              "  'AuthorKeywords': ['Sampling,',\n",
              "   'random',\n",
              "   'sampling,',\n",
              "   'lens,',\n",
              "   'clutter,',\n",
              "   'occlusion,',\n",
              "   'density',\n",
              "   'reduction,',\n",
              "   'overplotting,',\n",
              "   'information',\n",
              "   'visualisation,',\n",
              "   'parallel',\n",
              "   'coordinates'],\n",
              "  'MultipartiteRank': [{'score': 0.11891704978268228, 'word': 'sampling'},\n",
              "   {'score': 0.09066710744343925, 'word': 'occlusion'},\n",
              "   {'score': 0.05993684581558609, 'word': 'lens'},\n",
              "   {'score': 0.05968672026357736, 'word': 'efficient'},\n",
              "   {'score': 0.05968672026357736, 'word': 'method'},\n",
              "   {'score': 0.0589802039670962, 'word': 'random'},\n",
              "   {'score': 0.049641447877851214, 'word': 'accuracy'}],\n",
              "  'Title': 'Enabling Automatic Clutter Reduction in Parallel Coordinate Plots',\n",
              "  'distance': 0,\n",
              "  'no': '434',\n",
              "  'parent': '4034'},\n",
              " {'Abstract': 'We extend the popular force-directed approach to network (or graph) layout to allow separation constraints, which enforce a minimum horizontal or vertical separation between selected pairs of nodes. This simple class of linear constraints is expressive enough to satisfy a wide variety of application-specific layout requirements, including: layout of directed graphs to better show flow; layout with non-overlapping node labels; and layout of graphs with grouped nodes (called clusters). In the stress majorization force-directed layout process, separation constraints can be treated as a quadratic programming problem. We give an incremental algorithm based on gradient projection for efficiently solving this problem. The algorithm is considerably faster than using generic constraint optimization techniques and is comparable in speed to unconstrained stress majorization. We demonstrate the utility of our technique with sample data from a number of practical applications including gene-activation networks, terrorist networks and visualization of high-dimensional data.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'drawing,',\n",
              "   'constraints,',\n",
              "   'stress',\n",
              "   'majorization,',\n",
              "   'force',\n",
              "   'directed',\n",
              "   'algorithms,multidimensional',\n",
              "   'scaling'],\n",
              "  'MultipartiteRank': [{'score': 0.07845850282280536, 'word': 'specific'},\n",
              "   {'score': 0.07845850282280536, 'word': 'layout'},\n",
              "   {'score': 0.07845850282280536, 'word': 'requirements'},\n",
              "   {'score': 0.05422256012062121, 'word': 'separation'},\n",
              "   {'score': 0.05422256012062121, 'word': 'constraints'},\n",
              "   {'score': 0.05306069498854943, 'word': 'graph'},\n",
              "   {'score': 0.0474035216012814, 'word': 'application'},\n",
              "   {'score': 0.042724507262320965, 'word': 'network'}],\n",
              "  'Title': 'IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '435',\n",
              "  'parent': '3797'},\n",
              " {'Abstract': 'Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.',\n",
              "  'AuthorKeywords': ['Uncertainty,',\n",
              "   'Data',\n",
              "   'Transformations,',\n",
              "   'Principal',\n",
              "   'Component',\n",
              "   'Analysis,',\n",
              "   'Model',\n",
              "   'fitting'],\n",
              "  'MultipartiteRank': [{'score': 0.08612776112863693, 'word': 'visual'},\n",
              "   {'score': 0.08612776112863693, 'word': 'analytics'},\n",
              "   {'score': 0.08502384438066414, 'word': 'data'},\n",
              "   {'score': 0.04600372992229393, 'word': 'analysts'},\n",
              "   {'score': 0.043929872023237206, 'word': 'important'},\n",
              "   {'score': 0.043929872023237206, 'word': 'tool'},\n",
              "   {'score': 0.04365009867193202, 'word': 'uncertainty'}],\n",
              "  'Title': 'A framework for uncertainty-aware visual analytics',\n",
              "  'distance': 0,\n",
              "  'no': '436',\n",
              "  'parent': '4448'},\n",
              " {'Abstract': 'Color vision deficiency (CVD) affects approximately 200 million people worldwide, compromising the ability of these individuals to effectively perform color and visualization-related tasks. This has a significant impact on their private and professional lives. We present a physiologically-based model for simulating color vision. Our model is based on the stage theory of human color vision and is derived from data reported in electrophysiological studies. It is the first model to consistently handle normal color vision, anomalous trichromacy, and dichromacy in a unified way. We have validated the proposed model through an experimental evaluation involving groups of color vision deficient individuals and normal color vision ones. Our model can provide insights and feedback on how to improve visualization experiences for individuals with CVD. It also provides a framework for testing hypotheses about some aspects of the retinal photoreceptors in color vision deficient individuals.',\n",
              "  'AuthorKeywords': ['Models',\n",
              "   'of',\n",
              "   'Color',\n",
              "   'Vision,',\n",
              "   'Color',\n",
              "   'Perception,',\n",
              "   'Simulation',\n",
              "   'of',\n",
              "   'Color',\n",
              "   'Vision',\n",
              "   'Deficiency,',\n",
              "   'Anomalous',\n",
              "   'Trichromacy,',\n",
              "   'Dichromacy'],\n",
              "  'MultipartiteRank': [{'score': 0.22135198029907438, 'word': 'color'},\n",
              "   {'score': 0.22135198029907438, 'word': 'vision'},\n",
              "   {'score': 0.22135198029907438, 'word': 'deficiency'},\n",
              "   {'score': 0.10378249639091484, 'word': 'cvd'},\n",
              "   {'score': 0.0646950929697033, 'word': 'model'},\n",
              "   {'score': 0.05011127883661444, 'word': 'individuals'},\n",
              "   {'score': 0.04620442532753437, 'word': 'visualization'}],\n",
              "  'Title': 'A Physiologically-based Model for Simulation of Color Vision Deficiency',\n",
              "  'distance': 0,\n",
              "  'no': '437',\n",
              "  'parent': '4669'},\n",
              " {'Abstract': 'The use of multi-dimensional transfer functions for direct volume rendering has been shown to be an effective means of extracting materials and their boundaries for both scalar and multivariate data. The most common multi-dimensional transfer function consists of a two-dimensional (2D) histogram with axes representing a subset of the feature space (e.g., value vs. value gradient magnitude), with each entry in the 2D histogram being the number of voxels at a given feature space pair. Users then assign color and opacity to the voxel distributions within the given feature space through the use of interactive widgets (e.g., box, circular, triangular selection). Unfortunately, such tools lead users through a trial-and-error approach as they assess which data values within the feature space map to a given area of interest within the volumetric space. In this work, we propose the addition of non-parametric clustering within the transfer function feature space in order to extract patterns and guide transfer function generation. We apply a non-parametric kernel density estimation to group voxels of similar features within the 2D histogram. These groups are then binned and colored based on their estimated density, and the user may interactively grow and shrink the binned regions to explore feature boundaries and extract regions of interest. We also extend this scheme to temporal volumetric data in which time steps of 2D histograms are composited into a histogram volume. A three-dimensional (3D) density estimation is then applied, and users can explore regions within the feature space across time without adjusting the transfer function at each time step. Our work enables users to effectively explore the structures found within a feature space of the volume and provide a context in which the user can understand how these structures relate to their volumetric data. We provide tools for enhanced exploration and manipulation of the transfer function, and we show that the initial transfer function generation serves as a reasonable base for volumetric rendering, reducing the trial-and-error overhead typically found in transfer function design.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'rendering,',\n",
              "   'kernel',\n",
              "   'density',\n",
              "   'estimation,',\n",
              "   'transfer',\n",
              "   'function',\n",
              "   'design,',\n",
              "   'temporal',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.0656190922392221, 'word': 'feature'},\n",
              "   {'score': 0.0656190922392221, 'word': 'space'},\n",
              "   {'score': 0.04471596237871365, 'word': 'users'},\n",
              "   {'score': 0.041158415584794286, 'word': 'histogram'},\n",
              "   {'score': 0.029415472134524015, 'word': 'transfer'},\n",
              "   {'score': 0.029415472134524015, 'word': 'function'},\n",
              "   {'score': 0.029415472134524015, 'word': 'generation'},\n",
              "   {'score': 0.028789187108691914, 'word': 'value'}],\n",
              "  'Title': 'Structuring Feature Space: A Non-Parametric Method for Volumetric Transfer Function Generation',\n",
              "  'distance': 0,\n",
              "  'no': '438',\n",
              "  'parent': '5350'},\n",
              " {'Abstract': \"Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.\",\n",
              "  'AuthorKeywords': ['Quantitative',\n",
              "   'evaluation,',\n",
              "   'qualitative',\n",
              "   'evaluation,',\n",
              "   'biomedical',\n",
              "   'and',\n",
              "   'medical',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.14180802469032364, 'word': 'disease'},\n",
              "   {'score': 0.10255062356267605, 'word': 'heart'},\n",
              "   {'score': 0.04659966635295094, 'word': 'ess'},\n",
              "   {'score': 0.039257401127647584, 'word': 'coronary'},\n",
              "   {'score': 0.039257401127647584, 'word': 'artery'},\n",
              "   {'score': 0.03265938591203151, 'word': 'number'},\n",
              "   {'score': 0.02961794559492663, 'word': 'formative'},\n",
              "   {'score': 0.02961794559492663, 'word': 'user'},\n",
              "   {'score': 0.02961794559492663, 'word': 'study'}],\n",
              "  'Title': 'Evaluation of Artery Visualizations for Heart Disease Diagnosis',\n",
              "  'distance': 0,\n",
              "  'no': '439',\n",
              "  'parent': '5552'},\n",
              " {'Abstract': 'Visual analytics (VA) system development started in academic research institutions where novel visualization techniques and open source toolkits were developed. Simultaneously, small software companies, sometimes spin-offs from academic research institutions, built solutions for specific application domains. In recent years we observed the following trend: some small VA companies grew exponentially; at the same time some big software vendors such as IBM and SAP started to acquire successful VA companies and integrated the acquired VA components into their existing frameworks. Generally the application domains of VA systems have broadened substantially. This phenomenon is driven by the generation of more and more data of high volume and complexity, which leads to an increasing demand for VA solutions from many application domains. In this paper we survey a selection of state-of-the-art commercial VA frameworks, complementary to an existing survey on open source VA tools. From the survey results we identify several improvement opportunities as future research directions.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06912714294424574, 'word': 'specific'},\n",
              "   {'score': 0.06912714294424574, 'word': 'application'},\n",
              "   {'score': 0.06912714294424574, 'word': 'domains'},\n",
              "   {'score': 0.06766397927348487, 'word': 'academic'},\n",
              "   {'score': 0.06766397927348487, 'word': 'research'},\n",
              "   {'score': 0.06766397927348487, 'word': 'institutions'},\n",
              "   {'score': 0.0649102861420838, 'word': 'small'},\n",
              "   {'score': 0.0649102861420838, 'word': 'software'},\n",
              "   {'score': 0.0649102861420838, 'word': 'companies'},\n",
              "   {'score': 0.05514416192858731, 'word': 'solutions'},\n",
              "   {'score': 0.04833675850209301, 'word': 'open'},\n",
              "   {'score': 0.04833675850209301, 'word': 'source'},\n",
              "   {'score': 0.04833675850209301, 'word': 'toolkits'}],\n",
              "  'Title': 'Visual analytics for the big data era---A comparative review of state-of-the-art commercial systems',\n",
              "  'distance': 0,\n",
              "  'no': '440',\n",
              "  'parent': '5200'},\n",
              " {'Abstract': \"To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.\",\n",
              "  'AuthorKeywords': ['Dimensionality',\n",
              "   'reduction,',\n",
              "   'scatterplots,',\n",
              "   'quantitative',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.13362097959733385, 'word': 'scatterplots'},\n",
              "   {'score': 0.08018842426901575, 'word': '2d'},\n",
              "   {'score': 0.06665267732260369, 'word': 'dimensional'},\n",
              "   {'score': 0.06665267732260369, 'word': 'data'},\n",
              "   {'score': 0.057287836684270295, 'word': 'technique'},\n",
              "   {'score': 0.053432555328318095, 'word': 'interactive'},\n",
              "   {'score': 0.053432555328318095, 'word': '3d'},\n",
              "   {'score': 0.04478255557184486, 'word': 'cluster'},\n",
              "   {'score': 0.04478255557184486, 'word': 'separation'}],\n",
              "  'Title': 'Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices',\n",
              "  'distance': 0,\n",
              "  'no': '441',\n",
              "  'parent': '5191'},\n",
              " {'Abstract': \"Presents an algorithm that accelerates the extraction of iso-surfaces from unstructured grids by avoiding the traversal of the entire set of cells in the volume. The algorithm consists of a sweep algorithm and a data decomposition scheme. The sweep algorithm incrementally locates intersected elements, and the data decomposition scheme restricts the algorithm's worst-case performance. For data sets consisting of hundreds of thousands of elements, our algorithm can reduce the cell traversal time by more than 90% over the naive iso-surface extraction algorithm, thus facilitating interactive probing of scalar fields for large-scale problems on unstructured three-dimensional grids.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12975991344223253, 'word': 'algorithm'},\n",
              "   {'score': 0.057462840086932324, 'word': 'entire'},\n",
              "   {'score': 0.057462840086932324, 'word': 'set'},\n",
              "   {'score': 0.056111121022223, 'word': 'iso'},\n",
              "   {'score': 0.05265006048040288, 'word': 'extraction'},\n",
              "   {'score': 0.05181215535062957, 'word': 'unstructured'},\n",
              "   {'score': 0.05181215535062957, 'word': 'grids'}],\n",
              "  'Title': 'Sweeping simplices: a fast iso-surface extraction algorithm for unstructured grids',\n",
              "  'distance': 0,\n",
              "  'no': '442',\n",
              "  'parent': '3586'},\n",
              " {'Abstract': 'We present a generalization of the geometry coder by Touma and Gotsman (1998) to polygon meshes. We let the polygon information dictate where to apply the parallelogram rule that they use to predict vertex positions. Since polygons tend to be fairly planar and fairly convex, it is beneficial to make predictions within a polygon rather than across polygons. This, for example, avoids poor predictions due to a crease angle between polygons. Up to 90 percent of the vertices can be predicted this way. Our strategy improves geometry compression by 10 to 40 percent depending on (a) how polygonal the mesh is and (b) on the quality (planarity/convexity) of the polygons.',\n",
              "  'AuthorKeywords': ['mesh',\n",
              "   'compression,',\n",
              "   'polygon',\n",
              "   'meshes,',\n",
              "   'geometric',\n",
              "   'coding,',\n",
              "   'linear',\n",
              "   'prediction,',\n",
              "   'parallelogram',\n",
              "   'rule'],\n",
              "  'MultipartiteRank': [{'score': 0.13178726166727678, 'word': 'polygon'},\n",
              "   {'score': 0.13178726166727678, 'word': 'information'},\n",
              "   {'score': 0.09992098012470493, 'word': 'polygons'},\n",
              "   {'score': 0.06828326370659682, 'word': 'geometry'},\n",
              "   {'score': 0.06828326370659682, 'word': 'coder'},\n",
              "   {'score': 0.06156132769256891, 'word': 'meshes'},\n",
              "   {'score': 0.052553935128852904, 'word': 'touma'}],\n",
              "  'Title': 'Compressing polygon mesh geometry with parallelogram prediction',\n",
              "  'distance': 0,\n",
              "  'no': '443',\n",
              "  'parent': '3930'},\n",
              " {'Abstract': 'We present an algorithm for interactively extracting and rendering isosurfaces of large volume datasets in a view-dependent fashion. A recursive tetrahedral mesh refinement scheme, based on longest edge bisection, is used to hierarchically decompose the data into a multiresolution structure. This data structure allows fast extraction of arbitrary isosurfaces to within user specified view-dependent error bounds. A data layout scheme based on hierarchical space filling curves provides access to the data in a cache coherent manner that follows the data access pattern indicated by the mesh refinement.',\n",
              "  'AuthorKeywords': ['View-Dependent',\n",
              "   'Rendering,',\n",
              "   'Isosurfaces,',\n",
              "   'Multiresolution',\n",
              "   'Tetrahedal',\n",
              "   'Meshes,',\n",
              "   'Multiresolution',\n",
              "   'Techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.11815358542017704, 'word': 'data'},\n",
              "   {'score': 0.08413540608813196, 'word': 'view'},\n",
              "   {'score': 0.08069660426823805, 'word': 'rendering'},\n",
              "   {'score': 0.08069660426823805, 'word': 'isosurfaces'},\n",
              "   {'score': 0.06453118628604487, 'word': 'access'},\n",
              "   {'score': 0.0585448529832731, 'word': 'recursive'},\n",
              "   {'score': 0.0585448529832731, 'word': 'tetrahedral'},\n",
              "   {'score': 0.0585448529832731, 'word': 'mesh'},\n",
              "   {'score': 0.0585448529832731, 'word': 'refinement'},\n",
              "   {'score': 0.0585448529832731, 'word': 'scheme'}],\n",
              "  'Title': 'Interactive view-dependent rendering of large isosurfaces',\n",
              "  'distance': 0,\n",
              "  'no': '444',\n",
              "  'parent': '3567'},\n",
              " {'Abstract': 'In computer-based literary analysis different types of features are used to characterize a text. Usually, only a single feature value or vector is calculated for the whole text. In this paper, we combine automatic literature analysis methods with an effective visualization technique to analyze the behavior of the feature values across the text. For an interactive visual analysis, we calculate a sequence of feature values per text and present them to the user as a characteristic fingerprint. The feature values may be calculated on different hierarchy levels, allowing the analysis to be done on different resolution levels. A case study shows several successful applications of our new method to known literature problems and demonstrates the advantage of our new visual literature fingerprinting.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'literature',\n",
              "   'analysis,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'literature',\n",
              "   'fingerprinting'],\n",
              "  'MultipartiteRank': [{'score': 0.13861153734570986, 'word': 'features'},\n",
              "   {'score': 0.11705024554164116, 'word': 'analysis'},\n",
              "   {'score': 0.10385530806403669, 'word': 'text'},\n",
              "   {'score': 0.07185501732031149, 'word': 'feature'},\n",
              "   {'score': 0.07185501732031149, 'word': 'values'},\n",
              "   {'score': 0.06887446339069607, 'word': 'literary'},\n",
              "   {'score': 0.06887446339069607, 'word': 'different'},\n",
              "   {'score': 0.06887446339069607, 'word': 'types'},\n",
              "   {'score': 0.04817578215094509, 'word': 'interactive'},\n",
              "   {'score': 0.04817578215094509, 'word': 'visual'}],\n",
              "  'Title': 'Literature Fingerprinting: A New Method for Visual Literary Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '445',\n",
              "  'parent': '3899'},\n",
              " {'Abstract': 'Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired \"art work,\" harnessing the power behind the ever-increasing popularity of Wordle.',\n",
              "  'AuthorKeywords': ['Interaction',\n",
              "   'design,',\n",
              "   'direct',\n",
              "   'manipulation,',\n",
              "   'flexibilty-usability',\n",
              "   'tradeoff,',\n",
              "   'tag-cloud,',\n",
              "   'participatory',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.11862130570826859, 'word': 'layout'},\n",
              "   {'score': 0.07154329907858738, 'word': 'maniwordle'},\n",
              "   {'score': 0.07130505295293563, 'word': 'aesthetic'},\n",
              "   {'score': 0.07105039745746228, 'word': 'wordle'},\n",
              "   {'score': 0.051370317737654006, 'word': 'multifarious'},\n",
              "   {'score': 0.051370317737654006, 'word': 'tag'}],\n",
              "  'Title': 'ManiWordle: Providing Flexible Control over Wordle',\n",
              "  'distance': 0,\n",
              "  'no': '446',\n",
              "  'parent': '4457'},\n",
              " {'Abstract': \"We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09539065686553586, 'word': 'lda'},\n",
              "   {'score': 0.07539749579934368, 'word': 'ivisclassifier'},\n",
              "   {'score': 0.05525342839936176, 'word': 'dimensional'},\n",
              "   {'score': 0.05525342839936176, 'word': 'data'},\n",
              "   {'score': 0.053457402053365764, 'word': 'cluster'},\n",
              "   {'score': 0.053457402053365764, 'word': 'structure'},\n",
              "   {'score': 0.042019455696379285, 'word': 'good'},\n",
              "   {'score': 0.042019455696379285, 'word': 'overview'}],\n",
              "  'Title': 'iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction',\n",
              "  'distance': 0,\n",
              "  'no': '447',\n",
              "  'parent': '4535'},\n",
              " {'Abstract': \"Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0886104169126881, 'word': 'complex'},\n",
              "   {'score': 0.0886104169126881, 'word': 'visual'},\n",
              "   {'score': 0.0886104169126881, 'word': 'analytics'},\n",
              "   {'score': 0.0886104169126881, 'word': 'tasks'},\n",
              "   {'score': 0.0623486266203501, 'word': 'problem'},\n",
              "   {'score': 0.05783037105381579, 'word': 'system'},\n",
              "   {'score': 0.05585880091572095, 'word': 'collaboration'},\n",
              "   {'score': 0.04513593758631723, 'word': 'participant'},\n",
              "   {'score': 0.04513593758631723, 'word': 'pairs'}],\n",
              "  'Title': 'An exploratory study of co-located collaborative visual analytics around a tabletop display',\n",
              "  'distance': 0,\n",
              "  'no': '448',\n",
              "  'parent': '3734'},\n",
              " {'Abstract': 'Multi-resolution hierarchies of polygons and more recently of points are familiar and useful tools for achieving interactive rendering rates. We present an algorithm for tightly integrating the two into a single hierarchical data structure. The trade-off between rendering portions of a model with points or with polygons is made automatically. Our approach to this problem is to apply a bottom-up simplification process involving not only polygon simplification operations, but point replacement and point simplification operations as well. Given one or more surface meshes, our algorithm produces a hybrid hierarchy comprising both polygon and point primitives. This hierarchy may be optimized according to the relative performance characteristics of these primitive types on the intended rendering platform. We also provide a range of aggressiveness for performing point replacement operations. The most conservative approach produces a hierarchy that is better than a purely polygonal hierarchy in some places, and roughly equal in others. A less conservative approach can trade reduced complexity at the far viewing ranges for some increased complexity at the near viewing ranges. We demonstrate our approach on a number of input models, achieving primitive counts that are 1.3 to 4.7 times smaller than those of triangle-only simplification.',\n",
              "  'AuthorKeywords': ['rendering,',\n",
              "   'simplification,',\n",
              "   'multi-resolution,',\n",
              "   'trianlge,',\n",
              "   'points,',\n",
              "   'hybrid'],\n",
              "  'MultipartiteRank': [{'score': 0.09088153769835065, 'word': 'points'},\n",
              "   {'score': 0.06636788242062341, 'word': 'polygons'},\n",
              "   {'score': 0.05292859207688623, 'word': 'approach'},\n",
              "   {'score': 0.04862631733151799, 'word': 'simplification'},\n",
              "   {'score': 0.04862631733151799, 'word': 'process'},\n",
              "   {'score': 0.042132836636872874, 'word': 'hybrid'},\n",
              "   {'score': 0.042132836636872874, 'word': 'hierarchy'}],\n",
              "  'Title': 'Hybrid simplification: combining multi-resolution polygon and point rendering',\n",
              "  'distance': 0,\n",
              "  'no': '449',\n",
              "  'parent': '5599'},\n",
              " {'Abstract': 'We present an alternative method for viewing time-varying volumetric data. We consider such data as a four-dimensional data field, rather than considering space and time as separate entities. If we treat the data in this manner, we can apply high dimensional slicing and projection techniques to generate an image hyperplane. The user is provided with an intuitive user interface to specify arbitrary hyperplanes in 4D, which can be displayed with standard volume rendering techniques. From the volume specification, we are able to extract arbitrary hyperslices, combine slices together into a hyperprojection volume, or apply a 4D raycasting method to generate the same results. In combination with appropriate integration operators and transfer functions, we are able to extract and present different space-time features to the user.',\n",
              "  'AuthorKeywords': ['time-varying',\n",
              "   'data,',\n",
              "   'hyperslice,',\n",
              "   'hyperprojection,',\n",
              "   'integration',\n",
              "   'operator,',\n",
              "   'transfer',\n",
              "   'function,',\n",
              "   'raycasting,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.09662043666606313, 'word': 'time'},\n",
              "   {'score': 0.07496657134970343, 'word': 'volumetric'},\n",
              "   {'score': 0.07496657134970343, 'word': 'data'},\n",
              "   {'score': 0.0610147292674536, 'word': 'projection'},\n",
              "   {'score': 0.0610147292674536, 'word': 'techniques'},\n",
              "   {'score': 0.05932028443854589, 'word': 'user'},\n",
              "   {'score': 0.054586343677432966, 'word': 'space'}],\n",
              "  'Title': 'High dimensional direct rendering of time-varying volumetric data',\n",
              "  'distance': 0,\n",
              "  'no': '450',\n",
              "  'parent': '4255'},\n",
              " {'Abstract': 'This paper presents a strategy for seeding streamlines in 3D flow fields. Its main goal is to capture the essential flow patterns and to provide sufficient coverage in the field while reducing clutter. First, critical points of the flow field are extracted to identify regions with important flow patterns that need to be presented. Different seeding templates are then used around the vicinity of the different critical points. Because there is significant variability in the flow pattern even for the same type of critical point, our template can change shape depending on how far the critical point is from transitioning into another type of critical point. To accomplish this, we introduce the /spl alpha/-/spl beta/ map of 3D critical points. Next, we use Poisson seeding to populate the empty regions. Finally, we filter the streamlines based on their geometric and spatial properties. Altogether, this multi-step strategy reduces clutter and yet captures the important 3D flow features.',\n",
              "  'AuthorKeywords': ['streamlines,',\n",
              "   'flow',\n",
              "   'guided,',\n",
              "   'feature',\n",
              "   'based,',\n",
              "   'filtering,',\n",
              "   'critical',\n",
              "   'points,',\n",
              "   'variable',\n",
              "   'templates'],\n",
              "  'MultipartiteRank': [{'score': 0.16564644940782614, 'word': 'flow'},\n",
              "   {'score': 0.10331193569313153, 'word': 'critical'},\n",
              "   {'score': 0.10331193569313153, 'word': 'points'},\n",
              "   {'score': 0.0918878772941904, 'word': '3d'},\n",
              "   {'score': 0.0918878772941904, 'word': 'fields'},\n",
              "   {'score': 0.07375857211363572, 'word': 'essential'},\n",
              "   {'score': 0.07375857211363572, 'word': 'patterns'},\n",
              "   {'score': 0.06142756320410341, 'word': 'streamlines'},\n",
              "   {'score': 0.04664488079457771, 'word': 'clutter'}],\n",
              "  'Title': 'Strategy for seeding 3D streamlines',\n",
              "  'distance': 0,\n",
              "  'no': '451',\n",
              "  'parent': '4099'},\n",
              " {'Abstract': 'Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analysis,',\n",
              "   'Clustering,',\n",
              "   'Information',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1178669926990335,\n",
              "    'word': 'multidimensional'},\n",
              "   {'score': 0.1178669926990335, 'word': 'clustering'},\n",
              "   {'score': 0.1178669926990335, 'word': 'results'},\n",
              "   {'score': 0.06620389086419219, 'word': 'users'},\n",
              "   {'score': 0.05520898557580268, 'word': 'quality'},\n",
              "   {'score': 0.0485459005142001, 'word': 'clusters'},\n",
              "   {'score': 0.04167928762335343, 'word': 'level'},\n",
              "   {'score': 0.04167928762335343, 'word': 'statistical'},\n",
              "   {'score': 0.04167928762335343, 'word': 'information'}],\n",
              "  'Title': 'DICON: Interactive Visual Analysis of Multidimensional Clusters',\n",
              "  'distance': 0,\n",
              "  'no': '452',\n",
              "  'parent': '5441'},\n",
              " {'Abstract': 'Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09494512238080446, 'word': 'topics'},\n",
              "   {'score': 0.07265909991498887, 'word': 'documents'},\n",
              "   {'score': 0.057467106227376115, 'word': 'paralleltopics'},\n",
              "   {'score': 0.045589905656482736, 'word': 'large'},\n",
              "   {'score': 0.045589905656482736, 'word': 'text'},\n",
              "   {'score': 0.045589905656482736, 'word': 'corpora'},\n",
              "   {'score': 0.035932039136271625, 'word': 'lda'}],\n",
              "  'Title': 'ParallelTopics: A probabilistic approach to exploring document collections',\n",
              "  'distance': 0,\n",
              "  'no': '453',\n",
              "  'parent': '5266'},\n",
              " {'Abstract': 'Visualizing the third dimension while designing three-dimensional (3-D) objects is an awkward process in mechanical computer-aided-design (CAD) systems, given the current state of the art. The authors describe a computer system that automatically constructs the shape of a 3-D object from a single 2-D sketch. The method makes it convenient to create and manipulate 3-D objects, and is thus seen as an intelligent user interface for CAD and 3-D graphics applications. The proposed technique is built on well-known results in image analysis. These results are applied in conjunction with some perceptual rules to determine 3-D structure from a rough line drawing. The principles are illustrated by a computer implementation that works in a nontrivial object domain.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07460259065456258, 'word': 'cad'},\n",
              "   {'score': 0.06539861582797946, 'word': 'systems'},\n",
              "   {'score': 0.05209035432768517, 'word': 'object'},\n",
              "   {'score': 0.05162815636708504, 'word': 'mechanical'},\n",
              "   {'score': 0.05162815636708504, 'word': 'computer'},\n",
              "   {'score': 0.050470533130748736, 'word': 'results'}],\n",
              "  'Title': 'Interpreting a 3D object from a rough 2D line drawing',\n",
              "  'distance': 0,\n",
              "  'no': '454',\n",
              "  'parent': '3707'},\n",
              " {'Abstract': 'Line integral convolution (LIC), introduced by B. Cabral and C. Leedom (1993), is a powerful technique for imaging and animating vector fields. We extend the LIC paradigm in three ways: the existing technique is limited to vector fields over a regular Cartesian grid and we extend it to vector fields over parametric surfaces, specifically those found in curvilinear grids, used in computational fluid dynamics simulations; periodic motion filters can be used to animate the flow visualization, but when the flow lies on a parametric surface, the motion appears misleading, and we explain why this problem arises and show how to adjust the LIC algorithm to handle it; we introduce a technique to visualize vector magnitude as well as vector direction, which is based on varying the frequency of the filter function and we develop a different technique based on kernel phase shifts which we have found to show substantially better results. Implementation of these algorithms utilizes texture-mapping hardware to run in real time, which allows them to be included in interactive applications.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08132217291374902, 'word': 'powerful'},\n",
              "   {'score': 0.08132217291374902, 'word': 'technique'},\n",
              "   {'score': 0.07472402296987547, 'word': 'vector'},\n",
              "   {'score': 0.07472402296987547, 'word': 'fields'},\n",
              "   {'score': 0.05771661216750629, 'word': 'lic'},\n",
              "   {'score': 0.048137598061688006, 'word': 'periodic'},\n",
              "   {'score': 0.048137598061688006, 'word': 'motion'},\n",
              "   {'score': 0.048137598061688006, 'word': 'filters'},\n",
              "   {'score': 0.04751222234135852, 'word': 'parametric'},\n",
              "   {'score': 0.04751222234135852, 'word': 'surfaces'}],\n",
              "  'Title': 'Visualizing flow over curvilinear grid surfaces using line integral convolution',\n",
              "  'distance': 0,\n",
              "  'no': '455',\n",
              "  'parent': '5075'},\n",
              " {'Abstract': \"Lighthouse is an on-line interface for a Web-based information retrieval system. It accepts queries from a user, collects the retrieved documents from the search engine, organizes and presents them to the user. The system integrates two known presentations of the retrieved results, the ranked list and clustering visualization, in a novel and effective way. It accepts the user's input and adjusts the document visualization accordingly. We give a brief overview of the system.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17163854724763056, 'word': 'system'},\n",
              "   {'score': 0.12065528556387292, 'word': 'user'},\n",
              "   {'score': 0.11197829439756656, 'word': 'information'},\n",
              "   {'score': 0.11197829439756656, 'word': 'retrieval'},\n",
              "   {'score': 0.0750699366544624, 'word': 'documents'},\n",
              "   {'score': 0.061180165777875786, 'word': 'web'}],\n",
              "  'Title': 'Lighthouse: showing the way to relevant information',\n",
              "  'distance': 0,\n",
              "  'no': '456',\n",
              "  'parent': '3571'},\n",
              " {'Abstract': 'In many applications of scientific visualization, a large quantity of data is being processed and displayed in order to enable a viewer to make informed and effective decisions. Since little data is perfect, there is almost always some degree of associated uncertainty. This uncertainty is an important part of the data and should be taken into consideration when interpreting the data. Uncertainty, however, should not overshadow the data values. Many methods that address the problem of visualizing data with uncertainty can distort the data and emphasize areas with uncertain values. We have developed a method for showing the uncertainty information together with data with minimal distraction. This method uses procedurally generated annotations which are deformed according to the uncertainty information. As another possible technique we propose distorting glyphs according to the uncertainty information.',\n",
              "  'AuthorKeywords': ['procedure',\n",
              "   'generation,',\n",
              "   'uncertainty,',\n",
              "   'visualization,',\n",
              "   'annotation,',\n",
              "   'glyphs'],\n",
              "  'MultipartiteRank': [{'score': 0.15649332724859402, 'word': 'data'},\n",
              "   {'score': 0.14752308576965167, 'word': 'uncertainty'},\n",
              "   {'score': 0.08734327098801097, 'word': 'associated'},\n",
              "   {'score': 0.06783855483791465, 'word': 'informed'},\n",
              "   {'score': 0.05555819124091313, 'word': 'many'},\n",
              "   {'score': 0.05555819124091313, 'word': 'methods'}],\n",
              "  'Title': 'Procedural annotation of uncertain information',\n",
              "  'distance': 0,\n",
              "  'no': '457',\n",
              "  'parent': '5180'},\n",
              " {'Abstract': 'Grid computing provides a challenge for visualization system designers. In this research, we evolve the dataflow concept to allow parts of the visualization process to be executed remotely in a secure and seamless manner. We see dataflow at three levels: an abstract specification of the intent of the visualization; a binding of these abstract modules to a specific software system; and then a binding of software to processing and other resources. We develop an XML application capable of describing visualization at the three levels. To complement this, we have implemented an extension to a popular visualization system, IRIS Explorer, which allows modules in a dataflow pipeline to run on a set of grid resources. For computational steering applications, we have developed a library that allows a visualization system front-end to connect to a simulation running remotely on a grid resource. We demonstrate the work in two applications: the dispersion of a pollutant under different wind conditions; and the solution of a challenging numerical problem in elastohydrodynamic lubrication.',\n",
              "  'AuthorKeywords': ['grid',\n",
              "   'computing,',\n",
              "   'visualization',\n",
              "   'systems,',\n",
              "   'XML,',\n",
              "   'computational',\n",
              "   'steering,',\n",
              "   'visualization',\n",
              "   'reference',\n",
              "   'models'],\n",
              "  'MultipartiteRank': [{'score': 0.11685595654879427, 'word': 'visualization'},\n",
              "   {'score': 0.11685595654879427, 'word': 'system'},\n",
              "   {'score': 0.11685595654879427, 'word': 'designers'},\n",
              "   {'score': 0.07830610597205863, 'word': 'grid'},\n",
              "   {'score': 0.07830610597205863, 'word': 'computing'},\n",
              "   {'score': 0.06594016369216374, 'word': 'challenge'},\n",
              "   {'score': 0.05659699767136197, 'word': 'dataflow'},\n",
              "   {'score': 0.05659699767136197, 'word': 'concept'},\n",
              "   {'score': 0.036801802786336504, 'word': 'binding'}],\n",
              "  'Title': 'Visualization in grid computing environments',\n",
              "  'distance': 0,\n",
              "  'no': '458',\n",
              "  'parent': '5140'},\n",
              " {'Abstract': 'We present a system for enhancing observation of user interactions in virtual environments. In particular, we focus on analyzing behavior patterns in the popular team-based first-person perspective game Return to Castle Wolfenstein: Enemy Territory. This game belongs to a genre characterized by two moderate-sized teams (usually 6 to 12 players each) competing over a set of objectives. Our system allows spectators to visualize global features such as large-scale behaviors and team strategies, as opposed to the limited, local view that traditional spectating modes provide. We also add overlay visualizations of semantic information related to the action that might be important to a spectator in order to reduce the information overload that plagues traditional overview visualizations. These overlays can visualize information about abstract concepts such as player distribution over time and areas of intense combat activity, and also highlight important features like player paths, fire coverage, etc. This added information allows spectators to identify important game events more easily and reveals large-scale player behaviors that might otherwise be overlooked.',\n",
              "  'AuthorKeywords': ['Visualization,', 'Games,', 'Spectating'],\n",
              "  'MultipartiteRank': [{'score': 0.0567439231372622, 'word': 'popular'},\n",
              "   {'score': 0.0567439231372622, 'word': 'team'},\n",
              "   {'score': 0.048876268124334515, 'word': 'semantic'},\n",
              "   {'score': 0.048876268124334515, 'word': 'information'},\n",
              "   {'score': 0.04632494341181701, 'word': 'behavior'},\n",
              "   {'score': 0.04632494341181701, 'word': 'patterns'},\n",
              "   {'score': 0.04121516135570425, 'word': 'spectators'},\n",
              "   {'score': 0.03677627911359653, 'word': 'players'}],\n",
              "  'Title': 'Visualizing competitive behaviors in multi-user virtual environments',\n",
              "  'distance': 0,\n",
              "  'no': '459',\n",
              "  'parent': '4138'},\n",
              " {'Abstract': 'Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer function-based classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined \"fuzzy\" classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'visualization,',\n",
              "   'uncertainty,',\n",
              "   'classification,',\n",
              "   'risk',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.09572501010259518, 'word': 'quantitative'},\n",
              "   {'score': 0.06757447668940572, 'word': 'statistical'},\n",
              "   {'score': 0.06757447668940572, 'word': 'segmentation'},\n",
              "   {'score': 0.06757447668940572, 'word': 'algorithms'},\n",
              "   {'score': 0.062515829437284, 'word': 'visualization'},\n",
              "   {'score': 0.062515829437284, 'word': 'users'},\n",
              "   {'score': 0.055380808543181566, 'word': 'techniques'},\n",
              "   {'score': 0.05510141436635674, 'word': 'uncertainty'},\n",
              "   {'score': 0.04062359573623844, 'word': 'results'}],\n",
              "  'Title': 'Statistically quantitative volume visualization',\n",
              "  'distance': 0,\n",
              "  'no': '460',\n",
              "  'parent': '3623'},\n",
              " {'Abstract': 'Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.',\n",
              "  'AuthorKeywords': ['Local',\n",
              "   'statistical',\n",
              "   'complexity,',\n",
              "   'multifield',\n",
              "   'visualization,',\n",
              "   'time-dependent,',\n",
              "   'coherent',\n",
              "   'structures,',\n",
              "   'feature',\n",
              "   'detection,',\n",
              "   'information',\n",
              "   'theroy,',\n",
              "   'flow',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.13355605093102413, 'word': 'information'},\n",
              "   {'score': 0.06747757473714396, 'word': 'modern'},\n",
              "   {'score': 0.06747757473714396, 'word': 'unsteady'},\n",
              "   {'score': 0.058120580703713697, 'word': 'theoretic'},\n",
              "   {'score': 0.058120580703713697, 'word': 'concepts'},\n",
              "   {'score': 0.05747438735784849, 'word': 'new'},\n",
              "   {'score': 0.05747438735784849, 'word': 'approach'},\n",
              "   {'score': 0.05404658470831699, 'word': 'data'}],\n",
              "  'Title': 'Multifield Visualization Using Local Statistical Complexity',\n",
              "  'distance': 0,\n",
              "  'no': '461',\n",
              "  'parent': '4227'},\n",
              " {'Abstract': 'We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.',\n",
              "  'AuthorKeywords': ['Sound',\n",
              "   'propagation,',\n",
              "   'interactive',\n",
              "   'system,',\n",
              "   'auralization'],\n",
              "  'MultipartiteRank': [{'score': 0.07091279324264069, 'word': 'interactive'},\n",
              "   {'score': 0.07091279324264069, 'word': 'algorithm'},\n",
              "   {'score': 0.0654329566438433, 'word': 'complex'},\n",
              "   {'score': 0.0654329566438433, 'word': 'scenes'},\n",
              "   {'score': 0.06285483537652403, 'word': 'sound'},\n",
              "   {'score': 0.06285483537652403, 'word': 'propagation'},\n",
              "   {'score': 0.06285483537652403, 'word': 'paths'},\n",
              "   {'score': 0.05730816009860561, 'word': 'specular'},\n",
              "   {'score': 0.05730816009860561, 'word': 'reflection'},\n",
              "   {'score': 0.053026291010067436, 'word': 'diffraction'}],\n",
              "  'Title': 'AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation',\n",
              "  'distance': 0,\n",
              "  'no': '462',\n",
              "  'parent': '3472'},\n",
              " {'Abstract': 'A mathematical data model for scientific visualization that is based on the mathematics of fiber bundles is presented. Previous results are extended to the case of piecewise field representations (associated with grid-based data representations), and a general mathematical model for piecewise representations of fields on irregular grids is presented. The various types of regularity that can be found in computational grids and techniques for compact field representation based on each form of regularity are discussed. These techniques can be combined to obtain efficient methods for representing fields on grids with various regular or partially regular structures.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1125796728480718, 'word': 'mathematical'},\n",
              "   {'score': 0.1125796728480718, 'word': 'data'},\n",
              "   {'score': 0.1125796728480718, 'word': 'model'},\n",
              "   {'score': 0.10802387530621939, 'word': 'piecewise'},\n",
              "   {'score': 0.10802387530621939, 'word': 'field'},\n",
              "   {'score': 0.10802387530621939, 'word': 'representations'},\n",
              "   {'score': 0.10426661331144946, 'word': 'grid'},\n",
              "   {'score': 0.06738781997217284, 'word': 'regularity'},\n",
              "   {'score': 0.06111968049008358, 'word': 'scientific'},\n",
              "   {'score': 0.06111968049008358, 'word': 'visualization'}],\n",
              "  'Title': 'A data model for scientific visualization with provisions for regular and irregular grids',\n",
              "  'distance': 0,\n",
              "  'no': '463',\n",
              "  'parent': '3690'},\n",
              " {'Abstract': 'Explores the way in which data visualization systems, in particular modular visualization environments, can be used over the World Wide Web. The conventional approach is for the publisher of the data also to be responsible for creating the visualization, and posting it as an image on the Web. This leaves the viewer in a passive role, with no opportunity to analyse the data in any way. We look at different scenarios that occur as we transfer more responsibility for the creation of the visualization to the viewer, allowing visualization to be used for analysis as well as presentation. We have implemented one particular scenario, where the publisher mounts the raw data on the Web, and the viewer accesses this data through a modular visualization environment-in this case, IRIS Explorer. The visualization system is hosted by the publisher, but its fine control is the responsibility of the viewer. The picture is returned to the viewer as VRML, for exploration via a VRML viewer such as Webspace. We have applied this to air quality data which is posted on the Web hourly: through our system, the viewer selects what data to look at (e.g. species of pollutant, location, time period) and how to look at it-at any time and from anywhere on the Web.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1626601606432635, 'word': 'data'},\n",
              "   {'score': 0.0897289486168144, 'word': 'visualization'},\n",
              "   {'score': 0.0897289486168144, 'word': 'systems'},\n",
              "   {'score': 0.07505863608799347, 'word': 'viewer'},\n",
              "   {'score': 0.06795074149327296, 'word': 'explores'},\n",
              "   {'score': 0.06232619442735829, 'word': 'world'},\n",
              "   {'score': 0.06232619442735829, 'word': 'wide'},\n",
              "   {'score': 0.06232619442735829, 'word': 'web'}],\n",
              "  'Title': 'Visualization over the World Wide Web and its application to environmental data',\n",
              "  'distance': 0,\n",
              "  'no': '464',\n",
              "  'parent': '6030'},\n",
              " {'Abstract': 'Many volume filtering operations used for image enhancement, data processing or feature detection can be written in terms of three-dimensional convolutions. It is not possible to yield interactive frame rates on todays hardware when applying such convolutions on volume data using software filter routines. As modern graphics workstations have the ability to render two-dimensional convoluted images to the frame buffer, this feature can be used to accelerate the process significantly. This way generic 3D convolution can be added as a powerful tool in interactive volume visualization toolkits.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12235010435980809, 'word': 'many'},\n",
              "   {'score': 0.12235010435980809, 'word': 'volume'},\n",
              "   {'score': 0.09218509011075932, 'word': 'data'},\n",
              "   {'score': 0.09218509011075932, 'word': 'processing'},\n",
              "   {'score': 0.082640293959551, 'word': 'feature'},\n",
              "   {'score': 0.082640293959551, 'word': 'detection'},\n",
              "   {'score': 0.0765884317323581, 'word': 'operations'},\n",
              "   {'score': 0.07355342957222626, 'word': 'image'},\n",
              "   {'score': 0.07355342957222626, 'word': 'enhancement'}],\n",
              "  'Title': 'Accelerating 3D convolution using graphics hardware',\n",
              "  'distance': 0,\n",
              "  'no': '465',\n",
              "  'parent': '4069'},\n",
              " {'Abstract': 'Multi-resolution techniques and models have been shown to be effective for the display and transmission of large static geometric object. Dynamic environments with internally deforming models and scientific simulations using dynamic meshes pose greater challenges in terms of time and space, and need the development of similar solutions. We introduce the T-DAG, an adaptive multi-resolution representation for dynamic meshes with arbitrary deformations including attribute, position, connectivity and topology changes. T-DAG stands for time-dependent directed acyclic graph which defines the structure supporting this representation. We also provide an incremental algorithm (in time) for constructing the T-DAG representation of a given input mesh. This enables the traversal and use of the multi-resolution dynamic model for partial playback while still constructing new time-steps.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12231405673992958, 'word': 'dynamic'},\n",
              "   {'score': 0.08097879203218905, 'word': 'time'},\n",
              "   {'score': 0.07527034036434446, 'word': 'environments'},\n",
              "   {'score': 0.05366414191235082, 'word': 'dag'},\n",
              "   {'score': 0.04704371637558512, 'word': 'meshes'},\n",
              "   {'score': 0.04336781089786022, 'word': 'models'}],\n",
              "  'Title': 'Multi-resolution dynamic meshes with arbitrary deformations',\n",
              "  'distance': 0,\n",
              "  'no': '466',\n",
              "  'parent': '3923'},\n",
              " {'Abstract': \"In this paper we present a novel framework for direct volume rendering using a splatting approach based on elliptical Gaussian kernels. To avoid aliasing artifacts, we introduce the concept of a resampling filter combining a reconstruction with a low-pass kernel. Because of the similarity to Heckbert's EWA (elliptical weighted average) filter for texture mapping we call our technique EWA volume splatting. It provides high image quality without aliasing artifacts or excessive blurring even with non-spherical kernels. Hence it is suitable for regular, rectilinear, and irregular volume data sets. Moreover, our framework introduces a novel approach to compute the footprint function. It facilitates efficient perspective projection of arbitrary elliptical kernels at very little additional cost. Finally, we show that EWA volume reconstruction kernels can be reduced to surface reconstruction kernels. This makes our splat primitive universal in reconstructing surface and volume data.\",\n",
              "  'AuthorKeywords': ['Volume', 'Rendering,', 'Splatting,', 'Antialiasing'],\n",
              "  'MultipartiteRank': [{'score': 0.07295412040639478, 'word': 'elliptical'},\n",
              "   {'score': 0.07295412040639478, 'word': 'gaussian'},\n",
              "   {'score': 0.07295412040639478, 'word': 'kernels'},\n",
              "   {'score': 0.062292128701515445, 'word': 'direct'},\n",
              "   {'score': 0.062292128701515445, 'word': 'volume'},\n",
              "   {'score': 0.05572152827875494, 'word': 'resampling'},\n",
              "   {'score': 0.05572152827875494, 'word': 'filter'},\n",
              "   {'score': 0.050995465414306766, 'word': 'splatting'},\n",
              "   {'score': 0.050995465414306766, 'word': 'approach'},\n",
              "   {'score': 0.05086652442189772, 'word': 'novel'},\n",
              "   {'score': 0.05086652442189772, 'word': 'framework'}],\n",
              "  'Title': 'EWA volume splatting',\n",
              "  'distance': 0,\n",
              "  'no': '467',\n",
              "  'parent': '4207'},\n",
              " {'Abstract': 'Data sets with a large number of nominal variables, some with high cardinality, are becoming increasingly common and need to be explored. Unfortunately, most existing visual exploration displays are designed to handle numeric variables only. When importing data sets with nominal values into such visualization tools, most solutions to date are rather simplistic. Often, techniques that map nominal values to numbers do not assign order or spacing among the values in a manner that conveys semantic relationships. Moreover, displays designed for nominal variables usually cannot handle high cardinality variables well. This paper addresses the problem of how to display nominal variables in general-purpose visual exploration tools designed for numeric variables. Specifically, we investigate (1) how to assign order and spacing among the nominal values, and (2) how to reduce the number of distinct values to display. We propose that nominal variables be pre-processed using a distance-quantification-classing (DQC) approach before being imported into a visual exploration tool. In the distance step, we identify a set of independent dimensions that can be used to calculate the distance between nominal values. In the quantification step, we use the independent dimensions and the distance information to assign order and spacing among the nominal values. In the classing step, we use results from the previous steps to determine which values within a variable are similar to each other and thus can be grouped together. Each step in the DQC approach can be accomplished by a variety of techniques. We extended the XmdvTool package to incorporate this approach. We evaluated our approach on several data sets using a variety of evaluation measures.',\n",
              "  'AuthorKeywords': ['nominal',\n",
              "   'data,',\n",
              "   'visualization,',\n",
              "   'dimension',\n",
              "   'reduction,',\n",
              "   'correspondence',\n",
              "   'analysis,',\n",
              "   'quantification,',\n",
              "   'clustering,',\n",
              "   'classing'],\n",
              "  'MultipartiteRank': [{'score': 0.16514436460057785, 'word': 'nominal'},\n",
              "   {'score': 0.0924059128752617, 'word': 'variables'},\n",
              "   {'score': 0.09040914029456415, 'word': 'data'},\n",
              "   {'score': 0.07273845172531615, 'word': 'values'},\n",
              "   {'score': 0.05583060124470877, 'word': 'large'},\n",
              "   {'score': 0.05583060124470877, 'word': 'number'},\n",
              "   {'score': 0.037134626427880305, 'word': 'visual'},\n",
              "   {'score': 0.037134626427880305, 'word': 'exploration'},\n",
              "   {'score': 0.037134626427880305, 'word': 'displays'}],\n",
              "  'Title': 'Mapping nominal values to numbers for effective visualization',\n",
              "  'distance': 0,\n",
              "  'no': '468',\n",
              "  'parent': '6012'},\n",
              " {'Abstract': 'Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.',\n",
              "  'AuthorKeywords': ['Multivariate',\n",
              "   'data,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'parallel',\n",
              "   'coordinates,',\n",
              "   'dynamic',\n",
              "   'queries,',\n",
              "   'iterative',\n",
              "   'analysis,',\n",
              "   'starplot,',\n",
              "   'small',\n",
              "   'multiples'],\n",
              "  'MultipartiteRank': [{'score': 0.08365710019301925, 'word': 'visual'},\n",
              "   {'score': 0.08365710019301925, 'word': 'analytics'},\n",
              "   {'score': 0.04704483538034928, 'word': 'scale'},\n",
              "   {'score': 0.04704483538034928, 'word': 'multidimensional'},\n",
              "   {'score': 0.04704483538034928, 'word': 'datasets'},\n",
              "   {'score': 0.046967786375550505, 'word': 'interactivity'},\n",
              "   {'score': 0.04259825819003106, 'word': 'multiple'},\n",
              "   {'score': 0.04259825819003106, 'word': 'large'},\n",
              "   {'score': 0.0397509861031837, 'word': 'user'},\n",
              "   {'score': 0.0397509861031837, 'word': 'control'}],\n",
              "  'Title': 'DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data',\n",
              "  'distance': 0,\n",
              "  'no': '469',\n",
              "  'parent': '4742'},\n",
              " {'Abstract': 'Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.',\n",
              "  'AuthorKeywords': ['visualization,',\n",
              "   'statistical',\n",
              "   'analysis,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'data',\n",
              "   'variability,',\n",
              "   'medical',\n",
              "   'imaging'],\n",
              "  'MultipartiteRank': [{'score': 0.08329987927291765, 'word': 'transfer'},\n",
              "   {'score': 0.08329987927291765, 'word': 'functions'},\n",
              "   {'score': 0.07834532498772621, 'word': 'texture'},\n",
              "   {'score': 0.05703585811264787, 'word': 'features'},\n",
              "   {'score': 0.04988553975402578, 'word': 'direct'},\n",
              "   {'score': 0.04988553975402578, 'word': 'volume'},\n",
              "   {'score': 0.04582150847450701, 'word': 'gradient'},\n",
              "   {'score': 0.04582150847450701, 'word': 'values'}],\n",
              "  'Title': 'Texture-based Transfer Functions for Direct Volume Rendering',\n",
              "  'distance': 0,\n",
              "  'no': '470',\n",
              "  'parent': '6114'},\n",
              " {'Abstract': 'Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'Meta-visualization,',\n",
              "   'Collaboration,',\n",
              "   'Coordination,',\n",
              "   'Co-located',\n",
              "   'work,',\n",
              "   'Workspace',\n",
              "   'awareness'],\n",
              "  'MultipartiteRank': [{'score': 0.07708875272915862, 'word': 'coordination'},\n",
              "   {'score': 0.07325682555546831, 'word': 'information'},\n",
              "   {'score': 0.07325682555546831, 'word': 'visualizations'},\n",
              "   {'score': 0.06267620717168827, 'word': 'coordinated'},\n",
              "   {'score': 0.06267620717168827, 'word': 'views'},\n",
              "   {'score': 0.058141657621369455, 'word': 'interactions'},\n",
              "   {'score': 0.05779453702937197, 'word': 'data'}],\n",
              "  'Title': 'Lark: Coordinating Co-located Collaboration with Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '471',\n",
              "  'parent': '4173'},\n",
              " {'Abstract': 'Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge.In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.',\n",
              "  'AuthorKeywords': ['Transfer',\n",
              "   'functions,',\n",
              "   'Ambient',\n",
              "   'Occlusion,',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   'Interactive',\n",
              "   'Classification'],\n",
              "  'MultipartiteRank': [{'score': 0.11443877690399881, 'word': 'occlusion'},\n",
              "   {'score': 0.06946815773110569, 'word': 'ambient'},\n",
              "   {'score': 0.050555273679923046, 'word': 'voxels'},\n",
              "   {'score': 0.04497061917289313, 'word': 'patterns'},\n",
              "   {'score': 0.038989110761382555, 'word': 'weighted'},\n",
              "   {'score': 0.038989110761382555, 'word': 'average'},\n",
              "   {'score': 0.03611698838228596, 'word': 'features'}],\n",
              "  'Title': 'The Occlusion Spectrum for Volume Classification and Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '472',\n",
              "  'parent': '4464'},\n",
              " {'Abstract': 'Graphics artists commonly employ physically-based simulation for the generation of effects such as smoke, explosions, and similar phenomena. The task of finding the correct parameters for a desired result, however, is difficult and time-consuming as current tools provide little to no guidance. In this paper, we present a new approach for the visual exploration of such parameter spaces. Given a three-dimensional scene description, we utilize sampling and spatio-temporal clustering techniques to generate a concise overview of the achievable variations and their temporal evolution. Our visualization system then allows the user to explore the simulation space in a goal-oriented manner. Animation sequences with a set of desired characteristics can be composed using a novel search-by-example approach and interactive direct volume rendering is employed to provide instant visual feedback.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'exploration,',\n",
              "   'visual',\n",
              "   'effects,',\n",
              "   'clustering,',\n",
              "   'time-dependent',\n",
              "   'volume',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.0501279724818662, 'word': 'temporal'},\n",
              "   {'score': 0.04432073437838008, 'word': 'visual'},\n",
              "   {'score': 0.04432073437838008, 'word': 'exploration'},\n",
              "   {'score': 0.043422862309263704, 'word': 'simulation'},\n",
              "   {'score': 0.04304659724128804, 'word': 'new'},\n",
              "   {'score': 0.04304659724128804, 'word': 'approach'},\n",
              "   {'score': 0.033993445223125085, 'word': 'spatio'}],\n",
              "  'Title': 'Result-Driven Exploration of Simulation Parameter Spaces for Visual Effects Design',\n",
              "  'distance': 0,\n",
              "  'no': '473',\n",
              "  'parent': '3623'},\n",
              " {'Abstract': 'The use of critical point analysis to generate representations of the vector field topology of numerical flow data sets is discussed. Critical points are located and characterized in a two-dimensional domain, which may be either a two-dimensional flow field or the tangential velocity field near a three-dimensional body. Tangent curves are then integrated out along the principal directions of certain classes of critical points. The points and curves are linked to form a skeleton representing the two-dimensional vector field topology. When generated from the tangential velocity field near a body in a three-dimensional flow, the skeleton includes the critical points and curves which provide a basis for analyzing the three-dimensional structure of the flow separation.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15378876634884772, 'word': 'critical'},\n",
              "   {'score': 0.15378876634884772, 'word': 'point'},\n",
              "   {'score': 0.15378876634884772, 'word': 'analysis'},\n",
              "   {'score': 0.07204590674189915, 'word': 'vector'},\n",
              "   {'score': 0.07204590674189915, 'word': 'field'},\n",
              "   {'score': 0.07204590674189915, 'word': 'topology'},\n",
              "   {'score': 0.0713287173978702, 'word': 'tangent'},\n",
              "   {'score': 0.0713287173978702, 'word': 'curves'},\n",
              "   {'score': 0.06657046057820641, 'word': 'dimensional'},\n",
              "   {'score': 0.06657046057820641, 'word': 'domain'},\n",
              "   {'score': 0.06633631029529959, 'word': 'use'}],\n",
              "  'Title': 'Surface representations of two- and three-dimensional fluid flow topology',\n",
              "  'distance': 0,\n",
              "  'no': '474',\n",
              "  'parent': '4041'},\n",
              " {'Abstract': \"Three dimensional computer models of the anatomy generated from volume acquisitions of computed tomography and magnetic resonance imaging are useful adjuncts to 2D images. This paper describes a system that merges the computer generated 3D models with live video to enhance the surgeon's understanding of the anatomy beneath the surface. The system can be used as a planning aid before the operation and provide additional information during an operation. The application of the system to a brain operation is described.&lt;&lt;ETX&gt;&gt;\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12579576264218634, 'word': 'dimensional'},\n",
              "   {'score': 0.12579576264218634, 'word': 'computer'},\n",
              "   {'score': 0.12579576264218634, 'word': 'models'},\n",
              "   {'score': 0.08534093117194885, 'word': 'system'},\n",
              "   {'score': 0.08498064059579163, 'word': 'anatomy'},\n",
              "   {'score': 0.07514964972854189, 'word': 'magnetic'},\n",
              "   {'score': 0.07514964972854189, 'word': 'resonance'},\n",
              "   {'score': 0.07514964972854189, 'word': 'imaging'},\n",
              "   {'score': 0.06900784663936253, 'word': 'operation'}],\n",
              "  'Title': 'Enhancing reality in the operating room',\n",
              "  'distance': 0,\n",
              "  'no': '475',\n",
              "  'parent': '3461'},\n",
              " {'Abstract': 'A similarity metric based on the low-level content of images can be used to create a visualisation in which visually similar images are displayed close to each other. We are carrying out a series of experiments to evaluate the usefulness of this type of visualisation as an image browsing aid. The initial experiment, described, considered whether people would find a given photograph more quickly in a visualisation than in a randomly arranged grid of images. The results show that the subjects were faster with the visualisation, although in post-experiment interviews many of them said that they preferred the clarity and regularity of the grid. We describe an algorithm with which the best aspects of the two layout types can be combined.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11547310724660637, 'word': 'images'},\n",
              "   {'score': 0.1100283791166962, 'word': 'visualisation'},\n",
              "   {'score': 0.06533960203465278, 'word': 'grid'},\n",
              "   {'score': 0.06312501322141165, 'word': 'experiments'},\n",
              "   {'score': 0.05574511104252232, 'word': 'type'}],\n",
              "  'Title': 'Evaluating a visualisation of image similarity as a tool for image browsing',\n",
              "  'distance': 0,\n",
              "  'no': '476',\n",
              "  'parent': '3783'},\n",
              " {'Abstract': 'For a comprehensive understanding of tomographic image data in medicine, interactive and high-quality direct volume rendering is an essential prerequisite. This is provided by visualization using 3D texture mapping which is still limited to high-end graphics hardware. In order to make it available in a clinical environment, we present a system which uniquely combines local desktop computers and remote high-end graphics hardware. In this context, we exploit the standard visualization capabilities to a maximum which are available in the clinical environment. For 3D representations of high resolution and quality we access the remote specialized hardware. Various tools for 2D and 3D visualization are provided which meet the requirements of a medical diagnosis. This is demonstrated with examples from the field of neuroradiology which show the value of our strategy in practice.',\n",
              "  'AuthorKeywords': ['medical',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'distributed',\n",
              "   'systems,',\n",
              "   'PC',\n",
              "   'graphics',\n",
              "   'hardware,',\n",
              "   'remote',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.10017844295944618, 'word': 'high'},\n",
              "   {'score': 0.062219706612905504, 'word': 'visualization'},\n",
              "   {'score': 0.05320679859870946, 'word': 'end'},\n",
              "   {'score': 0.05320679859870946, 'word': 'graphics'},\n",
              "   {'score': 0.05320679859870946, 'word': 'hardware'},\n",
              "   {'score': 0.04176567476206583, 'word': 'available'},\n",
              "   {'score': 0.04134953760383833, 'word': 'clinical'},\n",
              "   {'score': 0.04134953760383833, 'word': 'environment'}],\n",
              "  'Title': 'Combining local and remote visualization techniques for interactive volume rendering in medical applications',\n",
              "  'distance': 0,\n",
              "  'no': '477',\n",
              "  'parent': '4332'},\n",
              " {'Abstract': 'We describe a visualization tool which allows a biologist to explore a large set of hypothetical evolutionary trees. Interacting with such a dataset allows the biologist to identify distinct hypotheses about how different species or organisms evolved, which would not have been clear from traditional analyses. Our system integrates a point-set visualization of the distribution of hypothetical trees with detail views of an individual tree, or of a consensus tree summarizing a subset of trees. Efficient algorithms were required for the key tasks of computing distances between trees, finding consensus trees, and laying out the point-set visualization.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1410750241723508, 'word': 'hypothetical'},\n",
              "   {'score': 0.1410750241723508, 'word': 'evolutionary'},\n",
              "   {'score': 0.1410750241723508, 'word': 'trees'},\n",
              "   {'score': 0.08474434708491235, 'word': 'biologist'},\n",
              "   {'score': 0.07671381815168055, 'word': 'visualization'},\n",
              "   {'score': 0.07671381815168055, 'word': 'tool'},\n",
              "   {'score': 0.06891406068474322, 'word': 'large'},\n",
              "   {'score': 0.06891406068474322, 'word': 'set'},\n",
              "   {'score': 0.045466134065797206, 'word': 'dataset'}],\n",
              "  'Title': 'Case study: visualizing sets of evolutionary trees',\n",
              "  'distance': 0,\n",
              "  'no': '478',\n",
              "  'parent': '3430'},\n",
              " {'Abstract': \"We present a novel surface reconstruction algorithm that can recover high-quality surfaces from noisy and defective data sets without any normal or orientation information. A set of new techniques is introduced to afford extra noise tolerability, robust orientation alignment, reliable outlier removal, and satisfactory feature recovery. In our algorithm, sample points are first organized by an octree. The points are then clustered into a set of monolithically singly-oriented groups. The inside/outside orientation of each group is determined through a robust voting algorithm. We locally fit an implicit quadric surface in each octree cell. The locally fitted implicit surfaces are then blended to produce a signed distance field using the modified Shepard's method. We develop sophisticated iterative fitting algorithms to afford improved noise tolerance both in topology recognition and geometry accuracy. Furthermore, this iterative fitting algorithm, coupled with a local model selection scheme, provides a reliable sharp feature recovery mechanism even in the presence of bad input.\",\n",
              "  'AuthorKeywords': ['Computer',\n",
              "   'Graphics,',\n",
              "   'Surface',\n",
              "   'Reconstruction,',\n",
              "   'Surface',\n",
              "   'Representation,',\n",
              "   'MPU',\n",
              "   'implicits,',\n",
              "   'Modified',\n",
              "   \"Shepard's\",\n",
              "   'Method'],\n",
              "  'MultipartiteRank': [{'score': 0.07709774191970732, 'word': 'defective'},\n",
              "   {'score': 0.07709774191970732, 'word': 'data'},\n",
              "   {'score': 0.07709774191970732, 'word': 'sets'},\n",
              "   {'score': 0.060811452263314955, 'word': 'quality'},\n",
              "   {'score': 0.060811452263314955, 'word': 'surfaces'},\n",
              "   {'score': 0.050655122110990845, 'word': 'orientation'},\n",
              "   {'score': 0.050655122110990845, 'word': 'information'},\n",
              "   {'score': 0.043999694907614, 'word': 'noisy'},\n",
              "   {'score': 0.04334714099470754, 'word': 'sample'},\n",
              "   {'score': 0.04334714099470754, 'word': 'points'}],\n",
              "  'Title': 'Surface reconstruction of noisy and defective data sets',\n",
              "  'distance': 0,\n",
              "  'no': '479',\n",
              "  'parent': '4222'},\n",
              " {'Abstract': 'Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'large',\n",
              "   'displays,',\n",
              "   'empirical',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.09586639324155774, 'word': 'higher'},\n",
              "   {'score': 0.09586639324155774, 'word': 'resolution'},\n",
              "   {'score': 0.09586639324155774, 'word': 'displays'},\n",
              "   {'score': 0.07983608450169423, 'word': 'larger'},\n",
              "   {'score': 0.04863584635388504, 'word': 'scalability'},\n",
              "   {'score': 0.0461681714924497, 'word': 'information'},\n",
              "   {'score': 0.0461681714924497, 'word': 'visualizations'},\n",
              "   {'score': 0.040506642128606205, 'word': 'time'}],\n",
              "  'Title': 'The Perceptual Scalability of Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '480',\n",
              "  'parent': '5406'},\n",
              " {'Abstract': 'Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Intelligence',\n",
              "   'analysis,',\n",
              "   'Problemsolving',\n",
              "   'environments,',\n",
              "   'Visual',\n",
              "   'Knowledge',\n",
              "   'Discovery'],\n",
              "  'MultipartiteRank': [{'score': 0.08317028324063179, 'word': 'amazon'},\n",
              "   {'score': 0.08317028324063179, 'word': 'customer'},\n",
              "   {'score': 0.08317028324063179, 'word': 'reviews'},\n",
              "   {'score': 0.06233576478564919, 'word': 'terms'},\n",
              "   {'score': 0.052920984671311976, 'word': 'opinions'},\n",
              "   {'score': 0.04184895664076716, 'word': 'features'},\n",
              "   {'score': 0.04154686297152395, 'word': 'study'}],\n",
              "  'Title': 'Visual Analysis of Conflicting Opinions',\n",
              "  'distance': 0,\n",
              "  'no': '481',\n",
              "  'parent': '6026'},\n",
              " {'Abstract': 'Wikipedia is a wiki-based encyclopedia that has become one of the most popular collaborative on-line knowledge systems. As in any large collaborative system, as Wikipedia has grown, conflicts and coordination costs have increased dramatically. Visual analytic tools provide a mechanism for addressing these issues by enabling users to more quickly and effectively make sense of the status of a collaborative environment. In this paper we describe a model for identifying patterns of conflicts in Wikipedia articles. The model relies on users\\' editing history and the relationships between user edits, especially revisions that void previous edits, known as \"reverts\". Based on this model, we constructed Revert Graph, a tool that visualizes the overall conflict patterns between groups of users. It enables visual analysis of opinion groups and rapid interactive exploration of those relationships via detail drill- downs. We present user patterns and case studies that show the effectiveness of these techniques, and discuss how they could generalize to other systems.',\n",
              "  'AuthorKeywords': ['Wikipedia,',\n",
              "   'wiki,',\n",
              "   'revert,',\n",
              "   'graph,',\n",
              "   'collaboration,',\n",
              "   'user',\n",
              "   'model,',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.0884931448762765, 'word': 'wikipedia'},\n",
              "   {'score': 0.06708449289246042, 'word': 'users'},\n",
              "   {'score': 0.06340299422016565, 'word': 'conflicts'},\n",
              "   {'score': 0.04848487688101668, 'word': 'model'},\n",
              "   {'score': 0.037975000844636814, 'word': 'popular'},\n",
              "   {'score': 0.037975000844636814, 'word': 'collaborative'}],\n",
              "  'Title': 'Us vs. Them: Understanding Social Dynamics in Wikipedia with Revert Graph Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '482',\n",
              "  'parent': '3823'},\n",
              " {'Abstract': 'Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools.',\n",
              "  'AuthorKeywords': ['Movement',\n",
              "   'data,',\n",
              "   'spatio-temporal',\n",
              "   'data,',\n",
              "   'aggregation,',\n",
              "   'scalable',\n",
              "   'visualization,',\n",
              "   'geovisualization'],\n",
              "  'MultipartiteRank': [{'score': 0.09725586805589677, 'word': 'useful'},\n",
              "   {'score': 0.09725586805589677, 'word': 'analytical'},\n",
              "   {'score': 0.09725586805589677, 'word': 'results'},\n",
              "   {'score': 0.07990271280730127, 'word': 'large'},\n",
              "   {'score': 0.07990271280730127, 'word': 'collections'},\n",
              "   {'score': 0.05824378218139364, 'word': 'collaborative'},\n",
              "   {'score': 0.05824378218139364, 'word': 'synthesis'},\n",
              "   {'score': 0.05824378218139364, 'word': 'experiments'},\n",
              "   {'score': 0.05774038788079389, 'word': 'analysts'},\n",
              "   {'score': 0.0401030004745743, 'word': 'paper'}],\n",
              "  'Title': 'Collaborative synthesis of visual analytic results',\n",
              "  'distance': 0,\n",
              "  'no': '483',\n",
              "  'parent': '4126'},\n",
              " {'Abstract': 'Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.',\n",
              "  'AuthorKeywords': ['Scientific',\n",
              "   'Workflows,',\n",
              "   'Scientific',\n",
              "   'Visualization,',\n",
              "   'Auto',\n",
              "   'Completion'],\n",
              "  'MultipartiteRank': [{'score': 0.18670612534266318, 'word': 'visualization'},\n",
              "   {'score': 0.1465934643942531, 'word': 'building'},\n",
              "   {'score': 0.13961844573600812, 'word': 'analysis'},\n",
              "   {'score': 0.13961844573600812, 'word': 'pipelines'},\n",
              "   {'score': 0.05098085680770234, 'word': 'workflow'},\n",
              "   {'score': 0.05098085680770234, 'word': 'systems'},\n",
              "   {'score': 0.04840772798757524, 'word': 'large'},\n",
              "   {'score': 0.04840772798757524, 'word': 'hurdle'}],\n",
              "  'Title': 'VisComplete: Automating Suggestions for Visualization Pipelines',\n",
              "  'distance': 0,\n",
              "  'no': '484',\n",
              "  'parent': '3498'},\n",
              " {'Abstract': 'Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.',\n",
              "  'AuthorKeywords': ['Ambient',\n",
              "   'visualization,',\n",
              "   'informative',\n",
              "   'art,',\n",
              "   'casual',\n",
              "   'infovis,',\n",
              "   'sustainability,',\n",
              "   'distributed',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08424676747558472, 'word': 'feedback'},\n",
              "   {'score': 0.06057124667075412, 'word': 'home'},\n",
              "   {'score': 0.04896501998927732, 'word': 'ambient'},\n",
              "   {'score': 0.045902725441947304, 'word': 'consumption'},\n",
              "   {'score': 0.045902725441947304, 'word': 'devices'},\n",
              "   {'score': 0.042795425959424246, 'word': 'use'},\n",
              "   {'score': 0.03834404203363742, 'word': 'effective'}],\n",
              "  'Title': 'Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback',\n",
              "  'distance': 0,\n",
              "  'no': '485',\n",
              "  'parent': '5123'},\n",
              " {'Abstract': 'When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'statistics,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'crowd-sourcing,',\n",
              "   'empirical',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.07809142267624779, 'word': 'measurement'},\n",
              "   {'score': 0.07809142267624779, 'word': 'error'},\n",
              "   {'score': 0.05019940097299579, 'word': 'actual'},\n",
              "   {'score': 0.05019940097299579, 'word': 'mean'},\n",
              "   {'score': 0.05019940097299579, 'word': 'values'},\n",
              "   {'score': 0.04607470796878461, 'word': 'incomplete'},\n",
              "   {'score': 0.04607470796878461, 'word': 'data'},\n",
              "   {'score': 0.0433413709458088, 'word': 'uncertain'},\n",
              "   {'score': 0.0338388096922523, 'word': 'confidence'},\n",
              "   {'score': 0.0338388096922523, 'word': 'intervals'}],\n",
              "  'Title': 'Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error',\n",
              "  'distance': 0,\n",
              "  'no': '486',\n",
              "  'parent': '4285'},\n",
              " {'Abstract': 'The task of reconstructing the derivative of a discrete function is essential for its shading and rendering as well as being widely used in image processing and analysis. We survey the possible methods for normal estimation in volume rendering and divide them into two classes based on the delivered numerical accuracy. The three members of the first class determine the normal in two steps by employing both interpolation and derivative filters. Among these is a new method which has never been realized. The members of the first class are all equally accurate. The second class has only one member and employs a continuous derivative filter obtained through the analytic derivation of an interpolation filter. We use the new method to analytically compare the accuracy of the first class with that of the second. As a result of our analysis we show that even inexpensive schemes can in fact be more accurate than high order methods. We describe the theoretical computational cost of applying the schemes in a volume rendering application and provide guidelines for helping one choose a scheme for estimating derivatives. In particular we find that the new method can be very inexpensive and can compete with the normal estimations which pre-shade and pre-classify the volume (M. Levoy, 1988).',\n",
              "  'AuthorKeywords': ['interpolation',\n",
              "   'filters,',\n",
              "   'derivative',\n",
              "   'filters,',\n",
              "   'filter',\n",
              "   'design,',\n",
              "   'normal',\n",
              "   'estimation,',\n",
              "   'Taylor',\n",
              "   'series',\n",
              "   'expansion,',\n",
              "   'efficient',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.06926145262642407, 'word': 'derivative'},\n",
              "   {'score': 0.0552769593559412, 'word': 'possible'},\n",
              "   {'score': 0.0552769593559412, 'word': 'methods'},\n",
              "   {'score': 0.05404560878324493, 'word': 'classes'},\n",
              "   {'score': 0.05109779581662949, 'word': 'normal'},\n",
              "   {'score': 0.05109779581662949, 'word': 'estimation'},\n",
              "   {'score': 0.044887921945315795, 'word': 'rendering'}],\n",
              "  'Title': 'A comparison of normal estimation schemes',\n",
              "  'distance': 0,\n",
              "  'no': '487',\n",
              "  'parent': '4449'},\n",
              " {'Abstract': 'One very effective method for managing large data sets is aggregation or binning. We consider two aggregation methods that are tightly coupled with interactive manipulation and the visual representation of the data. Through this integration we hope to provide effective support for the aggregation process, specifically by enabling: 1) automatic aggregation, 2) continuous change and control of the aggregation level, 3) spatially based aggregates, 4) context maintenance across different aggregate levels, and 5) feedback on the level of aggregation.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.28005119319282185, 'word': 'aggregation'},\n",
              "   {'score': 0.09481600490160318, 'word': 'level'},\n",
              "   {'score': 0.09401879015656633, 'word': 'large'},\n",
              "   {'score': 0.09401879015656633, 'word': 'data'},\n",
              "   {'score': 0.09401879015656633, 'word': 'sets'},\n",
              "   {'score': 0.07827742675251483, 'word': 'effective'},\n",
              "   {'score': 0.07827742675251483, 'word': 'method'},\n",
              "   {'score': 0.05670255464646204, 'word': 'binning'}],\n",
              "  'Title': 'Dynamic aggregation with circular visual designs',\n",
              "  'distance': 0,\n",
              "  'no': '488',\n",
              "  'parent': '3455'},\n",
              " {'Abstract': 'A fully automatic feature detection algorithm is presented that locates and distinguishes lines of flow separation and attachment on surfaces in 3D numerical flow fields. The algorithm is based on concepts from 2D phase-plane analysis of linear vector fields. Unlike prior visualization techniques based on particle tracing or flow topology, the phase-plane algorithm detects separation using local analytic tests. The results show that it not only detects the standard closed separation lines but also the illusive open separation lines which are not captured by flow topology methods.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.13719542612395416, 'word': 'flow'},\n",
              "   {'score': 0.0818770980057957, 'word': 'separation'},\n",
              "   {'score': 0.07875601829500256, 'word': '2d'},\n",
              "   {'score': 0.07875601829500256, 'word': 'phase'},\n",
              "   {'score': 0.07292699638152056, 'word': 'algorithm'},\n",
              "   {'score': 0.056107479513087824, 'word': 'attachment'},\n",
              "   {'score': 0.055318328118158455, 'word': '3d'},\n",
              "   {'score': 0.055318328118158455, 'word': 'numerical'},\n",
              "   {'score': 0.055318328118158455, 'word': 'fields'}],\n",
              "  'Title': 'Automatic detection of open and closed separation and attachment lines',\n",
              "  'distance': 0,\n",
              "  'no': '489',\n",
              "  'parent': '4080'},\n",
              " {'Abstract': 'This paper describes a method to simulate realistic wrinkles on clothes without fine mesh and large computational overheads. Cloth has very little in-plane deformations, as most of the deformations come from buckling. This can be looked at as area conservation property of cloth. The area conservation formulation of the method modulates the user defined wrinkle pattern, based on deformation of individual triangle. The methodology facilitates use of small in-plane deformation stiffnesses and a coarse mesh for the numerical simulation, this makes cloth simulation fast and robust. Moreover, the ability to design wrinkles (even on generalized deformable models) makes this method versatile for synthetic image generation. The method inspired from cloth wrinkling problem, being geometric in nature, can be extended to other wrinkling phenomena.',\n",
              "  'AuthorKeywords': ['clothmodeling,wrinklemodeling,deformablemodels'],\n",
              "  'MultipartiteRank': [{'score': 0.12032147317566279, 'word': 'clothes'},\n",
              "   {'score': 0.08613927250652278, 'word': 'plane'},\n",
              "   {'score': 0.08613927250652278, 'word': 'deformations'},\n",
              "   {'score': 0.07346360589383123, 'word': 'method'},\n",
              "   {'score': 0.06796547331691406, 'word': 'realistic'},\n",
              "   {'score': 0.06796547331691406, 'word': 'wrinkles'},\n",
              "   {'score': 0.054918902717158005, 'word': 'fine'},\n",
              "   {'score': 0.054918902717158005, 'word': 'mesh'}],\n",
              "  'Title': 'Animating wrinkles on clothes',\n",
              "  'distance': 0,\n",
              "  'no': '490',\n",
              "  'parent': '4129'},\n",
              " {'Abstract': 'Internet connectivity is defined by a set of routing protocols which let the routers that comprise the Internet backbone choose the best route for a packet to reach its destination. One way to improve the security and performance of Internet is to routinely examine the routing data. In this case study, we show how interactive visualization of Border Gateway Protocol (BGP) data helps characterize routing behavior, identify weaknesses in connectivity which could potentially cripple the Internet, as well as detect and explain actual anomalous events.',\n",
              "  'AuthorKeywords': ['anomaly',\n",
              "   'detection,',\n",
              "   'graph',\n",
              "   'drawing,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'network',\n",
              "   'security'],\n",
              "  'MultipartiteRank': [{'score': 0.18587065598370872, 'word': 'internet'},\n",
              "   {'score': 0.09741908353350334, 'word': 'backbone'},\n",
              "   {'score': 0.08845157245020538, 'word': 'connectivity'},\n",
              "   {'score': 0.08522410033349234, 'word': 'protocols'},\n",
              "   {'score': 0.05678095084378227, 'word': 'set'},\n",
              "   {'score': 0.056581490024593284, 'word': 'best'},\n",
              "   {'score': 0.056581490024593284, 'word': 'route'}],\n",
              "  'Title': 'Case study: Interactive visualization for Internet security',\n",
              "  'distance': 0,\n",
              "  'no': '491',\n",
              "  'parent': '3403'},\n",
              " {'Abstract': 'Curve-skeletons are a 1D subset of the medial surface of a 3D object and are useful for many visualization tasks including virtual navigation, reduced-model formulation, visualization improvement, mesh repair, animation, etc. There are many algorithms in the literature describing extraction methodologies for different applications; however, it is unclear how general and robust they are. In this paper, we provide an overview of many curve-skeleton applications and compile a set of desired properties of such representations. We also give a taxonomy of methods and analyze the advantages and drawbacks of each class of algorithms.',\n",
              "  'AuthorKeywords': ['skeleton,', 'curve-skeleton'],\n",
              "  'MultipartiteRank': [{'score': 0.08879281365233027, 'word': 'curve'},\n",
              "   {'score': 0.08263004295836905, 'word': 'many'},\n",
              "   {'score': 0.07437705139875687, 'word': 'skeletons'},\n",
              "   {'score': 0.04417934141675203, 'word': '1d'},\n",
              "   {'score': 0.04417934141675203, 'word': 'subset'},\n",
              "   {'score': 0.04238879160737485, 'word': 'algorithms'},\n",
              "   {'score': 0.040241251350994205, 'word': 'visualization'},\n",
              "   {'score': 0.040241251350994205, 'word': 'tasks'}],\n",
              "  'Title': 'Curve-skeleton applications',\n",
              "  'distance': 0,\n",
              "  'no': '492',\n",
              "  'parent': '3765'},\n",
              " {'Abstract': \"We present real-time vascular visualization methods, which extend on illustrative rendering techniques to particularly accentuate spatial depth and to improve the perceptive separation of important vascular properties such as branching level and supply area. The resulting visualization can and has already been used for direct projection on a patient's organ in the operation theater where the varying absorption and reflection characteristics of the surface limit the use of color. The important contributions of our work are a GPU-based hatching algorithm for complex tubular structures that emphasizes shape and depth as well as GPU-accelerated shadow-like depth indicators, which enable reliable comparisons of depth distances in a static monoscopic 3D visualization. In addition, we verify the expressiveness of our illustration methods in a large, quantitative study with 160 subjects\",\n",
              "  'AuthorKeywords': ['Vessel',\n",
              "   'visualization,',\n",
              "   'functional',\n",
              "   'realism,',\n",
              "   'illustrative',\n",
              "   'rendering,',\n",
              "   'spatial',\n",
              "   'perception,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.08257305860933953, 'word': 'spatial'},\n",
              "   {'score': 0.08257305860933953, 'word': 'depth'},\n",
              "   {'score': 0.04483761094042426, 'word': 'gpu'},\n",
              "   {'score': 0.03257031248924493, 'word': 'illustrative'},\n",
              "   {'score': 0.03257031248924493, 'word': 'rendering'},\n",
              "   {'score': 0.03257031248924493, 'word': 'techniques'},\n",
              "   {'score': 0.03185045633566159, 'word': 'use'},\n",
              "   {'score': 0.03139050257674239, 'word': 'surface'},\n",
              "   {'score': 0.03139050257674239, 'word': 'limit'}],\n",
              "  'Title': 'Real-Time Illustration of Vascular Structures',\n",
              "  'distance': 0,\n",
              "  'no': '493',\n",
              "  'parent': '3841'},\n",
              " {'Abstract': 'Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \"difference\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.',\n",
              "  'AuthorKeywords': ['Morse',\n",
              "   'theory,',\n",
              "   'Morse-Smale',\n",
              "   'complex,',\n",
              "   'distance',\n",
              "   'field,',\n",
              "   'topological',\n",
              "   'simplification,',\n",
              "   'wavefront,',\n",
              "   'critical',\n",
              "   'point,',\n",
              "   'porous',\n",
              "   'solid,',\n",
              "   'material',\n",
              "   'science'],\n",
              "  'MultipartiteRank': [{'score': 0.0930575853884082, 'word': 'distance'},\n",
              "   {'score': 0.0930575853884082, 'word': 'fields'},\n",
              "   {'score': 0.05249122675680003, 'word': 'topological'},\n",
              "   {'score': 0.05249122675680003, 'word': 'features'},\n",
              "   {'score': 0.05170214261081658, 'word': 'analysis'},\n",
              "   {'score': 0.03410695577000005, 'word': 'first'},\n",
              "   {'score': 0.03410695577000005, 'word': 'method'},\n",
              "   {'score': 0.031024242636629014, 'word': 'volumetric'},\n",
              "   {'score': 0.031024242636629014, 'word': 'domain'}],\n",
              "  'Title': 'Topologically Clean Distance fields',\n",
              "  'distance': 0,\n",
              "  'no': '494',\n",
              "  'parent': '5143'},\n",
              " {'Abstract': 'We present a direct volume rendering algorithm to speed up volume animation for flow visualizations. Data coherency between consecutive simulation time steps is used to avoid casting rays from those pixels retaining color values assigned to the previous image. The algorithm calculates the differential information among a sequence of 3D volumetric simulation data. At each time step the differential information is used to compute the locations of pixels that need updating and a ray-casting method as utilized to produce the updated image. We illustrate the utility and speed of the differential volume rendering algorithm with simulation data from computational bioelectric and fluid dynamics applications. We can achieve considerable disk-space savings and nearly real-time rendering of 3D flows using low-cost, single processor workstations for models which contain hundreds of thousands of data points.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07602208659225106, 'word': 'data'},\n",
              "   {'score': 0.07602208659225106, 'word': 'coherency'},\n",
              "   {'score': 0.07174683936421467, 'word': 'algorithm'},\n",
              "   {'score': 0.05979402517379052, 'word': 'differential'},\n",
              "   {'score': 0.05979402517379052, 'word': 'information'},\n",
              "   {'score': 0.055810206334446624, 'word': 'flow'},\n",
              "   {'score': 0.055810206334446624, 'word': 'visualizations'},\n",
              "   {'score': 0.048944373445469945, 'word': 'direct'},\n",
              "   {'score': 0.048944373445469945, 'word': 'volume'}],\n",
              "  'Title': 'Differential volume rendering: a fast volume visualization technique for flow animation',\n",
              "  'distance': 0,\n",
              "  'no': '495',\n",
              "  'parent': '4555'},\n",
              " {'Abstract': 'Visualization is a critical technology for understanding complex, data-rich systems. Effective visualizations make important features of the data immediately recognizable and enable the user to discover interesting and useful results by highlighting patterns. A key element of such systems is the ability to interact with displays of data by selecting a subset for further investigation. This operation is needed for use in linked-views systems and in drill-down analysis. It is a common manipulation in many other systems. It is as ubiquitous as selecting icons in a desktop GUI. It is therefore surprising to note that little research has been done on how selection can be implemented. This paper addresses this omission, presenting a taxonomy for selection mechanisms and discussing the interactions between branches of the taxonomy. Our suggestion of 524,288 possible systems [2/sup 16/ operation systems/spl times/2 (memory/memoryless)/spl times/2 (data-dependent/independent)/spl times/2 (brush/lasso)] is more in fun than serious, as within the taxonomy there are many different choices that can be made. This framework is the result of considering both the current state of the art and historical antecedents.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07100620612837286, 'word': 'data'},\n",
              "   {'score': 0.06949831762355425, 'word': 'visualization'},\n",
              "   {'score': 0.05272508586746939, 'word': 'rich'},\n",
              "   {'score': 0.05272508586746939, 'word': 'systems'},\n",
              "   {'score': 0.04041794432612778, 'word': 'taxonomy'},\n",
              "   {'score': 0.031725804903655994, 'word': 'useful'},\n",
              "   {'score': 0.031725804903655994, 'word': 'results'}],\n",
              "  'Title': 'Selection: 524,288 ways to say \"this is interesting\"',\n",
              "  'distance': 0,\n",
              "  'no': '496',\n",
              "  'parent': '4422'},\n",
              " {'Abstract': 'We are investigating methods for simplifying complex models for interactive visualizations using texture based representations. The paper presents a simplification method which dynamically \"caches\" distant geometry into textures and trades off accurate rendering of the distant geometry for performance. Smooth transitions and continuous borders are defined between the geometry and textures thus the representations can be switched without sudden jumps (as is the case with many current texturing techniques). All the computations for the transitions can be done a priori without the need to change the textures each frame thereafter.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12490425792486014, 'word': 'texture'},\n",
              "   {'score': 0.10212192101758923, 'word': 'distant'},\n",
              "   {'score': 0.10212192101758923, 'word': 'geometry'},\n",
              "   {'score': 0.06293073193180154, 'word': 'representations'},\n",
              "   {'score': 0.06270333988356903, 'word': 'methods'},\n",
              "   {'score': 0.061697527063676504, 'word': 'smooth'},\n",
              "   {'score': 0.061697527063676504, 'word': 'transitions'}],\n",
              "  'Title': 'Visualization of Complex Models Using Dynamic Texture-based Simplification',\n",
              "  'distance': 0,\n",
              "  'no': '497',\n",
              "  'parent': '3625'},\n",
              " {'Abstract': 'In recent years scientific visualization has been driven by the need to visualize high-dimensional data sets within high-dimensional spaces. However most visualization methods are designed to show only some statistical features of the data set. The paper deals with the visualization of trajectories of high-dimensional dynamical systems which form a L/sub n//sup n/ data set of a smooth n-dimensional flow. Three methods that are based on the idea of parallel coordinates are presented and discussed. Visualizations done with these new methods are shown and an interactive visualization tool for the exploration of high-dimensional dynamical systems is proposed.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17441766060918762, 'word': 'high'},\n",
              "   {'score': 0.16292905897232202, 'word': 'dimensional'},\n",
              "   {'score': 0.1031696024251205, 'word': 'visualization'},\n",
              "   {'score': 0.0886134309813142, 'word': 'data'},\n",
              "   {'score': 0.0886134309813142, 'word': 'sets'},\n",
              "   {'score': 0.0743156279910078, 'word': 'dynamical'},\n",
              "   {'score': 0.0743156279910078, 'word': 'systems'},\n",
              "   {'score': 0.05761350382004052, 'word': 'methods'}],\n",
              "  'Title': 'Visualizing the behaviour of higher dimensional dynamical systems',\n",
              "  'distance': 0,\n",
              "  'no': '498',\n",
              "  'parent': '3905'},\n",
              " {'Abstract': 'By virtue of their spatio-cognitive abilities, humans are able to navigate through geographic space as well as meaningfully communicate geographic information represented in cartographic form. The current dominance of spatial metaphors in information visualization research is the result of the realization that those cognitive skills also have value in the exploration and analysis of non-geographic information. While mapping or landscape metaphors are routinely used in this field, there is a noticeable lack of consideration for existing cartographic expertise. This is especially apparent whenever problematic issues are encountered, such as graphic complexity or feature labeling. There are a number of areas in which a cartographic outlook could provide a valuable perspective. This paper discusses how geographic and cartographic notions may influence the design of visualizations for textual information spaces. Map projections, generalization, feature labeling and map design issues are discussed.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0654492693617389, 'word': 'cartographic'},\n",
              "   {'score': 0.0654492693617389, 'word': 'form'},\n",
              "   {'score': 0.05920123054409136, 'word': 'geographic'},\n",
              "   {'score': 0.05920123054409136, 'word': 'space'},\n",
              "   {'score': 0.05711158503808813, 'word': 'cognitive'},\n",
              "   {'score': 0.05711158503808813, 'word': 'abilities'},\n",
              "   {'score': 0.05020612051504908, 'word': 'spatial'},\n",
              "   {'score': 0.05020612051504908, 'word': 'metaphors'},\n",
              "   {'score': 0.04443780946359378, 'word': 'information'},\n",
              "   {'score': 0.04443780946359378, 'word': 'visualization'},\n",
              "   {'score': 0.04443780946359378, 'word': 'research'}],\n",
              "  'Title': 'From metaphor to method: cartographic perspectives on information visualization',\n",
              "  'distance': 0,\n",
              "  'no': '499',\n",
              "  'parent': '4667'},\n",
              " {'Abstract': 'We describe a prototype same-time/different-place collaborative geovisualization environment. We outline an approach to understanding use and usability and present results of interviews with domain experts about the ways in which collaborative visualization might enable groups to work at a distance. One goal for our research is to design an effective and flexible system that can support group work on environmental science research mediated through dynamic geovisualization displays. We are addressing this goal using a four-step human-centered system design process, modeled on that proposed by (Gabbard et al., 1999) for development and evaluation of virtual environments. The steps they delineate are: user task analysis; expert guideline-based evaluation; formative user-centered evaluation; and summative comparative evaluation.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.05819691859338583, 'word': 'domain'},\n",
              "   {'score': 0.05819691859338583, 'word': 'experts'},\n",
              "   {'score': 0.056235590767543586, 'word': 'evaluation'},\n",
              "   {'score': 0.05471581143726882, 'word': 'groups'},\n",
              "   {'score': 0.0517921940948385, 'word': 'research'},\n",
              "   {'score': 0.05095899534248677, 'word': 'goal'}],\n",
              "  'Title': 'Collaborative geographic visualization: enabling shared understanding of environmental processes',\n",
              "  'distance': 0,\n",
              "  'no': '500',\n",
              "  'parent': '3849'},\n",
              " {'Abstract': 'Finding the \"best\" viewing parameters for a scene is a difficult but very important problem. Fully automatic procedures seem to be impossible as the notion of \"best\" strongly depends on human judgment as well as on the application. In this paper a solution to the sub-problem of placing light sources for given camera parameters is proposed. A light position is defined to be optimal, when the resulting illumination reveals more about the scene than illuminations from all other light positions, i.e. the light position maximizes information that is added to the image through the illumination. With the help of an experiment with several subjects we could adapt the information measure to the actually perceived information content. We present fast global optimization procedures and solutions for two and more light sources.',\n",
              "  'AuthorKeywords': ['Lighting',\n",
              "   'Design,',\n",
              "   'Visualization,',\n",
              "   'Illumination,',\n",
              "   'Maximum',\n",
              "   'Entropy,',\n",
              "   'Optimization,',\n",
              "   'User',\n",
              "   'Study'],\n",
              "  'MultipartiteRank': [{'score': 0.07484346981963307, 'word': 'light'},\n",
              "   {'score': 0.07484346981963307, 'word': 'sources'},\n",
              "   {'score': 0.06921318702809288, 'word': 'illumination'},\n",
              "   {'score': 0.06559634426145176, 'word': 'parameters'},\n",
              "   {'score': 0.06248982579949566, 'word': 'scene'},\n",
              "   {'score': 0.05737842614726086, 'word': 'best'}],\n",
              "  'Title': 'Maximum entropy light source placement',\n",
              "  'distance': 0,\n",
              "  'no': '501',\n",
              "  'parent': '3928'},\n",
              " {'Abstract': 'Hand-crafted illustrations are often more effective than photographs for conveying the shape and important features of an object, but they require expertise and time to produce. We describe an image compositing system and user interface that allow an artist to quickly and easily create technical illustrations from a set of photographs of an object taken from the same point of view under variable lighting conditions. Our system uses a novel compositing process in which images are combined using spatially-varying light mattes, enabling the final lighting in each area of the composite to be manipulated independently. We describe an interface that provides for the painting of local lighting effects (e.g. shadows, highlights, and tangential lighting to reveal texture) directly onto the composite. We survey some of the techniques used in illustration and lighting design to convey the shape and features of objects and describe how our system can be used to apply these techniques.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'Relighting,',\n",
              "   'Image',\n",
              "   'Composition,',\n",
              "   'Scientfic',\n",
              "   'Illustration,',\n",
              "   'Technical',\n",
              "   'Illustration,',\n",
              "   'Photography,',\n",
              "   'Lighting',\n",
              "   'Design'],\n",
              "  'MultipartiteRank': [{'score': 0.06178652541758416, 'word': 'light'},\n",
              "   {'score': 0.06178652541758416, 'word': 'mattes'},\n",
              "   {'score': 0.060627147644911894, 'word': 'illustrations'},\n",
              "   {'score': 0.05917522903810796, 'word': 'system'},\n",
              "   {'score': 0.05575242867547718, 'word': 'object'},\n",
              "   {'score': 0.05131044831909888, 'word': 'novel'},\n",
              "   {'score': 0.05131044831909888, 'word': 'compositing'},\n",
              "   {'score': 0.05131044831909888, 'word': 'process'}],\n",
              "  'Title': 'Conveying shape and features with image-based relighting',\n",
              "  'distance': 0,\n",
              "  'no': '502',\n",
              "  'parent': '4188'},\n",
              " {'Abstract': 'This paper presents a shading model for volumetric data which enhances the perception of surfaces within the volume. The model incorporates uniform diffuse illumination, which arrives equally from all directions at each surface point in the volume. This illumination is attenuated by occlusions in the local vicinity of the surface point, resulting in shadows in depressions and crevices. Experiments by other authors have shown that perception of a surface is superior under uniform diffuse lighting, compared to illumination from point source lighting.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'rendering,',\n",
              "   'shading',\n",
              "   'model,',\n",
              "   'diffuse',\n",
              "   'illumination,',\n",
              "   'perceptual',\n",
              "   'cues'],\n",
              "  'MultipartiteRank': [{'score': 0.12992074868200437, 'word': 'surfaces'},\n",
              "   {'score': 0.07500600361618148, 'word': 'model'},\n",
              "   {'score': 0.07434533123965051, 'word': 'perception'},\n",
              "   {'score': 0.07401175471643029, 'word': 'uniform'},\n",
              "   {'score': 0.07401175471643029, 'word': 'diffuse'},\n",
              "   {'score': 0.07401175471643029, 'word': 'illumination'},\n",
              "   {'score': 0.0723811639447233, 'word': 'volume'}],\n",
              "  'Title': 'Vicinity shading for enhanced perception of volumetric data',\n",
              "  'distance': 0,\n",
              "  'no': '503',\n",
              "  'parent': '3424'},\n",
              " {'Abstract': 'We study the problem of visualizing large networks and develop techniques for effectively abstracting a network and reducing the size to a level that can be clearly viewed. Our size reduction techniques are based on sampling, where only a sample instead of the full network is visualized. We propose a randomized notion of \"focus\" that specifies a part of the network and the degree to which it needs to be magnified. Visualizing a sample allows our method to overcome the scalability issues inherent in visualizing massive networks. We report some characteristics that frequently occur in large networks and the conditions under which they are preserved when sampling from a network. This can be useful in selecting a proper sampling scheme that yields a sample with similar characteristics as the original network. Our method is built on top of a relational database, thus it can be easily and efficiently implemented using any off-the-shelf database software. As a proof of concept, we implement our methods and report some of our experiments over the movie database and the connectivity graph of the Web.',\n",
              "  'AuthorKeywords': ['visualizing',\n",
              "   'the',\n",
              "   'Web,',\n",
              "   'large',\n",
              "   'network',\n",
              "   'visualization,',\n",
              "   'network',\n",
              "   'sampling'],\n",
              "  'MultipartiteRank': [{'score': 0.14783717642782843, 'word': 'large'},\n",
              "   {'score': 0.14783717642782843, 'word': 'networks'},\n",
              "   {'score': 0.0838042449688071, 'word': 'sampling'},\n",
              "   {'score': 0.05450136078152906, 'word': 'method'},\n",
              "   {'score': 0.05012882457595836, 'word': 'characteristics'},\n",
              "   {'score': 0.046367004745129774, 'word': 'network'}],\n",
              "  'Title': 'Effectively visualizing large networks through sampling',\n",
              "  'distance': 0,\n",
              "  'no': '504',\n",
              "  'parent': '5176'},\n",
              " {'Abstract': 'Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.',\n",
              "  'AuthorKeywords': ['Graphical',\n",
              "   'Perception,',\n",
              "   'Visualization,',\n",
              "   'Treemaps,',\n",
              "   'Rectangular',\n",
              "   'Area,',\n",
              "   'Visual',\n",
              "   'Encoding,',\n",
              "   'Experiment,',\n",
              "   'Mechanical',\n",
              "   'Turk'],\n",
              "  'MultipartiteRank': [{'score': 0.08412536880305634, 'word': 'treemaps'},\n",
              "   {'score': 0.04883769803973109, 'word': 'aspect'},\n",
              "   {'score': 0.04883769803973109, 'word': 'ratio'},\n",
              "   {'score': 0.04795062968426259, 'word': 'effective'},\n",
              "   {'score': 0.04795062968426259, 'word': 'rectangular'},\n",
              "   {'score': 0.03791606294317574, 'word': 'area'},\n",
              "   {'score': 0.03709722717518394, 'word': 'hierarchical'},\n",
              "   {'score': 0.03709722717518394, 'word': 'bar'},\n",
              "   {'score': 0.03709722717518394, 'word': 'chart'}],\n",
              "  'Title': 'Perceptual Guidelines for Creating Rectangular Treemaps',\n",
              "  'distance': 0,\n",
              "  'no': '505',\n",
              "  'parent': '6082'},\n",
              " {'Abstract': 'When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.',\n",
              "  'AuthorKeywords': ['Multidimensional',\n",
              "   'data,',\n",
              "   'cluster',\n",
              "   'comparison,',\n",
              "   'bioinformatics',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.058782719956296206, 'word': 'groups'},\n",
              "   {'score': 0.056261304467617186, 'word': 'dimensions'},\n",
              "   {'score': 0.03904724972464685, 'word': 'quantitative'},\n",
              "   {'score': 0.03904724972464685, 'word': 'data'},\n",
              "   {'score': 0.030317113077771907, 'word': 'comparison'},\n",
              "   {'score': 0.029139996332784003, 'word': 'algorithms'}],\n",
              "  'Title': 'Comparative Analysis of Multidimensional; Quantitative Data',\n",
              "  'distance': 0,\n",
              "  'no': '506',\n",
              "  'parent': '5700'},\n",
              " {'Abstract': 'We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'OpenGL,',\n",
              "   'edge',\n",
              "   'aggregation'],\n",
              "  'MultipartiteRank': [{'score': 0.0975470169489293, 'word': 'line'},\n",
              "   {'score': 0.0975470169489293, 'word': 'graph'},\n",
              "   {'score': 0.0975470169489293, 'word': 'drawings'},\n",
              "   {'score': 0.07774557349249107, 'word': 'edge'},\n",
              "   {'score': 0.07774557349249107, 'word': 'cumulation'},\n",
              "   {'score': 0.06650460468201258, 'word': 'node'},\n",
              "   {'score': 0.06650460468201258, 'word': 'aggregation'},\n",
              "   {'score': 0.056727383339262014, 'word': 'straight'},\n",
              "   {'score': 0.0543809749677462, 'word': 'density'}],\n",
              "  'Title': 'Interactive Level-of-Detail Rendering of Large Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '507',\n",
              "  'parent': '3409'},\n",
              " {'Abstract': \"Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users' analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user's reasoning and intuition.\",\n",
              "  'AuthorKeywords': ['User',\n",
              "   'Interaction,',\n",
              "   'visualization,',\n",
              "   'sensemaking,',\n",
              "   'analytic',\n",
              "   'reasoning,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.08108718333791193, 'word': 'visual'},\n",
              "   {'score': 0.08108718333791193, 'word': 'analytic'},\n",
              "   {'score': 0.08108718333791193, 'word': 'tools'},\n",
              "   {'score': 0.06483366785860806, 'word': 'users'},\n",
              "   {'score': 0.0642557626827039, 'word': 'expressive'},\n",
              "   {'score': 0.0642557626827039, 'word': 'interactions'},\n",
              "   {'score': 0.034730883967161376, 'word': 'mathematical'},\n",
              "   {'score': 0.034730883967161376, 'word': 'models'},\n",
              "   {'score': 0.03451293762259088, 'word': 'spatial'},\n",
              "   {'score': 0.03451293762259088, 'word': 'layout'}],\n",
              "  'Title': 'Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering',\n",
              "  'distance': 0,\n",
              "  'no': '508',\n",
              "  'parent': '4424'},\n",
              " {'Abstract': \"We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.\",\n",
              "  'AuthorKeywords': ['Retweeting',\n",
              "   'threads,',\n",
              "   'anomaly',\n",
              "   'detection,',\n",
              "   'social',\n",
              "   'media,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'machine',\n",
              "   'learning,',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.04052621797769125, 'word': 'anomalous'},\n",
              "   {'score': 0.04052621797769125, 'word': 'information'},\n",
              "   {'score': 0.03781955191727547, 'word': 'fluxflow'},\n",
              "   {'score': 0.03436885450106116, 'word': 'social'},\n",
              "   {'score': 0.03436885450106116, 'word': 'media'},\n",
              "   {'score': 0.030358183895315596, 'word': 'messages'},\n",
              "   {'score': 0.02673972751659908, 'word': 'twitter'}],\n",
              "  'Title': '#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media',\n",
              "  'distance': 0,\n",
              "  'no': '509',\n",
              "  'parent': '4551'},\n",
              " {'Abstract': 'While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.',\n",
              "  'AuthorKeywords': ['Provenance,',\n",
              "   'Analytic',\n",
              "   'provenance,',\n",
              "   'Visual',\n",
              "   'analytics,',\n",
              "   'Framework,',\n",
              "   'Visualization,',\n",
              "   'Conceptual',\n",
              "   'model'],\n",
              "  'MultipartiteRank': [{'score': 0.11137811635930711, 'word': 'research'},\n",
              "   {'score': 0.07570909573507814, 'word': 'provenance'},\n",
              "   {'score': 0.052440398187513934, 'word': 'different'},\n",
              "   {'score': 0.052440398187513934, 'word': 'types'},\n",
              "   {'score': 0.05105878918221352, 'word': 'visual'},\n",
              "   {'score': 0.05105878918221352, 'word': 'analytics'},\n",
              "   {'score': 0.03515976622299326, 'word': 'history'}],\n",
              "  'Title': 'Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes',\n",
              "  'distance': 0,\n",
              "  'no': '510',\n",
              "  'parent': '4722'},\n",
              " {'Abstract': 'The authors discuss FAST (flow analysis software toolkit), an implementation of a software system for fluid mechanics analysis. Visualization of computational aerodynamics requires flexible, extensible, and adaptable software tools for performing analysis tasks. An overview of FAST is given, and its architecture is discussed. Interactive visualization control is addressed. The advantages and disadvantages of FAST are discussed.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11311969118551668, 'word': 'fast'},\n",
              "   {'score': 0.09622758874105056, 'word': 'visualization'},\n",
              "   {'score': 0.07383415553029671, 'word': 'computational'},\n",
              "   {'score': 0.07383415553029671, 'word': 'aerodynamics'},\n",
              "   {'score': 0.0719403973247003, 'word': 'fluid'},\n",
              "   {'score': 0.0719403973247003, 'word': 'mechanics'},\n",
              "   {'score': 0.0719403973247003, 'word': 'analysis'},\n",
              "   {'score': 0.06693824027187621, 'word': 'flexible'}],\n",
              "  'Title': 'FAST: a multi-processed environment for visualization of computational fluid dynamics',\n",
              "  'distance': 0,\n",
              "  'no': '511',\n",
              "  'parent': '3335'},\n",
              " {'Abstract': 'The VIS-5D system provides highly interactive visual access to five-dimensional data sets containing up to 50 million data points. VIS-5D runs on the Stardent ST-1000 and ST-2000 workstations and generates animated three-dimensional graphics from gridded data sets in real time. It provides a widget-based user interface and fast visual response which allows scientists to interactively explore their data sets. VIS-5D generates literal and intuitive depictions of data, has user controls that are data oriented rather than graphics oriented, and provides a WYSIWYG (what-you-see-is-what-you-get) response. The result is a system that enables scientists to produce and direct their own animations.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.19315636636544828, 'word': 'dimensional'},\n",
              "   {'score': 0.14075894529859942, 'word': 'data'},\n",
              "   {'score': 0.14075894529859942, 'word': 'sets'},\n",
              "   {'score': 0.12641365509649632, 'word': 'vis-5d'},\n",
              "   {'score': 0.05805652674633227, 'word': 'system'},\n",
              "   {'score': 0.05666906964832557, 'word': 'interactive'},\n",
              "   {'score': 0.05666906964832557, 'word': 'visual'},\n",
              "   {'score': 0.05666906964832557, 'word': 'access'},\n",
              "   {'score': 0.05239742106684886, 'word': 'graphics'}],\n",
              "  'Title': 'The VIS-5D system for easy interactive visualization',\n",
              "  'distance': 0,\n",
              "  'no': '512',\n",
              "  'parent': '3695'},\n",
              " {'Abstract': 'A method is presented to obtain a unique shape description of an object by using wavelet transforms. Wavelet transform is a signal analysis technique which decomposes a signal using a family of functions having a local property in both time and frequency domains. A multiresolution expression of 3D volume data was first obtained by applying 3D orthogonal wavelet transforms, with the shape then being approximated with a relatively small number of 3D orthogonal functions using only the significant functions. In addition, the resolution of the approximation can be varied point by point using the local property of the wavelets. The method is applied to real volume data, i.e. facial range data and MR images of a human head, and typical results are shown.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09563778958322171, 'word': 'wavelet'},\n",
              "   {'score': 0.09563778958322171, 'word': 'transforms'},\n",
              "   {'score': 0.07012970698789543, 'word': 'functions'},\n",
              "   {'score': 0.060999599465307704, 'word': 'signal'},\n",
              "   {'score': 0.060999599465307704, 'word': 'analysis'},\n",
              "   {'score': 0.060999599465307704, 'word': 'technique'},\n",
              "   {'score': 0.05760089856553492, 'word': 'local'},\n",
              "   {'score': 0.05760089856553492, 'word': 'property'},\n",
              "   {'score': 0.04781504302626449, 'word': 'unique'},\n",
              "   {'score': 0.04781504302626449, 'word': 'shape'},\n",
              "   {'score': 0.04781504302626449, 'word': 'description'}],\n",
              "  'Title': 'Approximation and rendering of volume data using wavelet transforms',\n",
              "  'distance': 0,\n",
              "  'no': '513',\n",
              "  'parent': '3958'},\n",
              " {'Abstract': 'For types of data visualization where the cost of producing images is high, and the relationship between the rendering parameters and the image produced is less than obvious, a visual representation of the exploration process can make the process more efficient and effective. Image graphs represent not only the results but also the process of data visualization. Each node in an image graph consists of an image and the corresponding visualization parameters used to produce it. Each edge in a graph shows the change in rendering parameters between the two nodes it connects. Image graphs are not just static representations; users can interact with a graph to review a previous visualization session or to perform new rendering. Operations which cause changes in rendering parameters can propagate through the graph. The user can take advantage of the information in image graphs to understand how certain parameter changes affect visualization results. Users can also share image graphs to streamline the process of collaborative visualization. We have implemented a volume visualization system using the image graph interface, and the examples presented come from this application.',\n",
              "  'AuthorKeywords': ['knowledge',\n",
              "   'representations,',\n",
              "   'scientific',\n",
              "   'visualization,',\n",
              "   'visualization',\n",
              "   'systems,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.1355207480273285, 'word': 'images'},\n",
              "   {'score': 0.0728145942035867, 'word': 'data'},\n",
              "   {'score': 0.0728145942035867, 'word': 'visualization'},\n",
              "   {'score': 0.06273695490208031, 'word': 'rendering'},\n",
              "   {'score': 0.06273695490208031, 'word': 'parameters'},\n",
              "   {'score': 0.05928391371255063, 'word': 'exploration'},\n",
              "   {'score': 0.05928391371255063, 'word': 'process'},\n",
              "   {'score': 0.04908915835386861, 'word': 'image'},\n",
              "   {'score': 0.04908915835386861, 'word': 'graphs'}],\n",
              "  'Title': 'Image graphs-a novel approach to visual data exploration',\n",
              "  'distance': 0,\n",
              "  'no': '514',\n",
              "  'parent': '5437'},\n",
              " {'Abstract': 'We present a new hierarchical clustering and visualization algorithm called H-BLOB, which groups and visualizes cluster hierarchies at multiple levels-of-detail. Our method is fundamentally different to conventional clustering algorithms, such as C-means, K-means, or linkage methods that are primarily designed to partition a collection of objects into subsets sharing similar attributes. These approaches usually lack an efficient level-of-detail strategy that breaks down the visual complexity of very large datasets for visualization. In contrast, our method combines grouping and visualization in a two stage process constructing a hierarchical setting. In the first stage a cluster tree is computed making use of an edge contraction operator. Exploiting the inherent hierarchical structure of this tree, a second stage visualizes the clusters by computing a hierarchy of implicit surfaces. We believe that H-BLOB is especially suited for the visualization of very large datasets and for visual decision making in information visualization. The versatility of the algorithm is demonstrated using examples from visual data mining.',\n",
              "  'AuthorKeywords': ['clustering,',\n",
              "   'categorization,',\n",
              "   'partitioning,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'non-linear',\n",
              "   'dimensionality',\n",
              "   'reduction,',\n",
              "   'physics-based',\n",
              "   'graph',\n",
              "   'layout,',\n",
              "   'cluster',\n",
              "   'visualization,',\n",
              "   'multidimensional',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.07392966057853606, 'word': 'visual'},\n",
              "   {'score': 0.07392966057853606, 'word': 'complexity'},\n",
              "   {'score': 0.07338032168328895, 'word': 'new'},\n",
              "   {'score': 0.07338032168328895, 'word': 'hierarchical'},\n",
              "   {'score': 0.07338032168328895, 'word': 'clustering'},\n",
              "   {'score': 0.050511529841245434, 'word': 'method'},\n",
              "   {'score': 0.04280725822157324, 'word': 'visualization'},\n",
              "   {'score': 0.04280725822157324, 'word': 'algorithm'},\n",
              "   {'score': 0.0422676516945344, 'word': 'stage'},\n",
              "   {'score': 0.0422676516945344, 'word': 'process'}],\n",
              "  'Title': 'H-BLOB: a hierarchical visual clustering method using implicit surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '515',\n",
              "  'parent': '4280'},\n",
              " {'Abstract': 'We propose new clipping methods that are capable of using complex geometries for volume clipping. The clipping tests exploit per-fragment operations on the graphics hardware to achieve high frame rates. In combination with texture-based volume rendering, these techniques enable the user to interactively select and explore regions of the data set. We present depth-based clipping techniques that analyze the depth structure of the boundary representation of the clip geometry to decide which parts of the volume have to be clipped. In another approach, a voxelized clip object is used to identify the clipped regions.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'rendering,',\n",
              "   'clipping,',\n",
              "   'hardware',\n",
              "   'acceleration'],\n",
              "  'MultipartiteRank': [{'score': 0.1040244515864795, 'word': 'volume'},\n",
              "   {'score': 0.08056551843929921, 'word': 'clipping'},\n",
              "   {'score': 0.08056551843929921, 'word': 'tests'},\n",
              "   {'score': 0.06718317486926778, 'word': 'techniques'},\n",
              "   {'score': 0.055415247393764105, 'word': 'depth'},\n",
              "   {'score': 0.04785693843196798, 'word': 'complex'},\n",
              "   {'score': 0.04785693843196798, 'word': 'geometries'}],\n",
              "  'Title': 'Volume clipping via per-fragment operations in texture-based volume visualization',\n",
              "  'distance': 0,\n",
              "  'no': '516',\n",
              "  'parent': '3832'},\n",
              " {'Abstract': \"Animation is an effective way to show how time-varying phenomena evolve over time. A key issue of generating a good animation is to select ideal views through which the user can perceive the maximum amount of information from the time-varying dataset. In this paper, we first propose an improved view selection method for static data. The method measures the quality of a static view by analyzing the opacity, color and curvature distributions of the corresponding volume rendering images from the given view. Our view selection metric prefers an even opacity distribution with a larger projection area, a larger area of salient features' colors with an even distribution among the salient features, and more perceived curvatures. We use this static view selection method and a dynamic programming approach to select time-varying views. The time-varying view selection maximizes the information perceived from the time-varying dataset based on the constraints that the time-varying view should show smooth changes of direction and near-constant speed. We also introduce a method that allows the user to generate a smooth transition between any two views in a given time step, with the perceived information maximized as well. By combining the static and dynamic view selection methods, the users are able to generate a time-varying view that shows the maximum amount of information from a time-varying data set\",\n",
              "  'AuthorKeywords': ['Static',\n",
              "   'view',\n",
              "   'selection,',\n",
              "   'image',\n",
              "   'based',\n",
              "   'method,',\n",
              "   'dynamic',\n",
              "   'view',\n",
              "   'selection,',\n",
              "   'information',\n",
              "   'entropy,',\n",
              "   'optimization'],\n",
              "  'MultipartiteRank': [{'score': 0.11277789083843189, 'word': 'ideal'},\n",
              "   {'score': 0.11277789083843189, 'word': 'views'},\n",
              "   {'score': 0.09798852728362968, 'word': 'time'},\n",
              "   {'score': 0.061835978696961766, 'word': 'animation'},\n",
              "   {'score': 0.04052262576902373, 'word': 'information'},\n",
              "   {'score': 0.04014319377979817, 'word': 'view'}],\n",
              "  'Title': 'Dynamic View Selection for Time-Varying Volumes',\n",
              "  'distance': 0,\n",
              "  'no': '517',\n",
              "  'parent': '5308'},\n",
              " {'Abstract': 'We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.',\n",
              "  'AuthorKeywords': ['Weather',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'polar',\n",
              "   'system,',\n",
              "   'parallel',\n",
              "   'coordinates,',\n",
              "   'air',\n",
              "   'pollution,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.16520313253300611, 'word': 'comprehensive'},\n",
              "   {'score': 0.16520313253300611, 'word': 'system'},\n",
              "   {'score': 0.12707346350465482, 'word': 'weather'},\n",
              "   {'score': 0.12707346350465482, 'word': 'data'},\n",
              "   {'score': 0.12707346350465482, 'word': 'visualization'},\n",
              "   {'score': 0.06642915101219887, 'word': 'multivariate'},\n",
              "   {'score': 0.06391713499477401, 'word': 'parallel'},\n",
              "   {'score': 0.06391713499477401, 'word': 'coordinates'},\n",
              "   {'score': 0.05659727375219338, 'word': 'vector'},\n",
              "   {'score': 0.05659727375219338, 'word': 'fields'}],\n",
              "  'Title': 'Visual Analysis of the Air Pollution Problem in Hong Kong',\n",
              "  'distance': 0,\n",
              "  'no': '518',\n",
              "  'parent': '3413'},\n",
              " {'Abstract': 'The Morse-Smale complex is an efficient representation of the gradient behavior of a scalar function, and critical points paired by the complex identify topological features and their importance. We present an algorithm that constructs the Morse-Smale complex in a series of sweeps through the data, identifying various components of the complex in a consistent manner. All components of the complex, both geometric and topological, are computed, providing a complete decomposition of the domain. Efficiency is maintained by representing the geometry of the complex in terms of point sets.',\n",
              "  'AuthorKeywords': ['Morse',\n",
              "   'theory,',\n",
              "   'Morse-Smale',\n",
              "   'complexes,',\n",
              "   'computational',\n",
              "   'topology,',\n",
              "   'multiresolution,',\n",
              "   'simplification,',\n",
              "   'feature',\n",
              "   'detection,',\n",
              "   '3D',\n",
              "   'scalar',\n",
              "   'fields'],\n",
              "  'MultipartiteRank': [{'score': 0.24122423684990812, 'word': 'complex'},\n",
              "   {'score': 0.16209404790657558, 'word': 'smale'},\n",
              "   {'score': 0.07478635680448599, 'word': 'morse'},\n",
              "   {'score': 0.05519475049655097, 'word': 'efficient'},\n",
              "   {'score': 0.05519475049655097, 'word': 'representation'},\n",
              "   {'score': 0.052626362183689455, 'word': 'topological'},\n",
              "   {'score': 0.052626362183689455, 'word': 'features'}],\n",
              "  'Title': 'Efficient Computation of Morse-Smale Complexes for Three-dimensional Scalar Functions',\n",
              "  'distance': 0,\n",
              "  'no': '519',\n",
              "  'parent': '3400'},\n",
              " {'Abstract': \"Confocal microscopy is widely used in neurobiology for studying the three-dimensional structure of the nervous system. Confocal image data are often multi-channel, with each channel resulting from a different fluorescent dye or fluorescent protein; one channel may have dense data, while another has sparse; and there are often structures at several spatial scales: subneuronal domains, neurons, and large groups of neurons (brain regions). Even qualitative analysis can therefore require visualization using techniques and parameters fine-tuned to a particular dataset. Despite the plethora of volume rendering techniques that have been available for many years, the techniques standardly used in neurobiological research are somewhat rudimentary, such as looking at image slices or maximal intensity projections. Thus there is a real demand from neurobiologists, and biologists in general, for a flexible visualization tool that allows interactive visualization of multi-channel confocal data, with rapid fine-tuning of parameters to reveal the three-dimensional relationships of structures of interest. Together with neurobiologists, we have designed such a tool, choosing visualization methods to suit the characteristics of confocal data and a typical biologist's workflow. We use interactive volume rendering with intuitive settings for multidimensional transfer functions, multiple render modes and multi-views for multi-channel volume data, and embedding of polygon data into volume data for rendering and editing. As an example, we apply this tool to visualize confocal microscopy datasets of the developing zebrafish visual system.\",\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'neurobiology,',\n",
              "   'confocal',\n",
              "   'microscopy,',\n",
              "   'qualitative',\n",
              "   'analysis,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.05009378623712958, 'word': 'confocal'},\n",
              "   {'score': 0.05009378623712958, 'word': 'image'},\n",
              "   {'score': 0.05009378623712958, 'word': 'data'},\n",
              "   {'score': 0.04501323156019695, 'word': 'dimensional'},\n",
              "   {'score': 0.04501323156019695, 'word': 'structure'},\n",
              "   {'score': 0.04434922331466584, 'word': 'techniques'},\n",
              "   {'score': 0.03736883404023104, 'word': 'visualization'},\n",
              "   {'score': 0.03244994815028396, 'word': 'volume'}],\n",
              "  'Title': 'An interactive visualization tool for multi-channel confocal microscopy data in neurobiology research',\n",
              "  'distance': 0,\n",
              "  'no': '520',\n",
              "  'parent': '5524'},\n",
              " {'Abstract': 'We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R&lt;sup&gt;3&lt;/sup&gt; and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.',\n",
              "  'AuthorKeywords': ['Voxel',\n",
              "   'arrays,',\n",
              "   'oct-trees,',\n",
              "   'persistent',\n",
              "   'homology,',\n",
              "   'persistence',\n",
              "   'diagrams,',\n",
              "   'level',\n",
              "   'sets,',\n",
              "   'robustness,',\n",
              "   'approximations,',\n",
              "   'plant',\n",
              "   'roots'],\n",
              "  'MultipartiteRank': [{'score': 0.06623128906197061, 'word': 'homology'},\n",
              "   {'score': 0.06623128906197061, 'word': 'classes'},\n",
              "   {'score': 0.06591184967509313, 'word': 'continuous'},\n",
              "   {'score': 0.06591184967509313, 'word': 'function'},\n",
              "   {'score': 0.06036116474900498, 'word': 'level'},\n",
              "   {'score': 0.05902218197219839, 'word': 'interlevel'},\n",
              "   {'score': 0.05902218197219839, 'word': 'sets'},\n",
              "   {'score': 0.05667259548726896, 'word': 'intensity'},\n",
              "   {'score': 0.05667259548726896, 'word': 'values'}],\n",
              "  'Title': 'Computing Robustness and Persistence for Images',\n",
              "  'distance': 0,\n",
              "  'no': '521',\n",
              "  'parent': '3960'},\n",
              " {'Abstract': \"Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.\",\n",
              "  'AuthorKeywords': ['Tensor',\n",
              "   'Glyphs,',\n",
              "   'Stress',\n",
              "   'Tensors,',\n",
              "   'Rate-of-Deformation',\n",
              "   'Tensors,',\n",
              "   'Geometry',\n",
              "   'Tensors,',\n",
              "   'Glyph',\n",
              "   'Design'],\n",
              "  'MultipartiteRank': [{'score': 0.1778175780728995, 'word': 'tensor'},\n",
              "   {'score': 0.1250617264291731, 'word': 'order'},\n",
              "   {'score': 0.1250617264291731, 'word': 'fields'},\n",
              "   {'score': 0.06138358745998135, 'word': 'symmetric'},\n",
              "   {'score': 0.06138358745998135, 'word': 'second'},\n",
              "   {'score': 0.05275585164372639, 'word': 'glyph'},\n",
              "   {'score': 0.0493651686315456, 'word': 'extraction'},\n",
              "   {'score': 0.0493651686315456, 'word': 'methods'},\n",
              "   {'score': 0.03612603107804124, 'word': 'positive'}],\n",
              "  'Title': 'Superquadric Glyphs for Symmetric Second-Order Tensors',\n",
              "  'distance': 0,\n",
              "  'no': '522',\n",
              "  'parent': '5318'},\n",
              " {'Abstract': \"This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'knowledge',\n",
              "   'discovery,',\n",
              "   'visual',\n",
              "   'knowledge',\n",
              "   'representation,',\n",
              "   'sport',\n",
              "   'analytics,',\n",
              "   'visual',\n",
              "   'aggregation'],\n",
              "  'MultipartiteRank': [{'score': 0.0632396872607481, 'word': 'analysts'},\n",
              "   {'score': 0.05449149460400085, 'word': 'individual'},\n",
              "   {'score': 0.05449149460400085, 'word': 'players'},\n",
              "   {'score': 0.05197737316048897, 'word': 'soccerstories'},\n",
              "   {'score': 0.04461642624640883, 'word': 'visualization'},\n",
              "   {'score': 0.04461642624640883, 'word': 'interface'},\n",
              "   {'score': 0.039936301000988814, 'word': 'game'}],\n",
              "  'Title': 'SoccerStories: A Kick-off for Visual Soccer Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '523',\n",
              "  'parent': '4837'},\n",
              " {'Abstract': \"Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Knowledge',\n",
              "   'Generation,',\n",
              "   'Uncertainty',\n",
              "   'Measures',\n",
              "   'and',\n",
              "   'Propagation,',\n",
              "   'Trust',\n",
              "   'Building,',\n",
              "   'Human',\n",
              "   'Factors'],\n",
              "  'MultipartiteRank': [{'score': 0.0985681440699512, 'word': 'visual'},\n",
              "   {'score': 0.0985681440699512, 'word': 'analytics'},\n",
              "   {'score': 0.06583016161017984, 'word': 'user'},\n",
              "   {'score': 0.06522229095730407, 'word': 'knowledge'},\n",
              "   {'score': 0.05800892893653619, 'word': 'uncertainties'},\n",
              "   {'score': 0.050441141147262385, 'word': 'humans'}],\n",
              "  'Title': 'The Role of Uncertainty, Awareness, and Trust in Visual Analytics',\n",
              "  'distance': 0,\n",
              "  'no': '524',\n",
              "  'parent': '4052'},\n",
              " {'Abstract': 'Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'analytics,',\n",
              "   'movement',\n",
              "   'data,',\n",
              "   'networks,',\n",
              "   'graphs,',\n",
              "   'temporal',\n",
              "   'aggregation,',\n",
              "   'spatial',\n",
              "   'aggregation,',\n",
              "   'flows,',\n",
              "   'clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.0956157821334355, 'word': 'mobility'},\n",
              "   {'score': 0.05534750375747798, 'word': 'people'},\n",
              "   {'score': 0.046655138293720685, 'word': 'variation'},\n",
              "   {'score': 0.04645836822230999, 'word': 'time'},\n",
              "   {'score': 0.04124071429287035, 'word': 'movements'},\n",
              "   {'score': 0.04026827837595752, 'word': 'data'},\n",
              "   {'score': 0.04026827837595752, 'word': 'sets'}],\n",
              "  'Title': 'MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering',\n",
              "  'distance': 0,\n",
              "  'no': '525',\n",
              "  'parent': '4963'},\n",
              " {'Abstract': \"While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'analytics,deep',\n",
              "   'learning,machine',\n",
              "   'learning,information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1556140360404903, 'word': 'models'},\n",
              "   {'score': 0.0882869532349555, 'word': 'deep'},\n",
              "   {'score': 0.0882869532349555, 'word': 'learning'},\n",
              "   {'score': 0.04588289740388779, 'word': 'users'},\n",
              "   {'score': 0.043787285757585004, 'word': 'facebook'},\n",
              "   {'score': 0.039056067333790974, 'word': 'activis'}],\n",
              "  'Title': 'ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models',\n",
              "  'distance': 0,\n",
              "  'no': '526',\n",
              "  'parent': '4526'},\n",
              " {'Abstract': 'Volume rendering has been proposed as a useful tool for extracting information from large datasets, where non-visual analysis alone may not be feasible. The scale of these applications implies that data management is an important issue that needs to be addressed. Most volume rendering algorithms, however, process data in raw, uncompressed form. In previous work, we introduced a compressed volume format that may be volume rendered directly with minimal impact on rendering time. In this paper, we extend these ideas to a new volume format that not only reduces storage space and transmission time, but is designed for fast volume rendering as well. The volume dataset is represented as indices into a small codebook of representative blocks. With the data structure, volume shading calculations need only be performed on the codebook and image generation is accelerated by reusing precomputed block projections.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17778350855407007, 'word': 'volume'},\n",
              "   {'score': 0.17778350855407007, 'word': 'rendering'},\n",
              "   {'score': 0.06872970174660016, 'word': 'data'},\n",
              "   {'score': 0.06872970174660016, 'word': 'management'},\n",
              "   {'score': 0.056616814696261175, 'word': 'useful'},\n",
              "   {'score': 0.056616814696261175, 'word': 'tool'},\n",
              "   {'score': 0.053863752906990484, 'word': 'information'},\n",
              "   {'score': 0.048263213131888444, 'word': 'large'},\n",
              "   {'score': 0.048263213131888444, 'word': 'datasets'}],\n",
              "  'Title': 'Fast volume rendering of compressed data',\n",
              "  'distance': 0,\n",
              "  'no': '527',\n",
              "  'parent': '4118'},\n",
              " {'Abstract': 'VolVis is a diversified, easy to use, extensible, high performance, and portable volume visualization system for scientists and engineers as well as for visualization developers and researchers. VolVis accepts as input 3D scalar volumetric data as well as 3D volume-sampled and classical geometric models. Interaction with the data is controlled by a variety of 3D input devices in an input device-independent environment. VolVis output includes navigation preview, static images, and animation sequences. A variety of volume rendering algorithms are supported ranging from fast rough approximations, to compression-domain rendering, to accurate volumetric ray tracing and radiosity, and irregular grid rendering.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10977087322304147, 'word': 'volvis'},\n",
              "   {'score': 0.0915003455540283, 'word': '3d'},\n",
              "   {'score': 0.04858666125926485, 'word': 'volume'},\n",
              "   {'score': 0.048555955083369184, 'word': 'variety'},\n",
              "   {'score': 0.04291368429476346, 'word': 'input'},\n",
              "   {'score': 0.04291368429476346, 'word': 'devices'},\n",
              "   {'score': 0.042612663537418036, 'word': 'researchers'}],\n",
              "  'Title': 'VolVis: a diversified volume visualization system',\n",
              "  'distance': 0,\n",
              "  'no': '528',\n",
              "  'parent': '3415'},\n",
              " {'Abstract': 'Scalar fields arise in every scientific application. Existing scalar visualization techniques require that the user infers the global scalar structure from what is frequently an insufficient display of information. We present a visualization technique which numerically detects the structure at all scales, removing from the user the responsibility of extracting information implicit in the data, and presenting the structure explicitly for analysis. We further demonstrate how scalar topology detection proves useful for correct visualization and image processing applications such as image co-registration, isocontouring, and mesh compression.',\n",
              "  'AuthorKeywords': ['Scientific',\n",
              "   'Visualization,',\n",
              "   'Scalar',\n",
              "   'Fields,',\n",
              "   'Curves',\n",
              "   'and',\n",
              "   'Surfaces,',\n",
              "   'Vector',\n",
              "   'Topology'],\n",
              "  'MultipartiteRank': [{'score': 0.2253727307762894, 'word': 'scalar'},\n",
              "   {'score': 0.17268325252222572, 'word': 'structure'},\n",
              "   {'score': 0.11532155415738464, 'word': 'visualization'},\n",
              "   {'score': 0.11532155415738464, 'word': 'techniques'},\n",
              "   {'score': 0.11005117661890473, 'word': 'global'},\n",
              "   {'score': 0.10101734962592537, 'word': 'user'},\n",
              "   {'score': 0.08668789620743715, 'word': 'information'}],\n",
              "  'Title': 'Visualization of scalar topology for structural enhancement',\n",
              "  'distance': 0,\n",
              "  'no': '529',\n",
              "  'parent': '3769'},\n",
              " {'Abstract': '3D time-varying unstructured and structured data sets are difficult to visualize and analyze because of the immense amount of data involved. These data sets contain many evolving amorphous regions, and standard visualization techniques provide no facilities to aid the scientist to follow regions of interest. In this paper, we present a basic framework for the visualization of time-varying data sets, and a new algorithm and data structure to track volume features in unstructured scalar data sets. The algorithm and data structure are general and can be used for structured, curvilinear, adaptive and hybrid grids as well. The features tracked can be any type of connected regions. Examples are shown from ongoing research.',\n",
              "  'AuthorKeywords': ['Scientific',\n",
              "   'Visualization,',\n",
              "   'Time-varying',\n",
              "   'Visualization,Feature',\n",
              "   'Tracking,',\n",
              "   'Computer',\n",
              "   'Vision,',\n",
              "   'CFD'],\n",
              "  'MultipartiteRank': [{'score': 0.1444236050966725, 'word': 'structured'},\n",
              "   {'score': 0.1444236050966725, 'word': 'data'},\n",
              "   {'score': 0.1444236050966725, 'word': 'sets'},\n",
              "   {'score': 0.0746704048728122, 'word': '3d'},\n",
              "   {'score': 0.0746704048728122, 'word': 'time'},\n",
              "   {'score': 0.059515089032254276, 'word': 'unstructured'},\n",
              "   {'score': 0.059006306269712636, 'word': 'amorphous'},\n",
              "   {'score': 0.059006306269712636, 'word': 'regions'},\n",
              "   {'score': 0.05225820264458962, 'word': 'difficult'}],\n",
              "  'Title': 'Tracking scalar features in unstructured datasets',\n",
              "  'distance': 0,\n",
              "  'no': '530',\n",
              "  'parent': '3769'},\n",
              " {'Abstract': 'While molecular visualization software has advanced over the years, today, most tools still operate on individual molecular structures with limited facility to manipulate large multicomponent complexes. We approach this problem by extending 3D image-based rendering via programmable graphics units, resulting in an order of magnitude speedup over traditional triangle-based rendering. By incorporating a biochemically sensitive level-of-detail hierarchy into our molecular representation, we communicate appropriate volume occupancy and shape while dramatically reducing the visual clutter that normally inhibits higher-level spatial comprehension. Our hierarchical, image based rendering also allows dynamically computed physical properties data (e.g. electrostatics potential) to be mapped onto the molecular surface, tying molecular structure to molecular function. Finally, we present another approach to interactive molecular exploration using volumetric and structural rendering in tandem to discover molecular properties that neither rendering mode alone could reveal. These visualization techniques are realized in a high-performance, interactive molecular exploration tool we call TexMol, short for Texture Molecular viewer.',\n",
              "  'AuthorKeywords': ['molecular',\n",
              "   'visualization,',\n",
              "   'image-based',\n",
              "   'rendering,',\n",
              "   'texture-based',\n",
              "   'rendering,',\n",
              "   'imposter',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'programmable',\n",
              "   'graphics',\n",
              "   'hardware,',\n",
              "   'level-of-detail,',\n",
              "   'hierarchy,',\n",
              "   'multiresolution,',\n",
              "   'synchronous',\n",
              "   'view,',\n",
              "   'computer',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.11396586496062469, 'word': 'molecular'},\n",
              "   {'score': 0.08599812123427211, 'word': 'rendering'},\n",
              "   {'score': 0.0830744053648894, 'word': 'individual'},\n",
              "   {'score': 0.0830744053648894, 'word': 'structures'},\n",
              "   {'score': 0.047700107348327865, 'word': '3d'},\n",
              "   {'score': 0.047700107348327865, 'word': 'image'},\n",
              "   {'score': 0.040032145993487915, 'word': 'limited'},\n",
              "   {'score': 0.040032145993487915, 'word': 'facility'},\n",
              "   {'score': 0.03089145959573529, 'word': 'interactive'},\n",
              "   {'score': 0.03089145959573529, 'word': 'exploration'}],\n",
              "  'Title': 'TexMol: interactive visual exploration of large flexible multi-component molecular complexes',\n",
              "  'distance': 0,\n",
              "  'no': '531',\n",
              "  'parent': '4257'},\n",
              " {'Abstract': 'We present a novel visual correlation paradigm for situational awareness (SA) and suggest its usage in a diverse set of applications that require a high level of SA. Our approach is based on a concise and scalable representation, which leads to a flexible visualization tool that is both clear and intuitive to use. Situational awareness is the continuous extraction of environmental information, its integration with previous knowledge to form a coherent mental picture, and the use of that picture in anticipating future events. In this paper we build on our previous work on visualization for network intrusion detection and show how that approach can be generalized to encompass a much broader class of SA systems. We first propose a generalization that is based on what we term, the w/sup 3/ premise, namely that each event must have at least the what, when and where attributes. We also present a second generalization, which increases flexibility and facilitates complex visual correlations. Finally, we demonstrate the generality of our approaches by applying our visualization paradigm in a collection of diverse SA areas.',\n",
              "  'AuthorKeywords': ['situation',\n",
              "   'awareness,',\n",
              "   'network',\n",
              "   'intrusion,',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.07002406997884505, 'word': 'novel'},\n",
              "   {'score': 0.07002406997884505, 'word': 'visual'},\n",
              "   {'score': 0.07002406997884505, 'word': 'correlation'},\n",
              "   {'score': 0.07002406997884505, 'word': 'paradigm'},\n",
              "   {'score': 0.05801052708430805, 'word': 'situational'},\n",
              "   {'score': 0.05801052708430805, 'word': 'awareness'},\n",
              "   {'score': 0.04617641712202678, 'word': 'previous'},\n",
              "   {'score': 0.04617641712202678, 'word': 'knowledge'},\n",
              "   {'score': 0.04484878426251948, 'word': 'approach'},\n",
              "   {'score': 0.042386643581239176, 'word': 'coherent'},\n",
              "   {'score': 0.042386643581239176, 'word': 'mental'},\n",
              "   {'score': 0.042386643581239176, 'word': 'picture'}],\n",
              "  'Title': 'Visual correlation for situational awareness',\n",
              "  'distance': 0,\n",
              "  'no': '532',\n",
              "  'parent': '5538'},\n",
              " {'Abstract': 'This paper proposes novel methods for visualizing specifically the large power-law graphs that arise in sociology and the sciences. In such cases a large portion of edges can be shown to be less important and removed while preserving component connectedness and other features (e.g. cliques) to more clearly reveal the networkpsilas underlying connection pathways. This simplification approach deterministically filters (instead of clustering) the graph to retain important node and edge semantics, and works both automatically and interactively. The improved graph filtering and layout is combined with a novel computer graphics anisotropic shading of the dense crisscrossing array of edges to yield a full social network and scale-free graph visualization system. Both quantitative analysis and visual results demonstrate the effectiveness of this approach.',\n",
              "  'AuthorKeywords': ['Scale-free',\n",
              "   'network,',\n",
              "   'edge',\n",
              "   'filtering,',\n",
              "   'betweenness',\n",
              "   'centrality,',\n",
              "   'anisotropic',\n",
              "   'shading'],\n",
              "  'MultipartiteRank': [{'score': 0.08744315071272389, 'word': 'law'},\n",
              "   {'score': 0.08744315071272389, 'word': 'graphs'},\n",
              "   {'score': 0.07852952969718009, 'word': 'large'},\n",
              "   {'score': 0.07852952969718009, 'word': 'power'},\n",
              "   {'score': 0.07837941101683063, 'word': 'edges'},\n",
              "   {'score': 0.04737690767840263, 'word': 'important'},\n",
              "   {'score': 0.04108851273898201, 'word': 'sociology'}],\n",
              "  'Title': 'On the Visualization of Social and other Scale-Free Networks',\n",
              "  'distance': 0,\n",
              "  'no': '533',\n",
              "  'parent': '4341'},\n",
              " {'Abstract': 'Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.',\n",
              "  'AuthorKeywords': ['Network',\n",
              "   'layout',\n",
              "   'visualization,',\n",
              "   'perceptual',\n",
              "   'organization,',\n",
              "   'graph',\n",
              "   'layout,',\n",
              "   'user',\n",
              "   'studies'],\n",
              "  'MultipartiteRank': [{'score': 0.07256904590139035, 'word': 'many'},\n",
              "   {'score': 0.07256904590139035, 'word': 'graph'},\n",
              "   {'score': 0.07256904590139035, 'word': 'layout'},\n",
              "   {'score': 0.06379325469275846, 'word': 'clusters'},\n",
              "   {'score': 0.050049549513118255, 'word': 'edge'},\n",
              "   {'score': 0.050049549513118255, 'word': 'crossings'},\n",
              "   {'score': 0.04755268855550523, 'word': 'visual'},\n",
              "   {'score': 0.04755268855550523, 'word': 'characteristics'},\n",
              "   {'score': 0.04340918276297828, 'word': 'nodes'}],\n",
              "  'Title': 'Perceptual Organization in User-Generated Graph Layouts',\n",
              "  'distance': 0,\n",
              "  'no': '534',\n",
              "  'parent': '5500'},\n",
              " {'Abstract': 'The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'layout,',\n",
              "   'network',\n",
              "   'layout,',\n",
              "   'automatic',\n",
              "   'layout',\n",
              "   'algorithms,',\n",
              "   'user-generated',\n",
              "   'layout,',\n",
              "   'graph-drawing',\n",
              "   'aesthetics'],\n",
              "  'MultipartiteRank': [{'score': 0.15119788289081804, 'word': 'automatic'},\n",
              "   {'score': 0.15119788289081804, 'word': 'graph'},\n",
              "   {'score': 0.15119788289081804, 'word': 'layouts'},\n",
              "   {'score': 0.12346360248624043, 'word': 'user'},\n",
              "   {'score': 0.06882373496600747, 'word': 'layout'},\n",
              "   {'score': 0.05501046620865522, 'word': 'methods'},\n",
              "   {'score': 0.035341276820331745, 'word': 'analytical'},\n",
              "   {'score': 0.035341276820331745, 'word': 'tasks'}],\n",
              "  'Title': 'A Comparison of User-Generated and Automatic Graph Layouts',\n",
              "  'distance': 0,\n",
              "  'no': '535',\n",
              "  'parent': '5010'},\n",
              " {'Abstract': 'Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.',\n",
              "  'AuthorKeywords': ['Regression,',\n",
              "   'model',\n",
              "   'building,',\n",
              "   'visual',\n",
              "   'knowledge',\n",
              "   'discovery,',\n",
              "   'feature',\n",
              "   'selection,',\n",
              "   'data',\n",
              "   'partitioning,',\n",
              "   'guided',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.06243867650849258, 'word': 'regression'},\n",
              "   {'score': 0.06243867650849258, 'word': 'models'},\n",
              "   {'score': 0.05593403155356072, 'word': 'feature'},\n",
              "   {'score': 0.05593403155356072, 'word': 'subset'},\n",
              "   {'score': 0.05593403155356072, 'word': 'selection'},\n",
              "   {'score': 0.04176636580300993, 'word': 'quantitative'},\n",
              "   {'score': 0.04176636580300993, 'word': 'dependent'},\n",
              "   {'score': 0.04176636580300993, 'word': 'variable'},\n",
              "   {'score': 0.03917701521967883, 'word': 'local'},\n",
              "   {'score': 0.03917701521967883, 'word': 'structures'},\n",
              "   {'score': 0.03815299251356211, 'word': 'framework'}],\n",
              "  'Title': 'A Partition-Based Framework for Building and Validating Regression Models',\n",
              "  'distance': 0,\n",
              "  'no': '536',\n",
              "  'parent': '5676'},\n",
              " {'Abstract': \"Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n = 1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber's law. The results of this experiment contribute to our understanding of information visualization by establishing that: (1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber's law, (2) correlation judgment precision showed striking variation between negatively and positively correlated data, and (3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization.\",\n",
              "  'AuthorKeywords': ['Perception,', 'Visualization,', 'Evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.12193737489633553, 'word': 'visualization'},\n",
              "   {'score': 0.12193737489633553, 'word': 'design'},\n",
              "   {'score': 0.05822583813655587, 'word': 'perceptual'},\n",
              "   {'score': 0.05822583813655587, 'word': 'laws'},\n",
              "   {'score': 0.048354313802986264, 'word': 'correlation'},\n",
              "   {'score': 0.043785169783269975, 'word': 'weber'},\n",
              "   {'score': 0.03621276398491597, 'word': 'practitioners'}],\n",
              "  'Title': \"Ranking Visualizations of Correlation Using Weber's Law\",\n",
              "  'distance': 0,\n",
              "  'no': '537',\n",
              "  'parent': '3990'},\n",
              " {'Abstract': 'Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'Visualization,',\n",
              "   'Temporal',\n",
              "   'Event',\n",
              "   'Sequences,',\n",
              "   'Visual',\n",
              "   'Analytics,',\n",
              "   'Flow',\n",
              "   'Diagrams,',\n",
              "   'Medical',\n",
              "   'Informatics'],\n",
              "  'MultipartiteRank': [{'score': 0.14879737422243414, 'word': 'event'},\n",
              "   {'score': 0.09109944023477592, 'word': 'temporal'},\n",
              "   {'score': 0.09109944023477592, 'word': 'sequence'},\n",
              "   {'score': 0.09109944023477592, 'word': 'data'},\n",
              "   {'score': 0.06244799906158786, 'word': 'dimensional'},\n",
              "   {'score': 0.06244799906158786, 'word': 'datasets'},\n",
              "   {'score': 0.05769793398765821, 'word': 'distinct'},\n",
              "   {'score': 0.05769793398765821, 'word': 'types'},\n",
              "   {'score': 0.04422843878868466, 'word': 'decisionflow'},\n",
              "   {'score': 0.04371638321462516, 'word': 'techniques'}],\n",
              "  'Title': 'DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data',\n",
              "  'distance': 0,\n",
              "  'no': '538',\n",
              "  'parent': '3885'},\n",
              " {'Abstract': 'Interactive selection is a critical component in exploratory visualization, allowing users to isolate subsets of the displayed information for highlighting, deleting, analysis, or focussed investigation. Brushing, a popular method for implementing the selection process, has traditionally been performed in either screen space or data space. We introduce the concept of a structure-based brush, which can be used to perform selection in hierarchically structured data sets. Our structure-based brush allows users to navigate hierarchies by specifying focal extents and level-of-detail on a visual representation of the structure. Proximity-based coloring, which maps similar colors to data that are closely related within the structure, helps convey both structural relationships and anomalies. We describe the design and implementation of our structure-based brushing tool. We also validate its usefulness using two distinct hierarchical visualization techniques, namely hierarchical parallel coordinates and tree-maps.',\n",
              "  'AuthorKeywords': ['Brushing,',\n",
              "   'hierarchical',\n",
              "   'representation,',\n",
              "   'interactive',\n",
              "   'selection,',\n",
              "   'exploratory',\n",
              "   'data',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.08991369564868135, 'word': 'interactive'},\n",
              "   {'score': 0.08991369564868135, 'word': 'selection'},\n",
              "   {'score': 0.08140720760327438, 'word': 'structure'},\n",
              "   {'score': 0.05168931338055816, 'word': 'brushing'},\n",
              "   {'score': 0.05058875458942501, 'word': 'exploratory'},\n",
              "   {'score': 0.05058875458942501, 'word': 'visualization'},\n",
              "   {'score': 0.04965868161687365, 'word': 'data'},\n",
              "   {'score': 0.04965868161687365, 'word': 'space'}],\n",
              "  'Title': 'Navigating hierarchies with structure-based brushes',\n",
              "  'distance': 0,\n",
              "  'no': '539',\n",
              "  'parent': '3844'},\n",
              " {'Abstract': 'The Temporal Branch-on-Need Tree (T-BON) extends the three dimensional branch-on-need octree for time-varying isosurface extraction. At each time step, only those portions of the tree and data necessary to construct the current isosurface are read from disk. This algorithm can thus exploit the temporal locality of the isosurface and, as a geometric technique, spatial locality between cells in order to improve performance. Experimental results demonstrate the performance gained and memory overhead saved using this technique.',\n",
              "  'AuthorKeywords': ['isosurface,',\n",
              "   'time-dependent',\n",
              "   'scalar',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'multiresolution',\n",
              "   'methods,',\n",
              "   'octree'],\n",
              "  'MultipartiteRank': [{'score': 0.13102214191599604, 'word': 'temporal'},\n",
              "   {'score': 0.08721003143274587, 'word': 'isosurface'},\n",
              "   {'score': 0.08721003143274587, 'word': 'extraction'},\n",
              "   {'score': 0.07248244646976672, 'word': 'branch'},\n",
              "   {'score': 0.07139730297651367, 'word': 'time'},\n",
              "   {'score': 0.07099455140812476, 'word': 'need'},\n",
              "   {'score': 0.07099455140812476, 'word': 'tree'},\n",
              "   {'score': 0.05853969544622933, 'word': 'locality'}],\n",
              "  'Title': 'Isosurface extraction in time-varying fields using a Temporal Branch-on-Need Tree (T-BON)',\n",
              "  'distance': 0,\n",
              "  'no': '540',\n",
              "  'parent': '3431'},\n",
              " {'Abstract': 'Visualization is a powerful way to facilitate data analysis, but it is crucial that visualization systems explicitly convey the presence, nature, and degree of uncertainty to users. Otherwise, there is a danger that data will be falsely interpreted, potentially leading to inaccurate conclusions. A common method for denoting uncertainty is to use error bars or similar techniques designed to convey the degree of statistical uncertainty. While uncertainty can often be modeled statistically, a second form of uncertainty, bounded uncertainty, can also arise that has very different properties than statistical uncertainty. Error bars should not be used for bounded uncertainty because they do not convey the correct properties, so a different technique should be used instead. We describe a technique for conveying bounded uncertainty in visualizations and show how it can be applied systematically to common displays of abstract charts and graphs. Interestingly, it is not always possible to show the exact degree of uncertainty, and in some cases it can only be displayed approximately.',\n",
              "  'AuthorKeywords': ['uncertainty',\n",
              "   'visualization,',\n",
              "   'bounded',\n",
              "   'uncertainty'],\n",
              "  'MultipartiteRank': [{'score': 0.16069791554720342, 'word': 'uncertainty'},\n",
              "   {'score': 0.08632637369177104, 'word': 'visualization'},\n",
              "   {'score': 0.06558649823713925, 'word': 'degree'},\n",
              "   {'score': 0.05346202154326956, 'word': 'similar'},\n",
              "   {'score': 0.05346202154326956, 'word': 'techniques'},\n",
              "   {'score': 0.049275409046741235, 'word': 'error'},\n",
              "   {'score': 0.049275409046741235, 'word': 'bars'}],\n",
              "  'Title': 'Visualizing data with bounded uncertainty',\n",
              "  'distance': 0,\n",
              "  'no': '541',\n",
              "  'parent': '5845'},\n",
              " {'Abstract': 'In many application domains, data is collected and referenced by its geospatial location. Nowadays, different kinds of maps are used to emphasize the spatial distribution of one or more geospatial attributes. The nature of geospatial statistical data is the highly nonuniform distribution in the real world data sets. This has several impacts on the resulting map visualizations. Classical area maps tend to highlight patterns in large areas, which may, however, be of low importance. Cartographers and geographers used cartograms or value-by-area maps to address this problem long before computers were available. Although many automatic techniques have been developed, most of the value-by-area cartograms are generated manually via human interaction. In this paper, we propose a novel visualization technique for geospatial data sets called RecMap. Our technique approximates a rectangular partition of the (rectangular) display area into a number of map regions preserving important geospatial constraints. It is a fully automatic technique with explicit user control over all exploration constraints within the exploration process. Experiments show that our technique produces visualizations of geospatial data sets, which enhance the discovery of global and local correlations, and demonstrate its performance in a variety of applications',\n",
              "  'AuthorKeywords': ['Geographic',\n",
              "   'Visualization,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Database',\n",
              "   'and',\n",
              "   'Data',\n",
              "   'Mining',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08555418917384194, 'word': 'many'},\n",
              "   {'score': 0.07934943658190918, 'word': 'data'},\n",
              "   {'score': 0.06615891703325288, 'word': 'maps'},\n",
              "   {'score': 0.04515882278939582, 'word': 'application'},\n",
              "   {'score': 0.04515882278939582, 'word': 'domains'},\n",
              "   {'score': 0.04039536638444612, 'word': 'automatic'},\n",
              "   {'score': 0.04039536638444612, 'word': 'techniques'},\n",
              "   {'score': 0.03625374884889054, 'word': 'map'},\n",
              "   {'score': 0.03625374884889054, 'word': 'visualizations'}],\n",
              "  'Title': 'RecMap: Rectangular Map Approximations',\n",
              "  'distance': 0,\n",
              "  'no': '542',\n",
              "  'parent': '4153'},\n",
              " {'Abstract': 'We present a novel approach for interactive view-dependent rendering of massive models. Our algorithm combines view-dependent simplification, occlusion culling, and out-of-core rendering. We represent the model as a clustered hierarchy of progressive meshes (CHPM). We use the cluster hierarchy for coarse-grained selective refinement and progressive meshes for fine-grained local refinement. We present an out-of-core algorithm for computation of a CHPM that includes cluster decomposition, hierarchy generation, and simplification. We make use of novel cluster dependencies in preprocess to generate crack-free, drastic simplifications at runtime. The clusters are used for occlusion culling and out-of-core rendering. We add a frame of latency to the rendering pipeline to fetch newly visible clusters from the disk and to avoid stalls. The CHPM reduces the refinement cost for view-dependent rendering by more than an order of magnitude as compared to a vertex hierarchy. We have implemented our algorithm on a desktop PC. We can render massive CAD, isosurface, and scanned models, consisting of tens or a few hundreds of millions of triangles at 10-35 frames per second with little loss in image quality.',\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'display,',\n",
              "   'view-dependent',\n",
              "   'rendering,',\n",
              "   'occlusion',\n",
              "   'culling,',\n",
              "   'external-memory',\n",
              "   'algorithm,',\n",
              "   'levels-of-detail'],\n",
              "  'MultipartiteRank': [{'score': 0.10479061720803833, 'word': 'dependent'},\n",
              "   {'score': 0.06667619469690383, 'word': 'clustered'},\n",
              "   {'score': 0.06667619469690383, 'word': 'hierarchy'},\n",
              "   {'score': 0.06235478493218947, 'word': 'rendering'},\n",
              "   {'score': 0.05907165547423573, 'word': 'interactive'},\n",
              "   {'score': 0.05907165547423573, 'word': 'view'},\n",
              "   {'score': 0.0459441578284442, 'word': 'massive'},\n",
              "   {'score': 0.0459441578284442, 'word': 'models'},\n",
              "   {'score': 0.04243583227584886, 'word': 'simplification'}],\n",
              "  'Title': 'Quick-VDR: interactive view-dependent rendering of massive models',\n",
              "  'distance': 0,\n",
              "  'no': '543',\n",
              "  'parent': '4319'},\n",
              " {'Abstract': 'We present a tool for real-time visualization of motion features in 2D image sequences. The motion is estimated through an eigenvector analysis of the spatio-temporal structure tensor at every pixel location. This approach is computationally demanding but allows reliable velocity estimates as well as quality indicators for the obtained results. We use a 2D color map and a region of interest selector for the visualization of the velocities. On the selected velocities we apply a hierarchical smoothing scheme which allows the choice of the desired scale of the motion field. We demonstrate several examples of test sequences in which some persons are moving with different velocities than others. These persons are visually marked in the real-time display of the image sequence. The tool is also applied to angiography sequences to emphasize the blood flow and its distribution. An efficient processing of the data streams is achieved by mapping the operations onto the stream architecture of standard graphics cards. The card receives the images and performs both the motion estimation and visualization, taking advantage of the parallelism in the graphics processor and the superior memory bandwidth. The integration of data processing and visualization also saves on unnecessary data transfers and thus allows the real-time analysis of 320/spl times/240 images. We expect that on the newest generation of graphics hardware our tool could run in real time for the standard VGA format.',\n",
              "  'AuthorKeywords': ['motion',\n",
              "   'estimation,',\n",
              "   'motion',\n",
              "   'visualization,',\n",
              "   'structure',\n",
              "   'tensor,',\n",
              "   'eigenvector',\n",
              "   'analysis,',\n",
              "   'real-time',\n",
              "   'processing,',\n",
              "   'graphics',\n",
              "   'hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.0671615867627284, 'word': 'motion'},\n",
              "   {'score': 0.0671615867627284, 'word': 'features'},\n",
              "   {'score': 0.06056738089721374, 'word': 'time'},\n",
              "   {'score': 0.06056738089721374, 'word': 'visualization'},\n",
              "   {'score': 0.05011265083979713, 'word': '2d'},\n",
              "   {'score': 0.05011265083979713, 'word': 'image'},\n",
              "   {'score': 0.05011265083979713, 'word': 'sequences'},\n",
              "   {'score': 0.04983140460004817, 'word': 'real'},\n",
              "   {'score': 0.04295335699470345, 'word': 'reliable'},\n",
              "   {'score': 0.04295335699470345, 'word': 'velocity'},\n",
              "   {'score': 0.04295335699470345, 'word': 'estimates'}],\n",
              "  'Title': 'Real-time motion estimation and visualization on graphics cards',\n",
              "  'distance': 0,\n",
              "  'no': '544',\n",
              "  'parent': '5412'},\n",
              " {'Abstract': 'The multi triangulation framework (MT) is a very general approach for managing adaptive resolution in triangle meshes. The key idea is arranging mesh fragments at different resolution in a directed acyclic graph (DAG) which encodes the dependencies between fragments, thereby encompassing a wide class of multiresolution approaches that use hierarchies or DAGs with predefined topology. On current architectures, the classic MT is however unfit for real-time rendering, since DAG traversal costs vastly dominate raw rendering costs. In this paper, we redesign the MT framework in a GPU friendly fashion, moving its granularity from triangles to precomputed optimized triangle patches. The patches can be conveniently tri-stripped and stored in secondary memory to be loaded on demand, ready to be sent to the GPU using preferential paths. In this manner, central memory only contains the DAG structure and CPU workload becomes negligible. The major contributions of this work are: a new out-of-core multiresolution framework, that, just like the MT, encompasses a wide class of multiresolution structures; a robust and elegant way to build a well conditioned MT DAG by introducing the concept of V-partitions, that can encompass various state of the art multiresolution algorithms; an efficient multithreaded rendering engine and a general subsystem for the external memory processing and simplification of huge meshes.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06205285730813434, 'word': 'dag'},\n",
              "   {'score': 0.04162712738856399, 'word': 'adaptive'},\n",
              "   {'score': 0.04162712738856399, 'word': 'resolution'},\n",
              "   {'score': 0.03808129589965058, 'word': 'triangle'},\n",
              "   {'score': 0.03808129589965058, 'word': 'meshes'},\n",
              "   {'score': 0.03437966589629417, 'word': 'general'},\n",
              "   {'score': 0.03437966589629417, 'word': 'approach'},\n",
              "   {'score': 0.034138223273014245, 'word': 'mesh'},\n",
              "   {'score': 0.034138223273014245, 'word': 'fragments'}],\n",
              "  'Title': 'Batched multi triangulation',\n",
              "  'distance': 0,\n",
              "  'no': '545',\n",
              "  'parent': '4879'},\n",
              " {'Abstract': \"Finding suitable, less space consuming views for a document's main content is crucial to provide convenient access to large document collections on display devices of different size. We present a novel compact visualization which represents the document's key semantic as a mixture of images and important key terms, similar to cards in a top trumps game. The key terms are extracted using an advanced text mining approach based on a fully automatic document structure extraction. The images and their captions are extracted using a graphical heuristic and the captions are used for a semi-semantic image weighting. Furthermore, we use the image color histogram for classification and show at least one representative from each non-empty image class. The approach is demonstrated for the IEEE InfoVis publications of a complete year. The method can easily be applied to other publication collections and sets of documents which contain images.\",\n",
              "  'AuthorKeywords': ['document',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'summary,',\n",
              "   'content',\n",
              "   'extraction,',\n",
              "   'document',\n",
              "   'collection',\n",
              "   'browsing'],\n",
              "  'MultipartiteRank': [{'score': 0.10438552431145122, 'word': 'document'},\n",
              "   {'score': 0.08259503617696091, 'word': 'images'},\n",
              "   {'score': 0.07859599675712217, 'word': 'key'},\n",
              "   {'score': 0.07859599675712217, 'word': 'semantic'},\n",
              "   {'score': 0.037792196606678465, 'word': 'mixture'},\n",
              "   {'score': 0.035243728444294256, 'word': 'captions'}],\n",
              "  'Title': 'Document Cards: A Top Trumps Visualization for Documents',\n",
              "  'distance': 0,\n",
              "  'no': '546',\n",
              "  'parent': '3804'},\n",
              " {'Abstract': \"An increasing number of temporal categorical databases are being collected: Electronic Health Records in healthcare organizations, traffic incident logs in transportation systems, or student records in universities. Finding similar records within these large databases requires effective similarity measures that capture the searcher's intent. Many similarity measures exist for numerical time series, but temporal categorical records are different. We propose a temporal categorical similarity measure, the M&amp;M (Match &amp; Mismatch) measure, which is based on the concept of aligning records by sentinel events, then matching events between the target and the compared records. The M&amp;M measure combines the time differences between pairs of events and the number of mismatches. To accom-modate customization of parameters in the M&amp;M measure and results interpretation, we implemented Similan, an interactive search and visualization tool for temporal categorical records. A usability study with 8 participants demonstrated that Similan was easy to learn and enabled them to find similar records, but users had difficulty understanding the M&amp;M measure. The usability study feedback, led to an improved version with a continuous timeline, which was tested in a pilot study with 5 participants.\",\n",
              "  'AuthorKeywords': ['Similan,',\n",
              "   'M&M',\n",
              "   'Measure,',\n",
              "   'Similarity',\n",
              "   'Search,',\n",
              "   'Temporal',\n",
              "   'Categorical',\n",
              "   'Records'],\n",
              "  'MultipartiteRank': [{'score': 0.08906510705985932, 'word': 'electronic'},\n",
              "   {'score': 0.08906510705985932, 'word': 'health'},\n",
              "   {'score': 0.08906510705985932, 'word': 'records'},\n",
              "   {'score': 0.06531433198466755, 'word': 'temporal'},\n",
              "   {'score': 0.06531433198466755, 'word': 'categorical'},\n",
              "   {'score': 0.06531433198466755, 'word': 'databases'},\n",
              "   {'score': 0.04402835223114228, 'word': 'effective'},\n",
              "   {'score': 0.04402835223114228, 'word': 'similarity'},\n",
              "   {'score': 0.04402835223114228, 'word': 'measures'},\n",
              "   {'score': 0.0396941134131404, 'word': 'number'},\n",
              "   {'score': 0.03751504693188584, 'word': 'healthcare'},\n",
              "   {'score': 0.03751504693188584, 'word': 'organizations'}],\n",
              "  'Title': 'Finding comparable temporal categorical records: A similarity measure with an interactive visualization',\n",
              "  'distance': 0,\n",
              "  'no': '547',\n",
              "  'parent': '4963'},\n",
              " {'Abstract': 'We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'toolkits,',\n",
              "   'domain',\n",
              "   'specific',\n",
              "   'languages,',\n",
              "   'declarative',\n",
              "   'languages,',\n",
              "   'optimization'],\n",
              "  'MultipartiteRank': [{'score': 0.10817670832076576, 'word': 'specific'},\n",
              "   {'score': 0.10817670832076576, 'word': 'languages'},\n",
              "   {'score': 0.05905234041370509, 'word': 'declarative'},\n",
              "   {'score': 0.058970441854962974, 'word': 'design'},\n",
              "   {'score': 0.055762965973322864, 'word': 'interactive'},\n",
              "   {'score': 0.055762965973322864, 'word': 'visualizations'},\n",
              "   {'score': 0.04616824471531468, 'word': 'domain'}],\n",
              "  'Title': 'Declarative Language Design for Interactive Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '548',\n",
              "  'parent': '4566'},\n",
              " {'Abstract': 'A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.',\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'graph',\n",
              "   'drawing,',\n",
              "   'network',\n",
              "   'layout,',\n",
              "   'attribute-driven',\n",
              "   'layout,',\n",
              "   'parallel',\n",
              "   'coordinates,',\n",
              "   'scatterplot',\n",
              "   'matrix,',\n",
              "   'radial',\n",
              "   'menu'],\n",
              "  'MultipartiteRank': [{'score': 0.10519087358551332, 'word': 'scatterplots'},\n",
              "   {'score': 0.06706827543281997, 'word': 'multivariate'},\n",
              "   {'score': 0.06706827543281997, 'word': 'networks'},\n",
              "   {'score': 0.06629414985500934, 'word': 'nodes'},\n",
              "   {'score': 0.04575741581705109, 'word': 'layout'},\n",
              "   {'score': 0.04341418290083025, 'word': 'novel'},\n",
              "   {'score': 0.04341418290083025, 'word': 'approaches'}],\n",
              "  'Title': 'The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration',\n",
              "  'distance': 0,\n",
              "  'no': '549',\n",
              "  'parent': '4292'},\n",
              " {'Abstract': \"We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.\",\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'qualitative',\n",
              "   'evaluation,',\n",
              "   'quantitative',\n",
              "   'evaluation,',\n",
              "   'perception'],\n",
              "  'MultipartiteRank': [{'score': 0.06910496616093476, 'word': 'line'},\n",
              "   {'score': 0.06910496616093476, 'word': 'graphical'},\n",
              "   {'score': 0.06910496616093476, 'word': 'primitives'},\n",
              "   {'score': 0.06586581934192103, 'word': 'uncertainty'},\n",
              "   {'score': 0.047952843877665574, 'word': 'blur'},\n",
              "   {'score': 0.04537565588326132, 'word': 'visual'},\n",
              "   {'score': 0.04537565588326132, 'word': 'variables'},\n",
              "   {'score': 0.04343141216009713, 'word': 'visualizations'}],\n",
              "  'Title': 'Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty',\n",
              "  'distance': 0,\n",
              "  'no': '550',\n",
              "  'parent': '4528'},\n",
              " {'Abstract': \"Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, &amp; delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, &amp; prescribe) and interaction operands (space-alone, attributes-in-space, &amp; space-in-time; elementary &amp; general). The operator sort suggested five enabling operators (import, export, save, edit, &amp; annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, &amp; calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.\",\n",
              "  'AuthorKeywords': ['Science',\n",
              "   'of',\n",
              "   'interaction,',\n",
              "   'interaction',\n",
              "   'primitives,',\n",
              "   'interactive',\n",
              "   'maps,',\n",
              "   'geovisualization,',\n",
              "   'interaction',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.06321354394927303, 'word': 'primitives'},\n",
              "   {'score': 0.050294925359560864, 'word': 'interaction'},\n",
              "   {'score': 0.04210937989128604, 'word': 'information'},\n",
              "   {'score': 0.04210937989128604, 'word': 'visualization'},\n",
              "   {'score': 0.04003131215835614, 'word': 'amp'},\n",
              "   {'score': 0.036027543095854514, 'word': 'operator'},\n",
              "   {'score': 0.02718600085341852, 'word': 'objective'}],\n",
              "  'Title': 'An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization',\n",
              "  'distance': 0,\n",
              "  'no': '551',\n",
              "  'parent': '5737'},\n",
              " {'Abstract': \"Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.\",\n",
              "  'AuthorKeywords': ['Hierarchical',\n",
              "   'topic',\n",
              "   'visualization,',\n",
              "   'evolutionary',\n",
              "   'tree',\n",
              "   'clustering,',\n",
              "   'data',\n",
              "   'transformation'],\n",
              "  'MultipartiteRank': [{'score': 0.09912902818308128, 'word': 'topic'},\n",
              "   {'score': 0.09912902818308128, 'word': 'trees'},\n",
              "   {'score': 0.08371078529468887, 'word': 'topics'},\n",
              "   {'score': 0.06571564282280186, 'word': 'users'},\n",
              "   {'score': 0.0325879703310765, 'word': 'text'},\n",
              "   {'score': 0.0325879703310765, 'word': 'corpora'},\n",
              "   {'score': 0.02695337337020305, 'word': 'interests'}],\n",
              "  'Title': 'How Hierarchical Topics Evolve in Large Text Corpora',\n",
              "  'distance': 0,\n",
              "  'no': '552',\n",
              "  'parent': '5364'},\n",
              " {'Abstract': \"In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable “at-a-glance” are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.\",\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'memorability,',\n",
              "   'recognition,',\n",
              "   'recall,',\n",
              "   'eye-tracking',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.15541125548344437, 'word': 'memorability'},\n",
              "   {'score': 0.09464891773127021, 'word': 'visualizations'},\n",
              "   {'score': 0.05804105316720112, 'word': 'participants'},\n",
              "   {'score': 0.05401416051528032, 'word': 'paper'},\n",
              "   {'score': 0.051010249461212444, 'word': 'message'}],\n",
              "  'Title': 'Beyond Memorability: Visualization Recognition and Recall',\n",
              "  'distance': 0,\n",
              "  'no': '553',\n",
              "  'parent': '3747'},\n",
              " {'Abstract': 'The representation of a scene at different levels of detail is necessary to achieve real-time rendering. In aerial views, only the part of the scene that is close to the viewing point needs to be displayed with a high level of detail, while more distant parts can be displayed with a low level of detail. However, when a sequence of images is generated and displayed in real-time, the transition between different levels of detail causes noticeable temporal aliasing. In this paper, we propose a method, based on object blending, that visually softens the transition between two levels of Delaunay triangulation. We present an algorithm that establishes, in an off-line process, a correspondence between two given polygonal objects. The correspondence enables on-line blending between two representations of an object, so that one representation (level of detail) progressively evolves into the other.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11273146117997149, 'word': 'different'},\n",
              "   {'score': 0.11273146117997149, 'word': 'levels'},\n",
              "   {'score': 0.07461092141810527, 'word': 'detail'},\n",
              "   {'score': 0.05193198414761488, 'word': 'time'},\n",
              "   {'score': 0.05193198414761488, 'word': 'rendering'},\n",
              "   {'score': 0.05066933593084094, 'word': 'real'},\n",
              "   {'score': 0.04713426846587901, 'word': 'scene'}],\n",
              "  'Title': 'Temporal continuity of levels of detail in Delaunay triangulated terrain',\n",
              "  'distance': 0,\n",
              "  'no': '554',\n",
              "  'parent': '4389'},\n",
              " {'Abstract': '3D time varying datasets are difficult to visualize and analyze because of the immense amount of data involved. This is especially true when the datasets are turbulent with many evolving amorphous regions, as it is difficult to observe patterns and follow regions of interest. We present our volume based feature tracking algorithm and discuss how it can be used to help visualize and analyze large time varying datasets. We also address efficiency issues in dealing with massive time varying datasets.',\n",
              "  'AuthorKeywords': ['Scientific',\n",
              "   'Visualization,',\n",
              "   'Multi-dimensional',\n",
              "   'Visualization,',\n",
              "   'Feature',\n",
              "   'Tracking,',\n",
              "   'Computer',\n",
              "   'Vision,',\n",
              "   'CFD'],\n",
              "  'MultipartiteRank': [{'score': 0.1117224423504536, 'word': '3d'},\n",
              "   {'score': 0.1117224423504536, 'word': 'time'},\n",
              "   {'score': 0.1117224423504536, 'word': 'varying'},\n",
              "   {'score': 0.1117224423504536, 'word': 'datasets'},\n",
              "   {'score': 0.11000296344850298, 'word': 'difficult'},\n",
              "   {'score': 0.10101586235493173, 'word': 'amorphous'},\n",
              "   {'score': 0.10101586235493173, 'word': 'regions'},\n",
              "   {'score': 0.07402654746001136, 'word': 'many'},\n",
              "   {'score': 0.07113213767627392, 'word': 'turbulent'}],\n",
              "  'Title': 'Volume tracking',\n",
              "  'distance': 0,\n",
              "  'no': '555',\n",
              "  'parent': '4124'},\n",
              " {'Abstract': 'Distance judgments are difficult in current virtual environments, limiting their effectiveness in conveying spatial information. This problem is apparent when contact occurs while a user is manipulating objects. In particular, the computer graphics used to support current-generation immersive interfaces does a poor job of providing the visual cues necessary to perceive when contact between objects is about to occur. This perception of imminent contact is important in human motor control. Its absence prevents a sense of naturalness in interactive displays which allow for object manipulation. This paper reports results from an experiment evaluating the effectiveness of binocular disparity, cast shadows and diffuse inter-reflections in signaling imminent contact in a manipulation task.',\n",
              "  'AuthorKeywords': ['virtual',\n",
              "   'reality,',\n",
              "   'head',\n",
              "   'mounted',\n",
              "   'displays,',\n",
              "   'human',\n",
              "   'visual',\n",
              "   'perception'],\n",
              "  'MultipartiteRank': [{'score': 0.09148029797090687, 'word': 'contact'},\n",
              "   {'score': 0.0728908481800774, 'word': 'objects'},\n",
              "   {'score': 0.05830445518989592, 'word': 'current'},\n",
              "   {'score': 0.05830445518989592, 'word': 'virtual'},\n",
              "   {'score': 0.05830445518989592, 'word': 'environments'},\n",
              "   {'score': 0.049520330203118995, 'word': 'effectiveness'},\n",
              "   {'score': 0.03818510498301318, 'word': 'apparent'}],\n",
              "  'Title': 'Visual cues for imminent object contact in realistic virtual environment',\n",
              "  'distance': 0,\n",
              "  'no': '556',\n",
              "  'parent': '4402'},\n",
              " {'Abstract': 'This paper presents a procedure for virtual autopsies based on interactive 3D visualizations of large scale, high resolution data from CT-scans of human cadavers. The procedure is described using examples from forensic medicine and the added value and future potential of virtual autopsies is shown from a medical and forensic perspective. Based on the technical demands of the procedure state-of-the-art volume rendering techniques are applied and refined to enable real-time, full body virtual autopsies involving gigabyte sized data on standard GPUs. The techniques applied include transfer function based data reduction using level-of-detail selection and multi-resolution rendering techniques. The paper also describes a data management component for large, out-of-core data sets and an extension to the GPU-based raycaster for efficient dual TF rendering. Detailed benchmarks of the pipeline are presented using data sets from forensic cases',\n",
              "  'AuthorKeywords': ['Forensics,',\n",
              "   'autopsies,',\n",
              "   'medical',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'large',\n",
              "   'scale',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.06832251872284191, 'word': 'virtual'},\n",
              "   {'score': 0.06832251872284191, 'word': 'autopsies'},\n",
              "   {'score': 0.058403387134407264, 'word': 'data'},\n",
              "   {'score': 0.057516602651879994, 'word': 'procedure'},\n",
              "   {'score': 0.04949702385256161, 'word': 'forensic'},\n",
              "   {'score': 0.04949702385256161, 'word': 'medicine'},\n",
              "   {'score': 0.037612944532735774, 'word': 'large'},\n",
              "   {'score': 0.037612944532735774, 'word': 'scale'}],\n",
              "  'Title': 'Full Body Virtual Autopsies using a State-of-the-art Volume Rendering Pipeline',\n",
              "  'distance': 0,\n",
              "  'no': '557',\n",
              "  'parent': '5058'},\n",
              " {'Abstract': 'We have combined methods from volume visualization and data analysis to support better diagnosis and treatment of human retinal diseases. Many diseases can be identified by abnormalities in the thicknesses of various retinal layers captured using optical coherence tomography (OCT). We used a support vector machine (SVM) to perform semi-automatic segmentation of retinal layers for subsequent analysis including a comparison of layer thicknesses to known healthy parameters. We have extended and generalized an older SVM approach to support better performance in a clinical setting through performance enhancements and graceful handling of inherent noise in OCT data by considering statistical characteristics at multiple levels of resolution. The addition of the multi-resolution hierarchy extends the SVM to have \"global awareness\". A feature, such as a retinal layer, can therefore be modeled within the SVM as a combination of statistical characteristics across all levels; thus capturing high- and low-frequency information. We have compared our semi-automatically generated segmentations to manually segmented layers for verification purposes. Our main goals were to provide a tool that could (i) be used in a clinical setting; (ii) operate on noisy OCT data; and (iii) isolate individual or multiple retinal layers in both healthy and disease cases that contain structural deformities.',\n",
              "  'AuthorKeywords': ['support',\n",
              "   'vector',\n",
              "   'machine,',\n",
              "   'segmentation,',\n",
              "   'image',\n",
              "   'analysis,',\n",
              "   'retinal,',\n",
              "   'optical',\n",
              "   'coherence',\n",
              "   'tomography,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'image',\n",
              "   'processing'],\n",
              "  'MultipartiteRank': [{'score': 0.0581957155656342, 'word': 'various'},\n",
              "   {'score': 0.0581957155656342, 'word': 'retinal'},\n",
              "   {'score': 0.0581957155656342, 'word': 'layers'},\n",
              "   {'score': 0.046012989817268646, 'word': 'svm'},\n",
              "   {'score': 0.0425786962243779, 'word': 'thicknesses'},\n",
              "   {'score': 0.04204053244755308, 'word': 'oct'},\n",
              "   {'score': 0.039475810964310125, 'word': 'data'},\n",
              "   {'score': 0.039475810964310125, 'word': 'analysis'}],\n",
              "  'Title': 'Segmentation of Three-dimensional Retinal Image Data',\n",
              "  'distance': 0,\n",
              "  'no': '558',\n",
              "  'parent': '5037'},\n",
              " {'Abstract': \"Molecular dynamics simulations of proteins play a growing role in various fields such as pharmaceutical, biochemical and medical research. Accordingly, the need for high quality visualization of these protein systems raises. Highly interactive visualization techniques are especially needed for the analysis of time-dependent molecular simulations. Beside various other molecular representations the surface representations are of high importance for these applications. So far, users had to accept a trade-off between rendering quality and performance - particularly when visualizing trajectories of time-dependent protein data. We present a new approach for visualizing the solvent excluded surface of proteins using a GPU ray casting technique and thus achieving interactive frame rates even for long protein trajectories where conventional methods based on precomputation are not applicable. Furthermore, we propose a semantic simplification of the raw protein data to reduce the visual complexity of the surface and thereby accelerate the rendering without impeding perception of the protein's basic shape. We also demonstrate the application of our solvent excluded surface method to visualize the spatial probability density for the protein atoms over the whole period of the trajectory in one frame, providing a qualitative analysis of the protein flexibility.\",\n",
              "  'AuthorKeywords': ['Point-based',\n",
              "   'Data,',\n",
              "   'Time-varying',\n",
              "   'Data,',\n",
              "   'GPU,',\n",
              "   'Ray',\n",
              "   'Casting,',\n",
              "   'Molecular',\n",
              "   'Visualization,',\n",
              "   'Surface',\n",
              "   'Extraction,',\n",
              "   'Isosurfaces'],\n",
              "  'MultipartiteRank': [{'score': 0.10638265516217366, 'word': 'proteins'},\n",
              "   {'score': 0.05721134554303216, 'word': 'molecular'},\n",
              "   {'score': 0.052699346775659316, 'word': 'surface'},\n",
              "   {'score': 0.052699346775659316, 'word': 'representations'},\n",
              "   {'score': 0.038085195171546876, 'word': 'trajectories'},\n",
              "   {'score': 0.03594334069915451, 'word': 'applications'}],\n",
              "  'Title': 'Interactive Visualization of Molecular Surface Dynamics',\n",
              "  'distance': 0,\n",
              "  'no': '559',\n",
              "  'parent': '5613'},\n",
              " {'Abstract': 'Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.',\n",
              "  'AuthorKeywords': ['Multivariate',\n",
              "   'Networks,',\n",
              "   'Selections',\n",
              "   'of',\n",
              "   'Interest,',\n",
              "   'Interaction,',\n",
              "   'Direct',\n",
              "   'Manipulation'],\n",
              "  'MultipartiteRank': [{'score': 0.14093548354268834, 'word': 'network'},\n",
              "   {'score': 0.14093548354268834, 'word': 'data'},\n",
              "   {'score': 0.06885332255747223, 'word': 'multivariate'},\n",
              "   {'score': 0.04770370405102513, 'word': 'ubiquitous'},\n",
              "   {'score': 0.027320992954506865, 'word': 'examples'},\n",
              "   {'score': 0.02721747126707075, 'word': 'topological'},\n",
              "   {'score': 0.02721747126707075, 'word': 'structure'}],\n",
              "  'Title': 'Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations',\n",
              "  'distance': 0,\n",
              "  'no': '560',\n",
              "  'parent': '4613'},\n",
              " {'Abstract': 'In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.',\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'boxplots,',\n",
              "   'ensemble',\n",
              "   'visualization,',\n",
              "   'order',\n",
              "   'statistics,',\n",
              "   'data',\n",
              "   'depth,',\n",
              "   'nonparametric',\n",
              "   'statistic,',\n",
              "   'functional',\n",
              "   'data,',\n",
              "   'parametric',\n",
              "   'curves'],\n",
              "  'MultipartiteRank': [{'score': 0.11023114427043712, 'word': 'simulation'},\n",
              "   {'score': 0.09089642993333344, 'word': 'ensembles'},\n",
              "   {'score': 0.05451706497264757, 'word': 'science'},\n",
              "   {'score': 0.052798766850507065, 'word': 'curves'},\n",
              "   {'score': 0.04307330503592491, 'word': 'methods'}],\n",
              "  'Title': 'Curve Boxplot: Generalization of Boxplot for Ensembles of Curves',\n",
              "  'distance': 0,\n",
              "  'no': '561',\n",
              "  'parent': '5125'},\n",
              " {'Abstract': 'We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.',\n",
              "  'AuthorKeywords': ['Dynamic',\n",
              "   'Networks,',\n",
              "   'Exploration,',\n",
              "   'Dimensionality',\n",
              "   'Reduction'],\n",
              "  'MultipartiteRank': [{'score': 0.11281107654489796, 'word': 'approach'},\n",
              "   {'score': 0.08405110487447107, 'word': 'dynamic'},\n",
              "   {'score': 0.08405110487447107, 'word': 'networks'},\n",
              "   {'score': 0.06592874868366475, 'word': 'visual'},\n",
              "   {'score': 0.06592874868366475, 'word': 'analytics'},\n",
              "   {'score': 0.04807180572098363, 'word': 'stable'},\n",
              "   {'score': 0.04807180572098363, 'word': 'states'},\n",
              "   {'score': 0.04688232786123321, 'word': 'users'},\n",
              "   {'score': 0.0447946716660541, 'word': 'snapshots'}],\n",
              "  'Title': 'Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration',\n",
              "  'distance': 0,\n",
              "  'no': '562',\n",
              "  'parent': '3861'},\n",
              " {'Abstract': 'An algorithm for rendering of orthographic views of volume data on data-parallel computer architectures is described. In particular, the problem or rotating the volume in regard to the communication overhead associated with finely distributed memory is analyzed. An earlier technique (shear decomposition) is extended to 3D, and it is shown how this can be mapped onto a data-parallel architecture using only grid communication during the resampling associated with the rotation. The rendering uses efficient parallel computation constructs that allow one to use sophisticated shading models and still maintain high-speed throughout. This algorithm has been implemented on the connection machine and is used in an interactive volume-rendering application, with multiple frames-per-second performance.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14564552635136735, 'word': 'volume'},\n",
              "   {'score': 0.09115666703831365, 'word': 'data'},\n",
              "   {'score': 0.0865965295004137, 'word': 'parallel'},\n",
              "   {'score': 0.0865965295004137, 'word': 'computer'},\n",
              "   {'score': 0.0865965295004137, 'word': 'architectures'},\n",
              "   {'score': 0.061042682452658856, 'word': 'rendering'},\n",
              "   {'score': 0.052780343573877196, 'word': 'communication'}],\n",
              "  'Title': 'Fast rotation of volume data on parallel architectures',\n",
              "  'distance': 0,\n",
              "  'no': '563',\n",
              "  'parent': '3739'},\n",
              " {'Abstract': \"We present a case study of visualizing the global topology of the Internet MBone. The MBone is the Internet's multicast backbone. Multicast is the most efficient way of distributing data from one sender to multiple receivers with minimal packet duplication. Developed and initially deployed by researchers within the Internet community, the MBone has been extremely popular for efficient transmission across the Internet of real-time video and audio streams such as conferences, meetings, congressional sessions, and NASA shuttle launches. The MBone, like the Internet itself grew exponentially with no central authority. The resulting suboptimal topology is of growing concern to network providers and the multicast research community. We create a geographic representation of the tunnel structure as arcs on a globe by resolving the latitude and longitude of MBone routers. The interactive 3D maps permit an immediate understanding of the global structure unavailable from the data in its original form as lines of text with only hostnames and IP addresses. Data visualization techniques such as grouping and thresholding allow further analysis of specific aspects of the MBone topology. We distribute the interactive 3D maps through the World-Wide Web using the VRML file format thus allowing network maintainers throughout the world to analyze the structure move effectively than would be possible with still pictures or pre-made videos.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15307886534473117, 'word': 'mbone'},\n",
              "   {'score': 0.12356031192814725, 'word': 'internet'},\n",
              "   {'score': 0.03743505547687589, 'word': 'global'},\n",
              "   {'score': 0.03743505547687589, 'word': 'topology'},\n",
              "   {'score': 0.0371888503297861, 'word': 'multicast'},\n",
              "   {'score': 0.0371888503297861, 'word': 'backbone'}],\n",
              "  'Title': 'Visualizing the global topology of the MBone',\n",
              "  'distance': 0,\n",
              "  'no': '564',\n",
              "  'parent': '5328'},\n",
              " {'Abstract': 'Concerns the development of non-photorealistic rendering techniques for volume visualisation. In particular, we present two pen-and-ink rendering methods, a 3D method based on non-photorealistic solid textures, and a 2/sup +/D method that involves two rendering phases in the object space and the image space respectively. As both techniques utilize volume- and image-based data representations, they can be built upon a traditional volume rendering pipeline, and can be integrated with the photorealistic methods available in such a pipeline. We demonstrate that such an integration facilitates an effective mechanism for enhancing visualisation and its interpretation.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'rendering,',\n",
              "   'non-photorealistic',\n",
              "   'rendering,',\n",
              "   'pen-and-ink',\n",
              "   'rendering,',\n",
              "   '3D',\n",
              "   'texture',\n",
              "   'mapping'],\n",
              "  'MultipartiteRank': [{'score': 0.1364190582718897, 'word': 'space'},\n",
              "   {'score': 0.08317118750226671, 'word': 'image'},\n",
              "   {'score': 0.07052716771959792, 'word': 'volume'},\n",
              "   {'score': 0.07052716771959792, 'word': 'visualisation'},\n",
              "   {'score': 0.06005884308473744, 'word': 'pipeline'},\n",
              "   {'score': 0.056057340478782726, 'word': 'volume-'},\n",
              "   {'score': 0.053247870769622986, 'word': 'object'}],\n",
              "  'Title': 'Pen-and-ink rendering in volume visualisation',\n",
              "  'distance': 0,\n",
              "  'no': '565',\n",
              "  'parent': '3786'},\n",
              " {'Abstract': 'Visualization algorithms have seen substantial improvements in the past several years. However, very few algorithms have been developed for directly studying data in dimensions higher than three. Most algorithms require a sampling in three-dimensions before applying any visualization algorithms. This sampling typically ignores vital features that may be present when examined in oblique cross-sections, and places an undo burden on system resources when animation through additional dimensions is desired. For time-varying data of large data sets, smooth animation is desired at interactive rates. We provide a fast Marching Cubes like algorithm for hypercubes of any dimension. To support this, we have developed a new algorithm to automatically generate the isosurface and triangulation tables for any dimension. This allows the efficient calculation of 4D isosurfaces, which can be interactively sliced to provide smooth animation or slicing through oblique hyperplanes. The former allows for smooth animation in a very compressed format. The latter provide better tools to study time-evolving features as they move downstream. We also provide examples in using this technique to show interval volumes or the sensitivity of a particular isovalue threshold.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0941670695366211, 'word': 'visualization'},\n",
              "   {'score': 0.0941670695366211, 'word': 'algorithms'},\n",
              "   {'score': 0.08442941482231436, 'word': 'dimensions'},\n",
              "   {'score': 0.08442941482231436, 'word': 'higher'},\n",
              "   {'score': 0.06394069464106648, 'word': 'data'},\n",
              "   {'score': 0.06143991010099121, 'word': 'animation'},\n",
              "   {'score': 0.04482465068937515, 'word': 'sampling'}],\n",
              "  'Title': 'Isosurfacing in higher dimensions',\n",
              "  'distance': 0,\n",
              "  'no': '566',\n",
              "  'parent': '4510'},\n",
              " {'Abstract': 'Automatic detection of meaningful isosurfaces is important for producing informative visualizations of volume data, especially when no information about the data origin and imaging protocol is available. We propose a computationally efficient method for the automated detection of intensity transitions in volume data. In this approach, the dominant transitions correspond to clear maxima in cumulative Laplacian-weighted gray value histograms. Only one pass through the data volume is required to compute the histogram. Several other features which may be useful for exploration of data of unknown origin can be efficiently computed in a similar manner. The detected intensity transitions can be used for setting of visualization parameters for surface rendering, as well as for direct volume rendering of 3D datasets. When using surface rendering, the detected dominant intensity transition values correspond to the optimal surface isovalues for extraction of boundaries of the objects of interest. In direct volume rendering, such transitions are important for generation of the transfer functions, which are used to assign visualization properties to data voxels and determine the appearance of the rendered image. The proposed method is illustrated by examples with synthetic data as well as real biomedical datasets.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'surface',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'isosurfaces,',\n",
              "   'divergence',\n",
              "   'theorem'],\n",
              "  'MultipartiteRank': [{'score': 0.10071975155603174, 'word': 'volume'},\n",
              "   {'score': 0.10071975155603174, 'word': 'data'},\n",
              "   {'score': 0.0761939824206066, 'word': 'automatic'},\n",
              "   {'score': 0.0761939824206066, 'word': 'detection'},\n",
              "   {'score': 0.06140974023543105, 'word': 'intensity'},\n",
              "   {'score': 0.06140974023543105, 'word': 'transitions'},\n",
              "   {'score': 0.04415560144646621, 'word': 'informative'},\n",
              "   {'score': 0.04415560144646621, 'word': 'visualizations'},\n",
              "   {'score': 0.04022616550557185, 'word': 'important'}],\n",
              "  'Title': 'Fast detection of meaningful isosurfaces for volume data visualization',\n",
              "  'distance': 0,\n",
              "  'no': '567',\n",
              "  'parent': '4572'},\n",
              " {'Abstract': 'We describe a virtual reality environment for visualizing tensor-valued volumetric datasets acquired with diffusion tensor magnetic resonance imaging (DT-MRI). We have prototyped a virtual environment that displays geometric representations of the volumetric second-order diffusion tensor data and are developing interaction and visualization techniques for two application areas: studying changes in white-matter structures after gamma-knife capsulotomy and pre-operative planning for brain tumor surgery. Our feedback shows that compared to desktop displays, our system helps the user better interpret the large and complex geometric models, and facilitates communication among a group of users.',\n",
              "  'AuthorKeywords': ['Scientific',\n",
              "   'Visualization,',\n",
              "   'DT-MRI,',\n",
              "   'Diffusion,',\n",
              "   'Medical',\n",
              "   'Imaging,',\n",
              "   'Virtual',\n",
              "   'Reality'],\n",
              "  'MultipartiteRank': [{'score': 0.11943495215977351, 'word': 'tensor'},\n",
              "   {'score': 0.07360994705885271, 'word': 'volumetric'},\n",
              "   {'score': 0.07360994705885271, 'word': 'datasets'},\n",
              "   {'score': 0.0709407063032673, 'word': 'diffusion'},\n",
              "   {'score': 0.0709407063032673, 'word': 'magnetic'},\n",
              "   {'score': 0.0709407063032673, 'word': 'resonance'},\n",
              "   {'score': 0.0709407063032673, 'word': 'imaging'},\n",
              "   {'score': 0.06284475611611953, 'word': 'virtual'},\n",
              "   {'score': 0.06284475611611953, 'word': 'reality'},\n",
              "   {'score': 0.06284475611611953, 'word': 'environment'},\n",
              "   {'score': 0.051533711667162516, 'word': 'user'}],\n",
              "  'Title': 'An immersive virtual environment for DT-MRI volume visualization applications: a case study',\n",
              "  'distance': 0,\n",
              "  'no': '568',\n",
              "  'parent': '3492'},\n",
              " {'Abstract': 'We propose the use of textured splats as the basic display primitives for an open surface fire model. The high-detail textures help to achieve a smooth boundary of the fire and gain the small-scale turbulence appearance. We utilize the Lattice Boltzmann Model (LBM) to simulate physically-based equations describing the fire evolution and its interaction with the environment (e.g., obstacles, wind and temperature). The property of fuel and non-burning objects are defined on the lattice of the computation domain. A temperature field is also incorporated to model the generation of smoke from the fire due to incomplete combustion. The linear and local characteristics of the LBM enable us to accelerate the computation with graphics hardware to reach real-time simulation speed, while the texture splat primitives enable interactive rendering frame rates.',\n",
              "  'AuthorKeywords': ['Fire',\n",
              "   'Modeling,',\n",
              "   'Textured',\n",
              "   'Splatting,',\n",
              "   'Lattice',\n",
              "   'Boltzmann',\n",
              "   'Model,',\n",
              "   'Graphics',\n",
              "   'Hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.065713195033761, 'word': 'textured'},\n",
              "   {'score': 0.065713195033761, 'word': 'splats'},\n",
              "   {'score': 0.06348332017015813, 'word': 'fire'},\n",
              "   {'score': 0.04522287271039138, 'word': 'temperature'},\n",
              "   {'score': 0.04238492723298171, 'word': 'lattice'},\n",
              "   {'score': 0.04238492723298171, 'word': 'boltzmann'},\n",
              "   {'score': 0.04238492723298171, 'word': 'model'},\n",
              "   {'score': 0.042382533492297085, 'word': 'lbm'}],\n",
              "  'Title': 'Simulating fire with texture splats',\n",
              "  'distance': 0,\n",
              "  'no': '569',\n",
              "  'parent': '4148'},\n",
              " {'Abstract': 'We present a new method for guiding virtual colonoscopic navigation and registration by using teniae coli as anatomical landmarks. As most existing protocols require a patient to be scanned in both supine and prone positions to increase sensitivity in detecting colonic polyps, reference and registration between scans are necessary. However, the conventional centerline approach, generating only the longitudinal distance along the colon, lacks the necessary orientation information to synchronize the virtual navigation cameras in both scanned positions. In this paper we describe a semi-automatic method to detect teniae coli from a colonic surface model reconstructed from CT colonography. Teniae coli are three bands of longitudinal smooth muscle on the surface of the colon. They form a triple helix structure from the appendix to the sigmoid colon and are ideal references for virtual navigation. Our method was applied to 3 patients resulting in 6 data sets (supine and prone scans). The detected teniae coli matched well with our visual inspection. In addition, we demonstrate that polyps visible on both scans can be located and matched more efficiently with the aid of a teniae coli guided navigation implementation.',\n",
              "  'AuthorKeywords': ['virtual',\n",
              "   'colonoscopy,',\n",
              "   'CT',\n",
              "   'colonography,',\n",
              "   'virtual',\n",
              "   'endoscopy,',\n",
              "   'camera',\n",
              "   'control,',\n",
              "   'computer-aided',\n",
              "   'diagnosis,',\n",
              "   'colon',\n",
              "   'flattening,',\n",
              "   'parameterization'],\n",
              "  'MultipartiteRank': [{'score': 0.07016666887452493, 'word': 'teniae'},\n",
              "   {'score': 0.07016666887452493, 'word': 'coli'},\n",
              "   {'score': 0.0639580513986227, 'word': 'colonic'},\n",
              "   {'score': 0.0639580513986227, 'word': 'polyps'},\n",
              "   {'score': 0.06060279527673389, 'word': 'virtual'},\n",
              "   {'score': 0.06060279527673389, 'word': 'colonoscopic'},\n",
              "   {'score': 0.06060279527673389, 'word': 'navigation'},\n",
              "   {'score': 0.05798705260887752, 'word': 'registration'},\n",
              "   {'score': 0.050949530068111655, 'word': 'scans'}],\n",
              "  'Title': 'Teniae coli guided navigation and registration for virtual colonoscopy',\n",
              "  'distance': 0,\n",
              "  'no': '570',\n",
              "  'parent': '4783'},\n",
              " {'Abstract': 'Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks',\n",
              "  'AuthorKeywords': ['Metrics,',\n",
              "   'Clustering,',\n",
              "   'Sampling,',\n",
              "   'Multiresolution',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.12897796624435043, 'word': 'data'},\n",
              "   {'score': 0.12897796624435043, 'word': 'abstraction'},\n",
              "   {'score': 0.12897796624435043, 'word': 'techniques'},\n",
              "   {'score': 0.06045512161860011, 'word': 'multiresolution'},\n",
              "   {'score': 0.06045512161860011, 'word': 'visualization'},\n",
              "   {'score': 0.06045512161860011, 'word': 'systems'},\n",
              "   {'score': 0.05408968518507173, 'word': 'analysis'},\n",
              "   {'score': 0.05362133538988014, 'word': 'abstractions'},\n",
              "   {'score': 0.048111584201047525, 'word': 'analysts'}],\n",
              "  'Title': 'Measuring Data Abstraction Quality in Multiresolution Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '571',\n",
              "  'parent': '4587'},\n",
              " {'Abstract': 'Direct volume rendering techniques map volumetric attributes (e.g., density, gradient magnitude, etc.) to visual styles. Commonly this mapping is specified by a transfer function. The specification of transfer functions is a complex task and requires expert knowledge about the underlying rendering technique. In the case of multiple volumetric attributes and multiple visual styles the specification of the multi-dimensional transfer function becomes more challenging and non-intuitive. We present a novel methodology for the specification of a mapping from several volumetric attributes to multiple illustrative visual styles. We introduce semantic layers that allow a domain expert to specify the mapping in the natural language of the domain. A semantic layer defines the mapping of volumetric attributes to one visual style. Volumetric attributes and visual styles are represented as fuzzy sets. The mapping is specified by rules that are evaluated with fuzzy logic arithmetics. The user specifies the fuzzy sets and the rules without special knowledge about the underlying rendering technique. Semantic layers allow for a linguistic specification of the mapping from attributes to visual styles replacing the traditional transfer function specification.',\n",
              "  'AuthorKeywords': ['Illustrative',\n",
              "   'Visualization,',\n",
              "   'Focus+Context',\n",
              "   'Techniques,',\n",
              "   'Volume',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.11155191749137708, 'word': 'volumetric'},\n",
              "   {'score': 0.11155191749137708, 'word': 'attributes'},\n",
              "   {'score': 0.09433266702204182, 'word': 'visual'},\n",
              "   {'score': 0.09433266702204182, 'word': 'styles'},\n",
              "   {'score': 0.08704561447009075, 'word': 'mapping'},\n",
              "   {'score': 0.06151513040703511, 'word': 'techniques'},\n",
              "   {'score': 0.05620789306768138, 'word': 'specification'}],\n",
              "  'Title': 'Semantic Layers for Illustrative Volume Rendering',\n",
              "  'distance': 0,\n",
              "  'no': '572',\n",
              "  'parent': '6221'},\n",
              " {'Abstract': 'We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.',\n",
              "  'AuthorKeywords': ['Direct-touch',\n",
              "   'interaction,',\n",
              "   'wall',\n",
              "   'displays,',\n",
              "   '3D',\n",
              "   'navigation',\n",
              "   'and',\n",
              "   'exploration,',\n",
              "   'evaluation,',\n",
              "   'illustrative',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.0876072671907104, 'word': 'touch'},\n",
              "   {'score': 0.0523731534757307, 'word': 'data'},\n",
              "   {'score': 0.0523731534757307, 'word': 'exploration'},\n",
              "   {'score': 0.0523731534757307, 'word': 'technique'},\n",
              "   {'score': 0.04101178098626664, 'word': 'interaction'},\n",
              "   {'score': 0.032347139206806506, 'word': 'scientific'},\n",
              "   {'score': 0.032347139206806506, 'word': 'visualizations'},\n",
              "   {'score': 0.032087318370157415, 'word': '3d'},\n",
              "   {'score': 0.032087318370157415, 'word': 'visualization'},\n",
              "   {'score': 0.032087318370157415, 'word': 'spaces'}],\n",
              "  'Title': 'FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces',\n",
              "  'distance': 0,\n",
              "  'no': '573',\n",
              "  'parent': '5509'},\n",
              " {'Abstract': 'Most multidimensional projection techniques rely on distance (dissimilarity) information between data instances to embed high-dimensional data into a visual space. When data are endowed with Cartesian coordinates, an extra computational effort is necessary to compute the needed distances, making multidimensional projection prohibitive in applications dealing with interactivity and massive data. The novel multidimensional projection technique proposed in this work, called Part-Linear Multidimensional Projection (PLMP), has been tailored to handle multivariate data represented in Cartesian high-dimensional spaces, requiring only distance information between pairs of representative samples. This characteristic renders PLMP faster than previous methods when processing large data sets while still being competitive in terms of precision. Moreover, knowing the range of variation for data instances in the high-dimensional space, we can make PLMP a truly streaming data projection technique, a trait absent in previous methods.',\n",
              "  'AuthorKeywords': ['Dimensionality',\n",
              "   'Reduction,Projection',\n",
              "   'Methods,Visual',\n",
              "   'Data',\n",
              "   'Mining,Streaming',\n",
              "   'Technique'],\n",
              "  'MultipartiteRank': [{'score': 0.11975117838068293, 'word': 'data'},\n",
              "   {'score': 0.11975117838068293, 'word': 'instances'},\n",
              "   {'score': 0.061404770924049654, 'word': 'high'},\n",
              "   {'score': 0.05898389300517241, 'word': 'multidimensional'},\n",
              "   {'score': 0.05898389300517241, 'word': 'projection'},\n",
              "   {'score': 0.05898389300517241, 'word': 'prohibitive'},\n",
              "   {'score': 0.054926778134804594, 'word': 'visual'},\n",
              "   {'score': 0.054926778134804594, 'word': 'space'},\n",
              "   {'score': 0.04403890896741487, 'word': 'distance'}],\n",
              "  'Title': 'Two-Phase Mapping for Projecting Massive Data Sets',\n",
              "  'distance': 0,\n",
              "  'no': '574',\n",
              "  'parent': '3778'},\n",
              " {'Abstract': 'An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.',\n",
              "  'AuthorKeywords': ['Morse',\n",
              "   'theory,',\n",
              "   'High-dimensional',\n",
              "   'visualization,',\n",
              "   'Morse-Smale',\n",
              "   'complex'],\n",
              "  'MultipartiteRank': [{'score': 0.0515104394437579, 'word': 'input'},\n",
              "   {'score': 0.0515104394437579, 'word': 'parameters'},\n",
              "   {'score': 0.0467153097085231, 'word': 'system'},\n",
              "   {'score': 0.03386748510934391, 'word': 'scientific'},\n",
              "   {'score': 0.03386748510934391, 'word': 'data'},\n",
              "   {'score': 0.03386748510934391, 'word': 'analysis'},\n",
              "   {'score': 0.03189576743101667, 'word': 'method'},\n",
              "   {'score': 0.030825890004455014, 'word': 'geometric'},\n",
              "   {'score': 0.030825890004455014, 'word': 'techniques'}],\n",
              "  'Title': 'Visual Exploration of High Dimensional Scalar Functions',\n",
              "  'distance': 0,\n",
              "  'no': '575',\n",
              "  'parent': '5922'},\n",
              " {'Abstract': 'Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a “human in the loop” process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.',\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'visualization;machine',\n",
              "   'learning;visual',\n",
              "   'analytics;dimensionality',\n",
              "   'reduction'],\n",
              "  'MultipartiteRank': [{'score': 0.08941792947611953, 'word': 'many'},\n",
              "   {'score': 0.08941792947611953, 'word': 'visual'},\n",
              "   {'score': 0.08941792947611953, 'word': 'analytics'},\n",
              "   {'score': 0.08941792947611953, 'word': 'systems'},\n",
              "   {'score': 0.0486367494459181, 'word': 'dr'},\n",
              "   {'score': 0.0486367494459181, 'word': 'techniques'},\n",
              "   {'score': 0.04721312092662885, 'word': 'specific'},\n",
              "   {'score': 0.04721312092662885, 'word': 'problems'},\n",
              "   {'score': 0.046033544202516576, 'word': 'human'},\n",
              "   {'score': 0.046033544202516576, 'word': 'needs'},\n",
              "   {'score': 0.041940095899938974, 'word': 'fly'}],\n",
              "  'Title': 'Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '576',\n",
              "  'parent': '4848'},\n",
              " {'Abstract': 'We present a method for producing real-time volume visualizations of continuously captured, arbitrarily-oriented 2D arrays (slices) of data. Our system constructs a 3D representation on-the-fly from incoming 2D ultrasound slices by modeling and rendering the slices as planar polygons with translucent surface textures. We use binary space partition (BSP) tree data structures to provide non-intersecting, visibility-ordered primitives for accurate opacity accumulation images. New in our system is a method of using parallel, time-shifted BSP trees to efficiently manage the continuously captured ultrasound data and to decrease the variability in image generation time between output frames. This technique is employed in a functioning real-time augmented reality system that a physician has used to examine human patients prior to breast biopsy procedures. We expect the technique can be used for real-time visualization of any 2D data being collected from a tracked sensor moving along an arbitrary path.',\n",
              "  'AuthorKeywords': ['Augmented',\n",
              "   'reality,',\n",
              "   'ultrasound',\n",
              "   'echography,',\n",
              "   '3D',\n",
              "   'medical',\n",
              "   'imaging,',\n",
              "   'BSP',\n",
              "   'tree'],\n",
              "  'MultipartiteRank': [{'score': 0.08645145374676269, 'word': 'time'},\n",
              "   {'score': 0.08645145374676269, 'word': 'volume'},\n",
              "   {'score': 0.08645145374676269, 'word': 'visualizations'},\n",
              "   {'score': 0.07019415471773291, 'word': 'data'},\n",
              "   {'score': 0.06359061834320844, 'word': 'real'},\n",
              "   {'score': 0.061494085728264154, 'word': 'system'},\n",
              "   {'score': 0.0530401849010087, 'word': 'slices'}],\n",
              "  'Title': 'Real-time incremental visualization of dynamic ultrasound volumes using parallel BSP trees',\n",
              "  'distance': 0,\n",
              "  'no': '577',\n",
              "  'parent': '4362'},\n",
              " {'Abstract': 'View-dependent simplification has emerged as a powerful tool for graphics acceleration in visualization of complex environments. However, view-dependent simplification techniques have not been able to take full advantage of the underlying graphics hardware. Specifically, triangle strips are a widely used hardware-supported mechanism to compactly represent and efficiently render static triangle meshes. However, in a view-dependent framework, the triangle mesh connectivity changes at every frame, making it difficult to use triangle strips. We present a novel data structure, Skip Strip, that efficiently maintains triangle strips during such view-dependent changes. A Skip Strip stores the vertex hierarchy nodes in a skip-list-like manner with path compression. We anticipate that Skip Strips will provide a road map to combine rendering acceleration techniques for static datasets, typical of retained-mode graphics applications, with those for dynamic datasets found in immediate-mode applications.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07293770027612198, 'word': 'dependent'},\n",
              "   {'score': 0.07293770027612198, 'word': 'simplification'},\n",
              "   {'score': 0.0679544072213072, 'word': 'view'},\n",
              "   {'score': 0.05497537754707231, 'word': 'skip'},\n",
              "   {'score': 0.05497537754707231, 'word': 'strip'},\n",
              "   {'score': 0.04826041932605552, 'word': 'graphics'},\n",
              "   {'score': 0.04826041932605552, 'word': 'acceleration'},\n",
              "   {'score': 0.046007501820278025, 'word': 'triangle'},\n",
              "   {'score': 0.046007501820278025, 'word': 'strips'}],\n",
              "  'Title': 'Skip Strips: maintaining triangle strips for view-dependent rendering',\n",
              "  'distance': 0,\n",
              "  'no': '578',\n",
              "  'parent': '4117'},\n",
              " {'Abstract': \"This paper describes tools and techniques for the exploration of gee-scientific data from the oil and gas domain in stereoscopic virtual environments. The two main sources of data in the exploration task are seismic volumes and multivariate well logs of physical properties down a bore hole. We have developed a props-based interaction device called the cubic mouse to allow more direct and intuitive interaction with a cubic seismic volume. This device effectively places the seismic cube in the user's hand. Geologists who have tried this device have been enthusiastic about the ease of use, and were adept only a few moments after picking it up. We have also developed a multi-modal, visualisation and sonification technique for the dense, multivariate well log data. The visualisation can show two well log variables mapped along the well geometry in a bivariate colour scheme, and another variable on a sliding lens. A sonification probe is attached to the lens so that other variables can be heard. The sonification is based on a Geiger-counter metaphor that is widely understood and which makes it easy to explain. The data is sonified at higher or lower resolutions depending on the speed of the lens. Sweeps can be made at slower rates and over smaller intervals to home in on peaks, boundaries or other features in the full resolution data set.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06508879373846214, 'word': 'scientific'},\n",
              "   {'score': 0.06508879373846214, 'word': 'data'},\n",
              "   {'score': 0.04570337145868544, 'word': 'exploration'},\n",
              "   {'score': 0.04129342201326969, 'word': 'seismic'},\n",
              "   {'score': 0.04129342201326969, 'word': 'volumes'},\n",
              "   {'score': 0.035263982055271786, 'word': 'techniques'},\n",
              "   {'score': 0.034997975350120225, 'word': 'interaction'},\n",
              "   {'score': 0.034997975350120225, 'word': 'device'}],\n",
              "  'Title': 'Exploring geo-scientific data in virtual environments',\n",
              "  'distance': 0,\n",
              "  'no': '579',\n",
              "  'parent': '5773'},\n",
              " {'Abstract': 'We present a simple denoising technique for geometric data represented as a semiregular mesh, based on locally adaptive Wiener filtering. The degree of denoising is controlled by a single parameter (an estimate of the relative noise level) and the time required for denoising is independent of the magnitude of the estimate. The performance of the algorithm is sufficiently fast to allow interactive local denoising.',\n",
              "  'AuthorKeywords': ['Meshes,',\n",
              "   'multiresolution',\n",
              "   'surfaces,',\n",
              "   'Gaussian',\n",
              "   'scale',\n",
              "   'mixture',\n",
              "   'model,',\n",
              "   'denoising'],\n",
              "  'MultipartiteRank': [{'score': 0.11658648560988838, 'word': 'estimate'},\n",
              "   {'score': 0.06769909913108885, 'word': 'technique'},\n",
              "   {'score': 0.06621233545402429, 'word': 'magnitude'},\n",
              "   {'score': 0.06616345814692534, 'word': 'performance'},\n",
              "   {'score': 0.06436517429179939, 'word': 'geometric'},\n",
              "   {'score': 0.06436517429179939, 'word': 'data'}],\n",
              "  'Title': 'A simple algorithm for surface denoising',\n",
              "  'distance': 0,\n",
              "  'no': '580',\n",
              "  'parent': '3357'},\n",
              " {'Abstract': 'We present an approach for monitoring the positions of vector field singularities and related structural changes in time-dependent datasets. The concept of singularity index is discussed and extended from the well-understood planar case to the more intricate three-dimensional setting. Assuming a tetrahedral grid with linear interpolation in space and time, vector field singularities obey rules imposed by fundamental invariants (Poincare index), which we use as a basis for an efficient tracking algorithm. We apply the presented algorithm to CFD datasets to illustrate its purpose. We examine structures that exhibit topological variations with time and describe some of the insight gained with our method. Examples are given that show a correlation in the evolution of physical quantities that play a role in vortex breakdown.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'topology',\n",
              "   'tracking,',\n",
              "   'time-dependent',\n",
              "   'datasets,',\n",
              "   'vortex',\n",
              "   'breakdown'],\n",
              "  'MultipartiteRank': [{'score': 0.08489624916154759, 'word': 'time'},\n",
              "   {'score': 0.06103388020722404, 'word': 'vector'},\n",
              "   {'score': 0.06103388020722404, 'word': 'field'},\n",
              "   {'score': 0.06103388020722404, 'word': 'singularities'},\n",
              "   {'score': 0.052014028216607014, 'word': 'structural'},\n",
              "   {'score': 0.052014028216607014, 'word': 'changes'},\n",
              "   {'score': 0.051906958896433375, 'word': 'singularity'},\n",
              "   {'score': 0.051906958896433375, 'word': 'index'},\n",
              "   {'score': 0.04004011858290438, 'word': 'efficient'},\n",
              "   {'score': 0.04004011858290438, 'word': 'tracking'},\n",
              "   {'score': 0.04004011858290438, 'word': 'algorithm'}],\n",
              "  'Title': 'Tracking of vector field singularities in unstructured 3D time-dependent datasets',\n",
              "  'distance': 0,\n",
              "  'no': '581',\n",
              "  'parent': '3609'},\n",
              " {'Abstract': \"Visualizing and analyzing social networks is a challenging problem that has been receiving growing attention. An important first step, before analysis can begin, is ensuring that the data is accurate. A common data quality problem is that the data may inadvertently contain several distinct references to the same underlying entity; the process of reconciling these references is called entity-resolution. D-Dupe is an interactive tool that combines data mining algorithms for entity resolution with a task-specific network visualization. Users cope with complexity of cleaning large networks by focusing on a small subnetwork containing a potential duplicate pair. The subnetwork highlights relationships in the social network, making the common relationships easy to visually identify. D-Dupe users resolve ambiguities either by merging nodes or by marking them distinct. The entity resolution process is iterative: as pairs of nodes are resolved, additional duplicates may be revealed; therefore, resolution decisions are often chained together. We give examples of how users can flexibly apply sequences of actions to produce a high quality entity resolution result. We illustrate and evaluate the benefits of D-Dupe on three bibliographic collections. Two of the datasets had already been cleaned, and therefore should not have contained duplicates; despite this fact, many duplicates were rapidly identified using D-Dupe's unique combination of entity resolution algorithms within a task-specific visual interface\",\n",
              "  'AuthorKeywords': ['Data',\n",
              "   'cleaning',\n",
              "   'and',\n",
              "   'integration,',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'visual',\n",
              "   'data',\n",
              "   'mining'],\n",
              "  'MultipartiteRank': [{'score': 0.06779207442970506, 'word': 'entity'},\n",
              "   {'score': 0.048432794300877886, 'word': 'dupe'},\n",
              "   {'score': 0.047233091137667035, 'word': 'data'},\n",
              "   {'score': 0.04286800175797694, 'word': 'social'},\n",
              "   {'score': 0.04286800175797694, 'word': 'networks'},\n",
              "   {'score': 0.03599141687674598, 'word': 'resolution'}],\n",
              "  'Title': 'D-Dupe: An Interactive Tool for Entity Resolution in Social Networks',\n",
              "  'distance': 0,\n",
              "  'no': '582',\n",
              "  'parent': '4601'},\n",
              " {'Abstract': 'Wikipedia is a large and rapidly growing Web-based collaborative authoring environment, where anyone on the Internet can create, modify, and delete pages about encyclopedic topics. A remarkable property of some Wikipedia pages is that they are written by up to thousands of authors who may have contradicting opinions. In this paper we show that a visual analysis of the \"who revises whom\"- network gives deep insight into controversies. We propose a set of analysis and visualization techniques that reveal the dominant authors of a page, the roles they play, and the alters they confront. Thereby we provide tools to understand how Wikipedia authors collaborate in the presence of controversy.',\n",
              "  'AuthorKeywords': ['Wikipedia,',\n",
              "   'social',\n",
              "   'network',\n",
              "   'analysis,',\n",
              "   'controversy'],\n",
              "  'MultipartiteRank': [{'score': 0.08171485286339768, 'word': 'pages'},\n",
              "   {'score': 0.07404778724588133, 'word': 'wikipedia'},\n",
              "   {'score': 0.06192228640056382, 'word': 'authors'},\n",
              "   {'score': 0.05447469685741539, 'word': 'visual'},\n",
              "   {'score': 0.05447469685741539, 'word': 'analysis'},\n",
              "   {'score': 0.04652237450641752, 'word': 'controversies'}],\n",
              "  'Title': 'Visual Analysis of Controversy in User-generated Encyclopedias',\n",
              "  'distance': 0,\n",
              "  'no': '583',\n",
              "  'parent': '3684'},\n",
              " {'Abstract': 'Methods that faithfully and robustly capture the geometry of complex material interfaces in labeled volume data are important for generating realistic and accurate visualizations and simulations of real-world objects. The generation of such multimaterial models from measured data poses two unique challenges: first, the surfaces must be well-sampled with regular, efficient tessellations that are consistent across material boundaries; and second, the resulting meshes must respect the nonmanifold geometry of the multimaterial interfaces. This paper proposes a strategy for sampling and meshing multimaterial volumes using dynamic particle systems, including a novel, differentiable representation of the material junctions that allows the particle system to explicitly sample corners, edges, and surfaces of material intersections. The distributions of particles are controlled by fundamental sampling constraints, allowing Delaunay-based meshing algorithms to reliably extract watertight meshes of consistently high-quality.',\n",
              "  'AuthorKeywords': ['Sampling,', 'meshing,', 'visualizations'],\n",
              "  'MultipartiteRank': [{'score': 0.04955579544254064, 'word': 'material'},\n",
              "   {'score': 0.04955579544254064, 'word': 'boundaries'},\n",
              "   {'score': 0.048246205034499536, 'word': 'sampling'},\n",
              "   {'score': 0.04603506289825927, 'word': 'dynamic'},\n",
              "   {'score': 0.04603506289825927, 'word': 'particle'},\n",
              "   {'score': 0.04603506289825927, 'word': 'systems'},\n",
              "   {'score': 0.0451683885093122, 'word': 'multimaterial'},\n",
              "   {'score': 0.0451683885093122, 'word': 'interfaces'},\n",
              "   {'score': 0.04482235437870747, 'word': 'geometry'}],\n",
              "  'Title': 'Particle-based Sampling and Meshing of Surfaces in Multimaterial Volumes',\n",
              "  'distance': 0,\n",
              "  'no': '584',\n",
              "  'parent': '3910'},\n",
              " {'Abstract': 'This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf&lt;sup&gt;3&lt;/sup&gt;. We introduce a procedure called \"loop surgery\" that transforms M into a mesh M\\' by a sequence of cuts and guarantees the Reeb graph of f(M\\') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.',\n",
              "  'AuthorKeywords': ['Reeb',\n",
              "   'graph,',\n",
              "   'scalar',\n",
              "   'field',\n",
              "   'topology,',\n",
              "   'isosurfaces,',\n",
              "   'topological',\n",
              "   'simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.057838857122683246, 'word': 'loop'},\n",
              "   {'score': 0.057838857122683246, 'word': 'surgery'},\n",
              "   {'score': 0.05529758571448527, 'word': 'reeb'},\n",
              "   {'score': 0.05529758571448527, 'word': 'graph'},\n",
              "   {'score': 0.052386989424209676, 'word': 'efficient'},\n",
              "   {'score': 0.052386989424209676, 'word': 'algorithm'},\n",
              "   {'score': 0.03864917598533158, 'word': 'life'},\n",
              "   {'score': 0.03864917598533158, 'word': 'data'},\n",
              "   {'score': 0.03611911984470523, 'word': 'contour'},\n",
              "   {'score': 0.03611911984470523, 'word': 'tree'}],\n",
              "  'Title': 'Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees',\n",
              "  'distance': 0,\n",
              "  'no': '585',\n",
              "  'parent': '5196'},\n",
              " {'Abstract': 'We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'interaction',\n",
              "   'model,',\n",
              "   'notational',\n",
              "   'system,',\n",
              "   'physical',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.14111622505406962, 'word': 'model'},\n",
              "   {'score': 0.12072969112128654, 'word': 'interaction'},\n",
              "   {'score': 0.10900355637618868, 'word': 'desktop'},\n",
              "   {'score': 0.10900355637618868, 'word': 'visualizations'},\n",
              "   {'score': 0.07729128802014477, 'word': 'visualization'},\n",
              "   {'score': 0.07729128802014477, 'word': 'reference'},\n",
              "   {'score': 0.056904754087361696, 'word': 'instrumental'},\n",
              "   {'score': 0.056904754087361696, 'word': 'paradigm'},\n",
              "   {'score': 0.055414039827806086, 'word': 'sized'},\n",
              "   {'score': 0.055414039827806086, 'word': 'displays'}],\n",
              "  'Title': 'An Interaction Model for Visualizations Beyond The Desktop',\n",
              "  'distance': 0,\n",
              "  'no': '586',\n",
              "  'parent': '4249'},\n",
              " {'Abstract': \"We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis.\",\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'based',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'Centrality,',\n",
              "   'Taxi',\n",
              "   'trajectories,',\n",
              "   'Urban',\n",
              "   'network,',\n",
              "   'Transportation',\n",
              "   'assessment'],\n",
              "  'MultipartiteRank': [{'score': 0.07447109816094939, 'word': 'graph'},\n",
              "   {'score': 0.07447109816094939, 'word': 'modeling'},\n",
              "   {'score': 0.053553878757634656, 'word': 'taxi'},\n",
              "   {'score': 0.04713188596199429, 'word': 'city'},\n",
              "   {'score': 0.04713188596199429, 'word': 'streets'},\n",
              "   {'score': 0.04459358371596168, 'word': 'visual'},\n",
              "   {'score': 0.04459358371596168, 'word': 'analysis'},\n",
              "   {'score': 0.034834249457597624, 'word': 'trajgraph'}],\n",
              "  'Title': 'TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data',\n",
              "  'distance': 0,\n",
              "  'no': '587',\n",
              "  'parent': '3939'},\n",
              " {'Abstract': 'Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community.',\n",
              "  'AuthorKeywords': ['Visualization,Machine',\n",
              "   'Learning,Recurrent',\n",
              "   'Neural',\n",
              "   'Networks,LSTM'],\n",
              "  'MultipartiteRank': [{'score': 0.07543336518097178, 'word': 'effective'},\n",
              "   {'score': 0.07543336518097178, 'word': 'tool'},\n",
              "   {'score': 0.07376425639989424, 'word': 'recurrent'},\n",
              "   {'score': 0.07376425639989424, 'word': 'neural'},\n",
              "   {'score': 0.07376425639989424, 'word': 'networks'},\n",
              "   {'score': 0.04357283710639275, 'word': 'sequence'},\n",
              "   {'score': 0.04357283710639275, 'word': 'modeling'},\n",
              "   {'score': 0.03987719341580915, 'word': 'representation'},\n",
              "   {'score': 0.03555024359430362, 'word': 'changes'}],\n",
              "  'Title': 'LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks',\n",
              "  'distance': 0,\n",
              "  'no': '588',\n",
              "  'parent': '5775'},\n",
              " {'Abstract': 'The visualization of 3-D second-order tensor fields and matrix data is studied. The general problem of visualizing unsymmetric real or complex Hermitian second-order tensor fields can be reduced to the simultaneous visualization of a real and symmetric second-order tensor field and a real vector field. The emphasis is on exploiting the mathematical properties of tensor fields in order to facilitate their visualization and to produce a continuous representation of the data. The focus is on interactively sensing and exploring real and symmetric second-order tensor data by generalizing the vector notion of streamline to the tensor concept of hyperstreamline. The importance of a structural analysis of the data field analogous to the techniques of vector field topology extraction in order to obtain a unique and objective representation of second-order tensor fields is stressed.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.13301878473289303, 'word': 'order'},\n",
              "   {'score': 0.13301878473289303, 'word': 'tensor'},\n",
              "   {'score': 0.13301878473289303, 'word': 'fields'},\n",
              "   {'score': 0.11038120477135946, 'word': 'second'},\n",
              "   {'score': 0.05934485994115639, 'word': 'visualization'},\n",
              "   {'score': 0.05623194579718542, 'word': 'matrix'},\n",
              "   {'score': 0.05623194579718542, 'word': 'data'},\n",
              "   {'score': 0.05603363828531463, 'word': 'unsymmetric'},\n",
              "   {'score': 0.05603363828531463, 'word': 'real'}],\n",
              "  'Title': 'Visualization of second order tensor fields and matrix data',\n",
              "  'distance': 0,\n",
              "  'no': '589',\n",
              "  'parent': '3400'},\n",
              " {'Abstract': 'Experiences during the investigation of parallel methods for faster isosurface generation on SIMD (single instruction stream, multiple data stream) machines are described. A sequential version of a well-known isosurfacing algorithm is algorithmically enhanced for a particular type of SIMD architecture. The SIMD implementation takes full advantage of the data parallel nature of the algorithm, and experiments have proven the implementation to be highly scalable. A parallel tool, which can generate 170 K polygons/s, gives scientists the means to explore large 3D scalar or vector fields interactively.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15212988490928156, 'word': 'simd'},\n",
              "   {'score': 0.07510163073904907, 'word': 'parallel'},\n",
              "   {'score': 0.07510163073904907, 'word': 'methods'},\n",
              "   {'score': 0.0643364430092725, 'word': 'faster'},\n",
              "   {'score': 0.0643364430092725, 'word': 'isosurface'},\n",
              "   {'score': 0.0643364430092725, 'word': 'generation'},\n",
              "   {'score': 0.06185047549628462, 'word': 'implementation'},\n",
              "   {'score': 0.060927635140888906, 'word': 'single'},\n",
              "   {'score': 0.060927635140888906, 'word': 'instruction'},\n",
              "   {'score': 0.060927635140888906, 'word': 'stream'}],\n",
              "  'Title': 'Massively parallel isosurface extraction',\n",
              "  'distance': 0,\n",
              "  'no': '590',\n",
              "  'parent': '3541'},\n",
              " {'Abstract': \"We present a way to visualize a flow field using Line Integral Convolution (LIC) with a multi frequency noise texture. A broad range of feature sizes can enhance a user's perception of the magnitudes and direction of the flow. In addition, the multiple scales of feature size help a user clarify the motion of the flow in an animation.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.19928163493916407, 'word': 'flow'},\n",
              "   {'score': 0.1292955157899562, 'word': 'field'},\n",
              "   {'score': 0.09014596588064874, 'word': 'feature'},\n",
              "   {'score': 0.09014596588064874, 'word': 'sizes'},\n",
              "   {'score': 0.08443505421590278, 'word': 'line'},\n",
              "   {'score': 0.08443505421590278, 'word': 'integral'},\n",
              "   {'score': 0.08443505421590278, 'word': 'convolution'},\n",
              "   {'score': 0.08327828548053509, 'word': 'user'}],\n",
              "  'Title': 'Multi-frequency noise for LIC',\n",
              "  'distance': 0,\n",
              "  'no': '591',\n",
              "  'parent': '3404'},\n",
              " {'Abstract': 'Presents a new approach to isosurface extraction from volume data using particle systems. Particle behavior is dynamic and can be based on laws of physics or artificial rules. For isosurface extraction, we program particles to be attracted towards a specific surface value while simultaneously repelling adjacent particles. The repulsive forces are based on the curvature of the surface at that location. A birth-death process results in a denser concentration of particles in areas of high curvature and sparser populations in areas of lower curvature. The overall level of detail is controlled through a scaling factor that increases or decreases the repulsive forces of the particles. Once particles reach equilibrium, their locations are used as vertices in generating a triangular mesh of the surface. The advantages of our approach include: vertex densities are based on surface features rather than on the sampling rate of the volume; a single scaling factor simplifies level-of-detail control; and meshing is efficient because it uses neighbor information that has already been generated during the force calculations.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1059707800482446, 'word': 'particle'},\n",
              "   {'score': 0.1059707800482446, 'word': 'systems'},\n",
              "   {'score': 0.05528406685601287, 'word': 'volume'},\n",
              "   {'score': 0.05528406685601287, 'word': 'data'},\n",
              "   {'score': 0.051466292254903574, 'word': 'extraction'},\n",
              "   {'score': 0.048362700695774787, 'word': 'specific'},\n",
              "   {'score': 0.048362700695774787, 'word': 'surface'},\n",
              "   {'score': 0.048362700695774787, 'word': 'value'},\n",
              "   {'score': 0.04317648712631962, 'word': 'particles'}],\n",
              "  'Title': 'Isosurface extraction using particle systems',\n",
              "  'distance': 0,\n",
              "  'no': '592',\n",
              "  'parent': '4527'},\n",
              " {'Abstract': 'Generation of a three-dimensional model from an unorganized set of points is an active area of research in computer graphics. Alpha shapes can be employed to construct a surface which most closely reflects the object described by the points. However, no /spl alpha/-shape, for any value of /spl alpha/, can properly detail discontinuous regions of a model. We introduce herein two methods of improving the results of reconstruction using /spl alpha/-shapes: density-scaling, which modulates the value of a depending on the density of points in a region; and anisotropic shaping, which modulates the form of the /spl alpha/-ball based on point normals. We give experimental results that show the successes and limitations of our method.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09538483619250876, 'word': 'points'},\n",
              "   {'score': 0.05900886043131074, 'word': 'dimensional'},\n",
              "   {'score': 0.05900886043131074, 'word': 'model'},\n",
              "   {'score': 0.05525905786640939, 'word': 'alpha'},\n",
              "   {'score': 0.05525905786640939, 'word': 'shapes'},\n",
              "   {'score': 0.05432333234851069, 'word': 'density'},\n",
              "   {'score': 0.04940795107992011, 'word': 'discontinuous'},\n",
              "   {'score': 0.04940795107992011, 'word': 'regions'}],\n",
              "  'Title': 'Surface reconstruction with anisotropic density-scaled alpha shapes',\n",
              "  'distance': 0,\n",
              "  'no': '593',\n",
              "  'parent': '3594'},\n",
              " {'Abstract': 'In recent years, substantial progress has been achieved in the area of volume visualization on irregular grids, which is mainly based on tetrahedral meshes. Even moderately fine tetrahedral meshes consume several mega-bytes of storage. For archivation and transmission compression algorithms are essential. In scientific applications lossless compression schemes are of primary interest. This paper introduces a new lossless compression scheme for the connectivity of tetrahedral meshes. Our technique can handle all tetrahedral meshes in three dimensional euclidean space even with non manifold border. We present compression and decompression algorithms which consume for reasonable meshes linear time in the number of tetrahedra. The connectivity is compressed to less than 2.4 bits per tetrahedron for all measured meshes. Thus a tetrahedral mesh can almost be reduced to the vertex coordinates, which consume in a common representation about one quarter of the total storage space. We complete our work with solutions for the compression of vertex coordinates and additional attributes, which might be attached to the mesh.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12092683303240367, 'word': 'compression'},\n",
              "   {'score': 0.0970085288206625, 'word': 'tetrahedral'},\n",
              "   {'score': 0.0970085288206625, 'word': 'meshes'},\n",
              "   {'score': 0.06904308097745988, 'word': 'transmission'},\n",
              "   {'score': 0.06904308097745988, 'word': 'algorithms'},\n",
              "   {'score': 0.051883752054943784, 'word': 'scientific'},\n",
              "   {'score': 0.051883752054943784, 'word': 'applications'},\n",
              "   {'score': 0.051883752054943784, 'word': 'lossless'},\n",
              "   {'score': 0.051883752054943784, 'word': 'schemes'},\n",
              "   {'score': 0.04461251434647052, 'word': 'connectivity'},\n",
              "   {'score': 0.04049909483797754, 'word': 'storage'}],\n",
              "  'Title': 'Tetrahedral Mesh Compression with the Cut-Border Machine',\n",
              "  'distance': 0,\n",
              "  'no': '594',\n",
              "  'parent': '4230'},\n",
              " {'Abstract': 'This paper introduces two efficient algorithms that compute the Contour Tree of a 3D scalar field /spl Fscr/ and its augmented version with the Betti numbers of each isosurface. The Contour Tree is a fundamental data structure in scientific visualization that is used to preprocess the domain mesh to allow optimal computation of isosurfaces with minimal overhead storage. The Contour Tree can also be used to build user interfaces reporting the complete topological characterization of a scalar field. The first part of the paper presents a new scheme that augments the Contour Tree with the Betti numbers of each isocontour in linear time. We show how to extend the scheme with the Betti number computation without increasing its complexity. Thus, we improve on the time complexity from our previous approach from O(m log m) to O(n log n+m), where m is the number of tetrahedra and n is the number of vertices in the domain of /spl Fscr/. The second part of the paper introduces a new divide-and-conquer algorithm that computes the Augmented Contour Tree with improved efficiency. The central part of the scheme computes the output Contour Tree by merging two intermediate Contour Trees and is independent of the interpolant. In this way we confine any knowledge regarding a specific interpolant to an oracle that computes the tree for a single cell. We have implemented this oracle for the trilinear interpolant and plan to replace it with higher order interpolants when needed. The complexity of the scheme is O(n+t log n), where t is the number of critical points of /spl Fscr/. For the first time we can compute the Contour Tree in linear time in many practical cases when t=O(n/sup 1-/spl epsi//). Lastly, we report the running times for a parallel implementation of our algorithm, showing good scalability with the number of processors.',\n",
              "  'AuthorKeywords': ['Isosurfaces,',\n",
              "   'Level',\n",
              "   'Set',\n",
              "   'Topology,',\n",
              "   'Betti',\n",
              "   'Numbers'],\n",
              "  'MultipartiteRank': [{'score': 0.09589200820720155, 'word': 'contour'},\n",
              "   {'score': 0.09589200820720155, 'word': 'tree'},\n",
              "   {'score': 0.06973230979635443, 'word': 'betti'},\n",
              "   {'score': 0.06973230979635443, 'word': 'numbers'},\n",
              "   {'score': 0.043354213799497464, 'word': 'new'},\n",
              "   {'score': 0.043354213799497464, 'word': 'scheme'},\n",
              "   {'score': 0.04005899568835063, 'word': 'paper'},\n",
              "   {'score': 0.039480549152210095, 'word': 'linear'},\n",
              "   {'score': 0.039480549152210095, 'word': 'time'}],\n",
              "  'Title': 'Efficient computation of the topology of level sets',\n",
              "  'distance': 0,\n",
              "  'no': '595',\n",
              "  'parent': '6243'},\n",
              " {'Abstract': 'Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.',\n",
              "  'AuthorKeywords': ['computed',\n",
              "   'tomography',\n",
              "   'angiography,',\n",
              "   'vessel',\n",
              "   'analysis,',\n",
              "   'curved',\n",
              "   'planar',\n",
              "   'reformation'],\n",
              "  'MultipartiteRank': [{'score': 0.13948646540873488, 'word': 'vessel'},\n",
              "   {'score': 0.09965797492622928, 'word': 'segment'},\n",
              "   {'score': 0.06296334823544397, 'word': 'cpr'},\n",
              "   {'score': 0.056007964713810705, 'word': 'advances'},\n",
              "   {'score': 0.056007964713810705, 'word': 'methods'},\n",
              "   {'score': 0.04656687822544705, 'word': 'visible'}],\n",
              "  'Title': 'Advanced curved planar reformation: flattening of vascular structures',\n",
              "  'distance': 0,\n",
              "  'no': '596',\n",
              "  'parent': '4378'},\n",
              " {'Abstract': 'This research demonstrates how principles of self-organization and behavior simulation can be used to represent dynamic data evolutions by extending the concept of information flocking, originally introduced by Proctor &amp;amp; Winter (1998), to time-varying datasets. A rule-based behavior system continuously controls and updates the dynamic actions of individual, three-dimensional elements that represent the changing data values of reoccurring data objects. As a result, different distinguishable motion types emerge that are driven by local interactions between the spatial elements as well as the evolution of time-varying data values. Notably, this representation technique focuses on the representation of dynamic data alteration characteristics, or how reoccurring data objects change over time, instead of depicting the exact data values themselves. In addition, it demonstrates the potential of motion as a useful information visualization cue. The original information flocking approach is extended to incorporate time-varying datasets, live database querying, continuous data streaming, real-time data similarity evaluation, automatic shape generation and more stable flocking algorithms. Different experiments prove that information flocking is capable of representing short-term events as well as long-term temporal data evolutions of both individual and groups of time-dependent data objects. An historical stock market quote price dataset is used to demonstrate the algorithms and principles of time-varying information flocking',\n",
              "  'AuthorKeywords': ['time-varying',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'artificial',\n",
              "   'life,',\n",
              "   '3D',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'motion,',\n",
              "   'boids'],\n",
              "  'MultipartiteRank': [{'score': 0.1174638374256744, 'word': 'data'},\n",
              "   {'score': 0.07043857206897564, 'word': 'time'},\n",
              "   {'score': 0.05140421993323771, 'word': 'information'},\n",
              "   {'score': 0.05140421993323771, 'word': 'flocking'},\n",
              "   {'score': 0.04388249354325304, 'word': 'dynamic'},\n",
              "   {'score': 0.04388249354325304, 'word': 'evolutions'},\n",
              "   {'score': 0.03716045418554531, 'word': 'values'},\n",
              "   {'score': 0.036420889696876034, 'word': 'objects'}],\n",
              "  'Title': 'Time-Varying Data Visualization Using Information Flocking Boids',\n",
              "  'distance': 0,\n",
              "  'no': '597',\n",
              "  'parent': '5775'},\n",
              " {'Abstract': 'A new pseudo coloring technique for large scale one-dimensional datasets is proposed. For visualization of a large scale dataset, user interaction is indispensable for selecting focus areas in the dataset. However, excessive switching of the visualized image makes it difficult for the user to recognize overview/ detail and detail/ detail relationships. The goal of this research is to develop techniques for visualizing details as precisely as possible in overview display. In this paper, visualization of a one-dimensional but very large dataset is considered. The proposed method is based on pseudo coloring, however, each scalar value corresponds to two discrete colors. By painting with two colors at each value, users can read out the value precisely. This method has many advantages: it requires little image space for visualization; both the overview and details of the dataset are visible in one image without distortion; and implementation is very simple. Several application examples, such as meteorological observation data and train convenience evaluation data, show the effectiveness of the method.',\n",
              "  'AuthorKeywords': ['pseudo',\n",
              "   'color,',\n",
              "   'overview,',\n",
              "   'detail,',\n",
              "   'focus+context,',\n",
              "   'data',\n",
              "   'density'],\n",
              "  'MultipartiteRank': [{'score': 0.0810767463607816, 'word': 'new'},\n",
              "   {'score': 0.0810767463607816, 'word': 'pseudo'},\n",
              "   {'score': 0.0810767463607816, 'word': 'coloring'},\n",
              "   {'score': 0.0810767463607816, 'word': 'technique'},\n",
              "   {'score': 0.07950194392451762, 'word': 'large'},\n",
              "   {'score': 0.07950194392451762, 'word': 'scale'},\n",
              "   {'score': 0.06288528893975534, 'word': 'dimensional'},\n",
              "   {'score': 0.06288528893975534, 'word': 'datasets'},\n",
              "   {'score': 0.05120020207234214, 'word': 'visualization'},\n",
              "   {'score': 0.050669185313687096, 'word': 'user'},\n",
              "   {'score': 0.050669185313687096, 'word': 'interaction'}],\n",
              "  'Title': 'Two-tone pseudo coloring: compact visualization for one-dimensional data',\n",
              "  'distance': 0,\n",
              "  'no': '598',\n",
              "  'parent': '4438'},\n",
              " {'Abstract': \"This paper presents an advanced evenly-spaced streamline placement algorithm for fast, high-quality, and robust layout of flow lines. A fourth-order Runge-Kutta integrator with adaptive step size and error control is employed for rapid accurate streamline advection. Cubic Hermite polynomial interpolation with large sample-spacing is adopted to create fewer evenly-spaced samples along each streamline to reduce the amount of distance checking. We propose two methods to enhance placement quality. Double queues are used to prioritize topological seeding and to favor long streamlines to minimize discontinuities. Adaptive distance control based on the local flow variance is explored to reduce cavities. Furthermore, we propose a universal, effective, fast, and robust loop detection strategy to address closed and spiraling streamlines. Our algorithm is an order-of-magnitude faster than Jobard and Lefer's algorithm with better placement quality and over 5 times faster than Mebarki et al.'s algorithm with comparable placement quality, but with a more robust solution to loop detection\",\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'visualization,',\n",
              "   'evenly-spaced',\n",
              "   'streamlines,',\n",
              "   'streamline',\n",
              "   'placement,',\n",
              "   'seeding',\n",
              "   'strategy,',\n",
              "   'closed',\n",
              "   'streamlines'],\n",
              "  'MultipartiteRank': [{'score': 0.06305490029850844, 'word': 'quality'},\n",
              "   {'score': 0.042958709832895965, 'word': 'fast'},\n",
              "   {'score': 0.04295833545393373, 'word': 'streamline'},\n",
              "   {'score': 0.04018404396556786, 'word': 'order'},\n",
              "   {'score': 0.04018404396556786, 'word': 'runge'},\n",
              "   {'score': 0.037458719366012756, 'word': 'algorithm'}],\n",
              "  'Title': 'An Advanced Evenly-Spaced Streamline Placement Algorithm',\n",
              "  'distance': 0,\n",
              "  'no': '599',\n",
              "  'parent': '4909'},\n",
              " {'Abstract': 'We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.',\n",
              "  'AuthorKeywords': ['3D',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'time-varying',\n",
              "   'and',\n",
              "   'time-series',\n",
              "   'visualization,',\n",
              "   'surface',\n",
              "   'extraction'],\n",
              "  'MultipartiteRank': [{'score': 0.12465407015009183, 'word': 'integral'},\n",
              "   {'score': 0.12465407015009183, 'word': 'surfaces'},\n",
              "   {'score': 0.07629683980919136, 'word': 'time'},\n",
              "   {'score': 0.06319066410094368, 'word': 'novel'},\n",
              "   {'score': 0.06319066410094368, 'word': 'approach'},\n",
              "   {'score': 0.05451346694880779, 'word': 'dependent'},\n",
              "   {'score': 0.05451346694880779, 'word': 'vector'},\n",
              "   {'score': 0.05451346694880779, 'word': 'fields'},\n",
              "   {'score': 0.04128082543659471, 'word': 'direct'},\n",
              "   {'score': 0.04128082543659471, 'word': 'computation'}],\n",
              "  'Title': 'Generation of Accurate Integral Surfaces in Time-Dependent Vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '600',\n",
              "  'parent': '3920'},\n",
              " {'Abstract': 'In May of 2008, we published online a series of software visualization videos using a method called code_swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code_swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code_swarm has positive implications for the future of organic information design and open source information visualization practice.',\n",
              "  'AuthorKeywords': ['Software',\n",
              "   'visualization,',\n",
              "   'organic',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'software',\n",
              "   'development',\n",
              "   'history',\n",
              "   'and',\n",
              "   'evolution'],\n",
              "  'MultipartiteRank': [{'score': 0.13480314886379072, 'word': 'code'},\n",
              "   {'score': 0.08388345842655673, 'word': 'results'},\n",
              "   {'score': 0.07027031696607355, 'word': 'open'},\n",
              "   {'score': 0.07027031696607355, 'word': 'source'},\n",
              "   {'score': 0.06757632557338739, 'word': 'design'},\n",
              "   {'score': 0.06453283189771716, 'word': 'swarm'},\n",
              "   {'score': 0.06453283189771716, 'word': 'application'},\n",
              "   {'score': 0.047794694742824, 'word': 'organic'},\n",
              "   {'score': 0.047794694742824, 'word': 'information'},\n",
              "   {'score': 0.047794694742824, 'word': 'visualization'},\n",
              "   {'score': 0.047794694742824, 'word': 'technique'}],\n",
              "  'Title': 'code_swarm: A Design Study in Organic Software Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '601',\n",
              "  'parent': '4960'},\n",
              " {'Abstract': 'Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06875146725430714, 'word': 'investigative'},\n",
              "   {'score': 0.06875146725430714, 'word': 'analysis'},\n",
              "   {'score': 0.06763600879579555, 'word': 'visual'},\n",
              "   {'score': 0.06763600879579555, 'word': 'analytic'},\n",
              "   {'score': 0.06763600879579555, 'word': 'support'},\n",
              "   {'score': 0.06352453126065812, 'word': 'systems'},\n",
              "   {'score': 0.04845960323184282, 'word': 'participants'},\n",
              "   {'score': 0.04737221858915086, 'word': 'study'}],\n",
              "  'Title': 'Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study',\n",
              "  'distance': 0,\n",
              "  'no': '602',\n",
              "  'parent': '4958'},\n",
              " {'Abstract': 'Medical volumetric imaging requires high fidelity, high performance rendering algorithms. We motivate and analyze new volumetric rendering algorithms that are suited to modern parallel processing architectures. First, we describe the three major categories of volume rendering algorithms and confirm through an imaging scientist-guided evaluation that ray-casting is the most acceptable. We describe a thread- and data-parallel implementation of ray-casting that makes it amenable to key architectural trends of three modern commodity parallel architectures: multi-core, GPU, and an upcoming many-core Intel&lt;sup&gt;reg&lt;/sup&gt; architecture code-named Larrabee. We achieve more than an order of magnitude performance improvement on a number of large 3D medical datasets. We further describe a data compression scheme that significantly reduces data-transfer overhead. This allows our approach to scale well to large numbers of Larrabee cores.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Compositing,',\n",
              "   'Parallel',\n",
              "   'Processing,',\n",
              "   'Many-core',\n",
              "   'Computing,',\n",
              "   'Medical',\n",
              "   'Imaging,',\n",
              "   'Graphics',\n",
              "   'Architecture,',\n",
              "   'GPGPU'],\n",
              "  'MultipartiteRank': [{'score': 0.07215129009778881, 'word': 'algorithms'},\n",
              "   {'score': 0.061643477505060246, 'word': 'data'},\n",
              "   {'score': 0.0551610180205722, 'word': 'ray'},\n",
              "   {'score': 0.045722229328015423, 'word': 'high'},\n",
              "   {'score': 0.045722229328015423, 'word': 'fidelity'},\n",
              "   {'score': 0.04343302634415194, 'word': 'modern'},\n",
              "   {'score': 0.04343302634415194, 'word': 'parallel'},\n",
              "   {'score': 0.04343302634415194, 'word': 'processing'},\n",
              "   {'score': 0.04343302634415194, 'word': 'architectures'}],\n",
              "  'Title': 'Mapping High-fidelity Volume Rendering for Medical Imaging to CPU, GPU and Many-Core Architectures',\n",
              "  'distance': 0,\n",
              "  'no': '603',\n",
              "  'parent': '4070'},\n",
              " {'Abstract': \"We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.\",\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'systems,',\n",
              "   'toolkits,',\n",
              "   'declarative',\n",
              "   'specification,',\n",
              "   'optimization,',\n",
              "   'interaction,',\n",
              "   'streaming',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.09657948857258991, 'word': 'data'},\n",
              "   {'score': 0.09657948857258991, 'word': 'visualization'},\n",
              "   {'score': 0.0854092087049704, 'word': 'reactive'},\n",
              "   {'score': 0.0854092087049704, 'word': 'vega'},\n",
              "   {'score': 0.06937380224306451, 'word': 'interaction'},\n",
              "   {'score': 0.06937380224306451, 'word': 'design'},\n",
              "   {'score': 0.05438554893168859, 'word': 'first'},\n",
              "   {'score': 0.05438554893168859, 'word': 'robust'},\n",
              "   {'score': 0.04760416707560976, 'word': 'declarative'},\n",
              "   {'score': 0.04760416707560976, 'word': 'visual'}],\n",
              "  'Title': 'Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '604',\n",
              "  'parent': '3800'},\n",
              " {'Abstract': 'Brushing is a data visualization technique that identifies and highlights data subsets. We introduce a form of brushing in which the brushed data is usually displayed at a different resolution than the non brushed data. The paper presents the rationale behind the multiresolution support of multivariate data visualization and describes the construction of multiresolution brushing using wavelet approximations. The idea is implemented in an enhanced version of XmdvTool. Real scientific data is used for demonstration and practical applications are suggested.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.20014888263516428, 'word': 'data'},\n",
              "   {'score': 0.1468965362746912, 'word': 'visualization'},\n",
              "   {'score': 0.1468965362746912, 'word': 'technique'},\n",
              "   {'score': 0.08893205966960142, 'word': 'multiresolution'},\n",
              "   {'score': 0.08893205966960142, 'word': 'support'},\n",
              "   {'score': 0.05243450696234832, 'word': 'form'},\n",
              "   {'score': 0.052327204120841325, 'word': 'non'}],\n",
              "  'Title': 'Multiresolution multidimensional wavelet brushing',\n",
              "  'distance': 0,\n",
              "  'no': '605',\n",
              "  'parent': '3453'},\n",
              " {'Abstract': 'The authors describe a software system supporting interactive visualization of large terrains in a resource-limited environment, i.e. a low-end client computer accessing a large terrain database server through a low-bandwidth network. By \"large\", they mean that the size of the terrain database is orders of magnitude larger than the computer RAM. Superior performance is achieved by manipulating both geometric and texture data at a continuum of resolutions, and, at any given moment, using the best resolution dictated by the CPU and bandwidth constraints. The geometry is maintained as a Delaunay triangulation of a dynamic subset of the terrain data points, and the texture compressed by a progressive wavelet scheme. A careful blend of algorithmic techniques enables the system to achieve superior rendering performance on a low-end computer by optimizing the number of polygons and texture pixels sent to the graphics pipeline. It guarantees a frame rate depending only on the size and quality of the rendered image, independent of the viewing parameters and scene database size. An efficient paging scheme minimizes data I/O, thus enabling the use of the system in a low-bandwidth client/server data-streaming scenario, such as on the Internet.',\n",
              "  'AuthorKeywords': ['Terrain',\n",
              "   'rendering,',\n",
              "   'level-of-detail,',\n",
              "   'interactive',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.06943122295242826, 'word': 'large'},\n",
              "   {'score': 0.06943122295242826, 'word': 'terrains'},\n",
              "   {'score': 0.05894871354598496, 'word': 'low'},\n",
              "   {'score': 0.046925896326660964, 'word': 'end'},\n",
              "   {'score': 0.046925896326660964, 'word': 'client'},\n",
              "   {'score': 0.046925896326660964, 'word': 'computer'},\n",
              "   {'score': 0.04586653627934934, 'word': 'software'},\n",
              "   {'score': 0.04586653627934934, 'word': 'system'},\n",
              "   {'score': 0.039222035045529596, 'word': 'bandwidth'},\n",
              "   {'score': 0.039222035045529596, 'word': 'network'}],\n",
              "  'Title': 'Visualization of large terrains in resource-limited computing environments',\n",
              "  'distance': 0,\n",
              "  'no': '606',\n",
              "  'parent': '4827'},\n",
              " {'Abstract': 'We present an algorithm which renders opaque and/or translucent polygons embedded within volumetric data. The processing occurs such that all objects are composited in the correct order, by rendering thin slabs of the translucent polygons between volume slices using slice-order volume rendering. We implemented our algorithm with OpenGL on current general-purpose graphics systems. We discuss our system implementation, speed and image quality, as well as the renderings of several mixed scenes.',\n",
              "  'AuthorKeywords': ['Mixing',\n",
              "   'polygons',\n",
              "   'and',\n",
              "   'volumes,',\n",
              "   'Translucent',\n",
              "   'Polygon',\n",
              "   'Rendering,',\n",
              "   'Volume',\n",
              "   'rendering,',\n",
              "   'Ray',\n",
              "   'casting,',\n",
              "   'Voxelization'],\n",
              "  'MultipartiteRank': [{'score': 0.09628268723005136, 'word': 'translucent'},\n",
              "   {'score': 0.09628268723005136, 'word': 'polygons'},\n",
              "   {'score': 0.0836487917893409, 'word': 'correct'},\n",
              "   {'score': 0.0836487917893409, 'word': 'order'},\n",
              "   {'score': 0.08312634612158372, 'word': 'volume'},\n",
              "   {'score': 0.08312634612158372, 'word': 'slices'},\n",
              "   {'score': 0.07178462747797486, 'word': 'algorithm'},\n",
              "   {'score': 0.051931275290624024, 'word': 'current'},\n",
              "   {'score': 0.051931275290624024, 'word': 'general'}],\n",
              "  'Title': 'Mixing translucent polygons with volumes',\n",
              "  'distance': 0,\n",
              "  'no': '607',\n",
              "  'parent': '3475'},\n",
              " {'Abstract': \"We present an interactive navigation system for virtual colonoscopy, which is based solely on high performance volume rendering. Previous colonic navigation systems have employed either a surface rendering or a Z-buffer-assisted volume rendering method that depends on the surface rendering results. Our method is a fast direct volume rendering technique that exploits distance information stored in the potential field of the camera control model, and is parallelized on a multiprocessor. Experiments have been conducted on both a simulated pipe and patients' data sets acquired with a CT scanner.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09845643804258163, 'word': 'interactive'},\n",
              "   {'score': 0.09845643804258163, 'word': 'navigation'},\n",
              "   {'score': 0.09845643804258163, 'word': 'system'},\n",
              "   {'score': 0.08731427631240828, 'word': 'high'},\n",
              "   {'score': 0.08731427631240828, 'word': 'performance'},\n",
              "   {'score': 0.08731427631240828, 'word': 'volume'},\n",
              "   {'score': 0.07730278289087057, 'word': 'method'},\n",
              "   {'score': 0.07249933346256986, 'word': 'surface'},\n",
              "   {'score': 0.06799400218091901, 'word': 'virtual'},\n",
              "   {'score': 0.06799400218091901, 'word': 'colonoscopy'}],\n",
              "  'Title': 'Volume rendering based interactive navigation within the human colon',\n",
              "  'distance': 0,\n",
              "  'no': '608',\n",
              "  'parent': '3722'},\n",
              " {'Abstract': 'We introduce an approach to visual analysis of multivariate data that integrates several methods from information visualization, exploratory data analysis (EDA), and geovisualization. The approach leverages the component-based architecture implemented in GeoVISTA Studio to construct a flexible, multiview, tightly (but generically) coordinated, EDA toolkit. This toolkit builds upon traditional ideas behind both small multiples and scatterplot matrices in three fundamental ways. First, we develop a general, multiform, bivariate matrix and a complementary multiform, bivariate small multiple plot in which different bivariate representation forms can be used in combination. We demonstrate the flexibility of this approach with matrices and small multiples that depict multivariate data through combinations of: scatterplots, bivariate maps, and space-filling displays. Second, we apply a measure of conditional entropy to (a) identify variables from a high-dimensional data set that are likely to display interesting relationships and (b) generate a default order of these variables in the matrix or small multiple display. Third, we add conditioning, a kind of dynamic query/filtering in which supplementary (undisplayed) variables are used to constrain the view onto variables that are displayed. Conditioning allows the effects of one or more well understood variables to be removed form the analysis, making relationships among remaining variables easier to explore. We illustrate the individual and combined functionality enabled by this approach through application to analysis of cancer diagnosis and mortality data and their associated covariates and risk factors.',\n",
              "  'AuthorKeywords': ['geovisualization,',\n",
              "   'EDA,',\n",
              "   'scatterplot',\n",
              "   'matrix,bivariate',\n",
              "   'map,',\n",
              "   'space-filling',\n",
              "   'visualization,',\n",
              "   'conditional',\n",
              "   'entropy,',\n",
              "   'small',\n",
              "   'multiples,',\n",
              "   'conditioning,',\n",
              "   'GeoVISTA',\n",
              "   'Studio'],\n",
              "  'MultipartiteRank': [{'score': 0.05262904679815896, 'word': 'multivariate'},\n",
              "   {'score': 0.05262904679815896, 'word': 'data'},\n",
              "   {'score': 0.04907324032926842, 'word': 'approach'},\n",
              "   {'score': 0.04849824473673289, 'word': 'visual'},\n",
              "   {'score': 0.04849824473673289, 'word': 'analysis'},\n",
              "   {'score': 0.04762856104873874, 'word': 'small'},\n",
              "   {'score': 0.04762856104873874, 'word': 'multiples'},\n",
              "   {'score': 0.044486949292052, 'word': 'variables'}],\n",
              "  'Title': 'Exploring high-D spaces with multiform matrices and small multiples',\n",
              "  'distance': 0,\n",
              "  'no': '609',\n",
              "  'parent': '4883'},\n",
              " {'Abstract': \"We investigate two important, common fluid flow patterns from computational fluid dynamics (CFD) simulations, namely, swirl and tumble motion typical of automotive engines. We study and visualize swirl and tumble flow using three different flow visualization techniques: direct, geometric, and texture-based. When illustrating these methods side-by-side, we describe the relative strengths and weaknesses of each approach within a specific spatial dimension and across multiple spatial dimensions typical of an engineer's analysis. Our study is focused on steady-state flow. Based on this investigation we offer perspectives on where and when these techniques are best applied in order to visualize the behavior of swirl and tumble motion.\",\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'visualization,',\n",
              "   'computational',\n",
              "   'fluid',\n",
              "   'dynamics',\n",
              "   '(CFD),',\n",
              "   'swirl',\n",
              "   'flow,',\n",
              "   'tumble',\n",
              "   'flow,',\n",
              "   'visualization',\n",
              "   'systems,',\n",
              "   'engine',\n",
              "   'simulation,',\n",
              "   'in-cylinder',\n",
              "   'flow'],\n",
              "  'MultipartiteRank': [{'score': 0.10921711111114163, 'word': 'tumble'},\n",
              "   {'score': 0.08330315485494898, 'word': 'swirl'},\n",
              "   {'score': 0.056792766219230274, 'word': 'motion'},\n",
              "   {'score': 0.056792766219230274, 'word': 'typical'},\n",
              "   {'score': 0.05663446977443206, 'word': 'automotive'},\n",
              "   {'score': 0.05663446977443206, 'word': 'engines'},\n",
              "   {'score': 0.052424344891911355, 'word': 'flow'},\n",
              "   {'score': 0.042536023711770315, 'word': 'specific'},\n",
              "   {'score': 0.042536023711770315, 'word': 'spatial'},\n",
              "   {'score': 0.042536023711770315, 'word': 'dimension'}],\n",
              "  'Title': 'Investigating swirl and tumble flow with a comparison of visualization techniques',\n",
              "  'distance': 0,\n",
              "  'no': '610',\n",
              "  'parent': '3767'},\n",
              " {'Abstract': 'A new field of research, visual analytics, has been introduced. This has been defined as \"the science of analytical reasoning facilitated by interactive visual interfaces\" (Thomas and Cook, 2005). Visual analytic environments, therefore, support analytical reasoning using visual representations and interactions, with data representations and transformation capabilities, to support production, presentation, and dissemination. As researchers begin to develop visual analytic environments, it is advantageous to develop metrics and methodologies to help researchers measure the progress of their work and understand the impact their work has on the users who work in such environments. This paper presents five areas or aspects of visual analytic environments that should be considered as metrics and methodologies for evaluation are developed. Evaluation aspects need to include usability, but it is necessary to go beyond basic usability. The areas of situation awareness, collaboration, interaction, creativity, and utility are proposed as the five evaluation areas for initial consideration. The steps that need to be undertaken to develop systematic evaluation methodologies and metrics for visual analytic environments are outlined',\n",
              "  'AuthorKeywords': ['visualization,', 'analytic', 'environments,metrics'],\n",
              "  'MultipartiteRank': [{'score': 0.19530324590371012, 'word': 'visual'},\n",
              "   {'score': 0.100298750147124, 'word': 'analytics'},\n",
              "   {'score': 0.06866566781389939, 'word': 'research'},\n",
              "   {'score': 0.049583806746648966, 'word': 'interactive'},\n",
              "   {'score': 0.049583806746648966, 'word': 'interfaces'},\n",
              "   {'score': 0.04542068900993715, 'word': 'analytic'},\n",
              "   {'score': 0.04542068900993715, 'word': 'environments'},\n",
              "   {'score': 0.04024321425137168, 'word': 'metrics'}],\n",
              "  'Title': 'Beyond Usability: Evaluation Aspects of Visual Analytic Environments',\n",
              "  'distance': 0,\n",
              "  'no': '611',\n",
              "  'parent': '4577'},\n",
              " {'Abstract': 'Time-varying, multi-variate, and comparative data sets are not easily visualized due to the amount of data that is presented to the user at once. By combining several volumes together with different operators into one visualized volume, the user is able to compare values from different data sets in space over time, run, or field without having to mentally switch between different renderings of individual data sets. In this paper, we propose using a volume shader where the user is given the ability to easily select and operate on many data volumes to create comparison relationships. The user specifies an expression with set and numerical operations and her data to see relationships between data fields. Furthermore, we render the contextual information of the volume shader by converting it to a volume tree. We visualize the different levels and nodes of the volume tree so that the user can see the results of suboperations. This gives the user a deeper understanding of the final visualization, by seeing how the parts of the whole are operationally constructed',\n",
              "  'AuthorKeywords': ['multi-variate,',\n",
              "   'time-varying,',\n",
              "   'comparative,',\n",
              "   'focus',\n",
              "   '+',\n",
              "   'context'],\n",
              "  'MultipartiteRank': [{'score': 0.14225094887894585, 'word': 'data'},\n",
              "   {'score': 0.09847422233847643, 'word': 'user'},\n",
              "   {'score': 0.08690456113655569, 'word': 'several'},\n",
              "   {'score': 0.08690456113655569, 'word': 'volumes'},\n",
              "   {'score': 0.07488680255152645, 'word': 'comparative'},\n",
              "   {'score': 0.07488680255152645, 'word': 'sets'},\n",
              "   {'score': 0.060426301170060946, 'word': 'different'},\n",
              "   {'score': 0.060426301170060946, 'word': 'operators'}],\n",
              "  'Title': 'Multi-variate, Time Varying, and Comparative Visualization with Contextual Cues',\n",
              "  'distance': 0,\n",
              "  'no': '612',\n",
              "  'parent': '5519'},\n",
              " {'Abstract': 'As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples.',\n",
              "  'AuthorKeywords': ['visual',\n",
              "   'analytics,',\n",
              "   'cognition',\n",
              "   'and',\n",
              "   'perception',\n",
              "   'theory,',\n",
              "   'embodied',\n",
              "   'cognition,',\n",
              "   'visualization',\n",
              "   'taxonomies',\n",
              "   'and',\n",
              "   'models'],\n",
              "  'MultipartiteRank': [{'score': 0.14540234914475808, 'word': 'design'},\n",
              "   {'score': 0.10044293374420318, 'word': 'visualization'},\n",
              "   {'score': 0.09406603052334597, 'word': 'current'},\n",
              "   {'score': 0.09406603052334597, 'word': 'user'},\n",
              "   {'score': 0.09406603052334597, 'word': 'models'},\n",
              "   {'score': 0.06676406577680509, 'word': 'step'},\n",
              "   {'score': 0.06467324015879365, 'word': 'human'},\n",
              "   {'score': 0.06467324015879365, 'word': 'reasoning'},\n",
              "   {'score': 0.044959415400554884, 'word': 'guidelines'}],\n",
              "  'Title': 'Visual analytics for complex concepts using a human cognition model',\n",
              "  'distance': 0,\n",
              "  'no': '613',\n",
              "  'parent': '3803'},\n",
              " {'Abstract': \"In many application fields, data analysts have to deal with datasets that contain many expressions per item. The effective analysis of such multivariate datasets is dependent on the user's ability to understand both the intrinsic dimensionality of the dataset as well as the distribution of the dependent values with respect to the dimensions. In this paper, we propose a visualization model that enables the joint interactive visual analysis of multivariate datasets with respect to their dimensions as well as with respect to the actual data values. We describe a dual setting of visualization and interaction in items space and in dimensions space. The visualization of items is linked to the visualization of dimensions with brushing and focus+context visualization. With this approach, the user is able to jointly study the structure of the dimensions space as well as the distribution of data items with respect to the dimensions. Even though the proposed visualization model is general, we demonstrate its application in the context of a DNA microarray data analysis.\",\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'visual',\n",
              "   'analysis,',\n",
              "   'High-dimensional',\n",
              "   'data',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.08420812056564843, 'word': 'dimensions'},\n",
              "   {'score': 0.07577340357947825, 'word': 'visualization'},\n",
              "   {'score': 0.07577340357947825, 'word': 'model'},\n",
              "   {'score': 0.06896323715440361, 'word': 'item'},\n",
              "   {'score': 0.06301869709279098, 'word': 'respect'},\n",
              "   {'score': 0.053999188729324056, 'word': 'datasets'}],\n",
              "  'Title': 'Brushing Dimensions - A Dual Visual Analysis Model for High-Dimensional Data',\n",
              "  'distance': 0,\n",
              "  'no': '614',\n",
              "  'parent': '4643'},\n",
              " {'Abstract': 'Route suggestion is an important feature of GPS navigation systems. Recently, Microsoft T-drive has been enabled to suggest routes chosen by experienced taxi drivers for given source/destination pairs in given time periods, which often take less time than the routes calculated according to distance. However, in real environments, taxi drivers may use different routes to reach the same destination, which we call route diversity. In this paper we first propose a trajectory visualization method that examines the regions where the diversity exists and then develop several novel visualization techniques to display the high dimensional attributes and statistics associated with different routes to help users analyze diversity patterns. Our techniques have been applied to the real trajectory data of thousands of taxis and some interesting findings about route diversity have been obtained. We further demonstrate that our system can be used not only to suggest better routes for drivers but also to analyze traffic bottlenecks for transportation management.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.23328449542689234, 'word': 'route'},\n",
              "   {'score': 0.186022612569815, 'word': 'suggestion'},\n",
              "   {'score': 0.07172636737793696, 'word': 'important'},\n",
              "   {'score': 0.07172636737793696, 'word': 'feature'},\n",
              "   {'score': 0.06639115889147924, 'word': 'experienced'},\n",
              "   {'score': 0.06639115889147924, 'word': 'taxi'},\n",
              "   {'score': 0.06639115889147924, 'word': 'drivers'},\n",
              "   {'score': 0.05965137790658706, 'word': 'gps'},\n",
              "   {'score': 0.05965137790658706, 'word': 'navigation'},\n",
              "   {'score': 0.05965137790658706, 'word': 'systems'},\n",
              "   {'score': 0.04726188285707732, 'word': 'diversity'}],\n",
              "  'Title': 'Visual analysis of route diversity',\n",
              "  'distance': 0,\n",
              "  'no': '615',\n",
              "  'parent': '4258'},\n",
              " {'Abstract': 'An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'analytics',\n",
              "   'infrastructures,',\n",
              "   'integration,',\n",
              "   'interactive',\n",
              "   'algorithms,',\n",
              "   'user',\n",
              "   'involvement,',\n",
              "   'problem',\n",
              "   'subdivision'],\n",
              "  'MultipartiteRank': [{'score': 0.08188537799758128, 'word': 'algorithms'},\n",
              "   {'score': 0.04885123843940355, 'word': 'computational'},\n",
              "   {'score': 0.04885123843940355, 'word': 'software'},\n",
              "   {'score': 0.046890786342708365, 'word': 'interactive'},\n",
              "   {'score': 0.046890786342708365, 'word': 'visualization'},\n",
              "   {'score': 0.046890786342708365, 'word': 'tools'},\n",
              "   {'score': 0.04355386279600932, 'word': 'user'},\n",
              "   {'score': 0.04355386279600932, 'word': 'involvement'},\n",
              "   {'score': 0.04177438858348041, 'word': 'integration'}],\n",
              "  'Title': 'Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations',\n",
              "  'distance': 0,\n",
              "  'no': '616',\n",
              "  'parent': '5200'},\n",
              " {'Abstract': 'Vector field rendering is difficult in 3D because the vector icons overlap and hide each other. We propose four different techniques for visualizing vector fields only near surfaces. The first uses motion blurred particles in a thickened region around the surface. The second uses a voxel grid to contain integral curves of the vector field. The third uses many antialiased lines through the surface, and the fourth uses hairs sprouting from the surface and then bending in the direction of the vector field. All the methods use the graphics pipeline, allowing real time rotation and interaction, and the first two methods can animate the texture to move in the flow determined by the velocity field.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.2564038453130989, 'word': 'vector'},\n",
              "   {'score': 0.2052963918310488, 'word': 'field'},\n",
              "   {'score': 0.2052963918310488, 'word': 'rendering'},\n",
              "   {'score': 0.10305266711644749, 'word': 'difficult'},\n",
              "   {'score': 0.0838581748041167, 'word': 'surfaces'},\n",
              "   {'score': 0.05110745348205007, 'word': 'fields'},\n",
              "   {'score': 0.049882445465562114, 'word': 'first'}],\n",
              "  'Title': 'Visualizing 3D velocity fields near contour surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '617',\n",
              "  'parent': '3798'},\n",
              " {'Abstract': \"An important challenge in the visualization of three-dimensional volume data is the efficient processing and rendering of time-resolved sequences. Only the use of compression techniques, which allow the reconstruction of the original domain from the compressed one locally, makes it possible to evaluate these sequences in their entirety. In this paper, a new approach for the extraction and visualization of so-called time features from within time-resolved volume data is presented. Based on the asymptotic decay of multiscale representations of spatially localized time evolutions of the data, singular points can be discriminated. Also, the corresponding Lipschitz exponents, which describe the signals' local regularity, can be determined, and can be taken as a measure of the variation in time. The compression ratio and the comprehension of the underlying signal is improved if we first restore the extracted regions which contain the most important information.\",\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'rendering,',\n",
              "   'wavelet',\n",
              "   'transforms,',\n",
              "   'singularities,',\n",
              "   'Lipschitz',\n",
              "   'exponents'],\n",
              "  'MultipartiteRank': [{'score': 0.09854801995199514, 'word': 'time'},\n",
              "   {'score': 0.06583048605973352, 'word': 'dimensional'},\n",
              "   {'score': 0.06583048605973352, 'word': 'volume'},\n",
              "   {'score': 0.06583048605973352, 'word': 'data'},\n",
              "   {'score': 0.050890519332730144, 'word': 'sequences'},\n",
              "   {'score': 0.05043557822699923, 'word': 'visualization'},\n",
              "   {'score': 0.04814303254327225, 'word': 'compression'},\n",
              "   {'score': 0.04814303254327225, 'word': 'techniques'}],\n",
              "  'Title': 'Compression domain rendering of time-resolved volume data',\n",
              "  'distance': 0,\n",
              "  'no': '618',\n",
              "  'parent': '3556'},\n",
              " {'Abstract': 'As the amount of electronic information explodes, hierarchies to handle this information become huge and complex. Visualizing and interacting with these hierarchies become daunting tasks. The problem is exacerbated if the visualization is to be done on mass-market personal computers, with limited processing power and visual resolution. Many of the current visualization techniques work effectively for hierarchies of 1000 nodes, but as the number of nodes increases toward 5000, these techniques tend to break down. Hierarchies above 5000 nodes usually require special modifications such as clustering, which can affect visual stability. This paper introduces Cheops, a novel approach to the representation, browsing and exploration of huge, complex information hierarchies such as the Dewey Decimal Classification system, which can contain between a million and a billion nodes. The Cheops approach maintains context within a huge hierarchy, while simultaneously providing easy access to details. This paper presents some preliminary results from usability tests performed on an 8-wide-by-9-deep classification hierarchy, which if fully populated would contain over 19 million nodes.',\n",
              "  'AuthorKeywords': ['Hierarchical',\n",
              "   'representation,',\n",
              "   'information',\n",
              "   'visualization',\n",
              "   'and',\n",
              "   'exploration,',\n",
              "   'focus+context',\n",
              "   'techniques,',\n",
              "   'graphical',\n",
              "   'browser'],\n",
              "  'MultipartiteRank': [{'score': 0.07807082122680788, 'word': 'hierarchies'},\n",
              "   {'score': 0.06841585683461229, 'word': 'nodes'},\n",
              "   {'score': 0.059105554050718725, 'word': 'visualization'},\n",
              "   {'score': 0.04175784206813735, 'word': 'huge'},\n",
              "   {'score': 0.03815541661312465, 'word': 'electronic'},\n",
              "   {'score': 0.03815541661312465, 'word': 'information'},\n",
              "   {'score': 0.03815541661312465, 'word': 'explodes'}],\n",
              "  'Title': 'Cheops: a compact explorer for complex hierarchies',\n",
              "  'distance': 0,\n",
              "  'no': '619',\n",
              "  'parent': '5062'},\n",
              " {'Abstract': '3D virtual colonoscopy has recently been proposed as a non-invasive alternative procedure for the visualization of the human colon. Surface rendering is sufficient for implementing such a procedure to obtain an overview of the interior surface of the colon at interactive rendering speeds. Unfortunately, physicians can not use it to explore tissues beneath the surface to differentiate between benign and malignant structures. In this paper, we present a direct volume rendering approach based on perspective ray casting, as a supplement to the surface navigation. To accelerate the rendering speed, surface-assistant techniques are used to adapt the resampling rates by skipping the empty space inside the colon. In addition, a parallel version of the algorithm has been implemented on a shared-memory multiprocessing architecture. Experiments have been conducted on both simulation and patient data sets.',\n",
              "  'AuthorKeywords': ['Virtual',\n",
              "   'Colonoscopy,Endoscopy,Visibility,Interactive',\n",
              "   'Navigation,Volume',\n",
              "   'Rendering,Surface',\n",
              "   'Rendering,',\n",
              "   'Parallel',\n",
              "   'Processing,',\n",
              "   'Virtual',\n",
              "   'Environment'],\n",
              "  'MultipartiteRank': [{'score': 0.17519686599182266, 'word': 'rendering'},\n",
              "   {'score': 0.14280911857975487, 'word': 'colon'},\n",
              "   {'score': 0.12770799474236266, 'word': 'surface'},\n",
              "   {'score': 0.098049828226081, 'word': 'human'},\n",
              "   {'score': 0.054179846646526336, 'word': 'sufficient'},\n",
              "   {'score': 0.04748887124946001, 'word': 'interactive'},\n",
              "   {'score': 0.04748887124946001, 'word': 'speeds'}],\n",
              "  'Title': 'Interactive volume rendering for virtual colonoscopy',\n",
              "  'distance': 0,\n",
              "  'no': '620',\n",
              "  'parent': '3515'},\n",
              " {'Abstract': 'A number of usability studies report that many users of the WWW cannot find pages already visited, additionally many users cannot visualise where they are, or where they have been browsing. Currently, readily available WWW browsers provide history mechanisms that offer little or no support in the presentation and manipulation of visited sites. Manipulation and presentation of usage data, such as a browse history has been used in a number of cases to aid users in searching for previously attained data, and to teach or assist other users in their browse or searching techniques. The paper presents a virtual reality (VR) based application to be used alongside traditional Web browsers, which provides them with a flexibly tailorable real time visualisation of their history.',\n",
              "  'AuthorKeywords': ['Virtual',\n",
              "   'Environments,',\n",
              "   'World-Wide-Web,Visualisation,',\n",
              "   'Web',\n",
              "   'Browsing'],\n",
              "  'MultipartiteRank': [{'score': 0.08256757237268475, 'word': 'many'},\n",
              "   {'score': 0.08256757237268475, 'word': 'users'},\n",
              "   {'score': 0.07563088131274431, 'word': 'presentation'},\n",
              "   {'score': 0.07487488567894363, 'word': 'manipulation'},\n",
              "   {'score': 0.06413868345065969, 'word': 'www'},\n",
              "   {'score': 0.0587873220131455, 'word': 'number'}],\n",
              "  'Title': 'WEBPATH-a three dimensional Web history',\n",
              "  'distance': 0,\n",
              "  'no': '621',\n",
              "  'parent': '4277'},\n",
              " {'Abstract': 'The goal of this paper is to define a convolution operation which transfers image processing and pattern matching to vector fields from flow visualization. For this, a multiplication of vectors is necessary. Clifford algebra provides such a multiplication of vectors. We define a Clifford convolution on vector fields with uniform grids. The Clifford convolution works with multivector filter masks. Scalar and vector masks can be easily converted to multivector fields. So, filter masks from image processing on scalar fields can be applied as well as vector and scalar masks. Furthermore, a method for pattern matching with Clifford convolution on vector fields is described. The method is independent of the direction of the structures. This provides an automatic approach to feature detection. The features can be visualized using any known method like glyphs, isosurfaces or streamlines. The features are defined by filter masks instead of analytical properties and thus the approach is more intuitive.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'Visualization,',\n",
              "   'Convolution,',\n",
              "   'Pattern',\n",
              "   'Matching'],\n",
              "  'MultipartiteRank': [{'score': 0.1289162441743058, 'word': 'clifford'},\n",
              "   {'score': 0.10247032081602361, 'word': 'vector'},\n",
              "   {'score': 0.10247032081602361, 'word': 'fields'},\n",
              "   {'score': 0.07524570955516786, 'word': 'algebra'},\n",
              "   {'score': 0.07094103274074541, 'word': 'multivector'},\n",
              "   {'score': 0.07094103274074541, 'word': 'filter'},\n",
              "   {'score': 0.07094103274074541, 'word': 'masks'},\n",
              "   {'score': 0.05367053461913795, 'word': 'convolution'},\n",
              "   {'score': 0.048796302712216605, 'word': 'vectors'}],\n",
              "  'Title': 'Clifford convolution and pattern matching on vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '622',\n",
              "  'parent': '4080'},\n",
              " {'Abstract': 'Isosurfaces are ubiquitous in many fields, including visualization, graphics, and vision. They are often the main computational component of important processing pipelines (e.g., surface reconstruction), and are heavily used in practice. The classical approach to compute isosurfaces is to apply the Marching Cubes algorithm, which although robust and simple to implement, generates surfaces that require additional processing steps to improve triangle quality and mesh size. An important issue is that in some cases, the surfaces generated by Marching Cubes are irreparably damaged, and important details are lost which can not be recovered by subsequent processing. The main motivation of this work is to develop a technique capable of constructing high-quality and high-fidelity isosurfaces. We propose a new advancing front technique that is capable of creating high-quality isosurfaces from regular and irregular volumetric datasets. Our work extends the guidance field framework of Schreiner et al. to implicit surfaces, and improves it in significant ways. In particular, we describe a set of sampling conditions that guarantee that surface features will be captured by the algorithm. We also describe an efficient technique to compute a minimal guidance field, which greatly improves performance. Our experimental results show that our technique can generate high-quality meshes from complex datasets',\n",
              "  'AuthorKeywords': ['Isosurface',\n",
              "   'Extraction,',\n",
              "   'Curvature,',\n",
              "   'Advancing',\n",
              "   'Front'],\n",
              "  'MultipartiteRank': [{'score': 0.06450132547259729, 'word': 'isosurfaces'},\n",
              "   {'score': 0.06135617348187755, 'word': 'surface'},\n",
              "   {'score': 0.06135617348187755, 'word': 'reconstruction'},\n",
              "   {'score': 0.05042385503411673, 'word': 'triangle'},\n",
              "   {'score': 0.05042385503411673, 'word': 'quality'},\n",
              "   {'score': 0.04427570432932921, 'word': 'high'},\n",
              "   {'score': 0.02875798519217147, 'word': 'surfaces'}],\n",
              "  'Title': 'High-Quality Extraction of Isosurfaces from Regular and Irregular Grids',\n",
              "  'distance': 0,\n",
              "  'no': '623',\n",
              "  'parent': '5351'},\n",
              " {'Abstract': 'The visualization and exploration of multivariate data is still a challenging task. Methods either try to visualize all variables simultaneously at each position using glyph-based approaches or use linked views for the interaction between attribute space and physical domain such as brushing of scatterplots. Most visualizations of the attribute space are either difficult to understand or suffer from visual clutter. We propose a transformation of the high-dimensional data in attribute space to 2D that results in a point cloud, called attribute cloud, such that points with similar multivariate attributes are located close to each other. The transformation is based on ideas from multivariate density estimation and manifold learning. The resulting attribute cloud is an easy to understand visualization of multivariate data in two dimensions. We explain several techniques to incorporate additional information into the attribute cloud, that help the user get a better understanding of multivariate data. Using different examples from fluid dynamics and climate simulation, we show how brushing can be used to explore the attribute cloud and find interesting structures in physical space.',\n",
              "  'AuthorKeywords': ['Multivariate',\n",
              "   'data,',\n",
              "   'brushing,',\n",
              "   'data',\n",
              "   'transformation,',\n",
              "   'manifold',\n",
              "   'learning,',\n",
              "   'linked',\n",
              "   'views'],\n",
              "  'MultipartiteRank': [{'score': 0.1647641420611623, 'word': 'attribute'},\n",
              "   {'score': 0.10787078403207707, 'word': 'space'},\n",
              "   {'score': 0.09237777083835816, 'word': 'cloud'},\n",
              "   {'score': 0.08641158468241672, 'word': 'multivariate'},\n",
              "   {'score': 0.08641158468241672, 'word': 'data'},\n",
              "   {'score': 0.06314761102956351, 'word': 'visualization'},\n",
              "   {'score': 0.03548441280927293, 'word': 'point'}],\n",
              "  'Title': 'Brushing of Attribute Clouds for the Visualization of Multivariate Data',\n",
              "  'distance': 0,\n",
              "  'no': '624',\n",
              "  'parent': '5177'},\n",
              " {'Abstract': 'Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.',\n",
              "  'AuthorKeywords': ['Evaluation,',\n",
              "   'geovisualization,',\n",
              "   'context',\n",
              "   'of',\n",
              "   'use,',\n",
              "   'requirements,',\n",
              "   'field',\n",
              "   'study,',\n",
              "   'prototypes,',\n",
              "   'sketching,',\n",
              "   'design'],\n",
              "  'MultipartiteRank': [{'score': 0.05302048736073042, 'word': 'design'},\n",
              "   {'score': 0.04995386157584978, 'word': 'domain'},\n",
              "   {'score': 0.04995386157584978, 'word': 'data'},\n",
              "   {'score': 0.04725991593272481, 'word': 'use'},\n",
              "   {'score': 0.04386609481498045, 'word': 'approaches'},\n",
              "   {'score': 0.03125298914784977, 'word': 'requirements'}],\n",
              "  'Title': 'Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study',\n",
              "  'distance': 0,\n",
              "  'no': '625',\n",
              "  'parent': '6197'},\n",
              " {'Abstract': 'In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'rendering,',\n",
              "   'Sketching',\n",
              "   'input,',\n",
              "   'Human-computer',\n",
              "   'interaction,',\n",
              "   'Transfer',\n",
              "   'functions,',\n",
              "   'Feature',\n",
              "   'space'],\n",
              "  'MultipartiteRank': [{'score': 0.14409654147664555, 'word': 'volume'},\n",
              "   {'score': 0.13090931757532986, 'word': 'system'},\n",
              "   {'score': 0.12327647191775638, 'word': 'direct'},\n",
              "   {'score': 0.08148215048618558, 'word': 'visualization'},\n",
              "   {'score': 0.06066208092729641, 'word': 'manipulation'},\n",
              "   {'score': 0.03880901947125378, 'word': 'targeted'},\n",
              "   {'score': 0.03880901947125378, 'word': 'features'}],\n",
              "  'Title': 'WYSIWYG (What You See is What You Get) Volume Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '626',\n",
              "  'parent': '4562'},\n",
              " {'Abstract': 'In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1619323710407259, 'word': 'data'},\n",
              "   {'score': 0.06900664611581621, 'word': 'subspaces'},\n",
              "   {'score': 0.04782809433573887, 'word': 'explorative'},\n",
              "   {'score': 0.04782809433573887, 'word': 'analysis'},\n",
              "   {'score': 0.04445444575460912, 'word': 'many'},\n",
              "   {'score': 0.04445444575460912, 'word': 'methods'},\n",
              "   {'score': 0.03233761217930632, 'word': 'dimensional'}],\n",
              "  'Title': 'Subspace search and visualization to make sense of alternative clusterings in high-dimensional data',\n",
              "  'distance': 0,\n",
              "  'no': '627',\n",
              "  'parent': '5909'},\n",
              " {'Abstract': 'Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'design,',\n",
              "   'encoding,',\n",
              "   'perception,',\n",
              "   'model,',\n",
              "   'crowdsourcing,',\n",
              "   'automated',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'embedding'],\n",
              "  'MultipartiteRank': [{'score': 0.0883045214239912, 'word': 'perceptual'},\n",
              "   {'score': 0.0883045214239912, 'word': 'kernels'},\n",
              "   {'score': 0.0784636784105414, 'word': 'visualization'},\n",
              "   {'score': 0.0784636784105414, 'word': 'design'},\n",
              "   {'score': 0.05426609012768467, 'word': 'different'},\n",
              "   {'score': 0.05426609012768467, 'word': 'assignments'},\n",
              "   {'score': 0.048395942567084, 'word': 'shape'},\n",
              "   {'score': 0.047312114576242376, 'word': 'size'}],\n",
              "  'Title': 'Learning Perceptual Kernels for Visualization Design',\n",
              "  'distance': 0,\n",
              "  'no': '628',\n",
              "  'parent': '4285'},\n",
              " {'Abstract': 'We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use.',\n",
              "  'AuthorKeywords': ['Literacy,',\n",
              "   'Visualization',\n",
              "   'literacy,',\n",
              "   'Rasch',\n",
              "   'Model,',\n",
              "   'Item',\n",
              "   'Response',\n",
              "   'Theory'],\n",
              "  'MultipartiteRank': [{'score': 0.075604319154454, 'word': 'method'},\n",
              "   {'score': 0.0626925673981717, 'word': 'vl'},\n",
              "   {'score': 0.0626925673981717, 'word': 'tests'},\n",
              "   {'score': 0.05331515551387984, 'word': 'design'},\n",
              "   {'score': 0.04959614663893764, 'word': 'level'},\n",
              "   {'score': 0.049039795808437064, 'word': 'visualization'},\n",
              "   {'score': 0.049039795808437064, 'word': 'literacy'}],\n",
              "  'Title': 'A Principled Way of Assessing Visualization Literacy',\n",
              "  'distance': 0,\n",
              "  'no': '629',\n",
              "  'parent': '4128'},\n",
              " {'Abstract': 'We present a method for automatically identifying and validating predictive relationships between the visual appearance of a city and its non-visual attributes (e.g. crime statistics, housing prices, population density etc.). Given a set of street-level images and (location, city-attribute-value) pairs of measurements, we first identify visual elements in the images that are discriminative of the attribute. We then train a predictor by learning a set of weights over these elements using non-linear Support Vector Regression. To perform these operations efficiently, we implement a scalable distributed processing framework that speeds up the main computational bottleneck (extracting visual elements) by an order of magnitude. This speedup allows us to investigate a variety of city attributes across 6 different American cities. We find that indeed there is a predictive relationship between visual elements and a number of city attributes including violent crime rates, theft rates, housing prices, population density, tree presence, graffiti presence, and the perception of danger. We also test human performance for predicting theft based on street-level images and show that our predictor outperforms this baseline with 33% higher accuracy on average. Finally, we present three prototype applications that use our system to (1) define the visual boundary of city neighborhoods, (2) generate walking directions that avoid or seek out exposure to city attributes, and (3) validate user-specified visual elements for prediction.',\n",
              "  'AuthorKeywords': ['Data',\n",
              "   'mining,',\n",
              "   'big',\n",
              "   'data,',\n",
              "   'computational',\n",
              "   'geography,',\n",
              "   'visual',\n",
              "   'processing'],\n",
              "  'MultipartiteRank': [{'score': 0.08486677172243504, 'word': 'city'},\n",
              "   {'score': 0.06629378309846187, 'word': 'attribute'},\n",
              "   {'score': 0.056899682776926294, 'word': 'visual'},\n",
              "   {'score': 0.056899682776926294, 'word': 'elements'},\n",
              "   {'score': 0.04436542751639892, 'word': 'level'},\n",
              "   {'score': 0.04436542751639892, 'word': 'images'},\n",
              "   {'score': 0.033058456256809705, 'word': 'attributes'}],\n",
              "  'Title': 'City Forensics: Using Visual Elements to Predict Non-Visual City Attributes',\n",
              "  'distance': 0,\n",
              "  'no': '630',\n",
              "  'parent': '5389'},\n",
              " {'Abstract': 'This paper outlines a method to dynamically replace portals with textures in a cell-partitioned model. The rendering complexity is reduced to the geometry of the current cell thus increasing interactive performance. A portal is a generalization of windows and doors. It connects two adjacent cells (or rooms). Each portal of the current cell that is some distance away from the viewpoint is rendered as a texture. The portal texture (smoothly) returns to geometry when the viewpoint gets close to the portal. This way all portal sequences (not too close to the viewpoint) have a depth complexity of one. The size of each texture and distance at which the transition occurs is configurable for each portal.',\n",
              "  'AuthorKeywords': ['visibility',\n",
              "   'culling,',\n",
              "   'cells,',\n",
              "   'portals,',\n",
              "   'textures,',\n",
              "   'sample',\n",
              "   'points,',\n",
              "   'morphing'],\n",
              "  'MultipartiteRank': [{'score': 0.12309016293420755, 'word': 'portals'},\n",
              "   {'score': 0.09471777539408964, 'word': 'cell'},\n",
              "   {'score': 0.08846594674249242, 'word': 'textures'},\n",
              "   {'score': 0.05707315133581902, 'word': 'viewpoint'},\n",
              "   {'score': 0.05103267177461034, 'word': 'rendering'},\n",
              "   {'score': 0.05103267177461034, 'word': 'complexity'}],\n",
              "  'Title': 'Architectural walkthroughs using portal textures',\n",
              "  'distance': 0,\n",
              "  'no': '631',\n",
              "  'parent': '3859'},\n",
              " {'Abstract': 'We present a method for the construction of multiple levels of tetrahedral meshes approximating a trivariate function at different levels of detail. Starting with an initial, high-resolution triangulation of a three-dimensional region, we construct coarser representation levels by collapsing tetrahedra. Each triangulation defines a linear spline function, where the function values associated with the vertices are the spline coefficients. Based on predicted errors, we collapse tetrahedron in the grid that do not cause the maximum error to exceed a use-specified threshold. Bounds are stored for individual tetrahedra and are updated as the mesh is simplified. We continue the simplification process until a certain error is reached. The result is a hierarchical data description suited for the efficient visualization of large data sets at varying levels of detail.',\n",
              "  'AuthorKeywords': ['approximation,',\n",
              "   'hierarchical',\n",
              "   'representation,',\n",
              "   'mesh',\n",
              "   'generation,',\n",
              "   'multiresolution',\n",
              "   'method,',\n",
              "   'scattered',\n",
              "   'data,',\n",
              "   'spline,',\n",
              "   'triangulation,',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.10592301796527956, 'word': 'multiple'},\n",
              "   {'score': 0.10592301796527956, 'word': 'levels'},\n",
              "   {'score': 0.05948289837349572, 'word': 'tetrahedral'},\n",
              "   {'score': 0.05948289837349572, 'word': 'meshes'},\n",
              "   {'score': 0.05614919040262779, 'word': 'trivariate'},\n",
              "   {'score': 0.05614919040262779, 'word': 'function'},\n",
              "   {'score': 0.04813659535352884, 'word': 'resolution'},\n",
              "   {'score': 0.04813659535352884, 'word': 'triangulation'},\n",
              "   {'score': 0.04576123132028229, 'word': 'errors'}],\n",
              "  'Title': 'Simplification of tetrahedral meshes',\n",
              "  'distance': 0,\n",
              "  'no': '632',\n",
              "  'parent': '3551'},\n",
              " {'Abstract': 'Visualization of three-dimensional steady flow has to overcome a lot of problems to be effective. Among them are occlusion of distant details, lack of directional and depth hints and occlusion. We present methods which address these problems for real-time graphic representations applicable in virtual environments. We use dashtubes, i.e., animated, opacity-mapped streamlines, as a visualization icon for 3D-flow visualization. We present a texture mapping technique to keep the level of texture detail along a streamline nearly constant even when the velocity of the flow varies considerably. An algorithm is described which distributes the dashtubes evenly in space. We apply magic lenses and magic boxes as interaction techniques for investigating densely filled areas without overwhelming the observer with visual detail. Implementation details of these methods and their integration in our virtual environment conclude the paper.',\n",
              "  'AuthorKeywords': ['virtual',\n",
              "   'environments,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'texturing,',\n",
              "   'interaction,',\n",
              "   'magic',\n",
              "   'lens,',\n",
              "   'focussing'],\n",
              "  'MultipartiteRank': [{'score': 0.08950797938019603, 'word': 'visualization'},\n",
              "   {'score': 0.06271548993548708, 'word': 'dimensional'},\n",
              "   {'score': 0.06271548993548708, 'word': 'steady'},\n",
              "   {'score': 0.06271548993548708, 'word': 'flow'},\n",
              "   {'score': 0.06232131467886479, 'word': 'distant'},\n",
              "   {'score': 0.06232131467886479, 'word': 'details'},\n",
              "   {'score': 0.05565331463912544, 'word': 'occlusion'},\n",
              "   {'score': 0.05384657953872409, 'word': 'problems'}],\n",
              "  'Title': 'Real-time techniques for 3D flow visualization',\n",
              "  'distance': 0,\n",
              "  'no': '633',\n",
              "  'parent': '3818'},\n",
              " {'Abstract': 'A major challenge of current visualization and visual data mining (VDM) frameworks is to support users in the orientation in complex visual mining scenarios. An important aspect to increase user support and user orientation is to use a history mechanism that, first of all, provides un- and redoing functionality. In this paper, we present a new approach to include such history functionality into a VDM framework. Therefore, we introduce the theoretical background, outline design and implementation aspects of a history management unit, and conclude with a discussion showing the usefulness of our history management in a VDM framework',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'data',\n",
              "   'mining,',\n",
              "   'Visualization,',\n",
              "   'History,',\n",
              "   'Undo/Redo'],\n",
              "  'MultipartiteRank': [{'score': 0.10201085749127575, 'word': 'visual'},\n",
              "   {'score': 0.10201085749127575, 'word': 'data'},\n",
              "   {'score': 0.10201085749127575, 'word': 'mining'},\n",
              "   {'score': 0.07881969664643833, 'word': 'frameworks'},\n",
              "   {'score': 0.07770641556490575, 'word': 'users'},\n",
              "   {'score': 0.07714927762249225, 'word': 'orientation'},\n",
              "   {'score': 0.06245593870846051, 'word': 'vdm'}],\n",
              "  'Title': 'A History Mechanism for Visual Data Mining',\n",
              "  'distance': 0,\n",
              "  'no': '634',\n",
              "  'parent': '3553'},\n",
              " {'Abstract': 'Traditionally, time-varying data has been visualized using snapshots of the individual time steps or an animation of the snapshots shown in a sequential manner. For larger datasets with many time-varying features, animation can be limited in its use, as an observer can only track a limited number of features over the last few frames. Visually inspecting each snapshot is not practical either for a large number of time-steps. We propose new techniques inspired from the illustration literature to convey change over time more effectively in a time-varying dataset. Speedlines are used extensively by cartoonists to convey motion, speed, or change over different panels. Flow ribbons are another technique used by cartoonists to depict motion in a single frame. Strobe silhouettes are used to depict previous positions of an object to convey the previous positions of the object to the user. These illustration-inspired techniques can be used in conjunction with animation to convey change over time.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'visualization,',\n",
              "   'Non-photorealistic',\n",
              "   'rendering,',\n",
              "   'time-varying',\n",
              "   'data,',\n",
              "   'illustration'],\n",
              "  'MultipartiteRank': [{'score': 0.10255203662542732, 'word': 'time'},\n",
              "   {'score': 0.05195401321164167, 'word': 'animation'},\n",
              "   {'score': 0.048997986379557684, 'word': 'snapshots'},\n",
              "   {'score': 0.04878522994962743, 'word': 'new'},\n",
              "   {'score': 0.04878522994962743, 'word': 'techniques'},\n",
              "   {'score': 0.041750317614008194, 'word': 'larger'},\n",
              "   {'score': 0.041750317614008194, 'word': 'datasets'}],\n",
              "  'Title': 'Illustration-inspired techniques for visualizing time-varying data',\n",
              "  'distance': 0,\n",
              "  'no': '635',\n",
              "  'parent': '5320'},\n",
              " {'Abstract': 'Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08084396234716555, 'word': 'data'},\n",
              "   {'score': 0.07795549295456677, 'word': 'modern'},\n",
              "   {'score': 0.07795549295456677, 'word': 'machine'},\n",
              "   {'score': 0.05412143140404947, 'word': 'human'},\n",
              "   {'score': 0.05412143140404947, 'word': 'experts'},\n",
              "   {'score': 0.053428107911786274, 'word': 'modeling'},\n",
              "   {'score': 0.05205999411913152, 'word': 'robust'},\n",
              "   {'score': 0.05205999411913152, 'word': 'approaches'}],\n",
              "  'Title': 'Anomaly detection in GPS data based on visual analytics',\n",
              "  'distance': 0,\n",
              "  'no': '636',\n",
              "  'parent': '4768'},\n",
              " {'Abstract': 'Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.',\n",
              "  'AuthorKeywords': ['text',\n",
              "   'visualization,',\n",
              "   'multi-facet',\n",
              "   'data',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1382716660896964, 'word': 'text'},\n",
              "   {'score': 0.1382716660896964, 'word': 'visualization'},\n",
              "   {'score': 0.04742537928040259, 'word': 'many'},\n",
              "   {'score': 0.04742537928040259, 'word': 'people'},\n",
              "   {'score': 0.0435819936909096, 'word': 'facets'},\n",
              "   {'score': 0.04042577081996873, 'word': 'important'},\n",
              "   {'score': 0.04042577081996873, 'word': 'research'},\n",
              "   {'score': 0.04042577081996873, 'word': 'topic'},\n",
              "   {'score': 0.0384924439015846, 'word': 'data'},\n",
              "   {'score': 0.0384924439015846, 'word': 'model'}],\n",
              "  'Title': 'Understanding text corpora with multiple facets',\n",
              "  'distance': 0,\n",
              "  'no': '637',\n",
              "  'parent': '4093'},\n",
              " {'Abstract': 'Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'links,',\n",
              "   'highlighting,',\n",
              "   'connectedness,',\n",
              "   'routing,',\n",
              "   'image-based,',\n",
              "   'saliency'],\n",
              "  'MultipartiteRank': [{'score': 0.16798799663246164, 'word': 'visual'},\n",
              "   {'score': 0.08288958159996955, 'word': 'linking'},\n",
              "   {'score': 0.0708774435167447, 'word': 'information'},\n",
              "   {'score': 0.04273136940994206, 'word': 'related'},\n",
              "   {'score': 0.04273136940994206, 'word': 'elements'},\n",
              "   {'score': 0.042723777298476165, 'word': 'interference'},\n",
              "   {'score': 0.04237463773401592, 'word': 'data'},\n",
              "   {'score': 0.04237463773401592, 'word': 'analysis'}],\n",
              "  'Title': 'Context-Preserving Visual Links',\n",
              "  'distance': 0,\n",
              "  'no': '638',\n",
              "  'parent': '5052'},\n",
              " {'Abstract': \"While intelligence analysis has been a primary target domain for visual analytics system development, relatively little user and task analysis has been conducted within this area. Our research community's understanding of the work processes and practices of intelligence analysts is not deep enough to adequately address their needs. Without a better understanding of the analysts and their problems, we cannot build visual analytics systems that integrate well with their work processes and truly provide benefit to them. In order to close this knowledge gap, we conducted a longitudinal, observational field study of intelligence analysts in training within the intelligence program at Mercyhurst College. We observed three teams of analysts, each working on an intelligence problem for a ten-week period. Based upon study findings, we describe and characterize processes and methods of intelligence analysis that we observed, make clarifications regarding the processes and practices, and suggest design implications for visual analytics systems for intelligence analysis.\",\n",
              "  'AuthorKeywords': ['Intelligence',\n",
              "   'analysis,',\n",
              "   'qualitatvie',\n",
              "   'user',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.14579178892598565, 'word': 'intelligence'},\n",
              "   {'score': 0.07598850573752569, 'word': 'analysts'},\n",
              "   {'score': 0.07240815131165011, 'word': 'work'},\n",
              "   {'score': 0.07240815131165011, 'word': 'processes'},\n",
              "   {'score': 0.06980328318845995, 'word': 'analysis'},\n",
              "   {'score': 0.060404760286263445, 'word': 'visual'},\n",
              "   {'score': 0.060404760286263445, 'word': 'analytics'},\n",
              "   {'score': 0.060404760286263445, 'word': 'system'},\n",
              "   {'score': 0.060404760286263445, 'word': 'development'},\n",
              "   {'score': 0.045986434737856116, 'word': 'understanding'}],\n",
              "  'Title': 'Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study',\n",
              "  'distance': 0,\n",
              "  'no': '639',\n",
              "  'parent': '4379'},\n",
              " {'Abstract': 'High-quality immersive display technologies are becoming mainstream with the release of head-mounted displays (HMDs) such as the Oculus Rift. These devices potentially represent an affordable alternative to the more traditional, centralised CAVE-style immersive environments. One driver for the development of CAVE-style immersive environments has been collaborative sense-making. Despite this, there has been little research on the effectiveness of collaborative visualisation in CAVE-style facilities, especially with respect to abstract data visualisation tasks. Indeed, very few studies have focused on the use of these displays to explore and analyse abstract data such as networks and there have been no formal user studies investigating collaborative visualisation of abstract data in immersive environments. In this paper we present the results of the first such study. It explores the relative merits of HMD and CAVE-style immersive environments for collaborative analysis of network connectivity, a common and important task involving abstract data. We find significant differences between the two conditions in task completion time and the physical movements of the participants within the space: participants using the HMD were faster while the CAVE2 condition introduced an asymmetry in movement between collaborators. Otherwise, affordances for collaborative data analysis offered by the low-cost HMD condition were not found to be different for accuracy and communication with the CAVE2. These results are notable, given that the latest HMDs will soon be accessible (in terms of cost and potentially ubiquity) to a massive audience.',\n",
              "  'AuthorKeywords': ['3D',\n",
              "   'Network;Oculus',\n",
              "   'Rift;CAVE;Immersive',\n",
              "   'Analytics;Collaboration'],\n",
              "  'MultipartiteRank': [{'score': 0.06608628782423887, 'word': 'collaborative'},\n",
              "   {'score': 0.06608628782423887, 'word': 'sense'},\n",
              "   {'score': 0.05367677960793549, 'word': 'cave'},\n",
              "   {'score': 0.05334639708952767, 'word': 'style'},\n",
              "   {'score': 0.05334639708952767, 'word': 'immersive'},\n",
              "   {'score': 0.05334639708952767, 'word': 'environments'},\n",
              "   {'score': 0.03996664382406359, 'word': 'hmds'},\n",
              "   {'score': 0.03324757475689091, 'word': 'abstract'},\n",
              "   {'score': 0.03324757475689091, 'word': 'data'},\n",
              "   {'score': 0.03324757475689091, 'word': 'visualisation'},\n",
              "   {'score': 0.03324757475689091, 'word': 'tasks'}],\n",
              "  'Title': 'Immersive Collaborative Analysis of Network Connectivity: CAVE-style or Head-Mounted Display?',\n",
              "  'distance': 0,\n",
              "  'no': '640',\n",
              "  'parent': '4891'},\n",
              " {'Abstract': 'The interval volume is a generalization of the isosurface commonly associated with the marching cubes algorithm. Based upon samples at the locations of a 3D rectilinear grid, the algorithm produces a triangular approximation to the surface defined by F(x,y,z)=c. The interval volume is defined by /spl alpha//spl les/F(x,y,z)/spl les//spl beta/. The authors describe an algorithm for computing a tetrahedrization of a polyhedral approximation to the interval volume.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.24062008358368933, 'word': 'algorithm'},\n",
              "   {'score': 0.1500403629676508, 'word': 'marching'},\n",
              "   {'score': 0.1500403629676508, 'word': 'cubes'},\n",
              "   {'score': 0.10541705635236268, 'word': 'interval'},\n",
              "   {'score': 0.10541705635236268, 'word': 'volume'},\n",
              "   {'score': 0.09851788885255212, 'word': 'triangular'},\n",
              "   {'score': 0.09851788885255212, 'word': 'approximation'},\n",
              "   {'score': 0.07944190928000844, 'word': 'samples'}],\n",
              "  'Title': 'Interval volume tetrahedrization',\n",
              "  'distance': 0,\n",
              "  'no': '641',\n",
              "  'parent': '3337'},\n",
              " {'Abstract': 'Area cartograms are used for visualizing geographically distributed data by attaching measurements to regions of a map and scaling the regions such that their areas are proportional to the measured quantities. A continuous area cartogram is a cartogram that is constructed without changing the underlying map topology. We present a new algorithm for the construction of continuous area cartograms that was developed by viewing their construction as a constrained optimization problem. The algorithm uses a relaxation method that exploits hierarchical resolution, constrained dynamics, and a scheme that alternates goals of achieving correct region areas and adjusting region shapes. It is compared favorably to existing methods in its ability to preserve region shape recognition cues, while still achieving high accuracy.',\n",
              "  'AuthorKeywords': ['cartogram,',\n",
              "   'value-by-area',\n",
              "   'map,',\n",
              "   'map',\n",
              "   'transformation,anamorphosis,',\n",
              "   'thematic',\n",
              "   'cartography,',\n",
              "   'constrained',\n",
              "   'optimization'],\n",
              "  'MultipartiteRank': [{'score': 0.17788173917012823, 'word': 'area'},\n",
              "   {'score': 0.17788173917012823, 'word': 'cartograms'},\n",
              "   {'score': 0.0843541804103748, 'word': 'measurements'},\n",
              "   {'score': 0.08401666539696642, 'word': 'regions'},\n",
              "   {'score': 0.06271503366144793, 'word': 'map'},\n",
              "   {'score': 0.05620439170898438, 'word': 'data'}],\n",
              "  'Title': 'Continuous cartogram construction',\n",
              "  'distance': 0,\n",
              "  'no': '642',\n",
              "  'parent': '3722'},\n",
              " {'Abstract': 'The reconstruction of isosurfaces from scalar volume data has positioned itself as a fundamental visualization technique in many different applications. But the dramatically increasing size of volumetric data sets often prohibits the handling of these models on affordable low-end single processor architectures. Distributed client-server systems integrating high-bandwidth transmission channels and Web based visualization tools are one alternative to attack this particular problem, but therefore new approaches to reduce the load of numerical processing and the number of generated primitives are required. We outline different scenarios for distributed isosurface reconstruction from large scale volumetric data sets. We demonstrate how to directly generate stripped surface representations and we introduce adaptive and hierarchical concepts to minimize the number of vertices that have to be reconstructed, transmitted and rendered. Furthermore, we propose a novel computation scheme, which allows the user to flexibly exploit locally available resources. The proposed algorithms have been merged together in order to build a platform-independent Web based application. Extensive use of VRML and Java OpenGL bindings allows for the exploration of large scale volume data quite efficiently.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'visualization,',\n",
              "   'Isosurface',\n",
              "   'reconstruction,',\n",
              "   'Distributed',\n",
              "   'Systems,',\n",
              "   'Web-based',\n",
              "   'Applications'],\n",
              "  'MultipartiteRank': [{'score': 0.08103053143271402, 'word': 'data'},\n",
              "   {'score': 0.04856327304590944, 'word': 'isosurfaces'},\n",
              "   {'score': 0.04136787544123374, 'word': 'volumetric'},\n",
              "   {'score': 0.04136787544123374, 'word': 'sets'},\n",
              "   {'score': 0.041165771719332854, 'word': 'web'},\n",
              "   {'score': 0.04000327317575736, 'word': 'many'},\n",
              "   {'score': 0.04000327317575736, 'word': 'different'},\n",
              "   {'score': 0.04000327317575736, 'word': 'applications'},\n",
              "   {'score': 0.03966265599148027, 'word': 'scalar'},\n",
              "   {'score': 0.03966265599148027, 'word': 'volume'}],\n",
              "  'Title': 'Isosurface extraction techniques for Web-based volume visualization',\n",
              "  'distance': 0,\n",
              "  'no': '643',\n",
              "  'parent': '5131'},\n",
              " {'Abstract': 'In this paper, we propose a new technique to visualize dense representations of time-dependent vector fields based on a Lagrangian-Eulerian Advection (LEA) scheme. The algorithm produces animations with high spatio-temporal correlation at interactive rates. With this technique, every still frame depicts the instantaneous structure of the flow, whereas an animated sequence of frames reveals the motion a dense collection of particles would take when released into the flow. The simplicity of both the resulting data structures and the implementation suggest that LEA could become a useful component of any scientific visualization toolkit concerned with the display of unsteady flows.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06560464195216328, 'word': 'dense'},\n",
              "   {'score': 0.06560464195216328, 'word': 'representations'},\n",
              "   {'score': 0.05694439427174921, 'word': 'flow'},\n",
              "   {'score': 0.05558559560522491, 'word': 'new'},\n",
              "   {'score': 0.05558559560522491, 'word': 'technique'},\n",
              "   {'score': 0.05384307363002003, 'word': 'lea'},\n",
              "   {'score': 0.05152236094351222, 'word': 'frame'}],\n",
              "  'Title': 'Lagrangian-Eulerian Advection for Unsteady Flow Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '644',\n",
              "  'parent': '3589'},\n",
              " {'Abstract': 'Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks',\n",
              "  'AuthorKeywords': ['Image',\n",
              "   'retrieval,',\n",
              "   'image',\n",
              "   'layout,',\n",
              "   'semantic',\n",
              "   'image',\n",
              "   'classification,multi-dimensional',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.12649517984641673, 'word': 'images'},\n",
              "   {'score': 0.10062636569253233, 'word': 'semantic'},\n",
              "   {'score': 0.06762317708308145, 'word': 'browsing'},\n",
              "   {'score': 0.05546547073621472, 'word': 'high'},\n",
              "   {'score': 0.05546547073621472, 'word': 'level'},\n",
              "   {'score': 0.05546547073621472, 'word': 'contents'},\n",
              "   {'score': 0.050219242421248624, 'word': 'annotation'},\n",
              "   {'score': 0.04516089495631761, 'word': 'image'},\n",
              "   {'score': 0.04516089495631761, 'word': 'analysis'},\n",
              "   {'score': 0.04516089495631761, 'word': 'techniques'}],\n",
              "  'Title': 'Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '645',\n",
              "  'parent': '5882'},\n",
              " {'Abstract': 'We present a visual exploration paradigm that facilitates navigation through complex fiber tracts by combining traditional 3D model viewing with lower dimensional representations. To this end, we create standard streamtube models along with two two-dimensional representations, an embedding in the plane and a hierarchical clustering tree, for a given set of fiber tracts. We then link these three representations using both interaction and color obtained by embedding fiber tracts into a perceptually uniform color space. We describe an anecdotal evaluation with neuroscientists to assess the usefulness of our method in exploring anatomical and functional structures in the brain. Expert feedback indicates that, while a standalone clinical use of the proposed method would require anatomical landmarks in the lower dimensional representations, the approach would be particularly useful in accelerating tract bundle selection. Results also suggest that combining traditional 3D model viewing with lower dimensional representations can ease navigation through the complex fiber tract models, improving exploration of the connectivity in the brain.',\n",
              "  'AuthorKeywords': ['DTI',\n",
              "   'fiber',\n",
              "   'tracts,',\n",
              "   'embedding,',\n",
              "   'coloring,',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.08726716517668658, 'word': 'lower'},\n",
              "   {'score': 0.08726716517668658, 'word': 'dimensional'},\n",
              "   {'score': 0.08726716517668658, 'word': 'representations'},\n",
              "   {'score': 0.07847182382400418, 'word': 'complex'},\n",
              "   {'score': 0.07847182382400418, 'word': 'fiber'},\n",
              "   {'score': 0.07847182382400418, 'word': 'tracts'},\n",
              "   {'score': 0.053407247991724104, 'word': 'navigation'},\n",
              "   {'score': 0.05231572935994286, 'word': 'usefulness'},\n",
              "   {'score': 0.04679108509891386, 'word': 'traditional'},\n",
              "   {'score': 0.04679108509891386, 'word': '3d'},\n",
              "   {'score': 0.04679108509891386, 'word': 'model'}],\n",
              "  'Title': 'Exploring 3D DTI fiber Tracts with Linked 2D Representations',\n",
              "  'distance': 0,\n",
              "  'no': '646',\n",
              "  'parent': '4434'},\n",
              " {'Abstract': 'Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.',\n",
              "  'AuthorKeywords': ['Pen',\n",
              "   'and',\n",
              "   'touch,',\n",
              "   'interaction,',\n",
              "   'Wizard',\n",
              "   'of',\n",
              "   'Oz,',\n",
              "   'whiteboard,',\n",
              "   'data',\n",
              "   'exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.09506145280116503, 'word': 'interaction'},\n",
              "   {'score': 0.08368227851113182, 'word': 'pen'},\n",
              "   {'score': 0.05279929081344738, 'word': 'touch'},\n",
              "   {'score': 0.049576323903008056, 'word': 'current'},\n",
              "   {'score': 0.049576323903008056, 'word': 'interfaces'},\n",
              "   {'score': 0.03911452789245837, 'word': 'visualizations'}],\n",
              "  'Title': 'Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards',\n",
              "  'distance': 0,\n",
              "  'no': '647',\n",
              "  'parent': '4747'},\n",
              " {'Abstract': \"Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.\",\n",
              "  'AuthorKeywords': ['Data',\n",
              "   'storytelling,',\n",
              "   'narrative',\n",
              "   'visualization,',\n",
              "   'narrative',\n",
              "   'structure'],\n",
              "  'MultipartiteRank': [{'score': 0.08402373852648115,\n",
              "    'word': 'visualizations'},\n",
              "   {'score': 0.058890313088420715, 'word': 'narrative'},\n",
              "   {'score': 0.04397208435640324, 'word': 'possible'},\n",
              "   {'score': 0.04397208435640324, 'word': 'transitions'},\n",
              "   {'score': 0.03594941437914085, 'word': 'sequence'},\n",
              "   {'score': 0.03527793018578394, 'word': 'approach'}],\n",
              "  'Title': 'A Deeper Understanding of Sequence in Narrative Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '648',\n",
              "  'parent': '5488'},\n",
              " {'Abstract': 'This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'mapping,',\n",
              "   'kernel',\n",
              "   'smoothing,',\n",
              "   'generalization,',\n",
              "   'multi-resolution',\n",
              "   'mapping,',\n",
              "   'graph',\n",
              "   'drawing,',\n",
              "   'spatial',\n",
              "   'data',\n",
              "   'mining'],\n",
              "  'MultipartiteRank': [{'score': 0.07717079026912929, 'word': 'massive'},\n",
              "   {'score': 0.07717079026912929, 'word': 'geographic'},\n",
              "   {'score': 0.07717079026912929, 'word': 'mobility'},\n",
              "   {'score': 0.07717079026912929, 'word': 'data'},\n",
              "   {'score': 0.0770257184751684, 'word': 'new'},\n",
              "   {'score': 0.0770257184751684, 'word': 'approach'},\n",
              "   {'score': 0.04329777371122094, 'word': 'mapping'},\n",
              "   {'score': 0.04234746325508978, 'word': 'flow'},\n",
              "   {'score': 0.04234746325508978, 'word': 'volume'},\n",
              "   {'score': 0.04181572754381145, 'word': 'inherent'},\n",
              "   {'score': 0.04181572754381145, 'word': 'patterns'}],\n",
              "  'Title': 'Origin-Destination Flow Data Smoothing and Mapping',\n",
              "  'distance': 0,\n",
              "  'no': '649',\n",
              "  'parent': '5888'},\n",
              " {'Abstract': 'We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.',\n",
              "  'AuthorKeywords': ['Temporal',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'multidimensional',\n",
              "   'scaling'],\n",
              "  'MultipartiteRank': [{'score': 0.08153171372156488, 'word': 'patterns'},\n",
              "   {'score': 0.06657761298804675, 'word': 'time'},\n",
              "   {'score': 0.06657761298804675, 'word': 'curves'},\n",
              "   {'score': 0.06379518079376974, 'word': 'temporal'},\n",
              "   {'score': 0.06379518079376974, 'word': 'data'},\n",
              "   {'score': 0.05251307810314883, 'word': 'range'},\n",
              "   {'score': 0.04330528938330516, 'word': 'evolution'}],\n",
              "  'Title': 'Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data',\n",
              "  'distance': 0,\n",
              "  'no': '650',\n",
              "  'parent': '3651'},\n",
              " {'Abstract': 'The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.',\n",
              "  'AuthorKeywords': ['optimal',\n",
              "   'billboard',\n",
              "   'locations;taxi',\n",
              "   'trajectory;visual',\n",
              "   'analytics;comparative',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.0819032265167814, 'word': 'solutions'},\n",
              "   {'score': 0.07791568365695489, 'word': 'visual'},\n",
              "   {'score': 0.07791568365695489, 'word': 'analytics'},\n",
              "   {'score': 0.036514557607917136, 'word': 'data'},\n",
              "   {'score': 0.03152739913990141, 'word': 'study'},\n",
              "   {'score': 0.029971501291360225, 'word': 'problem'}],\n",
              "  'Title': 'SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations',\n",
              "  'distance': 0,\n",
              "  'no': '651',\n",
              "  'parent': '4799'},\n",
              " {'Abstract': \"Many high-performance isosurface extraction algorithms have been proposed in the past several years as a result of intensive research efforts. When applying these algorithms to large-scale time-varying fields, the storage overhead incurred from storing the search index often becomes overwhelming. This paper proposes an algorithm for locating isosurface cells in time-varying fields. We devise a new data structure, called the temporal hierarchical index tree, which utilizes the temporal coherence that exists in a time-varying field and adaptively coalesces the cells' extreme values over time; the resulting extreme values are then used to create the isosurface cell search index. For a typical time-varying scalar data set, not only does this temporal hierarchical index tree require much less storage space, but also the amount of I/O required to access the indices from the disk at different time steps is substantially reduced. We illustrate the utility and speed of our algorithm with data from several large-scale time-varying CFD simulations. Our algorithm can achieve more than 80% of disk-space savings when compared with the existing techniques, while the isosurface extraction time is nearly optimal.\",\n",
              "  'AuthorKeywords': ['scalar',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'isosurface',\n",
              "   'extraction,',\n",
              "   'time-varying',\n",
              "   'fields,',\n",
              "   'marching',\n",
              "   'cubes,',\n",
              "   'span',\n",
              "   'space'],\n",
              "  'MultipartiteRank': [{'score': 0.10674645290660742, 'word': 'scale'},\n",
              "   {'score': 0.10674645290660742, 'word': 'time'},\n",
              "   {'score': 0.07343229313132962, 'word': 'algorithms'},\n",
              "   {'score': 0.054720756801343376, 'word': 'fields'},\n",
              "   {'score': 0.05092908431860641, 'word': 'large'},\n",
              "   {'score': 0.04584636249236867, 'word': 'new'},\n",
              "   {'score': 0.04584636249236867, 'word': 'data'},\n",
              "   {'score': 0.04584636249236867, 'word': 'structure'}],\n",
              "  'Title': 'Isosurface extraction in time-varying fields using a temporal hierarchical index tree',\n",
              "  'distance': 0,\n",
              "  'no': '652',\n",
              "  'parent': '4805'},\n",
              " {'Abstract': \"Distance fields are an important volume representation. A high quality distance field facilitates accurate surface characterization and gradient estimation. However, due to Nyquist's law, no existing volumetric methods based on the linear sampling theory can fully capture surface details, such as comers and edges, in 3D space. We propose a novel complete distance field representation (CDFR) that does not rely on Nyquist's sampling theory. To accomplish this, we construct a volume where each voxel has a complete description of all portions of surface that affect the local distance field. For any desired distance, we are able to extract a surface contour in true Euclidean distance, at any level of accuracy, from the same CDFR representation. Such point-based iso-distance contours have faithful per-point gradients and can be interactively visualized using splatting, providing per-point shaded image quality. We also demonstrate applying CDFR to a cutting edge design for manufacturing application involving high-complexity parts at unprecedented accuracy using only commonly available computational resources.\",\n",
              "  'AuthorKeywords': ['distance',\n",
              "   'fields,',\n",
              "   'volume',\n",
              "   'modeling,',\n",
              "   'polygonal',\n",
              "   'surfaces,',\n",
              "   'point-based',\n",
              "   'models,',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.18325651483830313, 'word': 'distance'},\n",
              "   {'score': 0.1445014350475059, 'word': 'fields'},\n",
              "   {'score': 0.07602159517052412, 'word': 'accurate'},\n",
              "   {'score': 0.07602159517052412, 'word': 'surface'},\n",
              "   {'score': 0.07602159517052412, 'word': 'characterization'},\n",
              "   {'score': 0.06679643131911359, 'word': 'important'},\n",
              "   {'score': 0.06679643131911359, 'word': 'volume'},\n",
              "   {'score': 0.06679643131911359, 'word': 'representation'},\n",
              "   {'score': 0.035285723535347105, 'word': 'nyquist'}],\n",
              "  'Title': 'A complete distance field representation',\n",
              "  'distance': 0,\n",
              "  'no': '653',\n",
              "  'parent': '3870'},\n",
              " {'Abstract': 'We propose unsteady flow advection-convolution (UFAC) as a novel visualization approach for unsteady flows. It performs time evolution governed by pathlines, but builds spatial correlation according to instantaneous streamlines whose spatial extent is controlled by the flow unsteadiness. UFAC is derived from a generic framework that provides spacetime-coherent dense representations of time dependent-vector fields by a two-step process: 1) construction of continuous trajectories in spacetime for temporal coherence; and 2) convolution along another set of paths through the above spacetime for spatially correlated patterns. Within the framework, known visualization techniques-such as Lagrangian-Eulerian advection, image-based flow visualization, unsteady flow LIC, and dynamic LIC-can be reproduced, often with better image quality, higher performance, or increased flexibility of the visualization style. Finally, we present a texture-based discretization of the framework and its interactive implementation on graphics hardware, which allows the user to gradually balance visualization speed against quality.',\n",
              "  'AuthorKeywords': ['time-dependent',\n",
              "   'vector',\n",
              "   'fields,',\n",
              "   'unsteady',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'LIC,',\n",
              "   'texture',\n",
              "   'advection,',\n",
              "   'hardware',\n",
              "   'acceleration'],\n",
              "  'MultipartiteRank': [{'score': 0.086488416482664, 'word': 'unsteady'},\n",
              "   {'score': 0.056607470363832256, 'word': 'advection'},\n",
              "   {'score': 0.047653904704744295, 'word': 'convolution'},\n",
              "   {'score': 0.04451961865541477, 'word': 'ufac'},\n",
              "   {'score': 0.04315056644692416, 'word': 'visualization'},\n",
              "   {'score': 0.04315056644692416, 'word': 'techniques'}],\n",
              "  'Title': 'A texture-based framework for spacetime-coherent visualization of time-dependent vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '654',\n",
              "  'parent': '4170'},\n",
              " {'Abstract': 'In this paper we offer several new insights and techniques for effectively using color and texture to simultaneously convey information about multiple 2D scalar and vector distributions, in a way that facilitates allowing each distribution to be understood both individually and in the context of one or more of the other distributions. Specifically, we introduce the concepts of: color weaving for simultaneously representing information about multiple co-located color encoded distributions; and texture stitching for achieving more spatially accurate multi-frequency line integral convolution representations of combined scalar and vector distributions. The target application for our research is the definition, detection and visualization of regions of interest in a turbulent boundary layer flow at moderate Reynolds number. In this work, we examine and analyze streamwise-spanwise planes of three-component velocity vectors with the goal of identifying and characterizing spatially organized packets of hairpin vortices.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'line',\n",
              "   'integral',\n",
              "   'convolution,',\n",
              "   'multi-variate',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'color,',\n",
              "   'texture'],\n",
              "  'MultipartiteRank': [{'score': 0.08855438293970452, 'word': 'vector'},\n",
              "   {'score': 0.08855438293970452, 'word': 'distributions'},\n",
              "   {'score': 0.06514802059992911, 'word': 'color'},\n",
              "   {'score': 0.058270746911129614, 'word': 'scalar'},\n",
              "   {'score': 0.04934357339888941, 'word': 'information'},\n",
              "   {'score': 0.047779857900201395, 'word': 'texture'}],\n",
              "  'Title': 'Effectively visualizing multi-valued flow data using color and texture',\n",
              "  'distance': 0,\n",
              "  'no': '655',\n",
              "  'parent': '3901'},\n",
              " {'Abstract': 'We derive piecewise linear and piecewise cubic box spline reconstruction filters for data sampled on the body centered cubic (BCC) lattice. We analytically derive a time domain representation of these reconstruction filters and using the Fourier slice-projection theorem we derive their frequency responses. The quality of these filters, when used in reconstructing BCC sampled volumetric data, is discussed and is demonstrated with a raycaster. Moreover, to demonstrate the superiority of the BCC sampling, the resulting reconstructions are compared with those produced from similar filters applied to data sampled on the Cartesian lattice.',\n",
              "  'AuthorKeywords': ['Body',\n",
              "   'Centered',\n",
              "   'Cubic',\n",
              "   'Lattice,',\n",
              "   'Reconstruction,',\n",
              "   'Optimal',\n",
              "   'Regular',\n",
              "   'Sampling'],\n",
              "  'MultipartiteRank': [{'score': 0.11602834902915496, 'word': 'bcc'},\n",
              "   {'score': 0.0988367246771088, 'word': 'reconstruction'},\n",
              "   {'score': 0.0988367246771088, 'word': 'filters'},\n",
              "   {'score': 0.09247764101948144, 'word': 'data'},\n",
              "   {'score': 0.07044811281354446, 'word': 'lattice'},\n",
              "   {'score': 0.058620673452833415, 'word': 'cubic'}],\n",
              "  'Title': 'Linear and cubic box splines for the body centered cubic lattice',\n",
              "  'distance': 0,\n",
              "  'no': '656',\n",
              "  'parent': '3893'},\n",
              " {'Abstract': 'Quantitative techniques for visualization are critical to the successful analysis of both acquired and simulated scientific data. Many visualization techniques rely on indirect mappings, such as transfer functions, to produce the final imagery. In many situations, it is preferable and more powerful to express these mappings as mathematical expressions, or queries, that can then be directly applied to the data. We present a hardware-accelerated system that provides such capabilities and exploits current graphics hardware for portions of the computational tasks that would otherwise be executed on the CPU. In our approach, the direct programming of the graphics processor using a concise data parallel language, gives scientists the capability to efficiently explore and visualize data sets.',\n",
              "  'AuthorKeywords': ['Visualization',\n",
              "   'systems,',\n",
              "   'hardware',\n",
              "   'acceleration,',\n",
              "   'multi-variate',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.09002401073094456, 'word': 'visualization'},\n",
              "   {'score': 0.07021483749302775, 'word': 'scientific'},\n",
              "   {'score': 0.07021483749302775, 'word': 'data'},\n",
              "   {'score': 0.059389788781277625, 'word': 'indirect'},\n",
              "   {'score': 0.059389788781277625, 'word': 'mappings'},\n",
              "   {'score': 0.04987036357143721, 'word': 'critical'},\n",
              "   {'score': 0.045737775453072206, 'word': 'hardware'}],\n",
              "  'Title': 'Scout: a hardware-accelerated system for quantitatively driven visualization and analysis',\n",
              "  'distance': 0,\n",
              "  'no': '657',\n",
              "  'parent': '3748'},\n",
              " {'Abstract': 'People in different places talk about different things. This interest distribution is reflected by the newspaper articles circulated in a particular area. We use data from our large-scale newspaper analysis system (Lydia) to make entity datamaps, a spatial visualization of the interest in a given named entity. Our goal is to identify entities which display regional biases. We develop a model of estimating the frequency of reference of an entity in any given city from the reference frequency centered in surrounding cities, and techniques for evaluating the spatial significance of this distribution',\n",
              "  'AuthorKeywords': ['GIS,',\n",
              "   'geographic',\n",
              "   'visualization,',\n",
              "   'text',\n",
              "   'and',\n",
              "   'document',\n",
              "   'visualization,',\n",
              "   'information',\n",
              "   'analytics,',\n",
              "   'WWW',\n",
              "   'data',\n",
              "   'visualization,',\n",
              "   'spidering,',\n",
              "   'newspapers'],\n",
              "  'MultipartiteRank': [{'score': 0.1698313720316682, 'word': 'entity'},\n",
              "   {'score': 0.10314308461107273, 'word': 'datamaps'},\n",
              "   {'score': 0.06225721703753176, 'word': 'spatial'},\n",
              "   {'score': 0.06225721703753176, 'word': 'visualization'},\n",
              "   {'score': 0.06212059545727772, 'word': 'different'},\n",
              "   {'score': 0.06212059545727772, 'word': 'places'},\n",
              "   {'score': 0.050345927186706566, 'word': 'scale'},\n",
              "   {'score': 0.050345927186706566, 'word': 'newspaper'},\n",
              "   {'score': 0.050345927186706566, 'word': 'analysis'},\n",
              "   {'score': 0.050345927186706566, 'word': 'system'}],\n",
              "  'Title': 'Spatial Analysis of News Sources',\n",
              "  'distance': 0,\n",
              "  'no': '658',\n",
              "  'parent': '3924'},\n",
              " {'Abstract': \"This paper presents an interactive visualization system, named WebSearchViz, for visualizing the Web search results and facilitating users' navigation and exploration. The metaphor in our model is the solar system with its planets and asteroids revolving around the sun. Location, color, movement, and spatial distance of objects in the visual space are used to represent the semantic relationships between a query and relevant Web pages. Especially, the movement of objects and their speeds add a new dimension to the visual space, illustrating the degree of relevance among a query and Web search results in the context of users' subjects of interest. By interacting with the visual space, users are able to observe the semantic relevance between a query and a resulting Web page with respect to their subjects of interest, context information, or concern. Users' subjects of interest can be dynamically changed, redefined, added, or deleted from the visual space\",\n",
              "  'AuthorKeywords': ['Visualization',\n",
              "   'model,',\n",
              "   'Web',\n",
              "   'search',\n",
              "   'results,',\n",
              "   'movement,',\n",
              "   'speed'],\n",
              "  'MultipartiteRank': [{'score': 0.07022777593043175, 'word': 'users'},\n",
              "   {'score': 0.056364410156647865, 'word': 'visual'},\n",
              "   {'score': 0.056364410156647865, 'word': 'space'},\n",
              "   {'score': 0.055404511490613643, 'word': 'query'},\n",
              "   {'score': 0.04929073843646814, 'word': 'subjects'},\n",
              "   {'score': 0.04543672494479458, 'word': 'interest'}],\n",
              "  'Title': 'A Novel Visualization Model for Web Search Results',\n",
              "  'distance': 0,\n",
              "  'no': '659',\n",
              "  'parent': '4424'},\n",
              " {'Abstract': 'Most streamline generation algorithms either provide a particular density of streamlines across the domain or explicitly detect features, such as critical points, and follow customized rules to emphasize those features. However, the former generally includes many redundant streamlines, and the latter requires Boolean decisions on which points are features (and may thus suffer from robustness problems for real-world data). We take a new approach to adaptive streamline placement for steady vector fields in 2D and 3D. We define a metric for local similarity among streamlines and use this metric to grow streamlines from a dense set of candidate seed points. The metric considers not only Euclidean distance, but also a simple statistical measure of shape and directional similarity. Without explicit feature detection, our method produces streamlines that naturally accentuate regions of geometric interest. In conjunction with this method, we also propose a quantitative error metric for evaluating a streamline representation based on how well it preserves the information from the original vector field. This error metric reconstructs a vector field from points on the streamline representation and computes a difference of the reconstruction from the original vector field.',\n",
              "  'AuthorKeywords': ['Adaptive',\n",
              "   'streamlines,',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'reconstruction,',\n",
              "   'shape',\n",
              "   'matching'],\n",
              "  'MultipartiteRank': [{'score': 0.11954958522347835, 'word': 'streamlines'},\n",
              "   {'score': 0.06745013516128723, 'word': 'metric'},\n",
              "   {'score': 0.06378236359366156, 'word': 'features'},\n",
              "   {'score': 0.062211822444206755, 'word': 'critical'},\n",
              "   {'score': 0.062211822444206755, 'word': 'points'},\n",
              "   {'score': 0.042962185262179826, 'word': 'steady'},\n",
              "   {'score': 0.042962185262179826, 'word': 'vector'},\n",
              "   {'score': 0.042962185262179826, 'word': 'fields'}],\n",
              "  'Title': 'Similarity-Guided Streamline Placement with Error Evaluation',\n",
              "  'distance': 0,\n",
              "  'no': '660',\n",
              "  'parent': '5203'},\n",
              " {'Abstract': 'Hierarchical representations are common in digital repositories, yet are not always fully leveraged in their online search interfaces. This work describes ResultMaps, which use hierarchical treemap representations with query string-driven digital library search engines. We describe two lab experiments, which find that ResultsMap users yield significantly better results over a control condition on some subjective measures, and we find evidence that ResultMaps have ancillary benefits via increased understanding of some aspects of repository content. The ResultMap system and experiments contribute an understanding of the benefits-direct and indirect-of the ResultMap approach to repository search visualization.',\n",
              "  'AuthorKeywords': ['Treemap,',\n",
              "   'evaluation,',\n",
              "   'user',\n",
              "   'studies,',\n",
              "   'digital',\n",
              "   'library,',\n",
              "   'digital',\n",
              "   'repository,',\n",
              "   'search',\n",
              "   'engine,',\n",
              "   'search',\n",
              "   'visualization,',\n",
              "   'infovis'],\n",
              "  'MultipartiteRank': [{'score': 0.10620489863795905, 'word': 'hierarchical'},\n",
              "   {'score': 0.10620489863795905, 'word': 'representations'},\n",
              "   {'score': 0.09517578299456225, 'word': 'resultmaps'},\n",
              "   {'score': 0.07378154159117783, 'word': 'digital'},\n",
              "   {'score': 0.07378154159117783, 'word': 'repositories'},\n",
              "   {'score': 0.06706378517017698, 'word': 'common'},\n",
              "   {'score': 0.05123265742718264, 'word': 'ancillary'},\n",
              "   {'score': 0.05123265742718264, 'word': 'benefits'}],\n",
              "  'Title': 'ResultMaps: Visualization for Search Interfaces',\n",
              "  'distance': 0,\n",
              "  'no': '661',\n",
              "  'parent': '3721'},\n",
              " {'Abstract': \"Visual analytics tools provide powerful visual representations in order to support the sense-making process. In this process, analysts typically iterate through sequences of steps many times, varying parameters each time. Few visual analytics tools support this process well, nor do they provide support for visualizing and understanding the analysis process itself. To help analysts understand, explore, reference, and reuse their analysis process, we present a visual analytics system named CzSaw (See-Saw) that provides an editable and re-playable history navigation channel in addition to multiple visual representations of document collections and the entities within them (in a manner inspired by Jigsaw). Conventional history navigation tools range from basic undo and redo to branching timelines of user actions. In CzSaw's approach to this, first, user interactions are translated into a script language that drives the underlying scripting-driven propagation system. The latter allows analysts to edit analysis steps, and ultimately to program them. Second, on this base, we build both a history view showing progress and alternative paths, and a dependency graph showing the underlying logic of the analysis and dependency relations among the results of each step. These tools result in a visual model of the sense-making process, providing a way for analysts to visualize their analysis process, to reinterpret the problem, explore alternative paths, extract analysis patterns from existing history, and reuse them with other related analyses.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Sense-making,',\n",
              "   'Analysis',\n",
              "   'Process,',\n",
              "   'Visual',\n",
              "   'History'],\n",
              "  'MultipartiteRank': [{'score': 0.08359062146991461, 'word': 'visual'},\n",
              "   {'score': 0.07071981355288, 'word': 'process'},\n",
              "   {'score': 0.052060485473646, 'word': 'analysts'},\n",
              "   {'score': 0.04350908119777313, 'word': 'analytics'},\n",
              "   {'score': 0.04350908119777313, 'word': 'tools'},\n",
              "   {'score': 0.04008154027214148, 'word': 'powerful'},\n",
              "   {'score': 0.04008154027214148, 'word': 'representations'},\n",
              "   {'score': 0.030697124382565413, 'word': 'sense'}],\n",
              "  'Title': 'Capturing and supporting the analysis process',\n",
              "  'distance': 0,\n",
              "  'no': '662',\n",
              "  'parent': '4584'},\n",
              " {'Abstract': 'High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.',\n",
              "  'AuthorKeywords': ['Particle',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'ray-casting,',\n",
              "   'GPU',\n",
              "   'resampling'],\n",
              "  'MultipartiteRank': [{'score': 0.08853334607564801, 'word': 'particle'},\n",
              "   {'score': 0.08853334607564801, 'word': 'quantities'},\n",
              "   {'score': 0.06492331803571165, 'word': 'view'},\n",
              "   {'score': 0.06492331803571165, 'word': 'rays'},\n",
              "   {'score': 0.061471003775153424, 'word': 'dependent'},\n",
              "   {'score': 0.061471003775153424, 'word': 'resampling'},\n",
              "   {'score': 0.05011010523530589, 'word': 'high'},\n",
              "   {'score': 0.05011010523530589, 'word': 'quality'},\n",
              "   {'score': 0.05011010523530589, 'word': 'volume'},\n",
              "   {'score': 0.04998515330492978, 'word': 'uniform'},\n",
              "   {'score': 0.04998515330492978, 'word': 'grids'}],\n",
              "  'Title': 'Efficient High-Quality Volume Rendering of SPH Data',\n",
              "  'distance': 0,\n",
              "  'no': '663',\n",
              "  'parent': '4065'},\n",
              " {'Abstract': \"Although direct volume rendering is established as a powerful tool for the visualization of volumetric data, efficient and reliable feature detection is still an open topic. Usually, a tradeoff between fast but imprecise classification schemes and accurate but time-consuming segmentation techniques has to be made. Furthermore, the issue of uncertainty introduced with the feature detection process is completely neglected by the majority of existing approaches.In this paper we propose a guided probabilistic volume segmentation approach that focuses on the minimization of uncertainty. In an iterative process, our system continuously assesses uncertainty of a random walker-based segmentation in order to detect regions with high ambiguity, to which the user's attention is directed to support the correction of potential misclassifications. This reduces the risk of critical segmentation errors and ensures that information about the segmentation's reliability is conveyed to the user in a dependable way. In order to improve the efficiency of the segmentation process, our technique does not only take into account the volume data to be segmented, but also enables the user to incorporate classification information. An interactive workflow has been achieved by implementing the presented system on the GPU using the OpenCL API. Our results obtained for several medical data sets of different modalities, including brain MRI and abdominal CT, demonstrate the reliability and efficiency of our approach.\",\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'segmentation,',\n",
              "   'uncertainty,',\n",
              "   'classification,',\n",
              "   'random',\n",
              "   'walker'],\n",
              "  'MultipartiteRank': [{'score': 0.055653116986742655, 'word': 'segmentation'},\n",
              "   {'score': 0.044600909233284525, 'word': 'efficient'},\n",
              "   {'score': 0.04230071999167206, 'word': 'uncertainty'},\n",
              "   {'score': 0.03721560029067734, 'word': 'user'},\n",
              "   {'score': 0.03180688662571226, 'word': 'volumetric'},\n",
              "   {'score': 0.03180688662571226, 'word': 'data'}],\n",
              "  'Title': 'Uncertainty-Aware Guided Volume Segmentation',\n",
              "  'distance': 0,\n",
              "  'no': '664',\n",
              "  'parent': '5166'},\n",
              " {'Abstract': 'In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.',\n",
              "  'AuthorKeywords': ['Sparse',\n",
              "   'Traffic',\n",
              "   'Trajectory,',\n",
              "   'Traffic',\n",
              "   'Visualization,',\n",
              "   'Dynamic',\n",
              "   'Graph',\n",
              "   'Visualization,',\n",
              "   'Traffic',\n",
              "   'Congestion'],\n",
              "  'MultipartiteRank': [{'score': 0.09152717211049359,\n",
              "    'word': 'transportation'},\n",
              "   {'score': 0.09152717211049359, 'word': 'cells'},\n",
              "   {'score': 0.090687833618638, 'word': 'sparse'},\n",
              "   {'score': 0.090687833618638, 'word': 'traffic'},\n",
              "   {'score': 0.06038271084713721, 'word': 'movements'},\n",
              "   {'score': 0.05643644440157298, 'word': 'data'},\n",
              "   {'score': 0.048497994858991096, 'word': 'visual'},\n",
              "   {'score': 0.048497994858991096, 'word': 'analysis'},\n",
              "   {'score': 0.048497994858991096, 'word': 'system'}],\n",
              "  'Title': 'Visual Exploration of Sparse Traffic Trajectory Data',\n",
              "  'distance': 0,\n",
              "  'no': '665',\n",
              "  'parent': '4541'},\n",
              " {'Abstract': 'The authors present a ray-tracing algorithm for volume rendering designed to work efficiently when the data of interest is distributed sparsely through the volume. A simple preprocessing step identifies the voxels representing features of interest. Frequently this set of voxels, arbitrarily distributed in three-dimensional space, is a small fraction of the original voxel grid. A median-cut space partitioning scheme, combined with bounding volumes to prune void spaces in the resulting search structure, is used to store the voxels of interest in a k-d tree. The k-d tree is used as a data structure. The tree is then efficiently ray-traced to render the voxel data. The k-d tree is view independent, and can be used for animation sequences involving changes in positions of the viewer or positions of lights. This search structure has been applied to render voxel data from MRI, CAT scan, and electron density distributions.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11163956528240415, 'word': 'voxels'},\n",
              "   {'score': 0.07595519507918731, 'word': 'interest'},\n",
              "   {'score': 0.07002279984448304, 'word': 'volume'},\n",
              "   {'score': 0.07002279984448304, 'word': 'rendering'},\n",
              "   {'score': 0.043459786651045294, 'word': 'ray'},\n",
              "   {'score': 0.04295782605351417, 'word': 'data'}],\n",
              "  'Title': 'Applying space subdivision techniques to volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '666',\n",
              "  'parent': '4261'},\n",
              " {'Abstract': 'We present a new visualization technique, called RDT (Reconfigurable Disc Tree) which can alleviate the disadvantages of cone trees significantly for large hierarchies while maintaining its context of using 3D depth. In RDT, each node is associated with a disc, around which its children are placed. Using discs instead of cones as the basic shape in RDT has several advantages: significant reduction of occluded region, sharp increase in number of displayed nodes, and easy projection onto plane without visual overlapping. We show that RDT can greatly enhance user perception by transforming its shapes dynamically in several ways: (1) disc tree which can significantly reduce the occluded region by the foreground objects; (2) compact disc tree which can increase the number of nodes displayed on the screen; and (3) plane disc tree which can be mapped onto the plane without visual overlapping. We describe an implementation of our visualization system called VISIT (Visual Information System for reconfigurable dIsc tree). It provides 2D and 3D layouts for RDT and various user interface features such as tree reconfiguration, tree transformation, tree shading, viewing transformation, animation, selection and browsing which can enhance the user perception and navigation capabilities. We also evaluate our system using the following three metrics: percentage of occlusion, density of displayed nodes on a screen, and number of identifiable nodes.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'disc',\n",
              "   'tree,compact',\n",
              "   'disc',\n",
              "   'tree,',\n",
              "   'plane',\n",
              "   'disc',\n",
              "   'tree,',\n",
              "   'hierarchy'],\n",
              "  'MultipartiteRank': [{'score': 0.07378627214603732,\n",
              "    'word': 'reconfigurable'},\n",
              "   {'score': 0.07378627214603732, 'word': 'disc'},\n",
              "   {'score': 0.07378627214603732, 'word': 'tree'},\n",
              "   {'score': 0.06674692785728802, 'word': 'rdt'},\n",
              "   {'score': 0.05187102427911896, 'word': 'node'},\n",
              "   {'score': 0.040050004010920216, 'word': 'visualization'},\n",
              "   {'score': 0.040050004010920216, 'word': 'system'},\n",
              "   {'score': 0.03535616448060781, 'word': 'number'}],\n",
              "  'Title': 'Reconfigurable disc trees for visualizing large hierarchical information space',\n",
              "  'distance': 0,\n",
              "  'no': '667',\n",
              "  'parent': '5810'},\n",
              " {'Abstract': 'A recent line of treemap research has focused on layout algorithms that optimize properties such as stability, preservation of ordering information, and aspect ratio of rectangles. No ideal treemap layout algorithm has been found, and so it is natural to explore layouts that produce nonrectangular regions. This note describes a connection between space-filling visualizations and the mathematics of space-filling curves, and uses that connection to characterize a family of layout algorithms which produce nonrectangular regions but enjoy geometric continuity under changes to the data and legibility even for highly unbalanced trees.',\n",
              "  'AuthorKeywords': ['Hierarchy', 'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.10939667238196717, 'word': 'layout'},\n",
              "   {'score': 0.10939667238196717, 'word': 'algorithms'},\n",
              "   {'score': 0.0693942911374833, 'word': 'space'},\n",
              "   {'score': 0.06890820243477298, 'word': 'nonrectangular'},\n",
              "   {'score': 0.06890820243477298, 'word': 'regions'},\n",
              "   {'score': 0.06568585494698298, 'word': 'connection'},\n",
              "   {'score': 0.04219654379675725, 'word': 'family'}],\n",
              "  'Title': 'A note on space-filling visualizations and space-filling curves',\n",
              "  'distance': 0,\n",
              "  'no': '668',\n",
              "  'parent': '3645'},\n",
              " {'Abstract': \"Extensive spread of malicious code on the Internet and also within intranets has risen the user's concern about what kind of data is transferred between her or his computer and other hosts on the network. Visual analysis of this kind of information is a challenging task, due to the complexity and volume of the data type considered, and requires special design of appropriate visualization techniques. In this paper, we present a scalable visualization toolkit for analyzing network activity of computer hosts on a network. The visualization combines network packet volume and type distribution information with geographic information, enabling the analyst to use geographic distortion techniques such as the HistoMap technique to become aware of the traffic components in the course of the analysis. The presented analysis tool is especially useful to compare important network load characteristics in a geographically aware display, to relate communication partners, and to identify the type of network traffic occurring. The results of the analysis are helpful in understanding typical network communication activities, and in anticipating potential performance bottlenecks or problems. It is suited for both off-line analysis of historic data, and via animation for on-line monitoring of packet-based network traffic in real time\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Network',\n",
              "   'Traffic',\n",
              "   'Monitoring,',\n",
              "   'Information',\n",
              "   'Visualization',\n",
              "   'and',\n",
              "   'Geography-based',\n",
              "   'Solutions'],\n",
              "  'MultipartiteRank': [{'score': 0.0778862885846472, 'word': 'network'},\n",
              "   {'score': 0.06498648686068953, 'word': 'visual'},\n",
              "   {'score': 0.06498648686068953, 'word': 'analysis'},\n",
              "   {'score': 0.05019172922641812, 'word': 'kind'},\n",
              "   {'score': 0.043629580546659774, 'word': 'data'},\n",
              "   {'score': 0.038021478642559496, 'word': 'information'}],\n",
              "  'Title': 'Monitoring Network Traffic with Radial Traffic Analyzer',\n",
              "  'distance': 0,\n",
              "  'no': '669',\n",
              "  'parent': '4491'},\n",
              " {'Abstract': \"Parallel coordinate plots (PCPs) are commonly used in information visualization to provide insight into multi-variate data. These plots help to spot correlations between variables. PCPs have been successfully applied to unstructured datasets up to a few millions of points. In this paper, we present techniques to enhance the usability of PCPs for the exploration of large, multi-timepoint volumetric data sets, containing tens of millions of points per timestep. The main difficulties that arise when applying PCPs to large numbers of data points are visual clutter and slow performance, making interactive exploration infeasible. Moreover, the spatial context of the volumetric data is usually lost. We describe techniques for preprocessing using data quantization and compression, and for fast GPU-based rendering of PCPs using joint density distributions for each pair of consecutive variables, resulting in a smooth, continuous visualization. Also, fast brushing techniques are proposed for interactive data selection in multiple linked views, including a 3D spatial volume view. These techniques have been successfully applied to three large data sets: Hurricane Isabel (Vis'04 contest), the ionization front instability data set (Vis'08 design contest), and data from a large-eddy simulation of cumulus clouds. With these data, we show how PCPs can be extended to successfully visualize and interactively explore multi-timepoint volumetric datasets with an order of magnitude more data points.\",\n",
              "  'AuthorKeywords': ['Parallel',\n",
              "   'coordinate',\n",
              "   'plots,',\n",
              "   'time-varying,',\n",
              "   'multi-field,',\n",
              "   'linked',\n",
              "   'related',\n",
              "   'views'],\n",
              "  'MultipartiteRank': [{'score': 0.08714411922955374, 'word': 'pcps'},\n",
              "   {'score': 0.06598692020978143, 'word': 'data'},\n",
              "   {'score': 0.06598692020978143, 'word': 'points'},\n",
              "   {'score': 0.04863094897145759, 'word': 'information'},\n",
              "   {'score': 0.04863094897145759, 'word': 'visualization'},\n",
              "   {'score': 0.04782547364085556, 'word': 'large'},\n",
              "   {'score': 0.04503832969017286, 'word': 'parallel'},\n",
              "   {'score': 0.04503832969017286, 'word': 'coordinate'},\n",
              "   {'score': 0.04503832969017286, 'word': 'plots'}],\n",
              "  'Title': 'Extensions of Parallel Coordinates for Interactive Exploration of Large Multi-Timepoint Data Sets',\n",
              "  'distance': 0,\n",
              "  'no': '670',\n",
              "  'parent': '5353'},\n",
              " {'Abstract': 'The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.',\n",
              "  'AuthorKeywords': ['Spatio-temporal',\n",
              "   'visualization,',\n",
              "   'proximity,',\n",
              "   'linked',\n",
              "   'views,',\n",
              "   'principal',\n",
              "   'component',\n",
              "   'analysis,',\n",
              "   'temporal',\n",
              "   'trajectories,',\n",
              "   'movement',\n",
              "   'patterns'],\n",
              "  'MultipartiteRank': [{'score': 0.06911491477431947, 'word': 'spaces'},\n",
              "   {'score': 0.05762910280023741, 'word': 'visualization'},\n",
              "   {'score': 0.044229479881816115, 'word': 'movement'},\n",
              "   {'score': 0.044229479881816115, 'word': 'traces'},\n",
              "   {'score': 0.042991556328382724, 'word': 'proximity'},\n",
              "   {'score': 0.031889205241402346, 'word': 'motion'},\n",
              "   {'score': 0.031889205241402346, 'word': 'patterns'}],\n",
              "  'Title': 'Proximity-based visualization of movement trace data',\n",
              "  'distance': 0,\n",
              "  'no': '671',\n",
              "  'parent': '5255'},\n",
              " {'Abstract': 'DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06501726969042228, 'word': 'data'},\n",
              "   {'score': 0.06501726969042228, 'word': 'tables'},\n",
              "   {'score': 0.06451374459047171, 'word': 'expressions'},\n",
              "   {'score': 0.06395658112293236, 'word': 'analysis'},\n",
              "   {'score': 0.0534606234718098, 'word': 'users'},\n",
              "   {'score': 0.05218312496015058, 'word': 'operators'}],\n",
              "  'Title': 'DimStiller: Workflows for dimensional analysis and reduction',\n",
              "  'distance': 0,\n",
              "  'no': '672',\n",
              "  'parent': '3467'},\n",
              " {'Abstract': \"Web clickstream data are routinely collected to study how users browse the web or use a service. It is clear that the ability to recognize and summarize user behavior patterns from such data is valuable to e-commerce companies. In this paper, we introduce a visual analytics system to explore the various user behavior patterns reflected by distinct clickstream clusters. In a practical analysis scenario, the system first presents an overview of clickstream clusters using a Self-Organizing Map with Markov chain models. Then the analyst can interactively explore the clusters through an intuitive user interface. He can either obtain summarization of a selected group of data or further refine the clustering result. We evaluated our system using two different datasets from eBay. Analysts who were working on the same data have confirmed the system's effectiveness in extracting user behavior patterns from complex datasets and enhancing their ability to reason.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1297066156798977, 'word': 'clickstream'},\n",
              "   {'score': 0.12537580824811698, 'word': 'system'},\n",
              "   {'score': 0.07466398073115099, 'word': 'visual'},\n",
              "   {'score': 0.07466398073115099, 'word': 'analytics'},\n",
              "   {'score': 0.07233017139218265, 'word': 'distinct'},\n",
              "   {'score': 0.07233017139218265, 'word': 'clusters'},\n",
              "   {'score': 0.0720095981037433, 'word': 'user'},\n",
              "   {'score': 0.0720095981037433, 'word': 'behavior'},\n",
              "   {'score': 0.0720095981037433, 'word': 'patterns'},\n",
              "   {'score': 0.05737644428771505, 'word': 'web'},\n",
              "   {'score': 0.05737644428771505, 'word': 'data'}],\n",
              "  'Title': 'Visual cluster exploration of web clickstream data',\n",
              "  'distance': 0,\n",
              "  'no': '673',\n",
              "  'parent': '4515'},\n",
              " {'Abstract': \"We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to “simplify without destroying” by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER\",\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'Interaction,',\n",
              "   'Tabular',\n",
              "   'Data,',\n",
              "   'Bertin,',\n",
              "   'Crossing,',\n",
              "   'Crossets'],\n",
              "  'MultipartiteRank': [{'score': 0.11758110796506846, 'word': 'method'},\n",
              "   {'score': 0.07419199194515928, 'word': 'matrix'},\n",
              "   {'score': 0.07419199194515928, 'word': 'analysis'},\n",
              "   {'score': 0.07047734175863941, 'word': 'bertifier'},\n",
              "   {'score': 0.0626485936315892, 'word': 'jacques'},\n",
              "   {'score': 0.0626485936315892, 'word': 'bertin'},\n",
              "   {'score': 0.0433890923445662, 'word': 'computers'}],\n",
              "  'Title': 'Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '674',\n",
              "  'parent': '3711'},\n",
              " {'Abstract': 'Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).',\n",
              "  'AuthorKeywords': ['Topic',\n",
              "   'coopetition,',\n",
              "   'information',\n",
              "   'diffusion,',\n",
              "   'information',\n",
              "   'propagation,',\n",
              "   'time-based',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.11123050535542156, 'word': 'concurrent'},\n",
              "   {'score': 0.11123050535542156, 'word': 'topics'},\n",
              "   {'score': 0.09893099403433592, 'word': 'coopetition'},\n",
              "   {'score': 0.07693997382175283, 'word': 'interactions'},\n",
              "   {'score': 0.0550117404735807, 'word': 'social'},\n",
              "   {'score': 0.0550117404735807, 'word': 'media'},\n",
              "   {'score': 0.05278934383145995, 'word': 'set'}],\n",
              "  'Title': 'EvoRiver: Visual Analysis of Topic Coopetition on Social Media',\n",
              "  'distance': 0,\n",
              "  'no': '675',\n",
              "  'parent': '4157'},\n",
              " {'Abstract': 'Information visualization focuses on the use of visual means for exploring non-visual information. While free-form text is a rich, common source of information, visualization of text is a challenging problem since text is inherently non-spatial. The paper explores the use of implicit surface models for visualizing text. The authors describe several techniques for text visualization that aid in understanding document content and document relationships. A simple method is defined for mapping document content to shape. By comparing the shapes of multiple documents, global content similarities and differences may be noted. In addition, they describe a visual clustering method in which documents are arranged in 3D based upon similarity scoring. Documents deemed closely related blend together as a single connected shape. Hence, a document corpus becomes a collection of shapes that reflect inter-document relationships. These techniques provide methods to visualize individual documents as well as corpus meta-data. They then combine the two techniques to produce transparent clusters enclosing individual document shapes. This provides a way to visualize both local and global contextual information. Finally, they elaborate on several potential applications of these methods.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'text',\n",
              "   'visualization,',\n",
              "   'procedural',\n",
              "   'visualization,',\n",
              "   'implicit',\n",
              "   'surface',\n",
              "   'modeling,',\n",
              "   'blobby',\n",
              "   'models,',\n",
              "   'document',\n",
              "   'clustering,',\n",
              "   'information',\n",
              "   'retrieval,',\n",
              "   'graphics,',\n",
              "   'user',\n",
              "   'interfaces'],\n",
              "  'MultipartiteRank': [{'score': 0.08242678045904675, 'word': 'document'},\n",
              "   {'score': 0.08242678045904675, 'word': 'content'},\n",
              "   {'score': 0.0755836804342299, 'word': 'information'},\n",
              "   {'score': 0.0755836804342299, 'word': 'visualization'},\n",
              "   {'score': 0.06606423671280945, 'word': 'visual'},\n",
              "   {'score': 0.06606423671280945, 'word': 'means'},\n",
              "   {'score': 0.06389364131187511, 'word': 'form'},\n",
              "   {'score': 0.06389364131187511, 'word': 'text'},\n",
              "   {'score': 0.048322402817456055, 'word': 'use'}],\n",
              "  'Title': 'The shape of Shakespeare: visualizing text using implicit surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '676',\n",
              "  'parent': '4942'},\n",
              " {'Abstract': 'A novel approach is introduced to define a quantitative measure of closeness between vector fields. The usefulness of this measurement can be seen when comparing computational and experimental flow fields under the same conditions. Furthermore, its applicability can be extended to more cumbersome tasks, such as navigating through a large database, searching for similar topologies. This new measure relies on the use of critical points, which are a key feature in vector field topology. In order to characterize critical points, /spl alpha/ and /spl beta/ parameters are introduced. They are used to form a closed set of eight unique patterns for simple critical points. These patterns are also basic building blocks for higher-order nonlinear vector fields. In order to study and compare a given set of vector fields, a measure of distance between different patterns of critical points is introduced. The basic patterns of critical points are mapped onto a unit circle in /spl alpha/-/spl beta/ space. The concept of the \"Earth mover\\'s distance\" is used to compute the closeness between various pairs of vector fields, and a nearest-neighbor query is thus produced to illustrate the relationship between the given set of vector fields. This approach quantitatively measures the similarity and dissimilarity between vector fields. It is ideal for data compression of a large flow field, since only the number and types of critical points along with their corresponding /spl alpha/ and /spl beta/ parameters are necessary to reconstruct the whole field. It can also be used to better quantify the changes in time-varying data sets.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09587509779845982, 'word': 'vector'},\n",
              "   {'score': 0.09587509779845982, 'word': 'fields'},\n",
              "   {'score': 0.06610249023788146, 'word': 'critical'},\n",
              "   {'score': 0.06610249023788146, 'word': 'points'},\n",
              "   {'score': 0.05693613473751546, 'word': 'quantitative'},\n",
              "   {'score': 0.05693613473751546, 'word': 'measure'},\n",
              "   {'score': 0.0508032176875754, 'word': 'closeness'},\n",
              "   {'score': 0.04543417515253461, 'word': 'unique'},\n",
              "   {'score': 0.04543417515253461, 'word': 'patterns'}],\n",
              "  'Title': \"Feature comparisons of vector fields using Earth mover's distance\",\n",
              "  'distance': 0,\n",
              "  'no': '677',\n",
              "  'parent': '5912'},\n",
              " {'Abstract': 'Splatting is a fast volume rendering algorithm which achieves its speed by projecting voxels in the form of pre-integrated interpolation kernels, or splats. Presently, two main variants of the splatting algorithm exist: (i) the original method, in which all splats are composited back-to-front, and (ii) the sheet-buffer method, in which the splats are added in cache-sheets, aligned with the volume face most parallel to the image plane, which are subsequently composited back-to-front. The former method is prone to cause bleeding artifacts from hidden objects, while the latter method reduces bleeding, but causes very visible color popping artifacts when the orientation of the compositing sheets changes suddenly as the image screen becomes more parallel to another volume face. We present a new variant of the splatting algorithm in which the compositing sheets are always parallel to the image plane, eliminating the condition for popping, while maintaining the insensitivity to color bleeding. This enables pleasing animated viewing of volumetric objects without temporal color and lighting discontinuities. The method uses a hierarchy of partial splats and employs an efficient list-based volume traversal scheme for fast splat access. It also offers more accuracy for perspective splatting as the decomposition of the individual splats facilitates a better approximation to the diverging nature of the rays that traverse the splatting kernels.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12482497376725185, 'word': 'splatting'},\n",
              "   {'score': 0.061589377550468255, 'word': 'algorithm'},\n",
              "   {'score': 0.06017428492078652, 'word': 'fast'},\n",
              "   {'score': 0.06017428492078652, 'word': 'volume'},\n",
              "   {'score': 0.06011836322825162, 'word': 'original'},\n",
              "   {'score': 0.06011836322825162, 'word': 'method'},\n",
              "   {'score': 0.04918765731114947, 'word': 'sheet'}],\n",
              "  'Title': 'Eliminating popping artifacts in sheet buffer-based splatting',\n",
              "  'distance': 0,\n",
              "  'no': '678',\n",
              "  'parent': '5498'},\n",
              " {'Abstract': 'A sequential pattern in data mining is a finite series of elements such as A/spl rarr/B/spl rarr/C/spl rarr/D where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1175208102306405, 'word': 'sequential'},\n",
              "   {'score': 0.1175208102306405, 'word': 'pattern'},\n",
              "   {'score': 0.10840388107500214, 'word': 'data'},\n",
              "   {'score': 0.10840388107500214, 'word': 'mining'},\n",
              "   {'score': 0.05059172542341625, 'word': 'large'},\n",
              "   {'score': 0.05059172542341625, 'word': 'datasets'},\n",
              "   {'score': 0.047558732855917135, 'word': 'useful'},\n",
              "   {'score': 0.047558732855917135, 'word': 'information'},\n",
              "   {'score': 0.046525868593321834, 'word': 'visualization'}],\n",
              "  'Title': 'Visualizing sequential patterns for text mining',\n",
              "  'distance': 0,\n",
              "  'no': '679',\n",
              "  'parent': '4789'},\n",
              " {'Abstract': 'Volume graphics has not been accepted for widespread use. One of the inhibiting reasons is the lack of general methods for data-analysis and simple interfaces for data exploration. An error-and-trial iterative procedure is often used to select a desirable transfer function or mine the dataset for salient iso-values. New semi-automatic methods that are also data-centric have shown much promise. However, general and robust methods are still needed for data-exploration and analysis. In this paper, we propose general model-independent statistical methods based on central moments of data. Using these techniques we show how salient iso-surfaces at material boundaries can be determined. We provide examples from the medical and computational domain to demonstrate the effectiveness of our methods.',\n",
              "  'AuthorKeywords': ['Iso-values,',\n",
              "   'Transfer',\n",
              "   'Functions,',\n",
              "   'Surface',\n",
              "   'Extraction,',\n",
              "   'Direct',\n",
              "   'Volume',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.13363998935570862, 'word': 'methods'},\n",
              "   {'score': 0.11222231338559431, 'word': 'data'},\n",
              "   {'score': 0.07689715967780127, 'word': 'general'},\n",
              "   {'score': 0.05674282967790734, 'word': 'robust'},\n",
              "   {'score': 0.05366981984686639, 'word': 'analysis'},\n",
              "   {'score': 0.0462889047965074, 'word': 'salient'},\n",
              "   {'score': 0.0462889047965074, 'word': 'iso'}],\n",
              "  'Title': 'Salient iso-surface detection with model-independent statistical signatures',\n",
              "  'distance': 0,\n",
              "  'no': '680',\n",
              "  'parent': '3748'},\n",
              " {'Abstract': \"We describe a new method for the visualization of tree structured relational data. It can be used especially for the display of very large hierarchies in a 2-dimensional space. We discuss the advantages and limitations of current techniques of tree visualization. Our strategy is to optimize the drawing of trees in a geometrical plane and maximize the utilization of display space by allowing more nodes and links to be displayed at a limit screen resolution. We use the concept of enclosure to partition the entire display space into a collection of local regions that are assigned to all nodes in tree T for the display of their sub-trees and themselves. To enable the exploration of large hierarchies, we use a modified semantic zooming technique to view the detail of a particular part of the hierarchy at a time based on user's interest. Layout animation is also provided to preserve the mental map while the user is exploring the hierarchy by changing zoomed views.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08688983495687293, 'word': 'display'},\n",
              "   {'score': 0.07485496031822832, 'word': 'large'},\n",
              "   {'score': 0.07485496031822832, 'word': 'hierarchies'},\n",
              "   {'score': 0.07279638071378591, 'word': 'tree'},\n",
              "   {'score': 0.04477780106143997, 'word': 'limitations'},\n",
              "   {'score': 0.034950126226119316, 'word': 'user'}],\n",
              "  'Title': 'A space-optimized tree visualization',\n",
              "  'distance': 0,\n",
              "  'no': '681',\n",
              "  'parent': '4234'},\n",
              " {'Abstract': 'Surface texture is among the most salient haptic characteristics of objects; it can induce vibratory contact forces that lead to perception of roughness. We present a new algorithm to display haptic texture information resulting from the interaction between two textured objects. We compute contact forces and torques using low-resolution geometric representations along with texture images that encode surface details. We also introduce a novel force model based on directional penetration depth and describe an efficient implementation on programmable graphics hardware that enables interactive haptic texture rendering of complex models. Our force model takes into account important factors identified by psychophysics studies and is able to haptically display interaction due to fine surface textures that previous algorithms do not capture.',\n",
              "  'AuthorKeywords': ['haptics,', 'textures,', 'graphics', 'hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.16389910264241453, 'word': 'texture'},\n",
              "   {'score': 0.11161395989202756, 'word': 'surface'},\n",
              "   {'score': 0.1099291824092878, 'word': 'haptic'},\n",
              "   {'score': 0.07290909477672022, 'word': 'objects'},\n",
              "   {'score': 0.0656154734006832, 'word': 'vibratory'},\n",
              "   {'score': 0.0656154734006832, 'word': 'contact'},\n",
              "   {'score': 0.0656154734006832, 'word': 'forces'},\n",
              "   {'score': 0.057644039658900824, 'word': 'salient'},\n",
              "   {'score': 0.057644039658900824, 'word': 'characteristics'},\n",
              "   {'score': 0.052285142750386975, 'word': 'information'}],\n",
              "  'Title': 'Haptic display of interaction between textured models',\n",
              "  'distance': 0,\n",
              "  'no': '682',\n",
              "  'parent': '3966'},\n",
              " {'Abstract': 'This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20/spl deg/, and velocity must differ by at least 0.43/spl deg/ of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, and then discuss future work we plan to pursue.',\n",
              "  'AuthorKeywords': ['direction,',\n",
              "   'flicker,',\n",
              "   'motion,',\n",
              "   'multidimensional,',\n",
              "   'perception,',\n",
              "   'velocity,',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08868337802238734, 'word': 'perceptual'},\n",
              "   {'score': 0.08868337802238734, 'word': 'properties'},\n",
              "   {'score': 0.07028050113270802, 'word': 'data'},\n",
              "   {'score': 0.06756139025148473, 'word': 'flicker'},\n",
              "   {'score': 0.059528009710237986, 'word': 'direction'},\n",
              "   {'score': 0.0516905223271567, 'word': 'results'}],\n",
              "  'Title': 'Visualizing data with motion',\n",
              "  'distance': 0,\n",
              "  'no': '683',\n",
              "  'parent': '3868'},\n",
              " {'Abstract': \"Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user's perspectives on the data, thereby diminishing the user's spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user's mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems.\",\n",
              "  'AuthorKeywords': ['Urban',\n",
              "   'models,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'multi-resolution'],\n",
              "  'MultipartiteRank': [{'score': 0.09803352126544232, 'word': 'data'},\n",
              "   {'score': 0.09481592707332549, 'word': 'numerous'},\n",
              "   {'score': 0.09481592707332549, 'word': 'systems'},\n",
              "   {'score': 0.06676363875696749, 'word': 'urban'},\n",
              "   {'score': 0.06676363875696749, 'word': 'contexts'},\n",
              "   {'score': 0.05973544756669238, 'word': 'user'},\n",
              "   {'score': 0.03463892325517714, 'word': 'city'},\n",
              "   {'score': 0.03463892325517714, 'word': 'blocks'}],\n",
              "  'Title': 'Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships',\n",
              "  'distance': 0,\n",
              "  'no': '684',\n",
              "  'parent': '4903'},\n",
              " {'Abstract': 'Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.',\n",
              "  'AuthorKeywords': ['Text',\n",
              "   'and',\n",
              "   'document',\n",
              "   'visualization,',\n",
              "   'hierarchical',\n",
              "   'multidimensional',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'knowledge',\n",
              "   'discovery,',\n",
              "   'high-dimensional',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.0955856330629221, 'word': 'data'},\n",
              "   {'score': 0.0955856330629221, 'word': 'instances'},\n",
              "   {'score': 0.05810855995327222, 'word': 'point'},\n",
              "   {'score': 0.05810855995327222, 'word': 'placement'},\n",
              "   {'score': 0.05810855995327222, 'word': 'strategies'},\n",
              "   {'score': 0.05260381504441567, 'word': 'exploration'},\n",
              "   {'score': 0.05211681073570446, 'word': 'higher'},\n",
              "   {'score': 0.05211681073570446, 'word': 'dimensions'},\n",
              "   {'score': 0.048389731693106036, 'word': 'analysis'}],\n",
              "  'Title': 'HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections',\n",
              "  'distance': 0,\n",
              "  'no': '685',\n",
              "  'parent': '3706'},\n",
              " {'Abstract': 'Recent advances in scanning technology provide high resolution EM (electron microscopy) datasets that allow neuro-scientists to reconstruct complex neural connections in a nervous system. However, due to the enormous size and complexity of the resulting data, segmentation and visualization of neural processes in EM data is usually a difficult and very time-consuming task. In this paper, we present NeuroTrace, a novel EM volume segmentation and visualization system that consists of two parts: a semi-automatic multiphase level set segmentation with 3D tracking for reconstruction of neural processes, and a specialized volume rendering approach for visualization of EM volumes. It employs view-dependent on-demand filtering and evaluation of a local histogram edge metric, as well as on-the-fly interpolation and ray-casting of implicit surfaces for segmented neural structures. Both methods are implemented on the GPU for interactive performance. NeuroTrace is designed to be scalable to large datasets and data-parallel hardware architectures. A comparison of NeuroTrace with a commonly used manual EM segmentation tool shows that our interactive workflow is faster and easier to use for the reconstruction of complex neural processes.',\n",
              "  'AuthorKeywords': ['Segmentation,',\n",
              "   'neuroscience,',\n",
              "   'connectome,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'implicit',\n",
              "   'surface',\n",
              "   'rendering,',\n",
              "   'graphics',\n",
              "   'hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.08600440244148297, 'word': 'segmentation'},\n",
              "   {'score': 0.05757754414036391, 'word': 'complex'},\n",
              "   {'score': 0.05757754414036391, 'word': 'neural'},\n",
              "   {'score': 0.05757754414036391, 'word': 'connections'},\n",
              "   {'score': 0.050140748139616484, 'word': 'visualization'},\n",
              "   {'score': 0.04743619967432392, 'word': 'data'},\n",
              "   {'score': 0.04178479372171395, 'word': 'novel'},\n",
              "   {'score': 0.04178479372171395, 'word': 'em'},\n",
              "   {'score': 0.04178479372171395, 'word': 'volume'}],\n",
              "  'Title': 'Scalable and Interactive Segmentation and Visualization of Neural Processes in EM Datasets',\n",
              "  'distance': 0,\n",
              "  'no': '686',\n",
              "  'parent': '4051'},\n",
              " {'Abstract': \"In virtual colonoscopy, CT scans are typically acquired with the patient in both supine (facing up) and prone (facing down) positions. The registration of these two scans is desirable so that the user can clarify situations or confirm polyp findings at a location in one scan with the same location in the other, thereby improving polyp detection rates and reducing false positives. However, this supine-prone registration is challenging because of the substantial distortions in the colon shape due to the patient's change in position. We present an efficient algorithm and framework for performing this registration through the use of conformal geometry to guarantee that the registration is a diffeomorphism (a one-to-one and onto mapping). The taeniae coli and colon flexures are automatically extracted for each supine and prone surface, employing the colon geometry. The two colon surfaces are then divided into several segments using the flexures, and each segment is cut along a taenia coli and conformally flattened to the rectangular domain using holomorphic differentials. The mean curvature is color encoded as texture images, from which feature points are automatically detected using graph cut segmentation, mathematic morphological operations, and principal component analysis. Corresponding feature points are found between supine and prone and are used to adjust the conformal flattening to be quasi-conformal, such that the features become aligned. We present multiple methods of visualizing our results, including 2D flattened rendering, corresponding 3D endoluminal views, and rendering of distortion measurements. We demonstrate the efficiency and efficacy of our registration method by illustrating matched views on both the 2D flattened colon images and in the 3D volume rendered colon endoluminal view. We analytically evaluate the correctness of the results by measuring the distance between features on the registered colons.\",\n",
              "  'AuthorKeywords': ['Data',\n",
              "   'registration,',\n",
              "   'geometry-based',\n",
              "   'techniques,',\n",
              "   'medical',\n",
              "   'visualization,',\n",
              "   'mathematical',\n",
              "   'foundations',\n",
              "   'for',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.054767579367503746, 'word': 'registration'},\n",
              "   {'score': 0.04585031183792071, 'word': 'colon'},\n",
              "   {'score': 0.04585031183792071, 'word': 'shape'},\n",
              "   {'score': 0.04323143139800454, 'word': 'supine'},\n",
              "   {'score': 0.03746565125276425, 'word': 'positions'},\n",
              "   {'score': 0.03687599083099852, 'word': 'ct'},\n",
              "   {'score': 0.03687599083099852, 'word': 'scans'}],\n",
              "  'Title': 'Supine and Prone Colon Registration Using Quasi-Conformal Mapping',\n",
              "  'distance': 0,\n",
              "  'no': '687',\n",
              "  'parent': '4758'},\n",
              " {'Abstract': \"In modeling and analysis of longitudinal social networks, visual exploration is used in particular to complement and inform other methods. The most common graphical representations for this purpose appear to be animations and small multiples of intermediate states, depending on the type of media available. We present an alternative approach based on matrix representation of gestaltlines (a combination of Tufte's sparklines with glyphs based on gestalt theory). As a result, we obtain static, compact, yet data-rich diagrams that support specifically the exploration of evolving dyadic relations and persistent group structure, although at the expense of cross-sectional network views and indirect linkages.\",\n",
              "  'AuthorKeywords': ['Network',\n",
              "   'visualization,',\n",
              "   'Social',\n",
              "   'networks,',\n",
              "   'Time',\n",
              "   'series',\n",
              "   'data,',\n",
              "   'visual',\n",
              "   'knolwedge',\n",
              "   'discovery',\n",
              "   'and',\n",
              "   'representation,',\n",
              "   'glyph-based',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.058149836747598896, 'word': 'visual'},\n",
              "   {'score': 0.058149836747598896, 'word': 'exploration'},\n",
              "   {'score': 0.04435507354278846, 'word': 'longitudinal'},\n",
              "   {'score': 0.04435507354278846, 'word': 'social'},\n",
              "   {'score': 0.04435507354278846, 'word': 'networks'},\n",
              "   {'score': 0.04037443628901957, 'word': 'tufte'},\n",
              "   {'score': 0.0399300901226194, 'word': 'sparklines'},\n",
              "   {'score': 0.038360795089505045, 'word': 'combination'}],\n",
              "  'Title': 'Asymmetric Relations in Longitudinal Social Networks',\n",
              "  'distance': 0,\n",
              "  'no': '688',\n",
              "  'parent': '3547'},\n",
              " {'Abstract': 'We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'perception,',\n",
              "   'wall-displays'],\n",
              "  'MultipartiteRank': [{'score': 0.054970352084117796, 'word': 'perception'},\n",
              "   {'score': 0.050901712272083115, 'word': 'user'},\n",
              "   {'score': 0.050901712272083115, 'word': 'studies'},\n",
              "   {'score': 0.04954112533683211, 'word': 'resolution'},\n",
              "   {'score': 0.04954112533683211, 'word': 'wall'},\n",
              "   {'score': 0.04892616195748865, 'word': 'angles'},\n",
              "   {'score': 0.043650156604818, 'word': 'sized'},\n",
              "   {'score': 0.043650156604818, 'word': 'displays'}],\n",
              "  'Title': 'Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications',\n",
              "  'distance': 0,\n",
              "  'no': '689',\n",
              "  'parent': '4795'},\n",
              " {'Abstract': \"Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'knowledge',\n",
              "   'discovery,',\n",
              "   'visual',\n",
              "   'knowledge',\n",
              "   'representation,',\n",
              "   'hypothesis',\n",
              "   'testing,',\n",
              "   'visual',\n",
              "   'evidence,',\n",
              "   'human',\n",
              "   'computer',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.1010681759532491, 'word': 'visualization'},\n",
              "   {'score': 0.09927762379815054, 'word': 'sports'},\n",
              "   {'score': 0.09927762379815054, 'word': 'analysts'},\n",
              "   {'score': 0.06495212718511108, 'word': 'information'},\n",
              "   {'score': 0.06495212718511108, 'word': 'community'},\n",
              "   {'score': 0.036204543444367125, 'word': 'dynamic'},\n",
              "   {'score': 0.036204543444367125, 'word': 'games'},\n",
              "   {'score': 0.029036042185729444, 'word': 'analytics'}],\n",
              "  'Title': 'SnapShot: Visualization to Propel Ice Hockey Analytics',\n",
              "  'distance': 0,\n",
              "  'no': '690',\n",
              "  'parent': '4533'},\n",
              " {'Abstract': \"For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.\",\n",
              "  'AuthorKeywords': ['High',\n",
              "   'dimensional',\n",
              "   'data,',\n",
              "   'hierarchical',\n",
              "   'visualization,',\n",
              "   'sub-dimensional',\n",
              "   'space,',\n",
              "   'user',\n",
              "   'interaction,',\n",
              "   'subspace,',\n",
              "   'tree,',\n",
              "   'matrix'],\n",
              "  'MultipartiteRank': [{'score': 0.16818121733732733, 'word': 'data'},\n",
              "   {'score': 0.129801533707262, 'word': 'dimensional'},\n",
              "   {'score': 0.11197559536844381, 'word': 'dimension'},\n",
              "   {'score': 0.11197559536844381, 'word': 'aspect'},\n",
              "   {'score': 0.04801729441538455, 'word': 'high'},\n",
              "   {'score': 0.03783692774024287, 'word': 'scatterplot'},\n",
              "   {'score': 0.03783692774024287, 'word': 'matrix'}],\n",
              "  'Title': 'Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data',\n",
              "  'distance': 0,\n",
              "  'no': '691',\n",
              "  'parent': '5752'},\n",
              " {'Abstract': 'Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.',\n",
              "  'AuthorKeywords': ['Predictive',\n",
              "   'modeling,',\n",
              "   'feature',\n",
              "   'selection,',\n",
              "   'classification,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'high-dimensional',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.17168708863830917, 'word': 'predictive'},\n",
              "   {'score': 0.17168708863830917, 'word': 'modeling'},\n",
              "   {'score': 0.17168708863830917, 'word': 'techniques'},\n",
              "   {'score': 0.07455405639885088, 'word': 'data'},\n",
              "   {'score': 0.07455405639885088, 'word': 'scientists'},\n",
              "   {'score': 0.07388977886091207, 'word': 'features'},\n",
              "   {'score': 0.05191281433310453, 'word': 'outcomes'},\n",
              "   {'score': 0.04331072391714598, 'word': 'probability'}],\n",
              "  'Title': 'INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data',\n",
              "  'distance': 0,\n",
              "  'no': '692',\n",
              "  'parent': '4401'},\n",
              " {'Abstract': 'Genus-reducing simplifications are important in constructing multiresolution hierarchies for level-of-detail-based rendering, especially for datasets that have several relatively small holes, tunnels, and cavities. We present a genus-reducing simplification approach that is complementary to the existing work on genus-preserving simplifications. We propose a simplification framework in which genus-reducing and genus-preserving simplifications alternate to yield much better multiresolution hierarchies than would have been possible by using either one of them. In our approach we first identify the holes and the concavities by extending the concept of /spl alpha/-hulls to polygonal meshes under the L/sub /spl infin// distance metric and then generate valid triangulations to fill them.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10491006563546687,\n",
              "    'word': 'simplifications'},\n",
              "   {'score': 0.06892438977416647, 'word': 'multiresolution'},\n",
              "   {'score': 0.06892438977416647, 'word': 'hierarchies'},\n",
              "   {'score': 0.06826219736033493, 'word': 'small'},\n",
              "   {'score': 0.06826219736033493, 'word': 'holes'},\n",
              "   {'score': 0.06327585413533586, 'word': 'genus'},\n",
              "   {'score': 0.05058315085081562, 'word': 'simplification'},\n",
              "   {'score': 0.05058315085081562, 'word': 'approach'}],\n",
              "  'Title': 'Controlled simplification of genus for polygonal models ',\n",
              "  'distance': 0,\n",
              "  'no': '693',\n",
              "  'parent': '3793'},\n",
              " {'Abstract': 'Vortices are important features in many research and engineering fields. Visualization is an important step in gaining more understanding and control of vortices. Vortex detection criteria fall into two categories: point based scalar quantities, calculated at single points, and curve based geometric criteria, calculated for, e.g., streamlines. The first category is easy to compute, but does not work in all cases. The second category is more intuitive and should work in all cases, but currently only works in 2D (or 3D projected) flows. We show applications of both approaches in hydrodynamic flows.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0922320539130638, 'word': 'categories'},\n",
              "   {'score': 0.08070849335808754, 'word': 'point'},\n",
              "   {'score': 0.07831870927226577, 'word': 'important'},\n",
              "   {'score': 0.07831870927226577, 'word': 'features'},\n",
              "   {'score': 0.07733644357792248, 'word': 'vortices'},\n",
              "   {'score': 0.051243067697210376, 'word': 'scalar'},\n",
              "   {'score': 0.051243067697210376, 'word': 'quantities'}],\n",
              "  'Title': 'Selective visualization of vortices in hydrodynamic flows',\n",
              "  'distance': 0,\n",
              "  'no': '694',\n",
              "  'parent': '3953'},\n",
              " {'Abstract': 'We present an approach that integrates occlusion culling within the view-dependent rendering framework. View-dependent rendering provides the ability to change level of detail over the surface seamlessly and smoothly in real-time. The exclusive use of view-parameters to perform level-of-detail selection causes even occluded regions to be rendered in high level of detail. To overcome this serious drawback we have integrated occlusion culling into the level selection mechanism. Because computing exact visibility is expensive and it is currently not possible to perform this computation in real time, we use a visibility estimation technique instead. Our approach reduces dramatically the resolution at occluded regions.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1003606778799403, 'word': 'level'},\n",
              "   {'score': 0.09420622345445488, 'word': 'view'},\n",
              "   {'score': 0.08310489641099125, 'word': 'detail'},\n",
              "   {'score': 0.05999665694963606, 'word': 'dependent'},\n",
              "   {'score': 0.05999665694963606, 'word': 'rendering'},\n",
              "   {'score': 0.05999665694963606, 'word': 'framework'},\n",
              "   {'score': 0.052145614418263285, 'word': 'real'}],\n",
              "  'Title': 'Integrating occlusion culling with view-dependent rendering',\n",
              "  'distance': 0,\n",
              "  'no': '695',\n",
              "  'parent': '3601'},\n",
              " {'Abstract': 'This paper deals with vessel exploration based on computed tomography angiography. Large image sequences of the lower extremities are investigated in a clinical environment. Two different approaches for peripheral vessel diagnosis dealing with stenosis and calcification detection are introduced. The paper presents an automated vessel-tracking tool for curved planar reformation. An interactive segmentation tool for bone removal is proposed.',\n",
              "  'AuthorKeywords': ['Computed',\n",
              "   'Tomography',\n",
              "   'Angiography',\n",
              "   '(CTA),',\n",
              "   'semi',\n",
              "   'automatic',\n",
              "   'segmentation,',\n",
              "   'optimal',\n",
              "   'path',\n",
              "   'computation'],\n",
              "  'MultipartiteRank': [{'score': 0.15273928227539707, 'word': 'vessel'},\n",
              "   {'score': 0.15273928227539707, 'word': 'exploration'},\n",
              "   {'score': 0.09936443609836304, 'word': 'paper'},\n",
              "   {'score': 0.08289262519480878, 'word': 'computed'},\n",
              "   {'score': 0.08289262519480878, 'word': 'tomography'},\n",
              "   {'score': 0.08289262519480878, 'word': 'angiography'},\n",
              "   {'score': 0.08232387249906914, 'word': 'tool'},\n",
              "   {'score': 0.07223867913803225, 'word': 'large'},\n",
              "   {'score': 0.07223867913803225, 'word': 'image'},\n",
              "   {'score': 0.07223867913803225, 'word': 'sequences'}],\n",
              "  'Title': 'Computed tomography angiography: a case study of peripheral vessel investigation',\n",
              "  'distance': 0,\n",
              "  'no': '696',\n",
              "  'parent': '3423'},\n",
              " {'Abstract': 'By offering more detail and precision, large data sets can provide greater insights to researchers than small data sets. However, these data sets require greater computing resources to view and manage. Remote visualization techniques allow the use of computers that cannot be operated locally. The Semotus Visum framework applies a high-performance client-server paradigm to the problem. The framework utilizes both client and server resources via multiple rendering methods. Experimental results show the framework delivers high frame rates and low latency across a wide range of data sets.',\n",
              "  'AuthorKeywords': ['remote', 'visualization,', 'client/server'],\n",
              "  'MultipartiteRank': [{'score': 0.10148413443827183, 'word': 'large'},\n",
              "   {'score': 0.10148413443827183, 'word': 'data'},\n",
              "   {'score': 0.10148413443827183, 'word': 'sets'},\n",
              "   {'score': 0.0767873666891373, 'word': 'semotus'},\n",
              "   {'score': 0.0767873666891373, 'word': 'visum'},\n",
              "   {'score': 0.0767873666891373, 'word': 'framework'},\n",
              "   {'score': 0.07052231432380295, 'word': 'performance'},\n",
              "   {'score': 0.07052231432380295, 'word': 'client'},\n",
              "   {'score': 0.06561311230152939, 'word': 'high'},\n",
              "   {'score': 0.064373804007582, 'word': 'server'},\n",
              "   {'score': 0.064373804007582, 'word': 'paradigm'}],\n",
              "  'Title': 'Semotus Visum: a flexible remote visualization framework',\n",
              "  'distance': 0,\n",
              "  'no': '697',\n",
              "  'parent': '3416'},\n",
              " {'Abstract': 'Parallel coordinates are a powerful method for visualizing multidimensional data but, when applied to large data sets, they become cluttered and difficult to read. Star glyphs, on the other hand, can be used to display either the attributes of a data item or the values across all items for a single attribute. Star glyphs may readily provide a quick impression; however, since the full data set require multiple glyphs, overall readings are more difficult. We present parallel glyphs, an interactive integration of the visual representations of parallel coordinates and star glyphs that utilizes the advantages of both representations to offset the disadvantages they have separately. We discuss the role of uniform and stepped colour scales in the visual comparison of non-adjacent items and star glyphs. Parallel glyphs provide capabilities for focus-in-context exploration using two types of lenses and interactions specific to the 3D space.',\n",
              "  'AuthorKeywords': ['Parallel',\n",
              "   'Glyphs,',\n",
              "   'parallel',\n",
              "   'coordinates,',\n",
              "   'star',\n",
              "   'glyphs,',\n",
              "   'multi-dimensional',\n",
              "   'data',\n",
              "   'sets,',\n",
              "   '3D',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.12309459612999711, 'word': 'star'},\n",
              "   {'score': 0.12309459612999711, 'word': 'glyphs'},\n",
              "   {'score': 0.04845014234563651, 'word': 'attributes'},\n",
              "   {'score': 0.048105352189983755, 'word': 'parallel'},\n",
              "   {'score': 0.048105352189983755, 'word': 'coordinates'},\n",
              "   {'score': 0.04788327992385617, 'word': 'data'},\n",
              "   {'score': 0.04788327992385617, 'word': 'item'},\n",
              "   {'score': 0.04698985812296601, 'word': 'visual'},\n",
              "   {'score': 0.04698985812296601, 'word': 'representations'}],\n",
              "  'Title': 'An interactive 3D integration of parallel coordinates and star glyphs',\n",
              "  'distance': 0,\n",
              "  'no': '698',\n",
              "  'parent': '4333'},\n",
              " {'Abstract': 'In this paper, we present two novel texture-based techniques to visualize uncertainty in time-dependent 2D flow fields. Both methods use semi-Lagrangian texture advection to show flow direction by streaklines and convey uncertainty by blurring these streaklines. The first approach applies a cross advection perpendicular to the flow direction. The second method employs isotropic diffusion that can be implemented by Gaussian filtering. Both methods are derived from a generic filtering process that is incorporated into the traditional texture advection pipeline. Our visualization methods allow for a continuous change of the density of flow representation by adapting the density of particle injection. All methods can be mapped to efficient GPU implementations. Therefore, the user can interactively control all important characteristics of the system like particle density, error influence, or dye injection to create meaningful illustrations of the underlying uncertainty. Even though there are many sources of uncertainties, we focus on uncertainty that occurs during data acquisition. We demonstrate the usefulness of our methods for the example of real-world fluid flow data measured with the particle image velocimetry (PIV) technique. Furthermore, we compare these techniques with an adapted multi-frequency noise approach.',\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'unsteady',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'texture',\n",
              "   'advection,',\n",
              "   'GPU',\n",
              "   'programming'],\n",
              "  'MultipartiteRank': [{'score': 0.09521497251554786, 'word': 'methods'},\n",
              "   {'score': 0.07370951753287297, 'word': 'uncertainty'},\n",
              "   {'score': 0.05878556520300226, 'word': 'density'},\n",
              "   {'score': 0.05725910225978754, 'word': 'flow'},\n",
              "   {'score': 0.05725910225978754, 'word': 'direction'},\n",
              "   {'score': 0.03927639331830233, 'word': 'particle'},\n",
              "   {'score': 0.03927639331830233, 'word': 'injection'}],\n",
              "  'Title': 'Texture-based visualization of uncertainty in flow fields',\n",
              "  'distance': 0,\n",
              "  'no': '699',\n",
              "  'parent': '3943'},\n",
              " {'Abstract': 'Time and streak surfaces are ideal tools to illustrate time-varying vector fields since they directly appeal to the intuition about coherently moving particles. However, efficient generation of high-quality time and streak surfaces for complex, large and time-varying vector field data has been elusive due to the computational effort involved. In this work, we propose a novel algorithm for computing such surfaces. Our approach is based on a decoupling of surface advection and surface adaptation and yields improved efficiency over other surface tracking methods, and allows us to leverage inherent parallelization opportunities in the surface advection, resulting in more rapid parallel computation. Moreover, we obtain as a result of our algorithm the entire evolution of a time or streak surface in a compact representation, allowing for interactive, high-quality rendering, visualization and exploration of the evolving surface. Finally, we discuss a number of ways to improve surface depiction through advanced rendering and texturing, while preserving interactivity, and provide a number of examples for real-world datasets and analyze the behavior of our algorithm on them.',\n",
              "  'AuthorKeywords': ['3D',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'time-varying,',\n",
              "   'time',\n",
              "   'and',\n",
              "   'streak',\n",
              "   'surfaces,',\n",
              "   'surface',\n",
              "   'extraction'],\n",
              "  'MultipartiteRank': [{'score': 0.1217834191417485, 'word': 'streak'},\n",
              "   {'score': 0.1217834191417485, 'word': 'surfaces'},\n",
              "   {'score': 0.11497175686286094, 'word': 'time'},\n",
              "   {'score': 0.03820110971704471, 'word': 'high'},\n",
              "   {'score': 0.03571143380258528, 'word': 'vector'},\n",
              "   {'score': 0.03571143380258528, 'word': 'fields'},\n",
              "   {'score': 0.03464348565363751, 'word': 'novel'},\n",
              "   {'score': 0.03464348565363751, 'word': 'algorithm'}],\n",
              "  'Title': 'Time and Streak Surfaces for Flow Visualization in Large Time-Varying Data Sets',\n",
              "  'distance': 0,\n",
              "  'no': '700',\n",
              "  'parent': '5378'},\n",
              " {'Abstract': 'How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The \"Rorschach\" helps the analyst calibrate their understanding of uncertainty and \"line-up\" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.',\n",
              "  'AuthorKeywords': ['Statistics,',\n",
              "   'visual',\n",
              "   'testing,',\n",
              "   'permutation',\n",
              "   'tests,',\n",
              "   'null',\n",
              "   'hypotheses,',\n",
              "   'data',\n",
              "   'plots'],\n",
              "  'MultipartiteRank': [{'score': 0.1533447109530286, 'word': 'relationships'},\n",
              "   {'score': 0.09179310943899335, 'word': 'statistics'},\n",
              "   {'score': 0.08356850630601918, 'word': 'new'},\n",
              "   {'score': 0.08192126327310932, 'word': 'visual'},\n",
              "   {'score': 0.08192126327310932, 'word': 'discoveries'},\n",
              "   {'score': 0.06977620464700943, 'word': 'spurious'},\n",
              "   {'score': 0.04953323839345166, 'word': 'random'},\n",
              "   {'score': 0.04953323839345166, 'word': 'noise'}],\n",
              "  'Title': 'Graphical inference for infovis',\n",
              "  'distance': 0,\n",
              "  'no': '701',\n",
              "  'parent': '4039'},\n",
              " {'Abstract': 'Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative \"chartjunk\" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user\\'s understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.',\n",
              "  'AuthorKeywords': ['Desirable',\n",
              "   'difficulites,',\n",
              "   'cognitive',\n",
              "   'efficiency,',\n",
              "   'active',\n",
              "   'processing,',\n",
              "   'engagement,',\n",
              "   'individual',\n",
              "   'differences'],\n",
              "  'MultipartiteRank': [{'score': 0.07790371188278729, 'word': 'visual'},\n",
              "   {'score': 0.07790371188278729, 'word': 'representation'},\n",
              "   {'score': 0.04555795834445617, 'word': 'visualization'},\n",
              "   {'score': 0.04555795834445617, 'word': 'design'},\n",
              "   {'score': 0.04555795834445617, 'word': 'state'},\n",
              "   {'score': 0.04201850372372736, 'word': 'comprehension'},\n",
              "   {'score': 0.04160607376099857, 'word': 'user'},\n",
              "   {'score': 0.03830587244034562, 'word': 'cognitive'},\n",
              "   {'score': 0.03830587244034562, 'word': 'difficulties'}],\n",
              "  'Title': 'Benefitting InfoVis with Visual Difficulties',\n",
              "  'distance': 0,\n",
              "  'no': '702',\n",
              "  'parent': '5154'},\n",
              " {'Abstract': 'In this paper we present a new technique and prototype graph visualization system, stereoscopic highlighting, to help answer accessibility and adjacency queries when interacting with a node-link diagram. Our technique utilizes stereoscopic depth to highlight regions of interest in a 2D graph by projecting these parts onto a plane closer to the viewpoint of the user. This technique aims to isolate and magnify specific portions of the graph that need to be explored in detail without resorting to other highlighting techniques like color or motion, which can then be reserved to encode other data attributes. This mechanism of stereoscopic highlighting also enables focus+context views by juxtaposing a detailed image of a region of interest with the overall graph, which is visualized at a further depth with correspondingly less detail. In order to validate our technique, we ran a controlled experiment with 16 subjects comparing static visual highlighting to stereoscopic highlighting on 2D and 3D graph layouts for a range of tasks. Our results show that while for most tasks the difference in performance between stereoscopic highlighting alone and static visual highlighting is not statistically significant, users performed better when both highlighting methods were used concurrently. In more complicated tasks, 3D layout with static visual highlighting outperformed 2D layouts with a single highlighting method. However, it did not outperform the 2D layout utilizing both highlighting techniques simultaneously. Based on these results, we conclude that stereoscopic highlighting is a promising technique that can significantly enhance graph visualizations for certain use cases.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'stereo',\n",
              "   'displays,',\n",
              "   'virtual',\n",
              "   'reality'],\n",
              "  'MultipartiteRank': [{'score': 0.13610863886850416, 'word': 'technique'},\n",
              "   {'score': 0.08781175530672844, 'word': 'new'},\n",
              "   {'score': 0.07577662332250655, 'word': 'stereoscopic'},\n",
              "   {'score': 0.07577662332250655, 'word': 'highlighting'},\n",
              "   {'score': 0.07208523377354893, 'word': 'graph'},\n",
              "   {'score': 0.07208523377354893, 'word': 'visualization'},\n",
              "   {'score': 0.07208523377354893, 'word': 'system'},\n",
              "   {'score': 0.04229563410651485, 'word': 'highlight'},\n",
              "   {'score': 0.04229563410651485, 'word': 'regions'}],\n",
              "  'Title': 'Stereoscopic Highlighting: 2D Graph Visualization on Stereo Displays',\n",
              "  'distance': 0,\n",
              "  'no': '703',\n",
              "  'parent': '5701'},\n",
              " {'Abstract': 'An information retrieval frame work that promotes graphical displays, and that will make documents in the computer visualizable to the searcher, is described. As examples of such graphical displays, two simulation results of using a Kohonen feature map to generate map displays for information retrieval are presented and discussed. The map displays are a mapping from a high-dimensional document space to a two-dimensional space. They show document relationships by various visual cues, such as dots, links, clusters, and areas, as well as their measurement and spatial arrangement. Using the map displays as an interface for document retrieval systems, the user is provided with richer visual information to support browsing and searching.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1557743561900076, 'word': 'map'},\n",
              "   {'score': 0.10008666245819732, 'word': 'kohonen'},\n",
              "   {'score': 0.10008666245819732, 'word': 'feature'},\n",
              "   {'score': 0.08126931668207399, 'word': 'documents'},\n",
              "   {'score': 0.0786821631428558, 'word': 'information'},\n",
              "   {'score': 0.0786821631428558, 'word': 'retrieval'},\n",
              "   {'score': 0.0786821631428558, 'word': 'frame'},\n",
              "   {'score': 0.0786821631428558, 'word': 'work'},\n",
              "   {'score': 0.05568769373181028, 'word': 'displays'},\n",
              "   {'score': 0.04672506974081914, 'word': 'computer'},\n",
              "   {'score': 0.04672506974081914, 'word': 'visualizable'}],\n",
              "  'Title': 'Visualization for the document space',\n",
              "  'distance': 0,\n",
              "  'no': '704',\n",
              "  'parent': '3746'},\n",
              " {'Abstract': \"Many clustering and layout techniques have been used for structuring and visualising complex data. This paper is inspired by a number of such contemporary techniques and presents a novel hybrid approach based upon stochastic sampling, interpolation and spring models. We use Chalmers' 1996 O(N/sup 2/) spring model as a benchmark when evaluating our technique, comparing layout quality and run times using data sets of synthetic and real data. Our algorithm runs in O(N/spl radic/N) and executes significantly faster than Chalmers' 1996 algorithm, whilst producing superior layouts. In reducing complexity and run time, we allow the visualisation of data sets of previously infeasible size. Our results indicate that our method is a solid foundation for interactive and visual exploration of data.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10668016714367734, 'word': 'layout'},\n",
              "   {'score': 0.08624193213909653, 'word': 'data'},\n",
              "   {'score': 0.08624193213909653, 'word': 'sets'},\n",
              "   {'score': 0.05902905316535597, 'word': 'techniques'},\n",
              "   {'score': 0.051891502788727964, 'word': 'times'},\n",
              "   {'score': 0.04990607309444693, 'word': 'spring'},\n",
              "   {'score': 0.04990607309444693, 'word': 'models'},\n",
              "   {'score': 0.04765111397832137, 'word': 'quality'}],\n",
              "  'Title': 'A hybrid layout algorithm for sub-quadratic multidimensional scaling',\n",
              "  'distance': 0,\n",
              "  'no': '705',\n",
              "  'parent': '3820'},\n",
              " {'Abstract': 'We present a haptic rendering technique that uses directional constraints to facilitate enhanced exploration modes for volumetric datasets. The algorithm restricts user motion in certain directions by incrementally moving a proxy point along the axes of a local reference frame. Reaction forces are generated by a spring coupler between the proxy and the data probe, which can be tuned to the capabilities of the haptic interface. Secondary haptic effects including field forces, friction, and texture can be easily incorporated to convey information about additional characteristics of the data. We illustrate the technique with two examples: displaying fiber orientation in heart muscle layers and exploring diffusion tensor fiber tracts in brain white matter tissue. Initial evaluation of the approach indicates that haptic constraints provide an intuitive means or displaying directional information in volume data.',\n",
              "  'AuthorKeywords': ['haptic',\n",
              "   'rendering,',\n",
              "   'immersive',\n",
              "   'visualization,',\n",
              "   'human-computer',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.057088066132333595, 'word': 'directional'},\n",
              "   {'score': 0.057088066132333595, 'word': 'constraints'},\n",
              "   {'score': 0.051587969643749634, 'word': 'reaction'},\n",
              "   {'score': 0.051587969643749634, 'word': 'forces'},\n",
              "   {'score': 0.05124608096135048, 'word': 'proxy'},\n",
              "   {'score': 0.05124608096135048, 'word': 'point'},\n",
              "   {'score': 0.050796590956462474, 'word': 'data'},\n",
              "   {'score': 0.050796590956462474, 'word': 'probe'},\n",
              "   {'score': 0.04574195667164854, 'word': 'haptic'},\n",
              "   {'score': 0.04574195667164854, 'word': 'rendering'},\n",
              "   {'score': 0.04574195667164854, 'word': 'technique'}],\n",
              "  'Title': 'A constraint-based technique for haptic volume exploration',\n",
              "  'distance': 0,\n",
              "  'no': '706',\n",
              "  'parent': '4010'},\n",
              " {'Abstract': 'Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus &amp; context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.',\n",
              "  'AuthorKeywords': ['focus',\n",
              "   '&',\n",
              "   'context',\n",
              "   'technique,',\n",
              "   'direct',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'curved',\n",
              "   'planar',\n",
              "   'reformation,',\n",
              "   'vessel',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1074723214354324, 'word': 'visualization'},\n",
              "   {'score': 0.06695559799715026, 'word': 'blood'},\n",
              "   {'score': 0.06695559799715026, 'word': 'vessels'},\n",
              "   {'score': 0.05568330501006087, 'word': 'context'},\n",
              "   {'score': 0.05568330501006087, 'word': 'techniques'},\n",
              "   {'score': 0.051789016425371516, 'word': 'reliable'},\n",
              "   {'score': 0.03907766913019651, 'word': 'several'},\n",
              "   {'score': 0.03907766913019651, 'word': 'regions'},\n",
              "   {'score': 0.03509394826098182, 'word': 'vesselglyph'}],\n",
              "  'Title': 'The VesselGlyph: focus & context visualization in CT-angiography',\n",
              "  'distance': 0,\n",
              "  'no': '707',\n",
              "  'parent': '3977'},\n",
              " {'Abstract': 'We introduce an approach to tracking vortex core lines in time-dependent 3D flow fields which are defined by the parallel vectors approach. They build surface structures in the 4D space-time domain. To extract them, we introduce two 4D vector fields which act as feature flow fields, i.e., their integration gives the vortex core structures. As part of this approach, we extract and classify local bifurcations of vortex core lines in space-time. Based on a 4D stream surface integration, we provide an algorithm to extract the complete vortex core structure. We apply our technique to a number of test data sets.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'vortex',\n",
              "   'core',\n",
              "   'lines,',\n",
              "   'bifurcations'],\n",
              "  'MultipartiteRank': [{'score': 0.13417943344145855, 'word': 'vortex'},\n",
              "   {'score': 0.13417943344145855, 'word': 'core'},\n",
              "   {'score': 0.13417943344145855, 'word': 'lines'},\n",
              "   {'score': 0.12017906338203793, 'word': 'time'},\n",
              "   {'score': 0.08639462844661588, 'word': '4d'},\n",
              "   {'score': 0.08639462844661588, 'word': 'space'},\n",
              "   {'score': 0.06667661136803323, 'word': 'dependent'},\n",
              "   {'score': 0.06667661136803323, 'word': '3d'},\n",
              "   {'score': 0.06667661136803323, 'word': 'flow'},\n",
              "   {'score': 0.06667661136803323, 'word': 'fields'},\n",
              "   {'score': 0.0568776656725475, 'word': 'approach'}],\n",
              "  'Title': 'Extraction of parallel vector surfaces in 3D time-dependent fields and application to vortex core line tracking',\n",
              "  'distance': 0,\n",
              "  'no': '708',\n",
              "  'parent': '3617'},\n",
              " {'Abstract': 'The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'network',\n",
              "   'security,',\n",
              "   'network',\n",
              "   'monitoring,',\n",
              "   'treemap'],\n",
              "  'MultipartiteRank': [{'score': 0.0899345229970977, 'word': 'hierarchy'},\n",
              "   {'score': 0.05646693339604627, 'word': 'interactive'},\n",
              "   {'score': 0.05646693339604627, 'word': 'visualization'},\n",
              "   {'score': 0.05226581137982954, 'word': 'large'},\n",
              "   {'score': 0.05226581137982954, 'word': 'data'},\n",
              "   {'score': 0.05226581137982954, 'word': 'sets'},\n",
              "   {'score': 0.039240058344023526, 'word': 'ip'},\n",
              "   {'score': 0.039240058344023526, 'word': 'address'},\n",
              "   {'score': 0.039240058344023526, 'word': 'space'},\n",
              "   {'score': 0.03605825653207764, 'word': 'vast'},\n",
              "   {'score': 0.03605825653207764, 'word': 'number'}],\n",
              "  'Title': 'Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats',\n",
              "  'distance': 0,\n",
              "  'no': '709',\n",
              "  'parent': '4168'},\n",
              " {'Abstract': 'In nature and in flow experiments particles form patterns of swirling motion in certain locations. Existing approaches identify these structures by considering the behavior of stream lines. However, in unsteady flows particle motion is described by path lines which generally gives different swirling patterns than stream lines. We introduce a novel mathematical characterization of swirling motion cores in unsteady flows by generalizing the approach of Sujudi/Haimes to path lines. The cores of swirling particle motion are lines sweeping over time, i.e., surfaces in the space-time domain. They occur at locations where three derived 4D vectors become coplanar. To extract them, we show how to re-formulate the problem using the parallel vectors operator. We apply our method to a number of unsteady flow fields.',\n",
              "  'AuthorKeywords': ['unsteady',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'feature',\n",
              "   'extraction,',\n",
              "   'particle',\n",
              "   'motion'],\n",
              "  'MultipartiteRank': [{'score': 0.09662695088921153, 'word': 'stream'},\n",
              "   {'score': 0.09662695088921153, 'word': 'lines'},\n",
              "   {'score': 0.07751760930618987, 'word': 'motion'},\n",
              "   {'score': 0.05941856763386179, 'word': 'patterns'},\n",
              "   {'score': 0.05758764404742579, 'word': 'unsteady'},\n",
              "   {'score': 0.04994682175645755, 'word': 'certain'},\n",
              "   {'score': 0.04994682175645755, 'word': 'locations'}],\n",
              "  'Title': 'Cores of Swirling Particle Motion in Unsteady Flows',\n",
              "  'distance': 0,\n",
              "  'no': '710',\n",
              "  'parent': '3936'},\n",
              " {'Abstract': 'In this paper we present a method to compute and visualize volumetric white matter connectivity in diffusion tensor magnetic resonance imaging (DT-MRI) using a Hamilton-Jacobi (H-J) solver on the GPU (graphics processing unit). Paths through the volume are assigned costs that are lower if they are consistent with the preferred diffusion directions. The proposed method finds a set of voxels in the DTI volume that contain paths between two regions whose costs are within a threshold of the optimal path. The result is a volumetric optimal path analysis, which is driven by clinical and scientific questions relating to the connectivity between various known anatomical regions of the brain. To solve the minimal path problem quickly, we introduce a novel numerical algorithm for solving H-J equations, which we call the fast iterative method (FIM). This algorithm is well-adapted to parallel architectures, and we present a GPU-based implementation, which runs roughly 50-100 times faster than traditional CPU-based solvers for anisotropic H-J equations. The proposed system allows users to freely change the endpoints of interesting pathways and to visualize the optimal volumetric path between them at an interactive rate. We demonstrate the proposed method on some synthetic and real DT-MRI datasets and compare the performance with existing methods.',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'tensor',\n",
              "   'visualization,',\n",
              "   'graphics',\n",
              "   'hardware,',\n",
              "   'interactivity'],\n",
              "  'MultipartiteRank': [{'score': 0.073656428208139, 'word': 'paths'},\n",
              "   {'score': 0.0573841548613977, 'word': 'method'},\n",
              "   {'score': 0.041610868937452805, 'word': 'costs'},\n",
              "   {'score': 0.04142762521463607, 'word': 'volume'},\n",
              "   {'score': 0.036771956333928164, 'word': 'regions'}],\n",
              "  'Title': 'Interactive Visualization of Volumetric White Matter Connectivity in DT-MRI Using a Parallel-Hardware Hamilton-Jacobi Solver',\n",
              "  'distance': 0,\n",
              "  'no': '711',\n",
              "  'parent': '3893'},\n",
              " {'Abstract': \"The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today's information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.\",\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'visual',\n",
              "   'exploration,',\n",
              "   'event-based',\n",
              "   'data,',\n",
              "   'sequence',\n",
              "   'identification,',\n",
              "   'graph',\n",
              "   'similarity,',\n",
              "   'node',\n",
              "   'similarity'],\n",
              "  'MultipartiteRank': [{'score': 0.07558510823216476, 'word': 'temporal'},\n",
              "   {'score': 0.07558510823216476, 'word': 'data'},\n",
              "   {'score': 0.05015573530643506, 'word': 'applications'},\n",
              "   {'score': 0.050136570647199175, 'word': 'complex'},\n",
              "   {'score': 0.050136570647199175, 'word': 'event'},\n",
              "   {'score': 0.04753178794714663, 'word': 'significant'},\n",
              "   {'score': 0.04753178794714663, 'word': 'sequences'},\n",
              "   {'score': 0.04069265185080382, 'word': 'identification'}],\n",
              "  'Title': 'ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity',\n",
              "  'distance': 0,\n",
              "  'no': '712',\n",
              "  'parent': '5137'},\n",
              " {'Abstract': 'Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented \\\\emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.',\n",
              "  'AuthorKeywords': ['Biomedical',\n",
              "   'visualization,',\n",
              "   'neurobiology,',\n",
              "   'visual',\n",
              "   'queries,',\n",
              "   'volume',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.052707871455135724, 'word': 'anatomical'},\n",
              "   {'score': 0.04965309360827823, 'word': 'volume'},\n",
              "   {'score': 0.04965309360827823, 'word': 'data'},\n",
              "   {'score': 0.04921497779763471, 'word': 'physiological'},\n",
              "   {'score': 0.04921497779763471, 'word': 'relationships'},\n",
              "   {'score': 0.04868760604809333, 'word': 'large'},\n",
              "   {'score': 0.04868760604809333, 'word': 'databases'},\n",
              "   {'score': 0.048258314908715134, 'word': 'visualization'},\n",
              "   {'score': 0.048258314908715134, 'word': 'techniques'}],\n",
              "  'Title': 'BrainGazer - Visual Queries for Neurobiology Research',\n",
              "  'distance': 0,\n",
              "  'no': '713',\n",
              "  'parent': '4776'},\n",
              " {'Abstract': 'GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring &amp; Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.',\n",
              "  'AuthorKeywords': ['Genealogy', 'visualization,', 'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.07633719453500994, 'word': 'large'},\n",
              "   {'score': 0.07633719453500994, 'word': 'genealogies'},\n",
              "   {'score': 0.06063557038402541, 'word': 'individuals'},\n",
              "   {'score': 0.05821877003482305, 'word': 'new'},\n",
              "   {'score': 0.05821877003482305, 'word': 'visualization'},\n",
              "   {'score': 0.05821877003482305, 'word': 'technique'},\n",
              "   {'score': 0.046961706143739845, 'word': 'geneaquilts'},\n",
              "   {'score': 0.04369608327842804, 'word': 'system'}],\n",
              "  'Title': 'GeneaQuilts: A System for Exploring Large Genealogies',\n",
              "  'distance': 0,\n",
              "  'no': '714',\n",
              "  'parent': '3509'},\n",
              " {'Abstract': \"We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.\",\n",
              "  'AuthorKeywords': ['Topic',\n",
              "   'graph,',\n",
              "   'graph',\n",
              "   'matching,',\n",
              "   'graph',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'interactions,',\n",
              "   'level-of-detail'],\n",
              "  'MultipartiteRank': [{'score': 0.07380427462642598, 'word': 'topic'},\n",
              "   {'score': 0.07380427462642598, 'word': 'graph'},\n",
              "   {'score': 0.06201967224343383, 'word': 'relevant'},\n",
              "   {'score': 0.06201967224343383, 'word': 'topics'},\n",
              "   {'score': 0.05505507707533045, 'word': 'full'},\n",
              "   {'score': 0.05505507707533045, 'word': 'picture'},\n",
              "   {'score': 0.05084202843395664, 'word': 'visual'},\n",
              "   {'score': 0.05084202843395664, 'word': 'analytics'},\n",
              "   {'score': 0.05084202843395664, 'word': 'approach'},\n",
              "   {'score': 0.045020430363321894, 'word': 'blogs'}],\n",
              "  'Title': 'TopicPanorama: A Full Picture of Relevant Topics',\n",
              "  'distance': 0,\n",
              "  'no': '715',\n",
              "  'parent': '4503'},\n",
              " {'Abstract': \"Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.\",\n",
              "  'AuthorKeywords': ['Spatial',\n",
              "   'temporal',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'Geo-tagged',\n",
              "   'social',\n",
              "   'media,',\n",
              "   'Sparsely',\n",
              "   'sampling,',\n",
              "   'Uncertainty,',\n",
              "   'Movement'],\n",
              "  'MultipartiteRank': [{'score': 0.1513036853573338, 'word': 'data'},\n",
              "   {'score': 0.10751376558749974, 'word': 'movements'},\n",
              "   {'score': 0.09965130451992979, 'word': 'social'},\n",
              "   {'score': 0.09965130451992979, 'word': 'media'},\n",
              "   {'score': 0.05165238083740402, 'word': 'traditional'},\n",
              "   {'score': 0.05165238083740402, 'word': 'movement'},\n",
              "   {'score': 0.04239656025901917, 'word': 'users'},\n",
              "   {'score': 0.03770615108036957, 'word': 'people'}],\n",
              "  'Title': 'Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data',\n",
              "  'distance': 0,\n",
              "  'no': '716',\n",
              "  'parent': '4482'},\n",
              " {'Abstract': 'In order to visualize both clouds and wind in climate simulations, clouds were rendered using a 3D texture which was advected by the wind flow. The simulation is described. Rendering, the advection of texture coordinates, and haze effects are discussed. Results are presented.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': ['advection,',\n",
              "   '3-D',\n",
              "   'texture,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'vectorfield,',\n",
              "   'wind,',\n",
              "   'clouds,',\n",
              "   'climate',\n",
              "   'modeling'],\n",
              "  'MultipartiteRank': [{'score': 0.17920517696521823, 'word': 'clouds'},\n",
              "   {'score': 0.16362434838179304, 'word': 'climate'},\n",
              "   {'score': 0.16362434838179304, 'word': 'simulations'},\n",
              "   {'score': 0.16346948525971192, 'word': 'wind'},\n",
              "   {'score': 0.11082622002515832, 'word': '3d'},\n",
              "   {'score': 0.11082622002515832, 'word': 'texture'},\n",
              "   {'score': 0.06376746547854384, 'word': 'order'}],\n",
              "  'Title': 'Visualizing wind velocities by advecting cloud textures',\n",
              "  'distance': 0,\n",
              "  'no': '717',\n",
              "  'parent': '3333'},\n",
              " {'Abstract': 'Volume ray casting is based on sampling the data along sight rays. In this technique, reconstruction is achieved by a convolution, which collects the contribution of multiple voxels to one sample point. Splatting, on the other hand, is based on projecting data points on to the screen, and reconstruction is implemented by an \"inverted convolution\", where the contribution of one data element is distributed to many sample points (i.e. pixels). Splatting produces images of a quality comparable to ray casting but at greater speeds. This is achieved by pre-computing the projection footprint that the interpolation kernel leaves on the image plane. However, while fast incremental schemes can be utilized for orthographic projection, the perspective projection complicates the mapping of the footprints and is therefore rather slow. In this paper, we merge the technique of splatting with the principles of ray casting to yield a ray-driven splatting approach. We imagine splats as being suspended in object space, a splat at every voxel. Rays are then spawned to traverse the space and intersect the splats. An efficient and accurate way of intersecting and addressing the splats is described. Not only is ray-driven splatting inherently insensitive to the complexity of the perspective viewing transform, it also offers acceleration methods such as early ray termination and bounding volumes, which are methods that traditional voxel-driven splatting cannot benefit from. This results in competitive or superior performance for parallel projection, and superior performance for perspective projection.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08991831435548041, 'word': 'splatting'},\n",
              "   {'score': 0.0726208535630114, 'word': 'sight'},\n",
              "   {'score': 0.0726208535630114, 'word': 'rays'},\n",
              "   {'score': 0.054585153066164814, 'word': 'data'},\n",
              "   {'score': 0.045083404555706336, 'word': 'volume'},\n",
              "   {'score': 0.045083404555706336, 'word': 'ray'},\n",
              "   {'score': 0.045083404555706336, 'word': 'casting'},\n",
              "   {'score': 0.03880590577255842, 'word': 'multiple'},\n",
              "   {'score': 0.03880590577255842, 'word': 'voxels'}],\n",
              "  'Title': 'Fast Perspective Volume Rendering with Splatting by Utilizing a Ray-Driven Approach',\n",
              "  'distance': 0,\n",
              "  'no': '718',\n",
              "  'parent': '5868'},\n",
              " {'Abstract': 'Integrated presentation of data with uncertainty is a worthy goal in scientific visualization. It allows researchers to make informed decisions based on imperfect data. It also allows users to visually compare and contrast different algorithms for performing the same task or different models for representing the same physical phenomenon. We present LISTEN-a data sonification system that has been incorporated into two visualization systems: a system for visualizing geometric uncertainty of surface interpolants; and a system for visualizing uncertainty in fluid flow. LISTEN is written in C++ for the SGI platform. It works with the SGI internal audio chip or a MIDI device or both. LISTEN is an object-oriented system that is modular, flexible, adaptable, portable, interactive and extensible. We demonstrate that sonification is very effective as an additional tool in visualizing geometric and fluid flow uncertainty.',\n",
              "  'AuthorKeywords': ['flow,',\n",
              "   'geometry,',\n",
              "   'interactive,',\n",
              "   'interpolation,',\n",
              "   'MIDI,',\n",
              "   'modular,',\n",
              "   'portable,',\n",
              "   'sonification,',\n",
              "   'uncertainty,',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.0819411925242468, 'word': 'uncertainty'},\n",
              "   {'score': 0.07243541185905321, 'word': 'visualization'},\n",
              "   {'score': 0.07243541185905321, 'word': 'systems'},\n",
              "   {'score': 0.06007121351736438, 'word': 'listen'},\n",
              "   {'score': 0.053753677782465606, 'word': 'system'},\n",
              "   {'score': 0.05184519830054773, 'word': 'data'}],\n",
              "  'Title': 'LISTEN: sounding uncertainty visualization',\n",
              "  'distance': 0,\n",
              "  'no': '719',\n",
              "  'parent': '3564'},\n",
              " {'Abstract': 'Presents a new method for using texture to visualize multi-dimensional data elements arranged on an underlying 3D height field. We hope to use simple texture patterns in combination with other visual features like hue and intensity to increase the number of attribute values we can display simultaneously. Our technique builds perceptual texture elements (or pexels) to represent each data element. Attribute values encoded in the data element are used to vary the appearance of a corresponding pexel. Texture patterns that form when the pexels are displayed can be used to rapidly and accurately explore the dataset. Our pexels are built by controlling three separate texture dimensions: height, density and regularity. Results from computer graphics, computer vision and cognitive psychology have identified these dimensions as important for the formation of perceptual texture patterns. We conducted a set of controlled experiments to measure the effectiveness of these dimensions, and to identify any visual interference that may occur when all three are displayed simultaneously at the same spatial location. Results from our experiments show that these dimensions can be used in specific combinations to form perceptual textures for visualizing multidimensional datasets. We demonstrate the effectiveness of our technique by applying it to two real-world visualization environments: tracking typhoon activity in southeast Asia, and analyzing ocean conditions in the northern Pacific.',\n",
              "  'AuthorKeywords': ['computer',\n",
              "   'graphics,',\n",
              "   'experimental',\n",
              "   'design,',\n",
              "   'human',\n",
              "   'vision,',\n",
              "   'multidimensional',\n",
              "   'dataset,',\n",
              "   'oceanography,',\n",
              "   'perception,',\n",
              "   'preattentive',\n",
              "   'processing,',\n",
              "   'scientific',\n",
              "   'visualization,',\n",
              "   'texture,',\n",
              "   'typhoon'],\n",
              "  'MultipartiteRank': [{'score': 0.14246044711505823, 'word': 'texture'},\n",
              "   {'score': 0.05205183409752007, 'word': 'pexels'},\n",
              "   {'score': 0.051482135708133106, 'word': 'separate'},\n",
              "   {'score': 0.051482135708133106, 'word': 'dimensions'},\n",
              "   {'score': 0.03913846877312966, 'word': 'new'},\n",
              "   {'score': 0.03913846877312966, 'word': 'method'},\n",
              "   {'score': 0.03337323740653307, 'word': 'computer'},\n",
              "   {'score': 0.03337323740653307, 'word': 'graphics'}],\n",
              "  'Title': 'Building perceptual textures to visualize multidimensional datasets',\n",
              "  'distance': 0,\n",
              "  'no': '720',\n",
              "  'parent': '4368'},\n",
              " {'Abstract': 'We approach the problem of exploring a virtual space by exploiting positional and camera-model constraints on navigation to provide extra assistance that focuses the user\\'s explorational wanderings on the task objectives. Our specific design incorporates not only task-based constraints on the viewer\\'s location, gaze, and viewing parameters, but also a personal \"glide\" that serves two important functions: keeping the user oriented in the navigation space, and \"pointing\" to interesting subject areas as they are approached. The guide\\'s cues may be ignored by continuing in motion, but if the user stops, the gaze shifts automatically toward whatever the guide was interested in. This design has the serendipitous feature that it automatically incorporates a nested collaborative paradigm simply by allowing any given viewer to be seen as the \"guide\" of one or more viewers following behind; the leading automated guide (we tend to select a guide dog for this avatar) can remind the leading live human guide of interesting sites to point out, while each real human collaborator down the chain has some choices about whether to follow the local leader\\'s hints. We have chosen VRML as our initial development medium primarily because of its portability, and we have implemented a variety of natural modes for leading and collaborating, including ways for collaborators to attach to and detach from a particular leader.',\n",
              "  'AuthorKeywords': ['wayfinding,',\n",
              "   'locomotion,',\n",
              "   'navigation,',\n",
              "   'exploration,',\n",
              "   'collaboration,',\n",
              "   'virtual',\n",
              "   'reality,',\n",
              "   'VRML'],\n",
              "  'MultipartiteRank': [{'score': 0.060534603356369926, 'word': 'guide'},\n",
              "   {'score': 0.04862751043848737, 'word': 'user'},\n",
              "   {'score': 0.04754930257898776, 'word': 'model'},\n",
              "   {'score': 0.04754930257898776, 'word': 'constraints'},\n",
              "   {'score': 0.04106403472603274, 'word': 'navigation'},\n",
              "   {'score': 0.04038300711770541, 'word': 'interesting'},\n",
              "   {'score': 0.04038300711770541, 'word': 'subject'},\n",
              "   {'score': 0.04038300711770541, 'word': 'areas'}],\n",
              "  'Title': 'A framework for assisted exploration with collaboration',\n",
              "  'distance': 0,\n",
              "  'no': '721',\n",
              "  'parent': '5409'},\n",
              " {'Abstract': 'Specific rendering modes are developed for a combined visual/haptic interface to allow exploration and understanding of fluid dynamics data. The focus is on visualization of shock surfaces and vortex cores. Advantages provided by augmenting traditional graphical rendering modes with haptic rendering modes are discussed. Particular emphasis is placed on synergistic combinations of visual and haptic modes which enable rapid, exploratory interaction with the data. Implementation issues are also discussed.',\n",
              "  'AuthorKeywords': ['haptic,',\n",
              "   'interface,',\n",
              "   'vortex,',\n",
              "   'shock,',\n",
              "   'visualization,',\n",
              "   'fluid',\n",
              "   'dynamics,',\n",
              "   'virtual',\n",
              "   'environment'],\n",
              "  'MultipartiteRank': [{'score': 0.17909845937573238, 'word': 'specific'},\n",
              "   {'score': 0.17909845937573238, 'word': 'rendering'},\n",
              "   {'score': 0.17909845937573238, 'word': 'modes'},\n",
              "   {'score': 0.12733714484149392, 'word': 'visual'},\n",
              "   {'score': 0.07704102642677359, 'word': 'fluid'},\n",
              "   {'score': 0.07704102642677359, 'word': 'dynamics'},\n",
              "   {'score': 0.07704102642677359, 'word': 'data'},\n",
              "   {'score': 0.06067549712243654, 'word': 'understanding'},\n",
              "   {'score': 0.05922303396411059, 'word': 'haptic'},\n",
              "   {'score': 0.05922303396411059, 'word': 'interface'}],\n",
              "  'Title': 'Shock and vortex visualization using a combined visual/haptic interface',\n",
              "  'distance': 0,\n",
              "  'no': '722',\n",
              "  'parent': '3876'},\n",
              " {'Abstract': 'We present a new multiphase method for efficiently simplifying polygonal surface models of arbitrary size. It operates by combining an initial out-of-core uniform clustering phase with a subsequent in-core iterative edge contraction phase. These two phases are both driven by quadric error metrics, and quadrics are used to pass information about the original surface between phases. The result is a method that produces approximations of a quality comparable to quadric-based iterative edge contraction, but at a fraction of the cost in terms of running time and memory consumption.',\n",
              "  'AuthorKeywords': ['multiphase',\n",
              "   'simplification,',\n",
              "   'quadric',\n",
              "   'error',\n",
              "   'metrics,',\n",
              "   'massive',\n",
              "   'meshes,',\n",
              "   'out-of-core',\n",
              "   'simplification'],\n",
              "  'MultipartiteRank': [{'score': 0.08324929234837727, 'word': 'quadric'},\n",
              "   {'score': 0.08324929234837727, 'word': 'error'},\n",
              "   {'score': 0.08324929234837727, 'word': 'metrics'},\n",
              "   {'score': 0.07633791666196162, 'word': 'phases'},\n",
              "   {'score': 0.07091708494607496, 'word': 'core'},\n",
              "   {'score': 0.07091708494607496, 'word': 'iterative'},\n",
              "   {'score': 0.07091708494607496, 'word': 'edge'},\n",
              "   {'score': 0.07091708494607496, 'word': 'contraction'},\n",
              "   {'score': 0.07091708494607496, 'word': 'phase'},\n",
              "   {'score': 0.06844164853231316, 'word': 'new'},\n",
              "   {'score': 0.06844164853231316, 'word': 'multiphase'},\n",
              "   {'score': 0.06844164853231316, 'word': 'method'},\n",
              "   {'score': 0.05429162246385116, 'word': 'quadrics'}],\n",
              "  'Title': 'A multiphase approach to efficient surface simplification',\n",
              "  'distance': 0,\n",
              "  'no': '723',\n",
              "  'parent': '3506'},\n",
              " {'Abstract': 'The current state of the art in visualization research places strong emphasis on different techniques to derive insight from disparate types of data. However, little work has investigated the visualization process itself. The information content of the visualization process - the results, history, and relationships between those results - is addressed by this work. A characterization of the visualization process is discussed, leading to a general model of the visualization exploration process. The model, based upon a new parameter derivation calculus, can be used for automated reporting, analysis, or visualized directly. An XML-based language for expressing visualization sessions using the model is also described. These sessions can then be shared and reused by collaborators. The model, along with the XML representation, provides an effective means to utilize information within the visualization process to further data exploration.',\n",
              "  'AuthorKeywords': ['visualization',\n",
              "   'process,',\n",
              "   'visualization',\n",
              "   'models,',\n",
              "   'scientific',\n",
              "   'and',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'collaboration,',\n",
              "   'XML'],\n",
              "  'MultipartiteRank': [{'score': 0.18714391938894379, 'word': 'visualization'},\n",
              "   {'score': 0.12694607736483476, 'word': 'research'},\n",
              "   {'score': 0.06019784202410902, 'word': 'process'},\n",
              "   {'score': 0.056026713545277745, 'word': 'general'},\n",
              "   {'score': 0.056026713545277745, 'word': 'model'},\n",
              "   {'score': 0.0529785041299293, 'word': 'strong'},\n",
              "   {'score': 0.0529785041299293, 'word': 'emphasis'},\n",
              "   {'score': 0.04793018260704768, 'word': 'art'}],\n",
              "  'Title': 'A model for the visualization exploration process',\n",
              "  'distance': 0,\n",
              "  'no': '724',\n",
              "  'parent': '4183'},\n",
              " {'Abstract': 'Segmentation of the tracheo-bronchial tree of the lungs is notoriously difficult. This is due to the fact that the small size of some of the anatomical structures is subject to partial volume effects. Furthermore, the limited intensity contrast between the participating materials (air, blood, and tissue) increases the segmentation of difficulties. In this paper, we propose a hybrid segmentation method which is based on a pipeline of three segmentation stages to extract the lower airways down to the seventh generation of the bronchi. User interaction is limited to the specification of a seed point inside the easily detectable trachea at the upper end of the lower airways. Similarly, the complementary vascular tree of the lungs can be segmented. Furthermore, we modified our virtual endoscopy system to visualize the vascular and airway system of the lungs along with other features, such as lung tumors.',\n",
              "  'AuthorKeywords': ['Tracheo-bronchial',\n",
              "   'tree,',\n",
              "   'segmentation,',\n",
              "   'multi-slice',\n",
              "   'CT,',\n",
              "   'virtual',\n",
              "   'endoscopy'],\n",
              "  'MultipartiteRank': [{'score': 0.12230436668821482, 'word': 'segmentation'},\n",
              "   {'score': 0.05737526005665686, 'word': 'lungs'},\n",
              "   {'score': 0.037059302286720094, 'word': 'lower'},\n",
              "   {'score': 0.03574735256326576, 'word': 'difficulties'},\n",
              "   {'score': 0.03299687529643151, 'word': 'complementary'},\n",
              "   {'score': 0.03299687529643151, 'word': 'vascular'},\n",
              "   {'score': 0.03299687529643151, 'word': 'tree'}],\n",
              "  'Title': 'Hybrid segmentation and exploration of the human lungs',\n",
              "  'distance': 0,\n",
              "  'no': '725',\n",
              "  'parent': '3884'},\n",
              " {'Abstract': \"The technology available to building designers now makes it possible to monitor buildings on a very large scale. Video cameras and motion sensors are commonplace in practically every office space, and are slowly making their way into living spaces. The application of such technologies, in particular video cameras, while improving security, also violates privacy. On the other hand, motion sensors, while being privacy-conscious, typically do not provide enough information for a human operator to maintain the same degree of awareness about the space that can be achieved by using video cameras. We propose a novel approach in which we use a large number of simple motion sensors and a small set of video cameras to monitor a large office space. In our system we deployed 215 motion sensors and six video cameras to monitor the 3,000-square-meter office space occupied by 80 people for a period of about one year. The main problem in operating such systems is finding a way to present this highly multidimensional data, which includes both spatial and temporal components, to a human operator to allow browsing and searching recorded data in an efficient and intuitive way. In this paper we present our experiences and the solutions that we have developed in the course of our work on the system. We consider this work to be the first step in helping designers and managers of building systems gain access to information about occupants' behavior in the context of an entire building in a way that is only minimally intrusive to the occupants' privacy.\",\n",
              "  'AuthorKeywords': ['Sensor',\n",
              "   'networks,',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'surveillance,',\n",
              "   'timeline,',\n",
              "   'spatio-temporal',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.06353317665929441, 'word': 'video'},\n",
              "   {'score': 0.06353317665929441, 'word': 'cameras'},\n",
              "   {'score': 0.05673462112201308, 'word': 'office'},\n",
              "   {'score': 0.05673462112201308, 'word': 'space'},\n",
              "   {'score': 0.05473851787055968, 'word': 'motion'},\n",
              "   {'score': 0.05473851787055968, 'word': 'sensors'},\n",
              "   {'score': 0.045300369265665996, 'word': 'way'},\n",
              "   {'score': 0.04065273323175389, 'word': 'buildings'}],\n",
              "  'Title': 'Visualizing the History of Living Spaces',\n",
              "  'distance': 0,\n",
              "  'no': '726',\n",
              "  'parent': '5829'},\n",
              " {'Abstract': \"Visualization systems traditionally focus on graphical representation of information. They tend not to provide integrated analytical services that could aid users in tackling complex knowledge discovery tasks. Users' exploration in such environments is usually impeded due to several problems: 1) valuable information is hard to discover when too much data is visualized on the screen; 2) Users have to manage and organize their discoveries off line, because no systematic discovery management mechanism exists; 3) their discoveries based on visual exploration alone may lack accuracy; 4) and they have no convenient access to the important knowledge learned by other users. To tackle these problems, it has been recognized that analytical tools must be introduced into visualization systems. In this paper, we present a novel analysis-guided exploration system, called the nugget management system (NMS). It leverages the collaborative effort of human comprehensibility and machine computations to facilitate users' visual exploration processes. Specifically, NMS first extracts the valuable information (nuggets) hidden in datasets based on the interests of users. Given that similar nuggets may be re-discovered by different users, NMS consolidates the nugget candidate set by clustering based on their semantic similarity. To solve the problem of inaccurate discoveries, localized data mining techniques are applied to refine the nuggets to best represent the captured patterns in datasets. Lastly, the resulting well-organized nugget pool is used to guide users' exploration. To evaluate the effectiveness of NMS, we integrated NMS into Xmd- vTool, a freeware multivariate visualization system. User studies were performed to compare the users' efficiency and accuracy in finishing tasks on real datasets, with and without the help of NMS. Our user studies confirmed the effectiveness of NMS.\",\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Visual',\n",
              "   'Knowledge',\n",
              "   'Discovery,',\n",
              "   'Discovery',\n",
              "   'Management,',\n",
              "   'Analysis',\n",
              "   'Guided',\n",
              "   'Exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.09886425421366711, 'word': 'users'},\n",
              "   {'score': 0.062285979983664086, 'word': 'nms'},\n",
              "   {'score': 0.05845080732525652, 'word': 'exploration'},\n",
              "   {'score': 0.05146706134223818, 'word': 'nugget'},\n",
              "   {'score': 0.05146706134223818, 'word': 'management'},\n",
              "   {'score': 0.05146706134223818, 'word': 'system'},\n",
              "   {'score': 0.04578311102052418, 'word': 'visualization'},\n",
              "   {'score': 0.04578311102052418, 'word': 'systems'}],\n",
              "  'Title': 'Analysis Guided Visual Exploration of Multivariate Data',\n",
              "  'distance': 0,\n",
              "  'no': '727',\n",
              "  'parent': '5102'},\n",
              " {'Abstract': 'Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'Radviz,',\n",
              "   'Vectorized',\n",
              "   'Radviz,',\n",
              "   'Clustering,',\n",
              "   'Multiple',\n",
              "   'Clustering,',\n",
              "   'Cluster',\n",
              "   'Ensembles,',\n",
              "   'Flattening',\n",
              "   'Datasets'],\n",
              "  'MultipartiteRank': [{'score': 0.08920402945363252, 'word': 'vrv'},\n",
              "   {'score': 0.08430405170472285, 'word': 'radviz'},\n",
              "   {'score': 0.06909988668814446, 'word': 'dimensions'},\n",
              "   {'score': 0.061787520187923294, 'word': 'das'},\n",
              "   {'score': 0.05112791448350275, 'word': 'multiple'},\n",
              "   {'score': 0.05112791448350275, 'word': 'clusterings'}],\n",
              "  'Title': 'Vectorized Radviz and Its Application to Multiple Cluster Datasets',\n",
              "  'distance': 0,\n",
              "  'no': '728',\n",
              "  'parent': '3912'},\n",
              " {'Abstract': \"We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.\",\n",
              "  'AuthorKeywords': ['Geovisualization,',\n",
              "   'hierarchical,',\n",
              "   'layout,',\n",
              "   'guidelines,',\n",
              "   'exploratory,',\n",
              "   'notation'],\n",
              "  'MultipartiteRank': [{'score': 0.08349441868661261, 'word': 'alternative'},\n",
              "   {'score': 0.08349441868661261, 'word': 'layouts'},\n",
              "   {'score': 0.07780471534786146, 'word': 'multiple'},\n",
              "   {'score': 0.058975756137616096, 'word': 'hierarchical'},\n",
              "   {'score': 0.058975756137616096, 'word': 'displays'},\n",
              "   {'score': 0.03975776393338118, 'word': 'temporal'},\n",
              "   {'score': 0.03975776393338118, 'word': 'characteristics'},\n",
              "   {'score': 0.03894990402673791, 'word': 'discrete'},\n",
              "   {'score': 0.03894990402673791, 'word': 'variable'},\n",
              "   {'score': 0.03894990402673791, 'word': 'values'},\n",
              "   {'score': 0.03885481132112354, 'word': 'aspects'}],\n",
              "  'Title': 'Configuring Hierarchical Layouts to Address Research Questions',\n",
              "  'distance': 0,\n",
              "  'no': '729',\n",
              "  'parent': '5375'},\n",
              " {'Abstract': \"We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.\",\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'graph',\n",
              "   'drawing,',\n",
              "   'network',\n",
              "   'layout,',\n",
              "   'radial',\n",
              "   'menus,',\n",
              "   'marking',\n",
              "   'menus,',\n",
              "   'hotbox,',\n",
              "   'biological',\n",
              "   'networks'],\n",
              "  'MultipartiteRank': [{'score': 0.0884359837404042, 'word': 'interaction'},\n",
              "   {'score': 0.0884359837404042, 'word': 'techniques'},\n",
              "   {'score': 0.05592108158998829, 'word': 'novel'},\n",
              "   {'score': 0.05282563540869268, 'word': 'various'},\n",
              "   {'score': 0.05282563540869268, 'word': 'commands'},\n",
              "   {'score': 0.047730729779014026, 'word': 'visualizations'},\n",
              "   {'score': 0.041609314844786076, 'word': 'networks'}],\n",
              "  'Title': 'Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '730',\n",
              "  'parent': '4294'},\n",
              " {'Abstract': 'With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.',\n",
              "  'AuthorKeywords': ['Exemplar,',\n",
              "   'large-scale',\n",
              "   'document',\n",
              "   'visualization,',\n",
              "   'multidimensional',\n",
              "   'projection'],\n",
              "  'MultipartiteRank': [{'score': 0.16921530281520697, 'word': 'text'},\n",
              "   {'score': 0.10095401416827815, 'word': 'visualization'},\n",
              "   {'score': 0.05427331046373274, 'word': 'corpus'},\n",
              "   {'score': 0.0508869053853313, 'word': 'data'},\n",
              "   {'score': 0.03707095598803181, 'word': 'documents'}],\n",
              "  'Title': 'Exemplar-based Visualization of Large Document Corpus',\n",
              "  'distance': 0,\n",
              "  'no': '731',\n",
              "  'parent': '4952'},\n",
              " {'Abstract': \"Transfer functions facilitate the volumetric data visualization by assigning optical properties to various data features and scalar values. Automation of transfer function specifications still remains a challenge in volume rendering. This paper presents an approach for automating transfer function generations by utilizing topological attributes derived from the contour tree of a volume. The contour tree acts as a visual index to volume segments, and captures associated topological attributes involved in volumetric data. A residue flow model based on Darcy's law is employed to control distributions of opacity between branches of the contour tree. Topological attributes are also used to control color selection in a perceptual color space and create harmonic color transfer functions. The generated transfer functions can depict inclusion relationship between structures and maximize opacity and color differences between them. The proposed approach allows efficient automation of transfer function generations, and exploration on the data to be carried out based on controlling of opacity residue flow rate instead of complex low-level transfer function parameter adjustments. Experiments on various data sets demonstrate the practical use of our approach in transfer function generations.\",\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   'Transfer',\n",
              "   'Function,',\n",
              "   'Contour',\n",
              "   'Tree,',\n",
              "   'Residue',\n",
              "   'Flow,',\n",
              "   'Harmonic',\n",
              "   'Color'],\n",
              "  'MultipartiteRank': [{'score': 0.17160854043999846, 'word': 'transfer'},\n",
              "   {'score': 0.17160854043999846, 'word': 'functions'},\n",
              "   {'score': 0.07961153351442204, 'word': 'volumetric'},\n",
              "   {'score': 0.07961153351442204, 'word': 'data'},\n",
              "   {'score': 0.07961153351442204, 'word': 'visualization'},\n",
              "   {'score': 0.0387127889655288, 'word': 'topological'},\n",
              "   {'score': 0.0387127889655288, 'word': 'attributes'},\n",
              "   {'score': 0.03671234790148324, 'word': 'contour'},\n",
              "   {'score': 0.03671234790148324, 'word': 'tree'},\n",
              "   {'score': 0.03254930607999273, 'word': 'automation'}],\n",
              "  'Title': 'Automatic Transfer Function Generation Using Contour Tree Controlled Residue Flow Model and Color Harmonics',\n",
              "  'distance': 0,\n",
              "  'no': '732',\n",
              "  'parent': '3935'},\n",
              " {'Abstract': 'This paper introduces a new streamline placement and selection algorithm for 3D vector fields. Instead of considering the problem as a simple feature search in data space, we base our work on the observation that most streamline fields generate a lot of self-occlusion which prevents proper visualization. In order to avoid this issue, we approach the problem in a view-dependent fashion and dynamically determine a set of streamlines which contributes to data understanding without cluttering the view. Since our technique couples flow characteristic criteria and view-dependent streamline selection we are able achieve the best of both worlds: relevant flow description and intelligible, uncluttered pictures. We detail an efficient GPU implementation of our algorithm, show comprehensive visual results on multiple datasets and compare our method with existing flow depiction techniques. Our results show that our technique greatly improves the readability of streamline visualizations on different datasets without requiring user intervention.',\n",
              "  'AuthorKeywords': ['Streamlines,', 'Vector', 'fields,', 'View-dependent'],\n",
              "  'MultipartiteRank': [{'score': 0.08411519692173469, 'word': 'new'},\n",
              "   {'score': 0.08411519692173469, 'word': 'streamline'},\n",
              "   {'score': 0.08411519692173469, 'word': 'placement'},\n",
              "   {'score': 0.05662018941220114, 'word': 'selection'},\n",
              "   {'score': 0.05662018941220114, 'word': 'algorithm'},\n",
              "   {'score': 0.05132390139123491, 'word': 'view'},\n",
              "   {'score': 0.0396382045668908, 'word': 'data'},\n",
              "   {'score': 0.0396382045668908, 'word': 'space'},\n",
              "   {'score': 0.03963426052133709, 'word': 'technique'},\n",
              "   {'score': 0.03963426052133709, 'word': 'couples'}],\n",
              "  'Title': 'View-Dependent Streamlines for 3D Vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '733',\n",
              "  'parent': '4480'},\n",
              " {'Abstract': 'We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.',\n",
              "  'AuthorKeywords': ['Focus+context',\n",
              "   'visualization,',\n",
              "   'metro',\n",
              "   'map,',\n",
              "   'octilinear',\n",
              "   'layout,',\n",
              "   'graph',\n",
              "   'labeling,',\n",
              "   'optimization'],\n",
              "  'MultipartiteRank': [{'score': 0.05509224937123723, 'word': 'best'},\n",
              "   {'score': 0.05509224937123723, 'word': 'route'},\n",
              "   {'score': 0.0484230273625404, 'word': 'stations'},\n",
              "   {'score': 0.04437674927141584, 'word': 'metro'},\n",
              "   {'score': 0.04437674927141584, 'word': 'map'},\n",
              "   {'score': 0.03958039955228643, 'word': 'arrival'},\n",
              "   {'score': 0.03958039955228643, 'word': 'time'},\n",
              "   {'score': 0.03198864982802356, 'word': 'graph'},\n",
              "   {'score': 0.03198864982802356, 'word': 'cuts'},\n",
              "   {'score': 0.03198864982802356, 'word': 'method'}],\n",
              "  'Title': 'Focus+Context Metro Maps',\n",
              "  'distance': 0,\n",
              "  'no': '734',\n",
              "  'parent': '4525'},\n",
              " {'Abstract': 'Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'parameter',\n",
              "   'space,',\n",
              "   'image',\n",
              "   'analysis,',\n",
              "   'sampling'],\n",
              "  'MultipartiteRank': [{'score': 0.09991479422522644, 'word': 'image'},\n",
              "   {'score': 0.09991479422522644, 'word': 'analysis'},\n",
              "   {'score': 0.09991479422522644, 'word': 'algorithms'},\n",
              "   {'score': 0.0677859512542323, 'word': 'parameter'},\n",
              "   {'score': 0.0677859512542323, 'word': 'settings'},\n",
              "   {'score': 0.06381317793800835, 'word': 'user'},\n",
              "   {'score': 0.06381317793800835, 'word': 'requirements'},\n",
              "   {'score': 0.050344792372895825, 'word': 'much'},\n",
              "   {'score': 0.050344792372895825, 'word': 'human'},\n",
              "   {'score': 0.050344792372895825, 'word': 'input'},\n",
              "   {'score': 0.045752737630332566, 'word': 'users'}],\n",
              "  'Title': 'Visualization of Parameter Space for Image Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '735',\n",
              "  'parent': '5469'},\n",
              " {'Abstract': 'Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.',\n",
              "  'AuthorKeywords': ['Performance',\n",
              "   'analysis;classification;usable',\n",
              "   'machine',\n",
              "   'learning'],\n",
              "  'MultipartiteRank': [{'score': 0.24492052693637642, 'word': 'performance'},\n",
              "   {'score': 0.24492052693637642, 'word': 'analysis'},\n",
              "   {'score': 0.10972640916071609, 'word': 'critical'},\n",
              "   {'score': 0.08558772935796664, 'word': 'applied'},\n",
              "   {'score': 0.08558772935796664, 'word': 'machine'},\n",
              "   {'score': 0.06858449004994832, 'word': 'models'},\n",
              "   {'score': 0.06858449004994832, 'word': 'practitioners'},\n",
              "   {'score': 0.047830978663867076, 'word': 'squares'}],\n",
              "  'Title': 'Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers',\n",
              "  'distance': 0,\n",
              "  'no': '736',\n",
              "  'parent': '3827'},\n",
              " {'Abstract': 'The authors describe the real-time acoustic display capabilities developed for the virtual environment workstation (VIEW) project. The acoustic display is capable of generating localized acoustic cues in real time over headphones. An auditor symbology, a related collection of representational auditory objects or icons, can be designed using the auditory cue editor, which links both discrete and continuously varying acoustic parameters with information or events in the display. During a given display scenario, the symbology can be dynamically coordinated in real time with three-dimensional visual objects, speech, and gestural displays. The types of displays feasible with the system range from simple warnings and alarms to the acoustic representation of multidimensional data or events.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.18468216967128503, 'word': 'acoustic'},\n",
              "   {'score': 0.1688268018574212, 'word': 'time'},\n",
              "   {'score': 0.14147295812066893, 'word': 'real'},\n",
              "   {'score': 0.1270343199276542, 'word': 'display'},\n",
              "   {'score': 0.1270343199276542, 'word': 'capabilities'},\n",
              "   {'score': 0.05764784974363082, 'word': 'cues'},\n",
              "   {'score': 0.04281966110604828, 'word': 'virtual'},\n",
              "   {'score': 0.04281966110604828, 'word': 'environment'},\n",
              "   {'score': 0.04281966110604828, 'word': 'workstation'}],\n",
              "  'Title': \"A system for three-dimensional acoustic 'visualization' in a virtual environment workstation\",\n",
              "  'distance': 0,\n",
              "  'no': '737',\n",
              "  'parent': '3852'},\n",
              " {'Abstract': 'We propose a probability model for the handling of complicated interactions between volumetric objects. In our model each volume is associated with a \"probability map\" that assigns a \"surface crossing\" probability to each space point according to local volume properties. The interaction between two volumes is then described by finding the intersecting regions between the volumes, and calculating the \"collision probabilities\" at each intersecting point from the surface crossing probabilities. To enable fast and efficient calculations, we introduce the concept of a distance map and develop two hierarchical collision detection algorithms, taking advantage of the uniform structure of volumetric datasets.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'virtual',\n",
              "   'reality,',\n",
              "   'volume',\n",
              "   'graphics,',\n",
              "   'volumetric',\n",
              "   'collision,',\n",
              "   'collision',\n",
              "   'probability,',\n",
              "   'surface',\n",
              "   'crossing',\n",
              "   'probability,',\n",
              "   'distance',\n",
              "   'map,',\n",
              "   'octree,',\n",
              "   'sphere',\n",
              "   'tree'],\n",
              "  'MultipartiteRank': [{'score': 0.15351651698255228, 'word': 'probability'},\n",
              "   {'score': 0.10525704286236578, 'word': 'volume'},\n",
              "   {'score': 0.08165837126637364, 'word': 'complicated'},\n",
              "   {'score': 0.08165837126637364, 'word': 'interactions'},\n",
              "   {'score': 0.0776704959783143, 'word': 'map'},\n",
              "   {'score': 0.07584602100423798, 'word': 'model'},\n",
              "   {'score': 0.06586863104925791, 'word': 'volumetric'},\n",
              "   {'score': 0.06586863104925791, 'word': 'objects'}],\n",
              "  'Title': 'Collision detection for volumetric objects',\n",
              "  'distance': 0,\n",
              "  'no': '738',\n",
              "  'parent': '3431'},\n",
              " {'Abstract': 'We introduce a new subdivision-surface wavelet transform for arbitrary two-manifolds with boundary that is the first to use simple lifting-style filtering operations with bicubic precision. We also describe a conversion process for re-mapping large-scale isosurfaces to have subdivision connectivity and fair parameterizations so that the new wavelet transform can be used for compression and visualization. The main idea enabling our wavelet transform is the circular symmetrization of the filters in irregular neighborhoods, which replaces the traditional separation of filters into two 1D passes. Our wavelet transform uses polygonal base meshes to represent surface topology, from which a Catmull-Clark-style subdivision hierarchy is generated. The details between these levels of resolution are quickly computed and compactly stored as wavelet coefficients. The isosurface conversion process begins with a contour triangulation computed using conventional techniques, which we subsequently simplify with a variant edge-collapse procedure, followed by an edge-removal process. This provides a coarse initial base mesh, which is subsequently refined, relaxed and attracted in phases to converge to the contour. The conversion is designed to produce smooth, untangled and minimally-skewed parameterizations which improves the subsequent compression after applying the transform. We have demonstrated our conversion and transform for an isosurface obtained from a high-resolution turbulent-mixing hydrodynamics simulation, showing the potential for compression and level-of-detail visualization.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0806890275801709, 'word': 'surface'},\n",
              "   {'score': 0.0806890275801709, 'word': 'wavelet'},\n",
              "   {'score': 0.0806890275801709, 'word': 'transform'},\n",
              "   {'score': 0.046360201852272055, 'word': 'new'},\n",
              "   {'score': 0.046360201852272055, 'word': 'subdivision'},\n",
              "   {'score': 0.03797977655104887, 'word': 'conversion'},\n",
              "   {'score': 0.03797977655104887, 'word': 'process'},\n",
              "   {'score': 0.03355284298806639, 'word': 'style'},\n",
              "   {'score': 0.0322584116868117, 'word': 'arbitrary'}],\n",
              "  'Title': 'Bicubic subdivision-surface wavelets for large-scale isosurface representation and visualization',\n",
              "  'distance': 0,\n",
              "  'no': '739',\n",
              "  'parent': '5758'},\n",
              " {'Abstract': \"Most systems used for creating and displaying colormap-based visualizations are not photometrically calibrated. That is, the relationship between RGB input levels and perceived luminance is usually not known, due to variations in the monitor, hardware configuration, and the viewing environment. However, the luminance component of perceptually based colormaps should be controlled, due to the central role that luminance plays in our visual processing. We address this problem with a simple and effective method for performing luminance matching on an uncalibrated monitor. The method is akin to the minimally distinct border technique (a previous method of luminance matching used for measuring luminous efficiency), but our method relies on the brain's highly developed ability to distinguish human faces. We present a user study showing that our method produces equivalent results to the minimally distinct border technique, but with significantly improved precision. We demonstrate how results from our luminance matching method can be directly applied to create new univariate colormaps.\",\n",
              "  'AuthorKeywords': ['Colormaps,',\n",
              "   'Color',\n",
              "   'Scales,',\n",
              "   'Isoluminance,',\n",
              "   'Brightness',\n",
              "   'Matching,',\n",
              "   'Perceptually-based',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.14174748506978654, 'word': 'method'},\n",
              "   {'score': 0.12328344209787728, 'word': 'luminance'},\n",
              "   {'score': 0.0938835668844886, 'word': 'effective'},\n",
              "   {'score': 0.0543880278364704, 'word': 'monitor'},\n",
              "   {'score': 0.049497091132710475, 'word': 'colormap'}],\n",
              "  'Title': 'Face-based luminance matching for perceptual colormap generation',\n",
              "  'distance': 0,\n",
              "  'no': '740',\n",
              "  'parent': '4518'},\n",
              " {'Abstract': 'We present a hardware-accelerated method for visualizing 3D flow fields. The method is based on insertion, advection, and decay of dye. To this aim, we extend the texture-based IBFV technique presented by van Wijk (2001) for 2D flow visualization in two main directions. First, we decompose the 3D flow visualization problem in a series of 2D instances of the mentioned IBFV technique. This makes our method benefit from the hardware acceleration the original IBFV technique introduced. Secondly, we extend the concept of advected gray value (or color) noise by introducing opacity (or matter) noise. This allows us to produce sparse 3D noise pattern advections, thus address the occlusion problem inherent to 3D flow visualization. Overall, the presented method delivers interactively animated 3D flow, uses only standard OpenGL 1.1 calls and 2D textures, and is simple to understand and implement.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'Visualization,',\n",
              "   'Hardware',\n",
              "   'Acceleration,',\n",
              "   'Texture',\n",
              "   'Advection,',\n",
              "   'OpenGL'],\n",
              "  'MultipartiteRank': [{'score': 0.10248891785908298, 'word': 'method'},\n",
              "   {'score': 0.09907252798347772, 'word': '3d'},\n",
              "   {'score': 0.09907252798347772, 'word': 'flow'},\n",
              "   {'score': 0.09907252798347772, 'word': 'fields'},\n",
              "   {'score': 0.06003689020342654, 'word': 'ibfv'},\n",
              "   {'score': 0.06003689020342654, 'word': 'technique'},\n",
              "   {'score': 0.05086865009944029, 'word': 'hardware'},\n",
              "   {'score': 0.04127678203481736, 'word': 'noise'}],\n",
              "  'Title': '3D IBFV: hardware-accelerated 3D flow visualization',\n",
              "  'distance': 0,\n",
              "  'no': '741',\n",
              "  'parent': '3780'},\n",
              " {'Abstract': 'Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.',\n",
              "  'AuthorKeywords': ['Non-linear',\n",
              "   'Filtering,',\n",
              "   'Segmentation,',\n",
              "   'Hardware',\n",
              "   'Acceleration'],\n",
              "  'MultipartiteRank': [{'score': 0.06076570699410161, 'word': 'vertex'},\n",
              "   {'score': 0.06076570699410161, 'word': 'program'},\n",
              "   {'score': 0.04962801844069302, 'word': 'performance'},\n",
              "   {'score': 0.049038687345135834, 'word': 'volume'},\n",
              "   {'score': 0.049038687345135834, 'word': 'analysis'},\n",
              "   {'score': 0.04503785628553606, 'word': 'fragment'},\n",
              "   {'score': 0.04503785628553606, 'word': 'stages'},\n",
              "   {'score': 0.04102882151694437, 'word': 'operator'},\n",
              "   {'score': 0.04102882151694437, 'word': 'mask'}],\n",
              "  'Title': 'Hardware-based nonlinear filtering and segmentation using high-level shading languages',\n",
              "  'distance': 0,\n",
              "  'no': '742',\n",
              "  'parent': '4237'},\n",
              " {'Abstract': 'The physical interpretation of mathematical features of tensor fields is highly application-specific. Existing visualization methods for tensor fields only cover a fraction of the broad application areas. We present a visualization method tailored specifically to the class of tensor field exhibiting properties similar to stress and strain tensors, which are commonly encountered in geomechanics. Our technique is a global method that represents the physical meaning of these tensor fields with their central features: regions of compression or expansion. The method is based on two steps: first, we define a positive definite metric, with the same topological structure as the tensor field; second, we visualize the resulting metric. The eigenvector fields are represented using a texture-based approach resembling line integral convolution (LIC) methods. The eigenvalues of the metric are encoded in free parameters of the texture definition. Our method supports an intuitive distinction between positive and negative eigenvalues. We have applied our method to synthetic and some standard data sets, and \"real\" data from earth science and mechanical engineering application.',\n",
              "  'AuthorKeywords': ['tensors',\n",
              "   'field,',\n",
              "   'stress',\n",
              "   'tensor,',\n",
              "   'strain',\n",
              "   'tensor,',\n",
              "   'LIC'],\n",
              "  'MultipartiteRank': [{'score': 0.10514246474245845, 'word': 'tensor'},\n",
              "   {'score': 0.10514246474245845, 'word': 'fields'},\n",
              "   {'score': 0.0943859141608041, 'word': 'visualization'},\n",
              "   {'score': 0.0943859141608041, 'word': 'methods'},\n",
              "   {'score': 0.05329150711741395, 'word': 'application'},\n",
              "   {'score': 0.04747733228147189, 'word': 'mathematical'},\n",
              "   {'score': 0.04747733228147189, 'word': 'features'},\n",
              "   {'score': 0.04504983422357021, 'word': 'physical'},\n",
              "   {'score': 0.04504983422357021, 'word': 'interpretation'}],\n",
              "  'Title': 'Physically based methods for tensor field visualization',\n",
              "  'distance': 0,\n",
              "  'no': '743',\n",
              "  'parent': '4606'},\n",
              " {'Abstract': 'We present a visual analysis and exploration of fluid flow through a cooling jacket. Engineers invest a large amount of time and serious effort to optimize the flow through this engine component because of its important role in transferring heat away from the engine block. In this study we examine the design goals that engineers apply in order to construct an ideal-as-possible cooling jacket geometry and use a broad range of visualization tools in order to analyze, explore, and present the results. We systematically employ direct, geometric, and texture-based flow visualization techniques as well as automatic feature extraction and interactive feature-based methodology. And we discuss the relative advantages and disadvantages of these approaches as well as the challenges, both technical and perceptual with this application. The result is a feature-rich state-of-the-art flow visualization analysis applied to an important and complex data set from real-world computational fluid dynamics simulations.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'feature-extraction,',\n",
              "   'feature-based',\n",
              "   'visualization,',\n",
              "   'computational',\n",
              "   'fluid',\n",
              "   'dynamics',\n",
              "   '(CFD),',\n",
              "   'cooling',\n",
              "   'jacket,',\n",
              "   'visualization',\n",
              "   'systems,',\n",
              "   'engine',\n",
              "   'simulation,heat',\n",
              "   'transfer'],\n",
              "  'MultipartiteRank': [{'score': 0.07542470314243285, 'word': 'engineers'},\n",
              "   {'score': 0.0745366543331186, 'word': 'visual'},\n",
              "   {'score': 0.0745366543331186, 'word': 'analysis'},\n",
              "   {'score': 0.051933664222094326, 'word': 'fluid'},\n",
              "   {'score': 0.051933664222094326, 'word': 'flow'},\n",
              "   {'score': 0.04579842837934291, 'word': 'jacket'},\n",
              "   {'score': 0.04063875167331126, 'word': 'exploration'}],\n",
              "  'Title': 'Visual analysis and exploration of fluid flow in a cooling jacket',\n",
              "  'distance': 0,\n",
              "  'no': '744',\n",
              "  'parent': '4205'},\n",
              " {'Abstract': 'Treemaps provide an interesting solution for representing hierarchical data. However, most studies have mainly focused on layout algorithms and paid limited attention to the interaction with treemaps. This makes it difficult to explore large data sets and to get access to details, especially to those related to the leaves of the trees. We propose the notion of zoomable treemaps (ZTMs), an hybridization between treemaps and zoomable user interfaces that facilitates the navigation in large hierarchical data sets. By providing a consistent set of interaction techniques, ZTMs make it possible for users to browse through very large data sets (e.g., 700,000 nodes dispatched amongst 13 levels). These techniques use the structure of the displayed data to guide the interaction and provide a way to improve interactive navigation in treemaps.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'multi-scale',\n",
              "   'interaction,',\n",
              "   'structure-aware',\n",
              "   'navigation,',\n",
              "   'zoomable',\n",
              "   'treemaps'],\n",
              "  'MultipartiteRank': [{'score': 0.10248176660722481, 'word': 'hierarchical'},\n",
              "   {'score': 0.10248176660722481, 'word': 'data'},\n",
              "   {'score': 0.09199715690544336, 'word': 'treemaps'},\n",
              "   {'score': 0.058096434799352226, 'word': 'interaction'},\n",
              "   {'score': 0.04888287291565395, 'word': 'ztms'},\n",
              "   {'score': 0.047609116734252985, 'word': 'zoomable'},\n",
              "   {'score': 0.047609116734252985, 'word': 'user'},\n",
              "   {'score': 0.047609116734252985, 'word': 'interfaces'}],\n",
              "  'Title': 'Browsing Zoomable Treemaps: Structure-Aware Multi-Scale Navigation Techniques',\n",
              "  'distance': 0,\n",
              "  'no': '745',\n",
              "  'parent': '3728'},\n",
              " {'Abstract': 'Cluster analysis (CA) is a powerful strategy for the exploration of high-dimensional data in the absence of a-priori hypotheses or data classification models, and the results of CA can then be used to form such models. But even though formal models and classification rules may not exist in these data exploration scenarios, domain scientists and experts generally have a vast amount of non-compiled knowledge and intuition that they can bring to bear in this effort. In CA, there are various popular mechanisms to generate the clusters, however, the results from their non- supervised deployment rarely fully agree with this expert knowledge and intuition. To this end, our paper describes a comprehensive and intuitive framework to aid scientists in the derivation of classification hierarchies in CA, using k-means as the overall clustering engine, but allowing them to tune its parameters interactively based on a non-distorted compact visual presentation of the inherent characteristics of the data in high- dimensional space. These include cluster geometry, composition, spatial relations to neighbors, and others. In essence, we provide all the tools necessary for a high-dimensional activity we call cluster sculpting, and the evolving hierarchy can then be viewed in a space-efficient radial dendrogram. We demonstrate our system in the context of the mining and classification of a large collection of millions of data items of aerosol mass spectra, but our framework readily applies to any high-dimensional CA scenario.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'High-Dimensional',\n",
              "   'Data,',\n",
              "   'Visual',\n",
              "   'Data',\n",
              "   'Mining,',\n",
              "   'Visualization',\n",
              "   'in',\n",
              "   'Earth/Space/',\n",
              "   'and',\n",
              "   'Environmental',\n",
              "   'Sciences'],\n",
              "  'MultipartiteRank': [{'score': 0.09843044267757245, 'word': 'data'},\n",
              "   {'score': 0.08182653043221727, 'word': 'cluster'},\n",
              "   {'score': 0.08182653043221727, 'word': 'analysis'},\n",
              "   {'score': 0.05254311964551594, 'word': 'classification'},\n",
              "   {'score': 0.05254311964551594, 'word': 'models'},\n",
              "   {'score': 0.049634806620742086, 'word': 'high'},\n",
              "   {'score': 0.04588732303205652, 'word': 'dimensional'},\n",
              "   {'score': 0.043573289357199965, 'word': 'exploration'}],\n",
              "  'Title': 'ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data',\n",
              "  'distance': 0,\n",
              "  'no': '746',\n",
              "  'parent': '4662'},\n",
              " {'Abstract': 'Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown sub- populations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type.',\n",
              "  'AuthorKeywords': ['Web',\n",
              "   'session',\n",
              "   'log',\n",
              "   'analysis,',\n",
              "   'visual',\n",
              "   'exploratory',\n",
              "   'data',\n",
              "   'analysis,',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08613346501045596, 'word': 'session'},\n",
              "   {'score': 0.08613346501045596, 'word': 'viewer'},\n",
              "   {'score': 0.08443826697487693, 'word': 'data'},\n",
              "   {'score': 0.061710128339066445, 'word': 'statistical'},\n",
              "   {'score': 0.061710128339066445, 'word': 'methods'},\n",
              "   {'score': 0.06107585598958348, 'word': 'multiple'},\n",
              "   {'score': 0.056457285182327316, 'word': 'detailed'},\n",
              "   {'score': 0.056457285182327316, 'word': 'analyses'}],\n",
              "  'Title': 'Session Viewer: Visual Exploratory Analysis of Web Session Logs',\n",
              "  'distance': 0,\n",
              "  'no': '747',\n",
              "  'parent': '3926'},\n",
              " {'Abstract': \"We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.\",\n",
              "  'AuthorKeywords': ['Cardiac',\n",
              "   'MRI,',\n",
              "   'late',\n",
              "   'enhancement,',\n",
              "   'viability,',\n",
              "   \"bull's\",\n",
              "   'eye',\n",
              "   'plot'],\n",
              "  'MultipartiteRank': [{'score': 0.10298121232927461, 'word': 'comprehensive'},\n",
              "   {'score': 0.10298121232927461, 'word': 'visualization'},\n",
              "   {'score': 0.10298121232927461, 'word': 'techniques'},\n",
              "   {'score': 0.05915170347983236, 'word': 'coronary'},\n",
              "   {'score': 0.05915170347983236, 'word': 'artery'},\n",
              "   {'score': 0.05915170347983236, 'word': 'disease'},\n",
              "   {'score': 0.05463930682804723, 'word': 'eye'},\n",
              "   {'score': 0.05463930682804723, 'word': 'plot'},\n",
              "   {'score': 0.052880621642461885, 'word': 'bull'},\n",
              "   {'score': 0.04722535246148722, 'word': 'diagnosis'}],\n",
              "  'Title': 'CoViCAD: Comprehensive Visualization of Coronary Artery Disease',\n",
              "  'distance': 0,\n",
              "  'no': '748',\n",
              "  'parent': '3993'},\n",
              " {'Abstract': 'The speed of data retrieval qualitatively affects how analysts visually explore and analyze their data. To ensure smooth interactions in massive time series datasets, one needs to address the challenges of computing &lt;i&gt;ad&lt;/i&gt; &lt;i&gt;hoc&lt;/i&gt; queries, distributing query load, and hiding system latency. In this paper, we present ATLAS, a visualization tool for temporal data that addresses these issues using a combination of high performance database technology, predictive caching, and level of detail management. We demonstrate ATLAS using commodity hardware on a network traffic dataset of more than a billion records.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11191475741401631, 'word': 'data'},\n",
              "   {'score': 0.11191475741401631, 'word': 'retrieval'},\n",
              "   {'score': 0.06306467621262321, 'word': 'atlas'},\n",
              "   {'score': 0.05780932461062103, 'word': 'speed'},\n",
              "   {'score': 0.05140465294632048, 'word': 'queries'},\n",
              "   {'score': 0.04440249249022838, 'word': 'analysts'}],\n",
              "  'Title': 'Maintaining interactivity while exploring massive time series',\n",
              "  'distance': 0,\n",
              "  'no': '749',\n",
              "  'parent': '3416'},\n",
              " {'Abstract': 'Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.',\n",
              "  'AuthorKeywords': ['Unsteady',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'streak',\n",
              "   'surfaces,',\n",
              "   'smoke',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.19435285257966678, 'word': 'smoke'},\n",
              "   {'score': 0.19435285257966678, 'word': 'rendering'},\n",
              "   {'score': 0.08809662436846487, 'word': 'standard'},\n",
              "   {'score': 0.08809662436846487, 'word': 'technique'},\n",
              "   {'score': 0.05767746764905725, 'word': 'flow'},\n",
              "   {'score': 0.05767746764905725, 'word': 'visualization'},\n",
              "   {'score': 0.05469767327418884, 'word': 'representation'},\n",
              "   {'score': 0.05033291103446888, 'word': 'streak'},\n",
              "   {'score': 0.05033291103446888, 'word': 'surface'},\n",
              "   {'score': 0.05033291103446888, 'word': 'integration'}],\n",
              "  'Title': 'Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments',\n",
              "  'distance': 0,\n",
              "  'no': '750',\n",
              "  'parent': '3573'},\n",
              " {'Abstract': 'Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.',\n",
              "  'AuthorKeywords': ['4D',\n",
              "   'MRI',\n",
              "   'blood-flow,',\n",
              "   'Probing,',\n",
              "   'Flow',\n",
              "   'visualization,',\n",
              "   'Illustrative',\n",
              "   'visualization,',\n",
              "   'Phase-contrast',\n",
              "   'cine',\n",
              "   'MRI'],\n",
              "  'MultipartiteRank': [{'score': 0.12341916027355185, 'word': 'flow'},\n",
              "   {'score': 0.10239420069258792, 'word': 'blood'},\n",
              "   {'score': 0.046147713771689844, 'word': 'dynamics'},\n",
              "   {'score': 0.03388485643600784, 'word': 'visualization'},\n",
              "   {'score': 0.03388485643600784, 'word': 'styles'},\n",
              "   {'score': 0.026376700599839608, 'word': 'field'}],\n",
              "  'Title': 'Exploration of 4D MRI Blood Flow using Stylistic Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '751',\n",
              "  'parent': '4745'},\n",
              " {'Abstract': 'This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.',\n",
              "  'AuthorKeywords': ['Petascale',\n",
              "   'volume',\n",
              "   'exploration,',\n",
              "   'high-resolution',\n",
              "   'microscopy,',\n",
              "   'high-throughput',\n",
              "   'imaging,',\n",
              "   'neuroscience'],\n",
              "  'MultipartiteRank': [{'score': 0.0671431823650751, 'word': 'system'},\n",
              "   {'score': 0.06236865719479541, 'word': 'data'},\n",
              "   {'score': 0.06236865719479541, 'word': 'acquisition'},\n",
              "   {'score': 0.04671159648647743, 'word': 'ray'},\n",
              "   {'score': 0.044659801384616754, 'word': 'continuous'},\n",
              "   {'score': 0.044659801384616754, 'word': 'stream'},\n",
              "   {'score': 0.04287466813549291, 'word': 'petascale'},\n",
              "   {'score': 0.04287466813549291, 'word': 'volumes'}],\n",
              "  'Title': 'Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach',\n",
              "  'distance': 0,\n",
              "  'no': '752',\n",
              "  'parent': '5114'},\n",
              " {'Abstract': \"Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.\",\n",
              "  'AuthorKeywords': ['Text', 'visualization,', 'topic', 'modeling'],\n",
              "  'MultipartiteRank': [{'score': 0.07865328286818482, 'word': 'multiple'},\n",
              "   {'score': 0.07865328286818482, 'word': 'levels'},\n",
              "   {'score': 0.05687665577116498, 'word': 'information'},\n",
              "   {'score': 0.04743546140191714, 'word': 'large'},\n",
              "   {'score': 0.04743546140191714, 'word': 'text'},\n",
              "   {'score': 0.04743546140191714, 'word': 'corpus'},\n",
              "   {'score': 0.03668171392326108, 'word': 'exploration'},\n",
              "   {'score': 0.03573309023135363, 'word': 'discovery'}],\n",
              "  'Title': 'Serendip: Topic Model-Driven Visual Exploration of Text Corpora',\n",
              "  'distance': 0,\n",
              "  'no': '753',\n",
              "  'parent': '5135'},\n",
              " {'Abstract': 'Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.',\n",
              "  'AuthorKeywords': ['Progressive',\n",
              "   'visual',\n",
              "   'analytics,deep',\n",
              "   'neural',\n",
              "   'networks,machine',\n",
              "   'learning'],\n",
              "  'MultipartiteRank': [{'score': 0.1667207666988598, 'word': 'deep'},\n",
              "   {'score': 0.1667207666988598, 'word': 'neural'},\n",
              "   {'score': 0.1667207666988598, 'word': 'networks'},\n",
              "   {'score': 0.05665935629875416, 'word': 'layers'},\n",
              "   {'score': 0.05156163655526412, 'word': 'human'},\n",
              "   {'score': 0.05156163655526412, 'word': 'accuracy'},\n",
              "   {'score': 0.05085762642336596, 'word': 'features'},\n",
              "   {'score': 0.042170563552975354, 'word': 'several'},\n",
              "   {'score': 0.042170563552975354, 'word': 'pattern'},\n",
              "   {'score': 0.042170563552975354, 'word': 'recognition'},\n",
              "   {'score': 0.042170563552975354, 'word': 'problems'}],\n",
              "  'Title': 'DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks',\n",
              "  'distance': 0,\n",
              "  'no': '754',\n",
              "  'parent': '4650'},\n",
              " {'Abstract': 'Navigation in computer generated information spaces may be difficult, resulting in users getting \"lost in hyperspace\". This work aims to build on research from the area of city planning to try to solve this problem. We introduce the concepts of legibility and cognitive maps and the five features of urban landscape with which they are associated. Following this will be descriptions of techniques and algorithms which we have developed to allow these features to be introduced to three dimensional spaces for information visualisation. Next we describe a specific application of these techniques in the visualisation of the World Wide Web and conclude with a look at future development of the system.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1274337065581863, 'word': 'information'},\n",
              "   {'score': 0.07597250236953872, 'word': 'spaces'},\n",
              "   {'score': 0.05724030498006868, 'word': 'techniques'},\n",
              "   {'score': 0.05239435052216616, 'word': 'features'},\n",
              "   {'score': 0.0514612041886476, 'word': 'visualisation'},\n",
              "   {'score': 0.04860796255427774, 'word': 'computer'}],\n",
              "  'Title': 'Legibility enhancement for information visualisation',\n",
              "  'distance': 0,\n",
              "  'no': '755',\n",
              "  'parent': '4720'},\n",
              " {'Abstract': \"The National Library of Medicine is creating a digital atlas of the human body. This project, called the Visible Human, has already produced computed tomography, magnetic resonance imaging and physical cross-sections of a human male cadaver. This paper describes a methodology and results for extracting surfaces from the Visible Male's CT data. We use surface connectivity and isosurface extraction techniques to create polygonal models of the skin, bone, muscle and bowels. We also report early experiments with the physical cross-sections.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07622119932676273, 'word': 'surfaces'},\n",
              "   {'score': 0.06387394559622042, 'word': 'human'},\n",
              "   {'score': 0.06387394559622042, 'word': 'body'},\n",
              "   {'score': 0.05130763542287552, 'word': 'results'},\n",
              "   {'score': 0.04977269380439228, 'word': 'visible'},\n",
              "   {'score': 0.04977269380439228, 'word': 'male'},\n",
              "   {'score': 0.04911239257914177, 'word': 'methodology'}],\n",
              "  'Title': 'Marching through the Visible Man',\n",
              "  'distance': 0,\n",
              "  'no': '756',\n",
              "  'parent': '3491'},\n",
              " {'Abstract': 'Transparency can be a useful device for simultaneously depicting multiple superimposed layers of information in a single image. However, in computer-generated pictures-as in photographs and in directly viewed actual objects-it can often be difficult to adequately perceive the three-dimensional shape of a layered transparent surface or its relative depth distance from underlying structures. Inspired by artists\\' use of line to show shape, we have explored methods for automatically defining a distributed set of opaque surface markings that intend to portray the three-dimensional shape and relative depth of a smoothly curving layered transparent surface in an intuitively meaningful (and minimally occluding) way. This paper describes the perceptual motivation, artistic inspiration and practical implementation of an algorithm for \"texturing\" a transparent surface with uniformly distributed opaque short strokes, locally oriented in the direction of greatest normal curvature, and of length proportional to the magnitude of the surface curvature in the stroke direction. The driving application for this work is the visualization of layered surfaces in radiation therapy treatment planning data, and the technique is illustrated on transparent isointensity surfaces of radiation dose.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08106142062497601, 'word': 'layered'},\n",
              "   {'score': 0.08106142062497601, 'word': 'transparent'},\n",
              "   {'score': 0.08106142062497601, 'word': 'surface'},\n",
              "   {'score': 0.05456810575287752, 'word': 'dimensional'},\n",
              "   {'score': 0.05456810575287752, 'word': 'shape'},\n",
              "   {'score': 0.046888120939171093, 'word': 'useful'},\n",
              "   {'score': 0.046888120939171093, 'word': 'device'},\n",
              "   {'score': 0.04368978523407524, 'word': 'relative'},\n",
              "   {'score': 0.04368978523407524, 'word': 'depth'},\n",
              "   {'score': 0.04368978523407524, 'word': 'distance'},\n",
              "   {'score': 0.04117017096894207, 'word': 'artists'}],\n",
              "  'Title': 'Illustrating transparent surfaces with curvature-directed strokes',\n",
              "  'distance': 0,\n",
              "  'no': '757',\n",
              "  'parent': '3914'},\n",
              " {'Abstract': 'This paper presents efficient image-based rendering techniques used in the context of an architectural walkthrough system. Portals (doors and windows) are rendered by warping layered depth images (LDIs). In a preprocessing phase, for every portal, a number of pre-rendered images are combined into an LDI. The resulting LDI stores, exactly once, all surfaces visible in at least one of the images used in the construction, so most of the exposure errors are efficiently eliminated. The LDI can be warped in the McMillan occlusion compatible ordering. A substantial increase in performance is obtained by warping in parallel. Our parallelization scheme achieves good load balancing, scales with the number of processors, and preserves the occlusion compatible ordering. A fast, conservative reference-image-space clipping algorithm also reduces the warping effort.',\n",
              "  'AuthorKeywords': ['image-based',\n",
              "   'rendering,',\n",
              "   'parallel',\n",
              "   'warping,',\n",
              "   'occlusion',\n",
              "   'compatible',\n",
              "   'ordering',\n",
              "   'for',\n",
              "   'discrete',\n",
              "   'images,',\n",
              "   'portal,',\n",
              "   'cell,',\n",
              "   'exposure',\n",
              "   'error,',\n",
              "   'layered',\n",
              "   'depth',\n",
              "   'image,',\n",
              "   'clipping,',\n",
              "   'architectural',\n",
              "   'walkthrough'],\n",
              "  'MultipartiteRank': [{'score': 0.10022303218389104, 'word': 'efficient'},\n",
              "   {'score': 0.10022303218389104, 'word': 'image'},\n",
              "   {'score': 0.05271074845600239, 'word': 'portals'},\n",
              "   {'score': 0.05009498730090159, 'word': 'ldi'},\n",
              "   {'score': 0.046616471732907054, 'word': 'mcmillan'},\n",
              "   {'score': 0.046616471732907054, 'word': 'occlusion'},\n",
              "   {'score': 0.046616471732907054, 'word': 'compatible'},\n",
              "   {'score': 0.046616471732907054, 'word': 'ordering'},\n",
              "   {'score': 0.04341597329083363, 'word': 'paper'}],\n",
              "  'Title': 'Efficient warping for architectural walkthroughs using layered depth images',\n",
              "  'distance': 0,\n",
              "  'no': '758',\n",
              "  'parent': '3965'},\n",
              " {'Abstract': 'We propose a novel approach for segmentation and digital cleansing of endoscopic organs. Our method can be used for a variety of segmentation needs with little or no modification. It aims at fulfilling the dual and often conflicting requirements of a fast and accurate segmentation and also eliminates the undesirable partial volume effect which contemporary approaches cannot. For segmentation and digital cleansing, we use the peculiar characteristics exhibited by the intersection of any two distinct-intensity regions. To detect these intersections we cast rays through the volume, which we call the segmentation rays as they assist in the segmentation. We then associate a certain task of reconstruction and classification with each intersection the ray detects. We further use volumetric contrast enhancement to reconstruct surface lost by segmentation (if any), which aids in improving the quality of the volume rendering.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Segmentation,',\n",
              "   'Segmentation',\n",
              "   'Rays,',\n",
              "   'Partial',\n",
              "   'Volume',\n",
              "   'Voxels,',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   'Virtual',\n",
              "   'Endoscopy,',\n",
              "   'Virtual',\n",
              "   'Colonoscopy'],\n",
              "  'MultipartiteRank': [{'score': 0.12459978950781626, 'word': 'segmentation'},\n",
              "   {'score': 0.07218934387197089, 'word': 'intersection'},\n",
              "   {'score': 0.062169416687619376, 'word': 'rays'},\n",
              "   {'score': 0.05473090221736982, 'word': 'digital'},\n",
              "   {'score': 0.05473090221736982, 'word': 'cleansing'},\n",
              "   {'score': 0.050344494857881894, 'word': 'reconstruction'}],\n",
              "  'Title': '3D digital cleansing using segmentation rays',\n",
              "  'distance': 0,\n",
              "  'no': '759',\n",
              "  'parent': '4305'},\n",
              " {'Abstract': 'We present CEASAR, a centerline extraction algorithm that delivers smooth, accurate and robust results. Centerlines are needed for accurate measurements of length along winding tubular structures. Centerlines are also required in automatic virtual navigation through human organs, such as the colon or the aorta, as they are used to control movement and orientation of the virtual camera. We introduce a concise but general definition of a centerline, and provide an algorithm that finds the centerline accurately and rapidly. Our algorithm is provably correct for general geometries. Our solution is fully automatic, which frees the user from having to engage in data preprocessing. For a number of test datasets, we show the smooth and accurate centerlines computed by our CEASAR algorithm on a single 194 MHz MIPS R10000 CPU within five minutes.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1561680882927649, 'word': 'algorithm'},\n",
              "   {'score': 0.10990026675781224, 'word': 'centerline'},\n",
              "   {'score': 0.10990026675781224, 'word': 'extraction'},\n",
              "   {'score': 0.07709402654414504, 'word': 'accurate'},\n",
              "   {'score': 0.06973317742388574, 'word': 'centerlines'},\n",
              "   {'score': 0.06158104926176193, 'word': 'smooth'}],\n",
              "  'Title': 'CEASAR: a smooth, accurate and robust centerline extraction algorithm',\n",
              "  'distance': 0,\n",
              "  'no': '760',\n",
              "  'parent': '4110'},\n",
              " {'Abstract': 'We present a novel disk-based multiresolution triangle mesh data structure that supports paging and view-dependent rendering of very large meshes at interactive frame rates from external memory. Our approach, called XFastMesh, is based on a view-dependent mesh simplification framework that represents half-edge collapse operations in a binary hierarchy known as a merge-tree forest. The proposed technique partitions the merge-tree forest into so-called detail blocks, which consist of binary subtrees, that are stored on disk. We present an efficient external memory data structure and file format that stores all detail information of the multiresolution triangulation method using significantly less storage then previously reported approaches. Furthermore, we present a paging algorithm that provides efficient loading and interactive rendering of large meshes from external memory at varying and view-dependent level-of-detail. The presented approach is highly efficient both in terms of space cost and paging performance.',\n",
              "  'AuthorKeywords': ['level-of-detail,',\n",
              "   'multiresolution',\n",
              "   'modeling,',\n",
              "   'out-of-core',\n",
              "   'rendering,',\n",
              "   'interactive',\n",
              "   'large-scale',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.06715402898505188, 'word': 'view'},\n",
              "   {'score': 0.06124354091867237, 'word': 'external'},\n",
              "   {'score': 0.06124354091867237, 'word': 'memory'},\n",
              "   {'score': 0.0495642906335804, 'word': 'approach'},\n",
              "   {'score': 0.04922952852987132, 'word': 'large'},\n",
              "   {'score': 0.04922952852987132, 'word': 'meshes'},\n",
              "   {'score': 0.04511828190605705, 'word': 'dependent'},\n",
              "   {'score': 0.04511828190605705, 'word': 'rendering'}],\n",
              "  'Title': 'XFastMesh: fast view-dependent meshing from external memory',\n",
              "  'distance': 0,\n",
              "  'no': '761',\n",
              "  'parent': '3813'},\n",
              " {'Abstract': \"We present a novel family of data-driven linear transformations, aimed at visualizing multivariate data in a low-dimensional space in a way that optimally preserves the structure of the data. The well-studied PCA and Fisher's LDA (linear discriminant analysis) are shown to be special members in this family of transformations, and we demonstrate how to generalize these two methods such as to enhance their performance. Furthermore, our technique is the only one, to the best of our knowledge, that reflects in the resulting embedding both the data coordinates and pairwise similarities and/or dissimilarities between the data elements. Even more so, when information on the clustering (labeling) decomposition of the data is known, this information can be integrated in the linear transformation, resulting in embeddings that clearly show the separation between the clusters, as well as their infrastructure. All this makes our technique very flexible and powerful, and lets us cope with kinds of data that other techniques fail to describe properly.\",\n",
              "  'AuthorKeywords': ['visualization,',\n",
              "   'dimensionality-reduction,',\n",
              "   'projection,',\n",
              "   'principal',\n",
              "   'component',\n",
              "   'analysis,',\n",
              "   \"Fisher's\",\n",
              "   'linear',\n",
              "   'discriminant',\n",
              "   'analysis,',\n",
              "   'eigenprojection,',\n",
              "   'classification'],\n",
              "  'MultipartiteRank': [{'score': 0.13278068628444875, 'word': 'data'},\n",
              "   {'score': 0.06124772262727668, 'word': 'linear'},\n",
              "   {'score': 0.06124772262727668, 'word': 'transformations'},\n",
              "   {'score': 0.047192094057386766, 'word': 'novel'},\n",
              "   {'score': 0.047192094057386766, 'word': 'family'},\n",
              "   {'score': 0.045528278913294584, 'word': 'clustering'},\n",
              "   {'score': 0.04121460884226504, 'word': 'information'}],\n",
              "  'Title': 'Visualization of Labeled Data Using Linear Transformation',\n",
              "  'distance': 0,\n",
              "  'no': '762',\n",
              "  'parent': '5243'},\n",
              " {'Abstract': '2D and 3D views are used together in many visualization domains, such as medical imaging, flow visualization, oceanographic visualization, and computer aided design (CAD). Combining these views into one display can be done by: (1) orientation icon (i.e., separate windows), (2) in-place methods (e.g., clip and cutting planes), and (3) a new method called ExoVis. How 2D and 3D views are displayed affects ease of mental registration (understanding the spatial relationship between views), an important factor influencing user performance. This paper compares the above methods in terms of their ability to support mental registration. Empirical results show that mental registration is significantly easier with in-place displays than with ExoVis, and significantly easier with ExoVis than with orientation icons. Different mental transformation strategies can explain this result. The results suggest that ExoVis may be a better alternative to orientation icons when in-place displays are not appropriate (e.g., when in-place methods hide data or cut the 3D view into several pieces).',\n",
              "  'AuthorKeywords': ['2D',\n",
              "   'and',\n",
              "   '3D',\n",
              "   'visualization,',\n",
              "   'mental',\n",
              "   'registration,slice,',\n",
              "   'orthographic',\n",
              "   'projection,',\n",
              "   'empirical',\n",
              "   'study,',\n",
              "   'experiment'],\n",
              "  'MultipartiteRank': [{'score': 0.0874155782211308, 'word': '3d'},\n",
              "   {'score': 0.0874155782211308, 'word': 'views'},\n",
              "   {'score': 0.06108147690282371, 'word': 'exovis'},\n",
              "   {'score': 0.05757245311711165, 'word': 'mental'},\n",
              "   {'score': 0.05757245311711165, 'word': 'registration'},\n",
              "   {'score': 0.047286813968193044, 'word': 'display'},\n",
              "   {'score': 0.04640174576893894, 'word': 'place'},\n",
              "   {'score': 0.04640174576893894, 'word': 'methods'}],\n",
              "  'Title': 'Mental registration of 2D and 3D visualizations (an empirical study)',\n",
              "  'distance': 0,\n",
              "  'no': '763',\n",
              "  'parent': '4417'},\n",
              " {'Abstract': 'A visual investigation involves both the examination of existing information and the synthesis of new analytic knowledge. This is a progressive process in which newly synthesized knowledge becomes the foundation for future discovery. In this paper, we present a novel system supporting interactive, progressive synthesis of analytic knowledge. Here we use the term \"analytic knowledge\" to refer to concepts that a user derives from existing data along with the evidence supporting such concepts. Unlike existing visual analytic-tools, which typically support only exploration of existing information, our system offers two unique features. First, we support user-system cooperative visual synthesis of analytic knowledge from existing data. Specifically, users can visually define new concepts by annotating existing information, and refine partially formed concepts by linking additional evidence or manipulating related concepts. In response to user actions, our system can automatically manage the evolving corpus of synthesized knowledge and its corresponding evidence. Second, we support progressive visual analysis of synthesized knowledge. This feature allows analysts to visually explore both existing knowledge and synthesized knowledge, dynamically incorporating earlier analytic conclusions into the ensuing discovery process. We have applied our system to two complex but very different analytic applications. Our preliminary evaluation shows the promise of our work',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Intelligence',\n",
              "   'analysis,',\n",
              "   'Problem',\n",
              "   'solving',\n",
              "   'environments,',\n",
              "   'Visual',\n",
              "   'Knowledge',\n",
              "   'Discovery'],\n",
              "  'MultipartiteRank': [{'score': 0.10723269940453713, 'word': 'new'},\n",
              "   {'score': 0.10723269940453713, 'word': 'analytic'},\n",
              "   {'score': 0.10723269940453713, 'word': 'knowledge'},\n",
              "   {'score': 0.058120378667318374, 'word': 'synthesis'},\n",
              "   {'score': 0.051143003304577286, 'word': 'information'},\n",
              "   {'score': 0.04725624511600455, 'word': 'novel'},\n",
              "   {'score': 0.04725624511600455, 'word': 'system'},\n",
              "   {'score': 0.04433692214620679, 'word': 'user'}],\n",
              "  'Title': 'Interactive Visual Synthesis of Analytic Knowledge',\n",
              "  'distance': 0,\n",
              "  'no': '764',\n",
              "  'parent': '5730'},\n",
              " {'Abstract': \"We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy\",\n",
              "  'AuthorKeywords': ['Computer',\n",
              "   'Aided',\n",
              "   'Detection,',\n",
              "   'Virtual',\n",
              "   'Colonoscopy,',\n",
              "   'Texture',\n",
              "   'Analysis,',\n",
              "   'Volume',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.06126113235827163, 'word': 'colonic'},\n",
              "   {'score': 0.06126113235827163, 'word': 'polyps'},\n",
              "   {'score': 0.05432724616098919, 'word': 'automatic'},\n",
              "   {'score': 0.05432724616098919, 'word': 'method'},\n",
              "   {'score': 0.04948021265891508, 'word': 'volume'},\n",
              "   {'score': 0.04948021265891508, 'word': 'rendering'},\n",
              "   {'score': 0.046497264085528504, 'word': 'texture'},\n",
              "   {'score': 0.043104857475996454, 'word': 'cad'}],\n",
              "  'Title': 'A Pipeline for Computer Aided Polyp Detection',\n",
              "  'distance': 0,\n",
              "  'no': '765',\n",
              "  'parent': '5232'},\n",
              " {'Abstract': 'Conveying shape using feature lines is an important visualization tool in visual computing. The existing feature lines (e.g., ridges, valleys, silhouettes, suggestive contours, etc.) are solely determined by local geometry properties (e.g., normals and curvatures) as well as the view position. This paper is strongly inspired by the observation in human vision and perception that a sudden change in the luminance plays a critical role to faithfully represent and recover the 3D information. In particular, we adopt the edge detection techniques in image processing for 3D shape visualization and present photic extremum lines (PELs) which emphasize significant variations of illumination over 3D surfaces. Comparing with the existing feature lines, PELs are more flexible and offer users more freedom to achieve desirable visualization effects. In addition, the user can easily control the shape visualization by changing the light position, the number of light sources, and choosing various light models. We compare PELs with the existing approaches and demonstrate that PEL is a flexible and effective tool to illustrate 3D surface and volume for visual computing.',\n",
              "  'AuthorKeywords': ['Surface',\n",
              "   'and',\n",
              "   'volume',\n",
              "   'illustration,',\n",
              "   'illumination,',\n",
              "   'photic',\n",
              "   'extremum',\n",
              "   'lines',\n",
              "   '(PELs),',\n",
              "   'silhouettes,',\n",
              "   'suggestive',\n",
              "   'contours,',\n",
              "   'ridges',\n",
              "   'and',\n",
              "   'valleys,',\n",
              "   'digital',\n",
              "   'geometry',\n",
              "   'processing'],\n",
              "  'MultipartiteRank': [{'score': 0.0669167975472592, 'word': 'shape'},\n",
              "   {'score': 0.06238488934278747, 'word': 'feature'},\n",
              "   {'score': 0.06238488934278747, 'word': 'lines'},\n",
              "   {'score': 0.053318411122859975, 'word': 'pels'},\n",
              "   {'score': 0.04637239368797969, 'word': '3d'},\n",
              "   {'score': 0.04637239368797969, 'word': 'information'},\n",
              "   {'score': 0.03345169465125906, 'word': 'visual'},\n",
              "   {'score': 0.03345169465125906, 'word': 'computing'}],\n",
              "  'Title': 'An Effective Illustrative Visualization Framework Based on Photic Extremum Lines (PELs)',\n",
              "  'distance': 0,\n",
              "  'no': '766',\n",
              "  'parent': '4889'},\n",
              " {'Abstract': 'During continuous user interaction, it is hard to provide rich visual feedback at interactive rates for datasets containing millions of entries. The contribution of this paper is a generic architecture that ensures responsiveness of the application even when dealing with large data and that is applicable to most types of information visualizations. Our architecture builds on the separation of the main application thread and the visualization thread, which can be cancelled early due to user interaction. In combination with a layer mechanism, our architecture facilitates generating previews incrementally to provide rich visual feedback quickly. To help avoiding common pitfalls of multi-threading, we discuss synchronization and communication in detail. We explicitly denote design choices to control trade-offs. A quantitative evaluation based on the system VI S P L ORE shows fast visual feedback during continuous interaction even for millions of entries. We describe instantiations of our architecture in additional tools.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization',\n",
              "   'architecture,',\n",
              "   'continuous',\n",
              "   'interaction,',\n",
              "   'multi-threading,',\n",
              "   'layer,',\n",
              "   'preview'],\n",
              "  'MultipartiteRank': [{'score': 0.11721911349167016, 'word': 'architecture'},\n",
              "   {'score': 0.09788808555405354, 'word': 'continuous'},\n",
              "   {'score': 0.09788808555405354, 'word': 'user'},\n",
              "   {'score': 0.09788808555405354, 'word': 'interaction'},\n",
              "   {'score': 0.07245804585404851, 'word': 'generic'},\n",
              "   {'score': 0.05986277047382851, 'word': 'rich'},\n",
              "   {'score': 0.05986277047382851, 'word': 'visual'},\n",
              "   {'score': 0.05986277047382851, 'word': 'feedback'},\n",
              "   {'score': 0.05649445008898563, 'word': 'application'}],\n",
              "  'Title': 'A Multi-Threading Architecture to Support Interactive Visual Exploration',\n",
              "  'distance': 0,\n",
              "  'no': '767',\n",
              "  'parent': '4322'},\n",
              " {'Abstract': \"Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.\",\n",
              "  'AuthorKeywords': ['spatiotemporal',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'animal',\n",
              "   'behavior,',\n",
              "   'dense',\n",
              "   'pixel',\n",
              "   'displays'],\n",
              "  'MultipartiteRank': [{'score': 0.06464677923316985, 'word': 'sensor'},\n",
              "   {'score': 0.06464677923316985, 'word': 'logs'},\n",
              "   {'score': 0.062009557958325204, 'word': 'spatiotemporal'},\n",
              "   {'score': 0.062009557958325204, 'word': 'analysis'},\n",
              "   {'score': 0.03684738967855257, 'word': 'dimensional'},\n",
              "   {'score': 0.03684738967855257, 'word': 'maps'},\n",
              "   {'score': 0.029149132391569136, 'word': 'spatial'},\n",
              "   {'score': 0.029149132391569136, 'word': 'data'},\n",
              "   {'score': 0.028522510665221247, 'word': 'color'}],\n",
              "  'Title': 'Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps',\n",
              "  'distance': 0,\n",
              "  'no': '768',\n",
              "  'parent': '5105'},\n",
              " {'Abstract': 'Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.',\n",
              "  'AuthorKeywords': ['Particle',\n",
              "   'Systems,',\n",
              "   'Crease',\n",
              "   'Features,',\n",
              "   'Ridge',\n",
              "   'and',\n",
              "   'Valley',\n",
              "   'Detection,',\n",
              "   'Lung',\n",
              "   'CT,',\n",
              "   'Diffusion',\n",
              "   'Tensor',\n",
              "   'MRI'],\n",
              "  'MultipartiteRank': [{'score': 0.10015845878862968, 'word': 'particle'},\n",
              "   {'score': 0.10015845878862968, 'word': 'systems'},\n",
              "   {'score': 0.07777960604499987, 'word': 'scale'},\n",
              "   {'score': 0.04954820374986436, 'word': 'space'},\n",
              "   {'score': 0.04878322802420084, 'word': 'sampling'},\n",
              "   {'score': 0.04878322802420084, 'word': 'structure'},\n",
              "   {'score': 0.03884630682301524, 'word': 'unsegmented'},\n",
              "   {'score': 0.03884630682301524, 'word': 'data'}],\n",
              "  'Title': 'Sampling and Visualizing Creases with Scale-Space Particles',\n",
              "  'distance': 0,\n",
              "  'no': '769',\n",
              "  'parent': '5804'},\n",
              " {'Abstract': 'We introduce eSeeTrack, an eye-tracking visualization prototype that facilitates exploration and comparison of sequential gaze orderings in a static or a dynamic scene. It extends current eye-tracking data visualizations by extracting patterns of sequential gaze orderings, displaying these patterns in a way that does not depend on the number of fixations on a scene, and enabling users to compare patterns from two or more sets of eye-gaze data. Extracting such patterns was very difficult with previous visualization techniques. eSeeTrack combines a timeline and a tree-structured visual representation to embody three aspects of eye-tracking data that users are interested in: duration, frequency and orderings of fixations. We demonstrate the usefulness of eSeeTrack via two case studies on surgical simulation and retail store chain data. We found that eSeeTrack allows ordering of fixations to be rapidly queried, explored and compared. Furthermore, our tool provides an effective and efficient mechanism to determine pattern outliers. This approach can be effective for behavior analysis in a variety of domains that are described at the end of this paper.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06784504422127716, 'word': 'sequential'},\n",
              "   {'score': 0.06784504422127716, 'word': 'gaze'},\n",
              "   {'score': 0.06784504422127716, 'word': 'orderings'},\n",
              "   {'score': 0.06581555712824577, 'word': 'eye'},\n",
              "   {'score': 0.059502058227510674, 'word': 'patterns'},\n",
              "   {'score': 0.050478173575706, 'word': 'eseetrack'},\n",
              "   {'score': 0.05027811388255916, 'word': 'data'},\n",
              "   {'score': 0.05027811388255916, 'word': 'visualizations'}],\n",
              "  'Title': 'eSeeTrack—Visualizing Sequential fixation Patterns',\n",
              "  'distance': 0,\n",
              "  'no': '770',\n",
              "  'parent': '4266'},\n",
              " {'Abstract': 'In this paper, we present a user study in which we have investigated the influence of seven state-of-the-art volumetric illumination models on the spatial perception of volume rendered images. Within the study, we have compared gradient-based shading with half angle slicing, directional occlusion shading, multidirectional occlusion shading, shadow volume propagation, spherical harmonic lighting as well as dynamic ambient occlusion. To evaluate these models, users had to solve three tasks relying on correct depth as well as size perception. Our motivation for these three tasks was to find relations between the used illumination model, user accuracy and the elapsed time. In an additional task, users had to subjectively judge the output of the tested models. After first reviewing the models and their features, we will introduce the individual tasks and discuss their results. We discovered statistically significant differences in the testing performance of the techniques. Based on these findings, we have analyzed the models and extracted those features which are possibly relevant for the improved spatial comprehension in a relational task. We believe that a combination of these distinctive features could pave the way for a novel illumination model, which would be optimized based on our findings.',\n",
              "  'AuthorKeywords': ['Volumetric',\n",
              "   'illumination,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'spatial',\n",
              "   'comprehension'],\n",
              "  'MultipartiteRank': [{'score': 0.08691828447890824, 'word': 'art'},\n",
              "   {'score': 0.08691828447890824, 'word': 'volumetric'},\n",
              "   {'score': 0.08691828447890824, 'word': 'illumination'},\n",
              "   {'score': 0.08691828447890824, 'word': 'models'},\n",
              "   {'score': 0.05115103270605636, 'word': 'volume'},\n",
              "   {'score': 0.05088517886664673, 'word': 'spatial'},\n",
              "   {'score': 0.05088517886664673, 'word': 'perception'},\n",
              "   {'score': 0.04829461600214368, 'word': 'tasks'},\n",
              "   {'score': 0.0405667928173591, 'word': 'users'}],\n",
              "  'Title': 'About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering',\n",
              "  'distance': 0,\n",
              "  'no': '771',\n",
              "  'parent': '5334'},\n",
              " {'Abstract': 'We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'analytics,',\n",
              "   'exploratory',\n",
              "   'search,',\n",
              "   'multivariate',\n",
              "   'time',\n",
              "   'series,',\n",
              "   'motion',\n",
              "   'capture',\n",
              "   'data,',\n",
              "   'data',\n",
              "   'aggregation,',\n",
              "   'cluster',\n",
              "   'glyph'],\n",
              "  'MultipartiteRank': [{'score': 0.10651077475433726, 'word': 'human'},\n",
              "   {'score': 0.10651077475433726, 'word': 'motion'},\n",
              "   {'score': 0.04855233622345504, 'word': 'exploratory'},\n",
              "   {'score': 0.04855233622345504, 'word': 'search'},\n",
              "   {'score': 0.044326075669385505, 'word': 'sequences'},\n",
              "   {'score': 0.038888980027974314, 'word': 'motionexplorer'},\n",
              "   {'score': 0.037771235032984164, 'word': 'many'},\n",
              "   {'score': 0.037771235032984164, 'word': 'research'},\n",
              "   {'score': 0.037771235032984164, 'word': 'fields'}],\n",
              "  'Title': 'MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation',\n",
              "  'distance': 0,\n",
              "  'no': '772',\n",
              "  'parent': '5411'},\n",
              " {'Abstract': 'We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'interactivity,',\n",
              "   'dimensionality',\n",
              "   'reduction,',\n",
              "   'multidimensional',\n",
              "   'scaling'],\n",
              "  'MultipartiteRank': [{'score': 0.10117255300788146, 'word': 'projection'},\n",
              "   {'score': 0.10117255300788146, 'word': 'techniques'},\n",
              "   {'score': 0.0619691546560789, 'word': 'data'},\n",
              "   {'score': 0.05483841357838339, 'word': 'dimensionality'},\n",
              "   {'score': 0.04227107177185618, 'word': 'interactive'},\n",
              "   {'score': 0.04227107177185618, 'word': 'methods'},\n",
              "   {'score': 0.034677871676971526, 'word': 'set'}],\n",
              "  'Title': 'Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions',\n",
              "  'distance': 0,\n",
              "  'no': '773',\n",
              "  'parent': '5610'},\n",
              " {'Abstract': 'A methodology has been developed for constructing streamlines and particle paths in numerically generated fluid velocity fields. A graphical technique is used to convert the discretely defined flow within a cell into one represented by two three-dimensional stream functions. Streamlines are calculated by tracking constant values of each stream function, a process which corresponds to finding the intersection of two stream surfaces. The tracking process is mass conservative and does not use a time stepping method for integration, thus eliminating a computationally intensive part of traditional tracking algorithms. The method can be applied generally to any three-dimensional compressible or incompressible steady flow. Results presented compare the performance of the new method to the most commonly used scheme and show that calculation times can be reduced by an order of magnitude.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08762417785770704, 'word': 'dimensional'},\n",
              "   {'score': 0.08762417785770704, 'word': 'stream'},\n",
              "   {'score': 0.08762417785770704, 'word': 'functions'},\n",
              "   {'score': 0.07188515268616263, 'word': 'streamlines'},\n",
              "   {'score': 0.06974680514982014, 'word': 'method'},\n",
              "   {'score': 0.05830752320156718, 'word': 'process'},\n",
              "   {'score': 0.055061799426211554, 'word': 'flow'}],\n",
              "  'Title': 'A 3-D streamline tracking algorithm using dual stream functions',\n",
              "  'distance': 0,\n",
              "  'no': '774',\n",
              "  'parent': '4349'},\n",
              " {'Abstract': 'Flow volumes are extended for use in unsteady (time-dependent) flows. The resulting unsteady flow volumes are the 3D analogs of streaklines. There are few examples where methods other than particle tracing have been used to visualize time-varying flows. Since particle paths can become convoluted in time, there are additional considerations to be made when extending any visualization technique to unsteady flows. We present some solutions to the problems which occur in subdivision, rendering and system design. We apply the unsteady flow volumes to a variety of field types, including moving multi-zoned curvilinear grids.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.2122500487544654, 'word': 'flow'},\n",
              "   {'score': 0.2122500487544654, 'word': 'volumes'},\n",
              "   {'score': 0.10577309574630489, 'word': 'time'},\n",
              "   {'score': 0.0758836587384504, 'word': 'use'},\n",
              "   {'score': 0.06884862683070511, 'word': 'unsteady'},\n",
              "   {'score': 0.049547354458260855, 'word': 'dependent'}],\n",
              "  'Title': 'Unsteady flow volumes',\n",
              "  'distance': 0,\n",
              "  'no': '775',\n",
              "  'parent': '3612'},\n",
              " {'Abstract': 'The Bead visualization system employs a fast algorithm for laying out high-dimensional data in a low-dimensional space, and a number of features added to 3D visualizations to improve imageability. We describe recent work on both aspects of the system, in particular a generalization of the data types laid out and the implementation of imageability features in a 2D visualization tool. The variety of data analyzed in a financial institution such as UBS, and the ubiquity of spreadsheets as a medium for analysis, led us to extend our layout tools to handle data in a generic spreadsheet format. We describe the metrics of similarity used for this data type, and give examples of layouts of sets of records of financial trades. Conservatism and scepticism with regard to 3D visualization, along with the lack of functionality of widely available 3D web browsers, led to the development of a 2D visualization tool with refinements of a number of our imageability features.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08018643914977908, 'word': 'dimensional'},\n",
              "   {'score': 0.08018643914977908, 'word': 'data'},\n",
              "   {'score': 0.04548222942686165, 'word': 'features'},\n",
              "   {'score': 0.04402738127069121, 'word': 'bead'},\n",
              "   {'score': 0.04402738127069121, 'word': 'visualization'},\n",
              "   {'score': 0.04402738127069121, 'word': 'system'},\n",
              "   {'score': 0.03670064412569528, 'word': '3d'},\n",
              "   {'score': 0.03670064412569528, 'word': 'visualizations'},\n",
              "   {'score': 0.036179754247945846, 'word': 'number'}],\n",
              "  'Title': 'Domesticating Bead: adapting an information visualization system to a financial institution',\n",
              "  'distance': 0,\n",
              "  'no': '776',\n",
              "  'parent': '4989'},\n",
              " {'Abstract': 'Presents a new method to produce a hierarchical set of triangle meshes that can be used to blend different levels of detail in a smooth fashion. The algorithm produces a sequence of meshes /spl Mscr//sub 0/, /spl Mscr//sub 1/, /spl Mscr//sub 2/..., /spl Mscr//sub n/, where each mesh /spl Mscr//sub i/ can be transformed to mesh /spl Mscr//sub i+1/ through a set of triangle-collapse operations. For each triangle, a function is generated that approximates the underlying surface in the area of the triangle, and this function serves as a basis for assigning a weight to the triangle in the ordering operation, and for supplying the point to which the triangles are collapsed. This technique allows us to view a triangulated surface model at varying levels of detail while insuring that the simplified mesh approximates the original surface well.',\n",
              "  'AuthorKeywords': ['mesh',\n",
              "   'simplification,',\n",
              "   'triangle',\n",
              "   'meshes,level-of-detail',\n",
              "   'representation,',\n",
              "   'shape',\n",
              "   'approximation'],\n",
              "  'MultipartiteRank': [{'score': 0.21623374305390897, 'word': 'triangle'},\n",
              "   {'score': 0.13735033351127598, 'word': 'meshes'},\n",
              "   {'score': 0.08997982872363255, 'word': 'hierarchical'},\n",
              "   {'score': 0.08997982872363255, 'word': 'set'},\n",
              "   {'score': 0.06859359772193169, 'word': 'detail'},\n",
              "   {'score': 0.06525867851503755, 'word': 'different'},\n",
              "   {'score': 0.06525867851503755, 'word': 'levels'}],\n",
              "  'Title': 'Smooth hierarchical surface triangulations',\n",
              "  'distance': 0,\n",
              "  'no': '777',\n",
              "  'parent': '3551'},\n",
              " {'Abstract': 'In a large number of applications, data is collected and referenced by their spatial locations. Visualizing large amounts of spatially referenced data on a limited-size screen display often results in poor visualizations due to the high degree of overplotting of neighboring datapoints. We introduce a new approach to visualizing large amounts of spatially referenced data. The basic idea is to intelligently use the unoccupied pixels of the display instead of overplotting data points. After formally describing the problem, we present two solutions which are based on: placing overlapping data points on the nearest unoccupied pixel; and shifting data points along a screen-filling curve (e.g., Hilbert-curve). We then develop a more sophisticated approach called Gridfit, which is based on a hierarchical partitioning of the data space. We evaluate all three approaches with respect to their efficiency and effectiveness and show the superiority of the Gridfit approach. For measuring the effectiveness, we not only present the resulting visualizations but also introduce mathematical effectiveness criteria measuring properties of the generated visualizations with respect to the original data such as distance- and position-preservation.',\n",
              "  'AuthorKeywords': ['visualizing',\n",
              "   'large',\n",
              "   'data',\n",
              "   'sets,',\n",
              "   'visualizing',\n",
              "   'spatially',\n",
              "   'referenced',\n",
              "   'data,',\n",
              "   'visualizing',\n",
              "   'geographical',\n",
              "   'data,',\n",
              "   'interfaces',\n",
              "   'to',\n",
              "   'databases'],\n",
              "  'MultipartiteRank': [{'score': 0.13220128335047204, 'word': 'large'},\n",
              "   {'score': 0.11430948671940662, 'word': 'data'},\n",
              "   {'score': 0.0886758237760236, 'word': 'number'},\n",
              "   {'score': 0.05326014947964253, 'word': 'new'},\n",
              "   {'score': 0.05326014947964253, 'word': 'approach'},\n",
              "   {'score': 0.0512313711516125, 'word': 'applications'},\n",
              "   {'score': 0.04352545957444845, 'word': 'amounts'}],\n",
              "  'Title': 'The Gridfit algorithm: an efficient and effective approach to visualizing large amounts of spatial data',\n",
              "  'distance': 0,\n",
              "  'no': '778',\n",
              "  'parent': '3998'},\n",
              " {'Abstract': \"We present an algorithm for compressing 2D vector fields that preserves topology. Our approach is to simplify the given data set using constrained clustering. We employ different types of global and local error metrics including the earth mover's distance metric to measure the degradation in topology as well as weighted magnitude and angular errors. As a result, we obtain precise error bounds in the compressed vector fields. Experiments with both analytic and simulated data sets are presented. Results indicate that one can obtain significant compression with low errors without losing topology information.\",\n",
              "  'AuthorKeywords': ['compression,',\n",
              "   'topology,',\n",
              "   'vector',\n",
              "   'fields,',\n",
              "   'error',\n",
              "   'metrics,clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.09962499908615688, 'word': 'topology'},\n",
              "   {'score': 0.07596192314715713, 'word': '2d'},\n",
              "   {'score': 0.07596192314715713, 'word': 'vector'},\n",
              "   {'score': 0.07596192314715713, 'word': 'fields'},\n",
              "   {'score': 0.06110791549499689, 'word': 'angular'},\n",
              "   {'score': 0.06110791549499689, 'word': 'errors'},\n",
              "   {'score': 0.06033344258656102, 'word': 'data'},\n",
              "   {'score': 0.05296052211904855, 'word': 'result'}],\n",
              "  'Title': 'Topology preserving compression of 2D vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '779',\n",
              "  'parent': '3434'},\n",
              " {'Abstract': 'Isosurfaces are commonly used to visualize scalar fields. Critical isovalues indicate isosurface topology changes: the creation of new surface components, merging of surface components or the formation of holes in a surface component. Therefore, they highlight interesting isosurface behavior and are helpful in exploration of large trivariate data sets. We present a method that detects critical isovalues in a scalar field defined by piecewise trilinear interpolation over a rectilinear grid and describe how to use them when examining volume data. We further review varieties of the marching cubes (MC) algorithm, with the intention of preserving topology of the trilinear interpolant when extracting an isosurface. We combine and extend two approaches in such a way that it is possible to extract meaningful isosurfaces even when a critical value is chosen as the isovalue.',\n",
              "  'AuthorKeywords': ['scalar',\n",
              "   'field',\n",
              "   'topology,',\n",
              "   'critical',\n",
              "   'point,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'data',\n",
              "   'exploration,',\n",
              "   'isosurfaces,',\n",
              "   'marching',\n",
              "   'cubes'],\n",
              "  'MultipartiteRank': [{'score': 0.11805294481631003, 'word': 'isosurfaces'},\n",
              "   {'score': 0.06987235875873406, 'word': 'critical'},\n",
              "   {'score': 0.06987235875873406, 'word': 'isovalues'},\n",
              "   {'score': 0.06702514156673865, 'word': 'new'},\n",
              "   {'score': 0.06702514156673865, 'word': 'surface'},\n",
              "   {'score': 0.06702514156673865, 'word': 'components'},\n",
              "   {'score': 0.060008143703613015, 'word': 'isosurface'},\n",
              "   {'score': 0.060008143703613015, 'word': 'topology'},\n",
              "   {'score': 0.060008143703613015, 'word': 'changes'},\n",
              "   {'score': 0.056111800122551375, 'word': 'scalar'},\n",
              "   {'score': 0.056111800122551375, 'word': 'fields'}],\n",
              "  'Title': 'Exploring scalar fields using critical isovalues',\n",
              "  'distance': 0,\n",
              "  'no': '780',\n",
              "  'parent': '3556'},\n",
              " {'Abstract': 'Many direct volume rendering algorithms have been proposed during the last decade to render 256/sup 3/ voxels interactively. However a lot of limitations are inherent to all of them, like low-quality images, a small viewport size or a fixed classification. In contrast, interactive high quality algorithms are still a challenge nowadays. We introduce here an efficient and accurate technique called object-order ray-casting that can achieve up to 10 fps on current workstations. Like usual ray-casting, colors and opacities are evenly sampled along the ray, but now within a new object-order algorithm. Thus, it allows to combine the main advantages of both worlds in term of speed and quality. We also describe an efficient hidden volume removal technique to compensate for the loss of early ray termination.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   'Scientific',\n",
              "   'Visualization,',\n",
              "   'Medical',\n",
              "   'Imaging,',\n",
              "   'Ray',\n",
              "   'Tracing'],\n",
              "  'MultipartiteRank': [{'score': 0.07757573737017068, 'word': 'order'},\n",
              "   {'score': 0.07757573737017068, 'word': 'ray'},\n",
              "   {'score': 0.05580312896281544, 'word': 'casting'},\n",
              "   {'score': 0.053128331593853384, 'word': 'object'},\n",
              "   {'score': 0.04537807495812623, 'word': 'quality'},\n",
              "   {'score': 0.04537807495812623, 'word': 'images'},\n",
              "   {'score': 0.042932554463570874, 'word': 'efficient'}],\n",
              "  'Title': 'A new object-order ray-casting algorithm',\n",
              "  'distance': 0,\n",
              "  'no': '781',\n",
              "  'parent': '3975'},\n",
              " {'Abstract': 'We present a method to code the multiresolution structure of a 3D triangle mesh in a manner that allows progressive decoding and efficient rendering at a client machine. The code is based on a special ordering of the mesh vertices which has good locality and continuity properties, inducing a natural multiresolution structure. This ordering also incorporates information allowing efficient rendering of the mesh at all resolutions using the contemporary vertex buffer mechanism. The performance of our code is shown to be competitive with existing progressive mesh compression methods, while achieving superior rendering speed.',\n",
              "  'AuthorKeywords': ['progressive',\n",
              "   'compression,',\n",
              "   'wavelets,',\n",
              "   'geometry',\n",
              "   'coding,',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.11253434728040046, 'word': '3d'},\n",
              "   {'score': 0.11253434728040046, 'word': 'triangle'},\n",
              "   {'score': 0.11253434728040046, 'word': 'mesh'},\n",
              "   {'score': 0.0796767628501649, 'word': 'multiresolution'},\n",
              "   {'score': 0.0796767628501649, 'word': 'structure'},\n",
              "   {'score': 0.07848919385909556, 'word': 'efficient'},\n",
              "   {'score': 0.07848919385909556, 'word': 'rendering'},\n",
              "   {'score': 0.06384804973257728, 'word': 'special'},\n",
              "   {'score': 0.06384804973257728, 'word': 'ordering'},\n",
              "   {'score': 0.06114233491969707, 'word': 'code'}],\n",
              "  'Title': 'Efficient compression and rendering of multi-resolution meshes',\n",
              "  'distance': 0,\n",
              "  'no': '782',\n",
              "  'parent': '3592'},\n",
              " {'Abstract': \"This paper addresses the problem of surface reconstruction of highly noisy point clouds. The surfaces to be reconstructed are assumed to be 2-manifolds of piecewise C/sup 1/ continuity, with isolated small irregular regions of high curvature, sophisticated local topology or abrupt burst of noise. At each sample point, a quadric field is locally fitted via a modified moving least squares method. These locally fitted quadric fields are then blended together to produce a pseudo-signed distance field using Shepard's method. We introduce a prioritized front growing scheme in the process of local quadrics fitting. Flatter surface areas tend to grow faster. The already fitted regions will subsequently guide the fitting of those irregular regions in their neighborhood.\",\n",
              "  'AuthorKeywords': ['Computer',\n",
              "   'Graphics,',\n",
              "   'Surface',\n",
              "   'Reconstruction,',\n",
              "   'Point',\n",
              "   'Cloud,',\n",
              "   'Surface',\n",
              "   'Representation,',\n",
              "   'Solid',\n",
              "   'Modeling,',\n",
              "   'Moving',\n",
              "   'Least',\n",
              "   'Squares,',\n",
              "   \"Shepard's\",\n",
              "   'Method'],\n",
              "  'MultipartiteRank': [{'score': 0.0794706742166945, 'word': 'surface'},\n",
              "   {'score': 0.0794706742166945, 'word': 'reconstruction'},\n",
              "   {'score': 0.06967677616075511, 'word': 'quadric'},\n",
              "   {'score': 0.06967677616075511, 'word': 'field'},\n",
              "   {'score': 0.06729295104311356, 'word': 'isolated'},\n",
              "   {'score': 0.06729295104311356, 'word': 'small'},\n",
              "   {'score': 0.06729295104311356, 'word': 'irregular'},\n",
              "   {'score': 0.06729295104311356, 'word': 'regions'},\n",
              "   {'score': 0.04771996631017623, 'word': 'least'},\n",
              "   {'score': 0.04771996631017623, 'word': 'squares'},\n",
              "   {'score': 0.04771996631017623, 'word': 'method'},\n",
              "   {'score': 0.04616284031204627, 'word': 'problem'}],\n",
              "  'Title': 'Piecewise C¹ continuous surface reconstruction of noisy point clouds via local implicit quadric regression',\n",
              "  'distance': 0,\n",
              "  'no': '783',\n",
              "  'parent': '3843'},\n",
              " {'Abstract': 'Tracking and visualizing local features from a time-varying volumetric data allows the user to focus on selected regions of interest, both in space and time, which can lead to a better understanding of the underlying dynamics. In this paper, we present an efficient algorithm to track time-varying isosurfaces and interval volumes using isosurfacing in higher dimensions. Instead of extracting the data features such as isosurfaces or interval volumes separately from multiple time steps and computing the spatial correspondence between those features, our algorithm extracts the correspondence directly from the higher dimensional geometry and thus can more efficiently follow the user selected local features in time. In addition, by analyzing the resulting higher dimensional geometry, it becomes easier to detect important topological events and the corresponding critical time steps for the selected features. With our algorithm, the user can interact with the underlying time-varying data more easily. The computation cost for performing time-varying volume tracking is also minimized.',\n",
              "  'AuthorKeywords': ['tracking,',\n",
              "   'isosurface,',\n",
              "   'interval',\n",
              "   'volume,',\n",
              "   'higher',\n",
              "   'dimensional',\n",
              "   'isosurfacing'],\n",
              "  'MultipartiteRank': [{'score': 0.14444085583403773, 'word': 'time'},\n",
              "   {'score': 0.08652898258542745, 'word': 'local'},\n",
              "   {'score': 0.08652898258542745, 'word': 'features'},\n",
              "   {'score': 0.0600464388411247, 'word': 'user'},\n",
              "   {'score': 0.054761103512458276, 'word': 'efficient'},\n",
              "   {'score': 0.054761103512458276, 'word': 'algorithm'},\n",
              "   {'score': 0.05044717571280815, 'word': 'tracking'}],\n",
              "  'Title': 'Volume tracking using higher dimensional isosurfacing',\n",
              "  'distance': 0,\n",
              "  'no': '784',\n",
              "  'parent': '5212'},\n",
              " {'Abstract': 'We present a new algorithm for simplifying the shape of 3D objects by manipulating their medial axis transform (MAT). From an unorganized set of boundary points, our algorithm computes the MAT, decomposes the axis into parts, then selectively removes a subset of these parts in order to reduce the complexity of the overall shape. The result is simplified MAT that can be used for a variety of shape operations. In addition, a polygonal surface of the resulting shape can be directly generated from the filtered MAT using a robust surface reconstruction method. The algorithm presented is shown to have a number of advantages over other existing approaches.',\n",
              "  'AuthorKeywords': ['medial',\n",
              "   'axis',\n",
              "   'transform,',\n",
              "   'shape',\n",
              "   'simplification,',\n",
              "   'topology',\n",
              "   'preservation'],\n",
              "  'MultipartiteRank': [{'score': 0.11373449522830566, 'word': 'shape'},\n",
              "   {'score': 0.10534207924681911, 'word': 'mat'},\n",
              "   {'score': 0.08498736550602105, 'word': 'new'},\n",
              "   {'score': 0.08498736550602105, 'word': 'algorithm'},\n",
              "   {'score': 0.06613147505933131, 'word': 'medial'},\n",
              "   {'score': 0.06613147505933131, 'word': 'axis'},\n",
              "   {'score': 0.06613147505933131, 'word': 'transform'},\n",
              "   {'score': 0.05681610376240499, 'word': 'parts'}],\n",
              "  'Title': 'Shape simplification based on the medial axis transform',\n",
              "  'distance': 0,\n",
              "  'no': '785',\n",
              "  'parent': '3617'},\n",
              " {'Abstract': 'Diffusion tensor imaging is a magnetic resonance imaging method which has gained increasing importance in neuroscience and especially in neurosurgery. It acquires diffusion properties represented by a symmetric 2nd order tensor for each voxel in the gathered dataset. From the medical point of view, the data is of special interest due lo different diffusion characteristics of varying brain tissue allowing conclusions about the underlying structures such as while matter tracts. An obvious way to visualize this data is to focus on the anisotropic areas using the major eigenvector for tractography and rendering lines for visualization of the simulation results. Our approach extends this technique to avoid line representation since lines lead 10 very complex illustrations and furthermore are mistakable. Instead, we generate surfaces wrapping bundles of lines. Thereby, a more intuitive representation of different tracts is achieved.',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'Tensor',\n",
              "   'Imaging,',\n",
              "   'Tractography,',\n",
              "   'White',\n",
              "   'Matter',\n",
              "   'Tracts,',\n",
              "   'Clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.09375252692257145, 'word': 'lines'},\n",
              "   {'score': 0.04893427629158576, 'word': 'data'},\n",
              "   {'score': 0.044182717090626135, 'word': 'matter'},\n",
              "   {'score': 0.044182717090626135, 'word': 'tracts'},\n",
              "   {'score': 0.0359723442788769, 'word': 'visualization'},\n",
              "   {'score': 0.03565700613125464, 'word': 'tractography'}],\n",
              "  'Title': 'Visualization of white matter tracts with wrapped streamlines',\n",
              "  'distance': 0,\n",
              "  'no': '786',\n",
              "  'parent': '3982'},\n",
              " {'Abstract': 'Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.',\n",
              "  'AuthorKeywords': ['Multi-field',\n",
              "   'Visualization,',\n",
              "   'Visual',\n",
              "   'Data',\n",
              "   'Mining,',\n",
              "   'Time-varying',\n",
              "   'Volume',\n",
              "   'Data,',\n",
              "   'Integrating',\n",
              "   'InfoVis/SciVis'],\n",
              "  'MultipartiteRank': [{'score': 0.12373204227874185, 'word': 'data'},\n",
              "   {'score': 0.09282529619314155, 'word': 'perfusion'},\n",
              "   {'score': 0.07258667880515006, 'word': 'medical'},\n",
              "   {'score': 0.04167993271954975, 'word': 'diagnosis'},\n",
              "   {'score': 0.03942393901144819, 'word': 'efficient'},\n",
              "   {'score': 0.03942393901144819, 'word': 'evaluation'},\n",
              "   {'score': 0.03942393901144819, 'word': 'methods'},\n",
              "   {'score': 0.032595815629486595, 'word': 'feature'},\n",
              "   {'score': 0.030906746085600307, 'word': 'dynamic'},\n",
              "   {'score': 0.030906746085600307, 'word': 'image'}],\n",
              "  'Title': 'Interactive Visual Analysis of Perfusion Data',\n",
              "  'distance': 0,\n",
              "  'no': '787',\n",
              "  'parent': '4660'},\n",
              " {'Abstract': 'Integral surfaces are ideal tools to illustrate vector fields and fluid flow structures. However, these surfaces can be visually complex and exhibit difficult geometric properties, owing to strong stretching, shearing and folding of the flow from which they are derived. Many techniques for non-photorealistic rendering have been presented previously. It is, however, unclear how these techniques can be applied to integral surfaces. In this paper, we examine how transparency and texturing techniques can be used with integral surfaces to convey both shape and directional information. We present a rendering pipeline that combines these techniques aimed at faithfully and accurately representing integral surfaces while improving visualization insight. The presented pipeline is implemented directly on the GPU, providing real-time interaction for all rendering modes, and does not require expensive preprocessing of integral surfaces after computation.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'visualization,',\n",
              "   'integral',\n",
              "   'surfaces,',\n",
              "   'illustrative',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.15752067017085103, 'word': 'integral'},\n",
              "   {'score': 0.15752067017085103, 'word': 'surfaces'},\n",
              "   {'score': 0.1429833588729612, 'word': 'techniques'},\n",
              "   {'score': 0.08141503224948608, 'word': 'many'},\n",
              "   {'score': 0.05588163094413821, 'word': 'fluid'},\n",
              "   {'score': 0.05588163094413821, 'word': 'flow'},\n",
              "   {'score': 0.05588163094413821, 'word': 'structures'},\n",
              "   {'score': 0.04581810623403609, 'word': 'rendering'},\n",
              "   {'score': 0.04581810623403609, 'word': 'pipeline'}],\n",
              "  'Title': 'IRIS: Illustrative Rendering for Integral Surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '788',\n",
              "  'parent': '3818'},\n",
              " {'Abstract': 'Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.',\n",
              "  'AuthorKeywords': ['Time-series',\n",
              "   'Data,',\n",
              "   'Exploratory',\n",
              "   'Visualization,',\n",
              "   'Focus+Context,',\n",
              "   'Lens,',\n",
              "   'Interaction',\n",
              "   'Techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.12301252063367404, 'word': 'visual'},\n",
              "   {'score': 0.12301252063367404, 'word': 'representations'},\n",
              "   {'score': 0.07240881091340858, 'word': 'time'},\n",
              "   {'score': 0.07166918460147953, 'word': 'series'},\n",
              "   {'score': 0.05720860611811771, 'word': 'data'},\n",
              "   {'score': 0.04917820435428622, 'word': 'anomalies'}],\n",
              "  'Title': 'Exploratory Analysis of Time-Series with ChronoLenses',\n",
              "  'distance': 0,\n",
              "  'no': '789',\n",
              "  'parent': '4380'},\n",
              " {'Abstract': 'In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces “divided attention”, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'embellishments,',\n",
              "   'metaphors,',\n",
              "   'icons,',\n",
              "   'cognition,',\n",
              "   'working',\n",
              "   'memory,',\n",
              "   'long-term',\n",
              "   'memory,',\n",
              "   'visual',\n",
              "   'search,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.12393762869844092,\n",
              "    'word': 'embellishments'},\n",
              "   {'score': 0.07421614287328791, 'word': 'visualization'},\n",
              "   {'score': 0.050801146346714426, 'word': 'visual'},\n",
              "   {'score': 0.04053945329323445, 'word': 'tangible'},\n",
              "   {'score': 0.04053945329323445, 'word': 'concepts'},\n",
              "   {'score': 0.03165573356026062, 'word': 'abstract'}],\n",
              "  'Title': 'An Empirical Study on Using Visual Embellishments in Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '790',\n",
              "  'parent': '5366'},\n",
              " {'Abstract': 'Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.',\n",
              "  'AuthorKeywords': ['Faceted',\n",
              "   'browsing,',\n",
              "   'network',\n",
              "   'exploration,',\n",
              "   'dynamic',\n",
              "   'query,',\n",
              "   'interaction,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.09496188947712277, 'word': 'data'},\n",
              "   {'score': 0.09496188947712277, 'word': 'items'},\n",
              "   {'score': 0.0671408712604484, 'word': 'pivotslice'},\n",
              "   {'score': 0.046012209561107804, 'word': 'exploration'},\n",
              "   {'score': 0.04371136860375948, 'word': 'many'},\n",
              "   {'score': 0.04371136860375948, 'word': 'datasets'},\n",
              "   {'score': 0.04062515477172621, 'word': 'explicit'},\n",
              "   {'score': 0.04062515477172621, 'word': 'relational'},\n",
              "   {'score': 0.04062515477172621, 'word': 'references'}],\n",
              "  'Title': 'Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets',\n",
              "  'distance': 0,\n",
              "  'no': '791',\n",
              "  'parent': '4523'},\n",
              " {'Abstract': 'A hyperbox is a two-dimensional depiction of an N-dimensional box (rectangular parallelepiped). The authors define the visual syntax of hyperboxes, state some properties, and sketch two applications. Hyperboxes can be evocative visual names for tensors or multidimensional arrays in visual programming languages. They can also be used to simultaneously display all pairwise relationships in an N-dimensional dataset. This can be helpful in choosing a sequence of dimension-reducing transformations that preserve interesting properties of the dataset.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1277662502776802, 'word': 'hyperbox'},\n",
              "   {'score': 0.11567026895354282, 'word': 'visual'},\n",
              "   {'score': 0.09316228051631126, 'word': 'dimensional'},\n",
              "   {'score': 0.09316228051631126, 'word': 'depiction'},\n",
              "   {'score': 0.06934742448979027, 'word': 'properties'},\n",
              "   {'score': 0.058250346634202615, 'word': 'evocative'},\n",
              "   {'score': 0.058250346634202615, 'word': 'names'},\n",
              "   {'score': 0.057419922319340205, 'word': 'syntax'}],\n",
              "  'Title': 'The hyperbox',\n",
              "  'distance': 0,\n",
              "  'no': '792',\n",
              "  'parent': '3890'},\n",
              " {'Abstract': \"Methods are presented for the visualization of fuzzy data based on the sensitivity of the human visual system to motion and dynamic changes, and the ease of which electronic display devices can change their display. The methods include taking an otherwise static image and displaying in an animation loop either its segmented components or a series of blurred versions of the whole image. This approach was applied to sea-surface temperature data and was found to be effective in showing fuzzy details embedded in the data, and in drawing the viewer's attention. This approach and these methods could play a significant role in the display of browse products for massive data and information systems.&lt;&lt;ETX&gt;&gt;\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.14489626420938176, 'word': 'display'},\n",
              "   {'score': 0.09089437873070358, 'word': 'fuzzy'},\n",
              "   {'score': 0.09089437873070358, 'word': 'data'},\n",
              "   {'score': 0.08600633609772494, 'word': 'electronic'},\n",
              "   {'score': 0.08600633609772494, 'word': 'devices'},\n",
              "   {'score': 0.07444163298743312, 'word': 'visualization'},\n",
              "   {'score': 0.06583803358755763, 'word': 'methods'}],\n",
              "  'Title': 'Visualization of fuzzy data using generalized animation',\n",
              "  'distance': 0,\n",
              "  'no': '793',\n",
              "  'parent': '4004'},\n",
              " {'Abstract': 'A general volume rendering technique is described that efficiently produces images of excellent quality from data defined over irregular grids having a wide variety of formats. Rendering is done in software, eliminating the need for special graphics hardware, as well as any artifacts associated with graphics hardware. Images of volumes with about 1,000,000 cells can be produced in one to several minutes on a workstation with a 150-MHz processor. A significant advantage of this method for applications such as computational fluid dynamics is that it can process multiple intersecting grids. Such grids present problems for most current volume rendering techniques. Also, the wide range of cell sizes does not present difficulties, as it does for many techniques. A spatial hierarchical organization makes it possible to access data from a restricted region efficiently. The tree has greater depth in regions of greater detail, determined by the number of cells in the region. It also makes it possible to render useful \"preview\" images very quickly by displaying each region associated with a tree node as one cell. Previews show enough detail to navigate effectively in very large data sets. The algorithmic techniques include use of a k-d tree, with prefix-order partitioning of triangles, to reduce the number of primitives that must be processed for one rendering, coarse-grain parallelism for a shared-memory MIMD architecture, a new perspective transformation that achieves greater numerical accuracy, and a scanline algorithm with depth sorting and a new clipping technique.',\n",
              "  'AuthorKeywords': ['Computer',\n",
              "   'Graphics,',\n",
              "   'Scientific',\n",
              "   'Visualization,',\n",
              "   'Scanline,',\n",
              "   'Direct',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   'Curvilinear',\n",
              "   'Grid,',\n",
              "   'Irregular',\n",
              "   'Grid,',\n",
              "   'k-D',\n",
              "   'Tree'],\n",
              "  'MultipartiteRank': [{'score': 0.05091032164818482, 'word': 'restricted'},\n",
              "   {'score': 0.05091032164818482, 'word': 'region'},\n",
              "   {'score': 0.04945332037294174, 'word': 'cells'},\n",
              "   {'score': 0.04245345068058658, 'word': 'data'},\n",
              "   {'score': 0.039878375411826865, 'word': 'images'},\n",
              "   {'score': 0.03811620100469461, 'word': 'techniques'}],\n",
              "  'Title': 'Hierarchical and parallelizable direct volume rendering for irregular and multiple grids',\n",
              "  'distance': 0,\n",
              "  'no': '794',\n",
              "  'parent': '5269'},\n",
              " {'Abstract': 'Computer simulation and digital measuring systems are now generating data of unprecedented size. The size of data is becoming so large that conventional visualization tools are incapable of processing it, which is in turn is impacting the effectiveness of computational tools. In this paper we describe an object-oriented architecture that addresses this problem by automatically breaking data into pieces, and then processes the data piece-by-piece within a pipeline of filters. The piece size is user specified and can be controlled to eliminate the need for swapping (i.e., relying on virtual memory). In addition, because piece size can be controlled, any size problem can be run on any size computer, at the expense of extra computational time. Furthermore pieces are automatically broken into sub-pieces and each piece assigned to a different thread for parallel processing. This paper includes numerical performance studies and references to the source code which is freely available on the Web.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08827275380267538, 'word': 'data'},\n",
              "   {'score': 0.08076998697585636, 'word': 'pieces'},\n",
              "   {'score': 0.06945532762178401, 'word': 'computer'},\n",
              "   {'score': 0.06945532762178401, 'word': 'simulation'},\n",
              "   {'score': 0.060323930962694026, 'word': 'unprecedented'},\n",
              "   {'score': 0.060323930962694026, 'word': 'size'},\n",
              "   {'score': 0.03769063156437859, 'word': 'digital'}],\n",
              "  'Title': 'A multi-threaded streaming pipeline architecture for large structured data sets',\n",
              "  'distance': 0,\n",
              "  'no': '795',\n",
              "  'parent': '4492'},\n",
              " {'Abstract': 'Presents a two-level approach for fusing direct volume rendering (DVR) and maximum-intensity projection (MIP) within a joint rendering method. Different structures within the data set are rendered locally by either MIP or DVR on an object-by-object basis. Globally, all the results of subsequent object renderings are combined in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data, while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus-and-context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates.',\n",
              "  'AuthorKeywords': ['visualization,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'dynamical',\n",
              "   'systems,medical',\n",
              "   'applications'],\n",
              "  'MultipartiteRank': [{'score': 0.08001011321959377, 'word': 'object'},\n",
              "   {'score': 0.06566525072070757, 'word': 'data'},\n",
              "   {'score': 0.0620006825683552, 'word': 'dvr'},\n",
              "   {'score': 0.06006737854189869, 'word': 'mip'},\n",
              "   {'score': 0.05615844252644014, 'word': 'level'},\n",
              "   {'score': 0.05615844252644014, 'word': 'approach'}],\n",
              "  'Title': 'Two-level volume rendering - fusing MIP and DVR',\n",
              "  'distance': 0,\n",
              "  'no': '796',\n",
              "  'parent': '3891'},\n",
              " {'Abstract': 'The presented work aims to identify major research topics, co-authorships, and trends in the IV Contest 2004 dataset. Co-author, paper-citation, and burst analysis were used to analyze the dataset. The results are visually presented as graphs, static Pajek [1] visualizations and interactive network layouts using Pajek&amp;#146;s SVG output feature. A complementary web page with all the raw data, details of the analyses, and high resolution images of all figures is available online at http://iv.slis.indiana.edu/ref/iv04contest/.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08328651581214029, 'word': 'dataset'},\n",
              "   {'score': 0.05319343604159477, 'word': 'details'},\n",
              "   {'score': 0.05280997748272408, 'word': 'static'},\n",
              "   {'score': 0.05280997748272408, 'word': 'pajek'},\n",
              "   {'score': 0.05181310914681282, 'word': 'raw'},\n",
              "   {'score': 0.05181310914681282, 'word': 'data'},\n",
              "   {'score': 0.05098163793923188, 'word': 'high'},\n",
              "   {'score': 0.05098163793923188, 'word': 'resolution'},\n",
              "   {'score': 0.05098163793923188, 'word': 'images'}],\n",
              "  'Title': 'Major Information Visualization Authors, Papers and Topics in the ACM Library',\n",
              "  'distance': 0,\n",
              "  'no': '797',\n",
              "  'parent': '3412'},\n",
              " {'Abstract': 'The evolving technology of computer auto-fabrication (\"3D printing\") now makes it possible to produce physical models for complex biological molecules and assemblies. We report on an application that demonstrates the use of auto-fabricated tangible models and augmented reality for research and education in molecular biology, and for enhancing the scientific environment for collaboration and exploration. We have adapted an augmented reality system to allow virtual 3D representations (generated by the Python Molecular Viewer) to be overlaid onto a tangible molecular model. Users can easily change the overlaid information, switching between different representations of the molecule, displays of molecular properties such as electrostatics, or dynamic information. The physical model provides a powerful, intuitive interface for manipulating the computer models, streamlining the interface between human intent, the physical model, and the computational activity.',\n",
              "  'AuthorKeywords': ['Molecular',\n",
              "   'Modeling,',\n",
              "   'Molecular',\n",
              "   'Visualization,',\n",
              "   'Augmented',\n",
              "   'Reality'],\n",
              "  'MultipartiteRank': [{'score': 0.09793922401820883, 'word': 'physical'},\n",
              "   {'score': 0.09793922401820883, 'word': 'models'},\n",
              "   {'score': 0.05216054078936727, 'word': 'computer'},\n",
              "   {'score': 0.05216054078936727, 'word': 'auto'},\n",
              "   {'score': 0.04812525600928434, 'word': 'complex'},\n",
              "   {'score': 0.04812525600928434, 'word': 'biological'},\n",
              "   {'score': 0.04812525600928434, 'word': 'molecules'},\n",
              "   {'score': 0.0411973843173723, 'word': 'intuitive'},\n",
              "   {'score': 0.0411973843173723, 'word': 'interface'},\n",
              "   {'score': 0.039120504844098396, 'word': 'reality'}],\n",
              "  'Title': 'Augmented reality with tangible auto-fabricated models for molecular biology applications',\n",
              "  'distance': 0,\n",
              "  'no': '798',\n",
              "  'parent': '4249'},\n",
              " {'Abstract': 'We present the Visual Code Navigator, a set of three interrelated visual tools that we developed for exploring large source code software projects from three different perspectives, or views: the syntactic view shows the syntactic constructs in the source code. The symbol view shows the objects a file makes available after compilation, such as function signatures, variables, and namespaces. The evolution view looks at different versions in a project lifetime of a number of selected source files. The views share one code model, which combines hierarchical syntax based and line based information from multiple source files versions. We render this code model using a visual model that extends the pixel-filling, space partitioning properties of shaded cushion treemaps with novel techniques. We discuss how our views allow users to interactively answer complex questions on various code elements by simple mouse clicks. We validate the efficiency and effectiveness of our toolset by an informal user study on the source code of VTK, a large, industry-size C++ code base',\n",
              "  'AuthorKeywords': ['source',\n",
              "   'code',\n",
              "   'visualization,',\n",
              "   'multiple',\n",
              "   'views,',\n",
              "   'treemaps,',\n",
              "   'pixel-filling',\n",
              "   'displays,',\n",
              "   'source',\n",
              "   'code',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.08859970742725734, 'word': 'views'},\n",
              "   {'score': 0.08833845957334938, 'word': 'code'},\n",
              "   {'score': 0.055200851411942184, 'word': 'file'},\n",
              "   {'score': 0.047231090506329225, 'word': 'large'},\n",
              "   {'score': 0.047231090506329225, 'word': 'source'},\n",
              "   {'score': 0.047231090506329225, 'word': 'software'},\n",
              "   {'score': 0.047231090506329225, 'word': 'projects'},\n",
              "   {'score': 0.04110736906702015, 'word': 'model'},\n",
              "   {'score': 0.03792555086484087, 'word': 'different'},\n",
              "   {'score': 0.03792555086484087, 'word': 'perspectives'}],\n",
              "  'Title': 'The visual code navigator: an interactive toolset for source code investigation',\n",
              "  'distance': 0,\n",
              "  'no': '799',\n",
              "  'parent': '5442'},\n",
              " {'Abstract': 'We present a new particle tracing approach for the simulation of mid- and high-frequency sound. Inspired by the photorealism obtained by methods like photon mapping, we develop a similar method for the physical simulation of sound within rooms. For given source and listener positions, our method computes a finite-response filter accounting for the different reflections at various surfaces with frequency-dependent absorption coefficients. Convoluting this filter with an anechoic input signal reproduces a realistic aural impression of the simulated room. We do not consider diffraction effects due to low frequencies, since these can be better computed by finite elements. Our method allows the visualization of a wave front propagation using color-coded blobs traversing the paths of individual phonons.',\n",
              "  'AuthorKeywords': ['acoustics,',\n",
              "   'auralization,',\n",
              "   'raytracing,',\n",
              "   'photon',\n",
              "   'mapping'],\n",
              "  'MultipartiteRank': [{'score': 0.0823318829783281, 'word': 'methods'},\n",
              "   {'score': 0.06543798017234397, 'word': 'frequency'},\n",
              "   {'score': 0.06543798017234397, 'word': 'sound'},\n",
              "   {'score': 0.05814806746633002, 'word': 'simulation'},\n",
              "   {'score': 0.042986739961538845, 'word': 'finite'},\n",
              "   {'score': 0.04271053667017087, 'word': 'response'},\n",
              "   {'score': 0.04271053667017087, 'word': 'filter'}],\n",
              "  'Title': 'Phonon tracing for auralization and visualization of sound',\n",
              "  'distance': 0,\n",
              "  'no': '800',\n",
              "  'parent': '3608'},\n",
              " {'Abstract': 'Line primitives are a very powerful visual attribute used for scientific visualization and in particular for 3D vector-field visualization. We extend the basic line primitives with additional visual attributes including color, line width, texture and orientation. To implement the visual attributes we represent the stylized line primitives as generalized cylinders. One important contribution of our work is an efficient rendering algorithm for stylized lines, which is hybrid in the sense that it uses both CPU and GPU based rendering. We improve the depth perception with a shadow algorithm. We present several applications for the visualization with stylized lines among which are the visualizations of 3D vector fields and molecular structures.',\n",
              "  'AuthorKeywords': ['rendering,', 'vector', 'fields,', 'streamlines'],\n",
              "  'MultipartiteRank': [{'score': 0.20665128560447768, 'word': 'line'},\n",
              "   {'score': 0.20665128560447768, 'word': 'primitives'},\n",
              "   {'score': 0.13201254263369813, 'word': 'powerful'},\n",
              "   {'score': 0.13201254263369813, 'word': 'visual'},\n",
              "   {'score': 0.13201254263369813, 'word': 'attribute'},\n",
              "   {'score': 0.04572084956650446, 'word': '3d'},\n",
              "   {'score': 0.04572084956650446, 'word': 'vector'},\n",
              "   {'score': 0.04373581980955017, 'word': 'generalized'},\n",
              "   {'score': 0.04373581980955017, 'word': 'cylinders'},\n",
              "   {'score': 0.040787527012384014, 'word': 'efficient'},\n",
              "   {'score': 0.040787527012384014, 'word': 'rendering'},\n",
              "   {'score': 0.040787527012384014, 'word': 'algorithm'}],\n",
              "  'Title': 'Visualization with stylized line primitives',\n",
              "  'distance': 0,\n",
              "  'no': '801',\n",
              "  'parent': '4470'},\n",
              " {'Abstract': 'Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays',\n",
              "  'AuthorKeywords': ['Multi-projector',\n",
              "   'displays,',\n",
              "   'projector-camera',\n",
              "   'systems,',\n",
              "   'geometric',\n",
              "   'and',\n",
              "   'color',\n",
              "   'calibration,',\n",
              "   'distributed',\n",
              "   'algorithms'],\n",
              "  'MultipartiteRank': [{'score': 0.09317373696956155, 'word': 'projectors'},\n",
              "   {'score': 0.08784642486791502, 'word': 'resolution'},\n",
              "   {'score': 0.08784642486791502, 'word': 'displays'},\n",
              "   {'score': 0.05788203208048657, 'word': 'centralized'},\n",
              "   {'score': 0.05788203208048657, 'word': 'techniques'},\n",
              "   {'score': 0.05236011461991224, 'word': 'ppp'},\n",
              "   {'score': 0.044843028685401125, 'word': 'multiple'}],\n",
              "  'Title': 'Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays',\n",
              "  'distance': 0,\n",
              "  'no': '802',\n",
              "  'parent': '4763'},\n",
              " {'Abstract': 'Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.',\n",
              "  'AuthorKeywords': ['Clustering,',\n",
              "   'Graph',\n",
              "   'Visualization,',\n",
              "   'Node',\n",
              "   'Duplications,',\n",
              "   'Social',\n",
              "   'Networks'],\n",
              "  'MultipartiteRank': [{'score': 0.08725727195080325, 'word': 'social'},\n",
              "   {'score': 0.08725727195080325, 'word': 'network'},\n",
              "   {'score': 0.08725727195080325, 'word': 'analysis'},\n",
              "   {'score': 0.08426907840945305, 'word': 'group'},\n",
              "   {'score': 0.08426907840945305, 'word': 'actors'},\n",
              "   {'score': 0.07584409244199364, 'word': 'communities'},\n",
              "   {'score': 0.06630369342608916, 'word': 'important'},\n",
              "   {'score': 0.06630369342608916, 'word': 'task'},\n",
              "   {'score': 0.05483382395013736, 'word': 'duplication'}],\n",
              "  'Title': 'Improving the Readability of Clustered Social Networks using Node Duplication',\n",
              "  'distance': 0,\n",
              "  'no': '803',\n",
              "  'parent': '4772'},\n",
              " {'Abstract': 'One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data.',\n",
              "  'AuthorKeywords': ['Bioinformatics',\n",
              "   'visualization,',\n",
              "   'design',\n",
              "   'study,',\n",
              "   'DNA',\n",
              "   'sequence,',\n",
              "   'genome',\n",
              "   'assembly'],\n",
              "  'MultipartiteRank': [{'score': 0.046092353968316235, 'word': 'current'},\n",
              "   {'score': 0.046092353968316235, 'word': 'visualization'},\n",
              "   {'score': 0.046092353968316235, 'word': 'tools'},\n",
              "   {'score': 0.04306255424485247, 'word': 'concise'},\n",
              "   {'score': 0.04306255424485247, 'word': 'visual'},\n",
              "   {'score': 0.04306255424485247, 'word': 'encoding'},\n",
              "   {'score': 0.042258574589027195, 'word': 'manual'},\n",
              "   {'score': 0.042258574589027195, 'word': 'inspection'},\n",
              "   {'score': 0.04030571510614761, 'word': 'paper'},\n",
              "   {'score': 0.03908411376917124, 'word': 'scale'},\n",
              "   {'score': 0.03908411376917124, 'word': 'genome'},\n",
              "   {'score': 0.03908411376917124, 'word': 'sequencing'},\n",
              "   {'score': 0.03908411376917124, 'word': 'projects'}],\n",
              "  'Title': 'ABySS-Explorer: Visualizing Genome Sequence Assemblies',\n",
              "  'distance': 0,\n",
              "  'no': '804',\n",
              "  'parent': '5263'},\n",
              " {'Abstract': 'A great corpus of studies reports empirical evidence of how information visualization supports comprehension and analysis of data. The benefits of visualization for synchronous group knowledge work, however, have not been addressed extensively. Anecdotal evidence and use cases illustrate the benefits of synchronous collaborative information visualization, but very few empirical studies have rigorously examined the impact of visualization on group knowledge work. We have consequently designed and conducted an experiment in which we have analyzed the impact of visualization on knowledge sharing in situated work groups. Our experimental study consists of evaluating the performance of 131 subjects (all experienced managers) in groups of 5 (for a total of 26 groups), working together on a real-life knowledge sharing task. We compare (1) the control condition (no visualization provided), with two visualization supports: (2) optimal and (3) suboptimal visualization (based on a previous survey). The facilitator of each group was asked to populate the provided interactive visual template with insights from the group, and to organize the contributions according to the group consensus. We have evaluated the results through both objective and subjective measures. Our statistical analysis clearly shows that interactive visualization has a statistically significant, objective and positive impact on the outcomes of knowledge sharing, but that the subjects seem not to be aware of this. In particular, groups supported by visualization achieved higher productivity, higher quality of outcome and greater knowledge gains. No statistically significant results could be found between an optimal and a suboptimal visualization though (as classified by the pre-experiment survey). Subjects also did not seem to be aware of the benefits that the visualizations provided as no difference between the visualization and the control conditions was found for the self-reported measures of satisfaction and participation. An implication of our study for information visualization applications is to extend them by using real-time group annotation functionalities that aid in the group sense making process of the represented data.',\n",
              "  'AuthorKeywords': ['Laboratory',\n",
              "   'Studies,',\n",
              "   'Visual',\n",
              "   'Knowledge',\n",
              "   'Representation,',\n",
              "   'Collaborative',\n",
              "   'and',\n",
              "   'Distributed',\n",
              "   'Visualization,',\n",
              "   'synchronous',\n",
              "   'situated',\n",
              "   'collaboration,',\n",
              "   'group',\n",
              "   'work,',\n",
              "   'experiment,',\n",
              "   'knowledge',\n",
              "   'sharing'],\n",
              "  'MultipartiteRank': [{'score': 0.1675810319529762, 'word': 'visualization'},\n",
              "   {'score': 0.11879546220378925, 'word': 'information'},\n",
              "   {'score': 0.042649406461746094, 'word': 'groups'},\n",
              "   {'score': 0.039727138306117876, 'word': 'studies'},\n",
              "   {'score': 0.03819114121926709, 'word': 'empirical'},\n",
              "   {'score': 0.03819114121926709, 'word': 'evidence'}],\n",
              "  'Title': 'The Benefits of Synchronous Collaborative Information Visualization: Evidence from an Experimental Evaluation',\n",
              "  'distance': 0,\n",
              "  'no': '805',\n",
              "  'parent': '6276'},\n",
              " {'Abstract': 'We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.',\n",
              "  'AuthorKeywords': ['Semantic',\n",
              "   'lenses,',\n",
              "   'magic',\n",
              "   'lenses,',\n",
              "   'graph',\n",
              "   'bundling,',\n",
              "   'attribute',\n",
              "   'filtering'],\n",
              "  'MultipartiteRank': [{'score': 0.142405842396827, 'word': 'data'},\n",
              "   {'score': 0.09888996827672808, 'word': 'multivariate'},\n",
              "   {'score': 0.09888996827672808, 'word': 'relational'},\n",
              "   {'score': 0.0666071095271238, 'word': 'novel'},\n",
              "   {'score': 0.0666071095271238, 'word': 'technique'},\n",
              "   {'score': 0.048245591540563015, 'word': 'interactive'},\n",
              "   {'score': 0.048245591540563015, 'word': 'exploration'},\n",
              "   {'score': 0.0438099250212165, 'word': 'semantic'},\n",
              "   {'score': 0.0438099250212165, 'word': 'lens'}],\n",
              "  'Title': 'MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots',\n",
              "  'distance': 0,\n",
              "  'no': '806',\n",
              "  'parent': '4641'},\n",
              " {'Abstract': 'We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07905514867448635, 'word': 'features'},\n",
              "   {'score': 0.06809339492192606, 'word': 'entities'},\n",
              "   {'score': 0.05402992798134725, 'word': 'measures'},\n",
              "   {'score': 0.04798695886413433, 'word': 'data'},\n",
              "   {'score': 0.04798695886413433, 'word': 'table'},\n",
              "   {'score': 0.04636901724293039, 'word': 'feature'},\n",
              "   {'score': 0.04636901724293039, 'word': 'subset'},\n",
              "   {'score': 0.04636901724293039, 'word': 'selection'},\n",
              "   {'score': 0.04636901724293039, 'word': 'algorithms'}],\n",
              "  'Title': 'Guiding feature subset selection with an interactive visualization',\n",
              "  'distance': 0,\n",
              "  'no': '807',\n",
              "  'parent': '4444'},\n",
              " {'Abstract': 'For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.',\n",
              "  'AuthorKeywords': ['Time-series',\n",
              "   'data,',\n",
              "   'ranking',\n",
              "   'change,',\n",
              "   'Themeriver,',\n",
              "   'interaction',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.09569101082585828, 'word': 'time'},\n",
              "   {'score': 0.09569101082585828, 'word': 'series'},\n",
              "   {'score': 0.09569101082585828, 'word': 'data'},\n",
              "   {'score': 0.07044889342621029, 'word': 'changes'},\n",
              "   {'score': 0.04785130993375015, 'word': 'people'},\n",
              "   {'score': 0.0468886392037957, 'word': 'interested'},\n",
              "   {'score': 0.03987149209618072, 'word': 'novel'},\n",
              "   {'score': 0.03987149209618072, 'word': 'visualization'},\n",
              "   {'score': 0.03987149209618072, 'word': 'method'}],\n",
              "  'Title': 'RankExplorer: Visualization of Ranking Changes in Large Time Series Data',\n",
              "  'distance': 0,\n",
              "  'no': '808',\n",
              "  'parent': '5499'},\n",
              " {'Abstract': 'We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.',\n",
              "  'AuthorKeywords': ['Visualization',\n",
              "   'design,',\n",
              "   'Interactive',\n",
              "   'Design,',\n",
              "   'Interaction,',\n",
              "   'Expressiveness,',\n",
              "   'Web-based',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.0986788569047871, 'word': 'system'},\n",
              "   {'score': 0.08535168630954765, 'word': 'information'},\n",
              "   {'score': 0.08535168630954765, 'word': 'visualizations'},\n",
              "   {'score': 0.07241080966701469, 'word': 'high'},\n",
              "   {'score': 0.07241080966701469, 'word': 'interactive'},\n",
              "   {'score': 0.07241080966701469, 'word': 'expressiveness'},\n",
              "   {'score': 0.06111702328371074, 'word': 'ivisdesigner'},\n",
              "   {'score': 0.058905329048286575, 'word': 'implementation'}],\n",
              "  'Title': 'iVisDesigner: Expressive Interactive Design of Information Visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '809',\n",
              "  'parent': '4231'},\n",
              " {'Abstract': 'Virtual angioscopy is a non invasive medical procedure for exploring parts of the human vascular system. We have developed an interactive tool that takes as input, data acquired with standard medical imaging modalities and regards it as a virtual environment to be interactively inspected. The system supports real time navigation with stereoscopic direct volume rendering and dynamic endoscopic camera control, interactive tissue classification, and interactive point picking for morphological feature measurement. We provide an overview of the system, discuss the techniques used in our prototype, and present experimental results on human data sets.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10312855889592937, 'word': 'virtual'},\n",
              "   {'score': 0.10312855889592937, 'word': 'angioscopy'},\n",
              "   {'score': 0.10124529215901114, 'word': 'human'},\n",
              "   {'score': 0.10124529215901114, 'word': 'vascular'},\n",
              "   {'score': 0.10124529215901114, 'word': 'system'},\n",
              "   {'score': 0.07163944821342752, 'word': 'interactive'},\n",
              "   {'score': 0.07163944821342752, 'word': 'tool'},\n",
              "   {'score': 0.07009983800506342, 'word': 'non'},\n",
              "   {'score': 0.07009983800506342, 'word': 'invasive'},\n",
              "   {'score': 0.07009983800506342, 'word': 'medical'},\n",
              "   {'score': 0.07009983800506342, 'word': 'procedure'},\n",
              "   {'score': 0.06871804284886744, 'word': 'data'}],\n",
              "  'Title': 'Interactive virtual angioscopy',\n",
              "  'distance': 0,\n",
              "  'no': '810',\n",
              "  'parent': '3461'},\n",
              " {'Abstract': 'Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data in an intuitively understandable and precise way. Here a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of flow data and serves as an appropriate scale space method for the visualization of complicated flow patterns. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. An initial noisy image is smoothed along streamlines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown in 2D and 3D and the provisions for flow segmentation are outlined.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'multiscale,',\n",
              "   'nonlinear',\n",
              "   'diffusion,',\n",
              "   'segmentation'],\n",
              "  'MultipartiteRank': [{'score': 0.17582946779405706, 'word': 'field'},\n",
              "   {'score': 0.1252951479153249, 'word': 'vector'},\n",
              "   {'score': 0.1252951479153249, 'word': 'visualization'},\n",
              "   {'score': 0.061354256850065916, 'word': 'image'},\n",
              "   {'score': 0.061354256850065916, 'word': 'analysis'},\n",
              "   {'score': 0.05493405047497614, 'word': 'important'},\n",
              "   {'score': 0.05493405047497614, 'word': 'topic'},\n",
              "   {'score': 0.05377557915166857, 'word': 'anisotropic'},\n",
              "   {'score': 0.05377557915166857, 'word': 'nonlinear'},\n",
              "   {'score': 0.05377557915166857, 'word': 'diffusion'},\n",
              "   {'score': 0.050534319878732165, 'word': 'data'}],\n",
              "  'Title': 'Anisotropic nonlinear diffusion in flow visualization',\n",
              "  'distance': 0,\n",
              "  'no': '811',\n",
              "  'parent': '4216'},\n",
              " {'Abstract': 'The increasing diversity of computers, especially among small mobile devices such as mobile phones and PDAs, raise new questions about information visualization techniques developed for the desktop computer. Using a series of examples ranging from applications for ordinary desktop displays to web-browsers and other applications for PDAs, we describe how a focus+context technique, Flip Zooming, is changed due to the situation it is used in. Based on these examples, we discuss how the use of \"focus\" and \"context\" in focus+context techniques change in order to fit new areas of use for information visualization.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08473575402825828, 'word': 'computers'},\n",
              "   {'score': 0.07831197003655538, 'word': 'new'},\n",
              "   {'score': 0.07831197003655538, 'word': 'questions'},\n",
              "   {'score': 0.07663166410997067, 'word': 'pdas'},\n",
              "   {'score': 0.07386811175463065, 'word': 'information'},\n",
              "   {'score': 0.07386811175463065, 'word': 'visualization'},\n",
              "   {'score': 0.07386811175463065, 'word': 'techniques'},\n",
              "   {'score': 0.0654978721359715, 'word': 'examples'}],\n",
              "  'Title': 'Redefining the focus and context of focus+context visualization',\n",
              "  'distance': 0,\n",
              "  'no': '812',\n",
              "  'parent': '3628'},\n",
              " {'Abstract': 'Presents an efficient method to automatically compute a smooth approximation of large functional scattered data sets given over arbitrarily shaped planar domains. Our approach is based on the construction of a C/sup 1/-continuous bivariate cubic spline and our method offers optimal approximation order. Both local variation and nonuniform distribution of the data are taken into account by using local polynomial least squares approximations of varying degree. Since we only need to solve small linear systems and no triangulation of the scattered data points is required, the overall complexity of the algorithm is linear in the total number of points. Numerical examples dealing with several real-world scattered data sets with up to millions of points demonstrate the efficiency of our method. The resulting spline surface is of high visual quality and can be efficiently evaluated for rendering and modeling. In our implementation we achieve real-time frame rates for typical fly-through sequences and interactive frame rates for recomputing and rendering a locally modified spline surface.',\n",
              "  'AuthorKeywords': ['scattered',\n",
              "   'data',\n",
              "   'approximation,',\n",
              "   'least',\n",
              "   'squares',\n",
              "   'approximation,',\n",
              "   'terrain',\n",
              "   'visualization,',\n",
              "   'data',\n",
              "   'compression'],\n",
              "  'MultipartiteRank': [{'score': 0.07309872167934142, 'word': 'data'},\n",
              "   {'score': 0.07309872167934142, 'word': 'sets'},\n",
              "   {'score': 0.059834811150008584, 'word': 'smooth'},\n",
              "   {'score': 0.059834811150008584, 'word': 'approximation'},\n",
              "   {'score': 0.04563195522046466, 'word': 'efficient'},\n",
              "   {'score': 0.04563195522046466, 'word': 'method'},\n",
              "   {'score': 0.038143065497222454, 'word': 'points'},\n",
              "   {'score': 0.03785751775193166, 'word': 'several'},\n",
              "   {'score': 0.03785751775193166, 'word': 'real'}],\n",
              "  'Title': 'Smooth approximation and rendering of large scattered data sets',\n",
              "  'distance': 0,\n",
              "  'no': '813',\n",
              "  'parent': '3709'},\n",
              " {'Abstract': 'We introduce two dynamic visualization techniques using multidimensional scaling to analyze transient data streams such as newswires and remote sensing imagery. While the time-sensitive nature of these data streams requires immediate attention in many applications, the unpredictable and unbounded characteristics of this information can potentially overwhelm many scaling algorithms that require a full re-computation for every update. We present an adaptive visualization technique based on data stratification to ingest stream information adaptively when influx rate exceeds processing rate. We also describe an incremental visualization technique based on data fusion to project new information directly onto a visualization subspace spanned by the singular vectors of the previously processed neighboring data. The ultimate goal is to leverage the value of legacy and new information and minimize re-processing of the entire dataset in full resolution. We demonstrate these dynamic visualization results using a newswire corpus and a remote sensing imagery sequence.',\n",
              "  'AuthorKeywords': ['Dynamic',\n",
              "   'Visualization,',\n",
              "   'Text',\n",
              "   'Visualization,',\n",
              "   'Remote',\n",
              "   'Sensing',\n",
              "   'Imagery,',\n",
              "   'Transient',\n",
              "   'Data',\n",
              "   'Stream'],\n",
              "  'MultipartiteRank': [{'score': 0.07783909513181005, 'word': 'data'},\n",
              "   {'score': 0.07783909513181005, 'word': 'streams'},\n",
              "   {'score': 0.07311611161914985, 'word': 'dynamic'},\n",
              "   {'score': 0.07311611161914985, 'word': 'visualization'},\n",
              "   {'score': 0.07311611161914985, 'word': 'techniques'},\n",
              "   {'score': 0.06796796881398931, 'word': 'information'},\n",
              "   {'score': 0.06372597123554316, 'word': 'many'},\n",
              "   {'score': 0.06372597123554316, 'word': 'applications'},\n",
              "   {'score': 0.04820237537213364, 'word': 'immediate'},\n",
              "   {'score': 0.04820237537213364, 'word': 'attention'}],\n",
              "  'Title': 'Dynamic visualization of transient data streams',\n",
              "  'distance': 0,\n",
              "  'no': '814',\n",
              "  'parent': '4085'},\n",
              " {'Abstract': 'We present improved subdivision and isosurface reconstruction algorithms for polygonizing implicit surfaces and performing accurate geometric operations. Our improved reconstruction algorithm uses directed distance fields (Kobbelt et al., 2001) to detect multiple intersections along an edge, separates them into components and reconstructs an isosurface locally within each components using the dual contouring algorithm (Ju et al., 2002). It can reconstruct thin features without creating handles and results in improved surface extraction from volumetric data. Our subdivision algorithm takes into account sharp features that arise from intersecting surfaces or Boolean operations and generates an adaptive grid such that each voxel has at most one sharp feature. The subdivision algorithm is combined with our improved reconstruction algorithm to compute accurate polygonization of Boolean combinations or offsets of complex primitives that faithfully reconstruct the sharp features. We have applied these algorithms to polygonize complex CAD models designed using thousands of Boolean operations on curved primitives.',\n",
              "  'AuthorKeywords': ['Implicit',\n",
              "   'modeling,',\n",
              "   'Boolean',\n",
              "   'operations,',\n",
              "   'Marching',\n",
              "   'Cubes,',\n",
              "   'Distance',\n",
              "   'fields,',\n",
              "   'Subdivision'],\n",
              "  'MultipartiteRank': [{'score': 0.14496074598353245, 'word': 'isosurface'},\n",
              "   {'score': 0.14496074598353245, 'word': 'reconstruction'},\n",
              "   {'score': 0.14496074598353245, 'word': 'algorithms'},\n",
              "   {'score': 0.08831226523430519, 'word': 'implicit'},\n",
              "   {'score': 0.08831226523430519, 'word': 'surfaces'},\n",
              "   {'score': 0.060193547718785836, 'word': 'improved'},\n",
              "   {'score': 0.060193547718785836, 'word': 'subdivision'},\n",
              "   {'score': 0.05787382146516393, 'word': 'thin'},\n",
              "   {'score': 0.05787382146516393, 'word': 'features'},\n",
              "   {'score': 0.049195426248076796, 'word': 'boolean'},\n",
              "   {'score': 0.049195426248076796, 'word': 'operations'}],\n",
              "  'Title': 'Feature-sensitive subdivision and isosurface reconstruction',\n",
              "  'distance': 0,\n",
              "  'no': '815',\n",
              "  'parent': '4906'},\n",
              " {'Abstract': 'Visualization of 3D tensor fields continues to be a major challenge in terms of providing intuitive and uncluttered images that allow the users to better understand their data. The primary focus of this paper is on finding a formulation that lends itself to a stable numerical algorithm for extracting stable and persistent topological features from 2nd order real symmetric 3D tensors. While features in 2D tensors can be identified as either wedge or trisector points, in 3D, the corresponding stable features are lines, not just points. These topological feature lines provide a compact representation of the 3D tensor field and are essential in helping scientists and engineers understand their complex nature. Existing techniques work by finding degenerate points and are not numerically stable, and worse, produce both false positive and false negative feature points. This work seeks to address this problem with a robust algorithm that can extract these features in a numerically stable, accurate, and complete manner.',\n",
              "  'AuthorKeywords': ['hyperstreamlines,',\n",
              "   'real',\n",
              "   'symmetric',\n",
              "   'tensors,',\n",
              "   'degenerate',\n",
              "   'tensors,',\n",
              "   'tensor',\n",
              "   'topology,',\n",
              "   'topological',\n",
              "   'lines'],\n",
              "  'MultipartiteRank': [{'score': 0.13473837179186057, 'word': 'stable'},\n",
              "   {'score': 0.09057347639824062, 'word': 'persistent'},\n",
              "   {'score': 0.09057347639824062, 'word': 'topological'},\n",
              "   {'score': 0.09057347639824062, 'word': 'features'},\n",
              "   {'score': 0.07952678993681202, 'word': 'numerical'},\n",
              "   {'score': 0.07952678993681202, 'word': 'algorithm'},\n",
              "   {'score': 0.05317980944940744, 'word': 'trisector'},\n",
              "   {'score': 0.05317980944940744, 'word': 'points'},\n",
              "   {'score': 0.03747019404346759, 'word': '3d'},\n",
              "   {'score': 0.03747019404346759, 'word': 'tensor'},\n",
              "   {'score': 0.03747019404346759, 'word': 'fields'}],\n",
              "  'Title': 'Topological lines in 3D tensor fields',\n",
              "  'distance': 0,\n",
              "  'no': '816',\n",
              "  'parent': '3863'},\n",
              " {'Abstract': 'Diffusion tensor imaging (DTI) is an MRI-based technique for quantifying water diffusion in living tissue. In the white matter of the brain, water diffuses more rapidly along the neuronal axons than in the perpendicular direction. By exploiting this phenomenon, DTI can be used to determine trajectories of fiber bundles, or neuronal connections between regions, in the brain. The resulting bundles can be visualized. However, the resulting visualizations can be complex and difficult to interpret. An effective approach is to pre-determine trajectories from a large number of positions throughout the white matter (full brain fiber tracking) and to offer facilities to aid the user in selecting fiber bundles of interest. Two factors are crucial for the use and acceptance of this technique in clinical studies: firstly, the selection of the bundles by brain experts should be interactive, supported by real-time visualization of the trajectories registered with anatomical MRI scans. Secondly, the fiber selections should be reproducible, so that different experts will achieve the same results. In this paper we present a practical technique for the interactive selection of fiber-bundles using multiple convex objects that is an order of magnitude faster than similar techniques published earlier. We also present the results of a clinical study with ten subjects that show that our selection approach is highly reproducible for fractional anisotropy (FA) calculated over the selected fiber bundles.',\n",
              "  'AuthorKeywords': ['diffusion',\n",
              "   'tensor',\n",
              "   'imaging,',\n",
              "   'tractography,',\n",
              "   'white',\n",
              "   'matter'],\n",
              "  'MultipartiteRank': [{'score': 0.07942014209087059, 'word': 'bundles'},\n",
              "   {'score': 0.05399773329924301, 'word': 'brain'},\n",
              "   {'score': 0.04856715351370028, 'word': 'technique'},\n",
              "   {'score': 0.04284994129019104, 'word': 'fiber'},\n",
              "   {'score': 0.0355992527964884, 'word': 'trajectories'}],\n",
              "  'Title': 'Fast and reproducible fiber bundle selection in DTI visualization',\n",
              "  'distance': 0,\n",
              "  'no': '817',\n",
              "  'parent': '5262'},\n",
              " {'Abstract': 'Gaining a comprehensive understanding of turbulent flows still poses one of the great challenges in fluid dynamics. A well-established approach to advance this research is the analysis of the vortex structures contained in the flow. In order to be able to perform this analysis efficiently, supporting visualization tools with clearly defined requirements are needed. In this paper, we present a visualization system which matches these requirements to a large extent. The system consists of two components. The first component analyzes the flow by means of a novel combination of vortex core line detection and the /spl lambda//sub 2/ method. The second component is a vortex browser which allows for an interactive exploration and manipulation of the vortices detected and separated during the first phase. Our system improves the reliability and applicability of existing vortex detection methods and allows for a more efficient study of vortical flows which is demonstrated in an evaluation performed by experts.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'Features,',\n",
              "   'Vortex',\n",
              "   'Detection,',\n",
              "   'Interactive',\n",
              "   'Manipulation,',\n",
              "   '3D',\n",
              "   'Vector',\n",
              "   'Field',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.07368210307721769, 'word': 'turbulent'},\n",
              "   {'score': 0.07368210307721769, 'word': 'flows'},\n",
              "   {'score': 0.05558331134961983, 'word': 'visualization'},\n",
              "   {'score': 0.05558331134961983, 'word': 'system'},\n",
              "   {'score': 0.05206662336628208, 'word': 'components'},\n",
              "   {'score': 0.042834208006061136, 'word': 'analysis'},\n",
              "   {'score': 0.042321587053890004, 'word': 'flow'}],\n",
              "  'Title': 'Opening the can of worms: an exploration tool for vortical flows',\n",
              "  'distance': 0,\n",
              "  'no': '818',\n",
              "  'parent': '4900'},\n",
              " {'Abstract': 'This paper presents an approach to extracting and classifying higher order critical points of 3D vector fields. To do so, we place a closed convex surface s around the area of interest. Then we show that the complete 3D classification of a critical point into areas of different flow behavior is equivalent to extracting the topological skeleton of an appropriate 2D vector field on s, if each critical point is equipped with an additional bit of information. Out of this skeleton, we create an icon which replaces the complete topological structure inside s for the visualization. We apply our method to find a simplified visual representation of clusters of critical points, leading to expressive visualizations of topologically complex 3D vector fields.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.2062492134359289, 'word': 'critical'},\n",
              "   {'score': 0.13623524031899414, 'word': 'higher'},\n",
              "   {'score': 0.13623524031899414, 'word': 'order'},\n",
              "   {'score': 0.13623524031899414, 'word': 'points'},\n",
              "   {'score': 0.10549864687107197, 'word': '3d'},\n",
              "   {'score': 0.10549864687107197, 'word': 'vector'},\n",
              "   {'score': 0.10549864687107197, 'word': 'fields'},\n",
              "   {'score': 0.07001397311693473, 'word': 'point'},\n",
              "   {'score': 0.06387933112700742, 'word': 'area'},\n",
              "   {'score': 0.05607149904076221, 'word': 'visualization'}],\n",
              "  'Title': 'Extracting higher order critical points and topological simplification of 3D vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '819',\n",
              "  'parent': '4569'},\n",
              " {'Abstract': 'We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'Visualization,',\n",
              "   'Feature',\n",
              "   'Detection,',\n",
              "   'Pattern',\n",
              "   'Extraction,',\n",
              "   'Pattern',\n",
              "   'Recognition,',\n",
              "   'Image',\n",
              "   'Processing'],\n",
              "  'MultipartiteRank': [{'score': 0.10432140286899444, 'word': 'invariant'},\n",
              "   {'score': 0.10432140286899444, 'word': 'moments'},\n",
              "   {'score': 0.06996415463852021, 'word': 'field'},\n",
              "   {'score': 0.06996415463852021, 'word': 'data'},\n",
              "   {'score': 0.05019784129398997, 'word': 'flow'},\n",
              "   {'score': 0.05019784129398997, 'word': 'patterns'},\n",
              "   {'score': 0.04978265165299316, 'word': 'idea'},\n",
              "   {'score': 0.048259688899487056, 'word': 'novel'},\n",
              "   {'score': 0.048259688899487056, 'word': 'approach'}],\n",
              "  'Title': 'Moment Invariants for the Analysis of 2D Flow fields',\n",
              "  'distance': 0,\n",
              "  'no': '820',\n",
              "  'parent': '5110'},\n",
              " {'Abstract': 'Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.',\n",
              "  'AuthorKeywords': ['Scalar',\n",
              "   'topology,',\n",
              "   'comparative',\n",
              "   'visualization,',\n",
              "   'contour',\n",
              "   'tree,',\n",
              "   'largest',\n",
              "   'contours,',\n",
              "   'flow',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.09611961156548146, 'word': 'understanding'},\n",
              "   {'score': 0.09611961156548146, 'word': 'fluid'},\n",
              "   {'score': 0.09611961156548146, 'word': 'flow'},\n",
              "   {'score': 0.09611961156548146, 'word': 'data'},\n",
              "   {'score': 0.08077660993700703, 'word': 'features'},\n",
              "   {'score': 0.058355639737851864, 'word': 'scalar'},\n",
              "   {'score': 0.058355639737851864, 'word': 'fields'},\n",
              "   {'score': 0.04458547108794792, 'word': 'relationships'},\n",
              "   {'score': 0.034744296637046056, 'word': 'vortices'}],\n",
              "  'Title': 'Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '821',\n",
              "  'parent': '4405'},\n",
              " {'Abstract': 'Cells in an organism share the same genetic information in their DNA, but have very different forms and behavior because of the selective expression of subsets of their genes. The widely used approach of measuring gene expression over time from a tissue sample using techniques such as microarrays or sequencing do not provide information about the spatial position with in the tissue where these genes are expressed. In contrast, we are working with biologists who use techniques that measure gene expression in every individual cell of entire fruitfly embryos over an hour of their development, and do so for multiple closely-related subspecies of Drosophila. These scientists are faced with the challenge of integrating temporal gene expression data with the spatial location of cells and, moreover, comparing this data across multiple related species. We have worked with these biologists over the past two years to develop MulteeSum, a visualization system that supports inspection and curation of data sets showing gene expression over time, in conjunction with the spatial location of the cells where the genes are expressed - it is the first tool to support comparisons across multiple such data sets. MulteeSum is part of a general and flexible framework we developed with our collaborators that is built around multiple summaries for each cell, allowing the biologists to explore the results of computations that mix spatial information, gene expression measurements over time, and data from multiple related species or organisms. We justify our design decisions based on specific descriptions of the analysis needs of our collaborators, and provide anecdotal evidence of the efficacy of MulteeSum through a series of case studies.',\n",
              "  'AuthorKeywords': ['Spatial',\n",
              "   'data,',\n",
              "   'temporal',\n",
              "   'data,',\n",
              "   'gene',\n",
              "   'expression'],\n",
              "  'MultipartiteRank': [{'score': 0.07784144647224185, 'word': 'genes'},\n",
              "   {'score': 0.06110028658105575, 'word': 'cells'},\n",
              "   {'score': 0.03559972874017066, 'word': 'spatial'},\n",
              "   {'score': 0.03559972874017066, 'word': 'position'},\n",
              "   {'score': 0.031925887880534354, 'word': 'time'},\n",
              "   {'score': 0.031051073943520552, 'word': 'data'}],\n",
              "  'Title': 'MulteeSum: A Tool for Comparative Spatial and Temporal Gene Expression Data',\n",
              "  'distance': 0,\n",
              "  'no': '822',\n",
              "  'parent': '5623'},\n",
              " {'Abstract': 'In modeling infectious diseases, scientists are studying the mechanisms by which diseases spread, predicting the future course of the outbreak, and evaluating strategies applied to control an epidemic. While recent work has focused on accurately modeling disease spread, less work has been performed in developing interactive decision support tools for analyzing the future course of the outbreak and evaluating potential disease mitigation strategies. The absence of such tools makes it difficult for researchers, analysts and public health officials to evaluate response measures within outbreak scenarios. As such, our research focuses on the development of an interactive decision support environment in which users can explore epidemic models and their impact. This environment provides a spatiotemporal view where users can interactively utilize mitigative response measures and observe the impact of their decision over time. Our system also provides users with a linked decision history visualization and navigation tool that support the simultaneous comparison of mortality and infection rates corresponding to different response measures at different points in time.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.06451517304972763, 'word': 'infectious'},\n",
              "   {'score': 0.06451517304972763, 'word': 'diseases'},\n",
              "   {'score': 0.05710110591902098, 'word': 'outbreak'},\n",
              "   {'score': 0.047443216987690766, 'word': 'response'},\n",
              "   {'score': 0.047443216987690766, 'word': 'measures'},\n",
              "   {'score': 0.04337059738243718, 'word': 'users'},\n",
              "   {'score': 0.04051834368545858, 'word': 'future'},\n",
              "   {'score': 0.04051834368545858, 'word': 'course'}],\n",
              "  'Title': 'Visual analytics decision support environment for epidemic modeling and response evaluation',\n",
              "  'distance': 0,\n",
              "  'no': '823',\n",
              "  'parent': '4867'},\n",
              " {'Abstract': 'Blood flow and derived data are essential to investigate the initiation and progression of cerebral aneurysms as well as their risk of rupture. An effective visual exploration of several hemodynamic attributes like the wall shear stress (WSS) and the inflow jet is necessary to understand the hemodynamics. Moreover, the correlation between focus-and-context attributes is of particular interest. An expressive visualization of these attributes and anatomic information requires appropriate visualization techniques to minimize visual clutter and occlusions. We present the FLOWLENS as a focus-and-context approach that addresses these requirements. We group relevant hemodynamic attributes to pairs of focus-and-context attributes and assign them to different anatomic scopes. For each scope, we propose several FLOWLENS visualization templates to provide a flexible visual filtering of the involved hemodynamic pairs. A template consists of the visualization of the focus attribute and the additional depiction of the context attribute inside the lens. Furthermore, the FLOWLENS supports local probing and the exploration of attribute changes over time. The FLOWLENS minimizes visual cluttering, occlusions, and provides a flexible exploration of a region of interest. We have applied our approach to seven representative datasets, including steady and unsteady flow data from CFD simulations and 4D PC-MRI measurements. Informal user interviews with three domain experts confirm the usefulness of our approach.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'Visualization,',\n",
              "   'Focus-and-Context,',\n",
              "   'Illustrative',\n",
              "   'Rendering,',\n",
              "   'Aneurysm'],\n",
              "  'MultipartiteRank': [{'score': 0.1062717816338282, 'word': 'attributes'},\n",
              "   {'score': 0.05988428116632658, 'word': 'context'},\n",
              "   {'score': 0.05434120034427551, 'word': 'expressive'},\n",
              "   {'score': 0.05434120034427551, 'word': 'visualization'},\n",
              "   {'score': 0.04638750046750162, 'word': 'several'},\n",
              "   {'score': 0.04638750046750162, 'word': 'hemodynamic'},\n",
              "   {'score': 0.03964034048476872, 'word': 'effective'},\n",
              "   {'score': 0.03964034048476872, 'word': 'visual'},\n",
              "   {'score': 0.03964034048476872, 'word': 'exploration'},\n",
              "   {'score': 0.036498430154948296, 'word': 'flowlens'}],\n",
              "  'Title': 'The FLOWLENS: A Focus-and-Context Visualization Approach for Exploration of Blood Flow in Cerebral Aneurysms',\n",
              "  'distance': 0,\n",
              "  'no': '824',\n",
              "  'parent': '4959'},\n",
              " {'Abstract': 'Visual analysis is widely used to study the behavior of molecules. Of particular interest are the analysis of molecular interactions and the investigation of binding sites. For large molecules, however, it is difficult to detect possible binding sites and paths leading to these sites by pure visual inspection. In this paper, we present new methods for the computation and visualization of potential molecular paths. Using a novel filtering method, we extract the significant paths from the Voronoi diagram of spheres. For the interactive visualization of molecules and their paths, we present several methods using deferred shading and other state-of-theart techniques. To allow for a fast overview of reachable regions of the molecule, we illuminate the molecular surface using a large number of light sources placed on the extracted paths. We also provide a method to compute the extension surface of selected paths and visualize it using the skin surface. Furthermore, we use the extension surface to clip the molecule to allow easy visual tracking of even deeply buried paths. The methods are applied to several proteins to demonstrate their usefulness.',\n",
              "  'AuthorKeywords': ['Molecular',\n",
              "   'visualization,',\n",
              "   'data',\n",
              "   'filtering,',\n",
              "   'geometry-based',\n",
              "   'techniques,',\n",
              "   'view-dependent',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.09360423581509597, 'word': 'paths'},\n",
              "   {'score': 0.07372906229682442, 'word': 'molecules'},\n",
              "   {'score': 0.06739909111926541, 'word': 'pure'},\n",
              "   {'score': 0.06739909111926541, 'word': 'visual'},\n",
              "   {'score': 0.06739909111926541, 'word': 'inspection'},\n",
              "   {'score': 0.06709140317347537, 'word': 'new'},\n",
              "   {'score': 0.06709140317347537, 'word': 'methods'},\n",
              "   {'score': 0.05899673670490211, 'word': 'sites'}],\n",
              "  'Title': 'Voronoi-Based Extraction and Visualization of Molecular Paths',\n",
              "  'distance': 0,\n",
              "  'no': '825',\n",
              "  'parent': '4921'},\n",
              " {'Abstract': \"In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.\",\n",
              "  'AuthorKeywords': ['Perception,',\n",
              "   'attention,',\n",
              "   'color,',\n",
              "   'motion,',\n",
              "   'user',\n",
              "   'study,',\n",
              "   'nominal',\n",
              "   'axis,',\n",
              "   'layout,',\n",
              "   'goal-oriented',\n",
              "   'design'],\n",
              "  'MultipartiteRank': [{'score': 0.0986335109383719, 'word': 'information'},\n",
              "   {'score': 0.0986335109383719, 'word': 'visualizations'},\n",
              "   {'score': 0.0625094478327152, 'word': 'capacity'},\n",
              "   {'score': 0.0625094478327152, 'word': 'limits'},\n",
              "   {'score': 0.05250224150445736, 'word': 'effectiveness'},\n",
              "   {'score': 0.047143880528728976, 'word': 'attention'},\n",
              "   {'score': 0.045440739240412316, 'word': 'experiments'}],\n",
              "  'Title': 'How Capacity Limits of Attention Influence Information Visualization Effectiveness',\n",
              "  'distance': 0,\n",
              "  'no': '826',\n",
              "  'parent': '4355'},\n",
              " {'Abstract': 'Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.',\n",
              "  'AuthorKeywords': ['Mobility,',\n",
              "   'public',\n",
              "   'transportation,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.04991091536211261, 'word': 'isochrone'},\n",
              "   {'score': 0.04991091536211261, 'word': 'map'},\n",
              "   {'score': 0.04991091536211261, 'word': 'view'},\n",
              "   {'score': 0.04887852607122094, 'word': 'time'},\n",
              "   {'score': 0.0447359046970227, 'word': 'pts'},\n",
              "   {'score': 0.04100223012087089, 'word': 'various'},\n",
              "   {'score': 0.04100223012087089, 'word': 'mobility'},\n",
              "   {'score': 0.0408479100897118, 'word': 'visualization'},\n",
              "   {'score': 0.0408479100897118, 'word': 'modules'}],\n",
              "  'Title': 'Visualizing Mobility of Public Transportation System',\n",
              "  'distance': 0,\n",
              "  'no': '827',\n",
              "  'parent': '4369'},\n",
              " {'Abstract': \"When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other's activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.\",\n",
              "  'AuthorKeywords': ['Sensemaking,',\n",
              "   'Collaboration,',\n",
              "   'Externalization,',\n",
              "   'Linked',\n",
              "   'common',\n",
              "   'work,',\n",
              "   'Collaborative',\n",
              "   'thinking',\n",
              "   'space'],\n",
              "  'MultipartiteRank': [{'score': 0.06895294108328714, 'word': 'lcw'},\n",
              "   {'score': 0.05677367214644526, 'word': 'findings'},\n",
              "   {'score': 0.04748221678469613, 'word': 'collaborators'},\n",
              "   {'score': 0.043267338269976766, 'word': 'clip'},\n",
              "   {'score': 0.04299057100975895, 'word': 'collaborative'},\n",
              "   {'score': 0.04299057100975895, 'word': 'thinking'},\n",
              "   {'score': 0.04299057100975895, 'word': 'space'}],\n",
              "  'Title': 'Supporting Communication and Coordination in Collaborative Sensemaking',\n",
              "  'distance': 0,\n",
              "  'no': '828',\n",
              "  'parent': '4618'},\n",
              " {'Abstract': \"Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.\",\n",
              "  'AuthorKeywords': ['Anomaly',\n",
              "   'Detection,',\n",
              "   'Social',\n",
              "   'Media,',\n",
              "   'Visual',\n",
              "   'Analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.13453568412407627, 'word': 'users'},\n",
              "   {'score': 0.11344363836233365, 'word': 'behaviors'},\n",
              "   {'score': 0.07858427536113001, 'word': 'anomalous'},\n",
              "   {'score': 0.035882155642300684, 'word': 'anomaly'},\n",
              "   {'score': 0.035882155642300684, 'word': 'detection'},\n",
              "   {'score': 0.03346397026766673, 'word': 'targetvue'}],\n",
              "  'Title': 'TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems',\n",
              "  'distance': 0,\n",
              "  'no': '829',\n",
              "  'parent': '4410'},\n",
              " {'Abstract': 'The author describes a visualization model for three-dimensional scalar data fields based on linear transport theory. The concept of virtual particles for the extraction of information from data fields in introduced. The role of different types of interaction of the data field with those particles such as absorption, scattering, source and color shift are discussed and demonstrated. Special attention is given to possible tools for the enhancement of interesting data features. Random texturing can provide visual insights as to the magnitude and distribution of deviations of related data fields, e.g., originating from analytic models, and measurements, or in the noise content of a given data field. Hidden symmetries of a data set can often be identified visually by allowing it to interact with a preselected beam of physical particles with the attendant appearance of characteristic structural effects such as channeling.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17079973046219904, 'word': 'data'},\n",
              "   {'score': 0.17079973046219904, 'word': 'fields'},\n",
              "   {'score': 0.1168729352959811, 'word': 'dimensional'},\n",
              "   {'score': 0.1168729352959811, 'word': 'scalar'},\n",
              "   {'score': 0.053294234133556766, 'word': 'visualization'},\n",
              "   {'score': 0.053294234133556766, 'word': 'model'},\n",
              "   {'score': 0.04891263092226038, 'word': 'virtual'},\n",
              "   {'score': 0.04891263092226038, 'word': 'particles'},\n",
              "   {'score': 0.046137477742534336, 'word': 'linear'},\n",
              "   {'score': 0.046137477742534336, 'word': 'transport'},\n",
              "   {'score': 0.046137477742534336, 'word': 'theory'}],\n",
              "  'Title': 'The application of transport theory to visualization of 3D scalar data fields',\n",
              "  'distance': 0,\n",
              "  'no': '830',\n",
              "  'parent': '3646'},\n",
              " {'Abstract': 'In Rogowitz and Treinish (1993), we introduced an architecture for incorporating perceptual rules into the visualization process. In this architecture, higher-level descriptors of the data, metadata, flow to perceptual rules, which constrain visualization operations. In this paper, we develop a deeper analysis of the rules, the prerequisite metadata, and the system for enabling their operation.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.13640334637182466, 'word': 'perceptual'},\n",
              "   {'score': 0.13640334637182466, 'word': 'rules'},\n",
              "   {'score': 0.10863361816671771, 'word': 'architecture'},\n",
              "   {'score': 0.10035917815553452, 'word': 'visualization'},\n",
              "   {'score': 0.10035917815553452, 'word': 'process'},\n",
              "   {'score': 0.0945811976904967, 'word': 'metadata'},\n",
              "   {'score': 0.07611388717273257, 'word': 'higher'}],\n",
              "  'Title': 'An architecture for rule-based visualization',\n",
              "  'distance': 0,\n",
              "  'no': '831',\n",
              "  'parent': '3396'},\n",
              " {'Abstract': 'Some new piecewise constant wavelets defined over nested triangulated domains are presented and applied to the problem of multiresolution analysis of flow over a spherical domain. These new, nearly orthogonal wavelets have advantages over the existing weaker biorthogonal wavelets. In the planar case of uniform areas, the wavelets converge to one of two fully orthogonal Haar wavelets. These new, fully orthogonal wavelets are proven to be the only possible wavelets of this type.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.15865952667300373, 'word': 'orthogonal'},\n",
              "   {'score': 0.15865952667300373, 'word': 'wavelets'},\n",
              "   {'score': 0.11258678365394012, 'word': 'new'},\n",
              "   {'score': 0.1007163241907815, 'word': 'triangulated'},\n",
              "   {'score': 0.1007163241907815, 'word': 'domains'},\n",
              "   {'score': 0.07203422015547115, 'word': 'advantages'},\n",
              "   {'score': 0.07191710396796469, 'word': 'multiresolution'},\n",
              "   {'score': 0.07191710396796469, 'word': 'analysis'}],\n",
              "  'Title': 'Haar wavelets over triangular domains with applications to multiresolution models for flow over a sphere',\n",
              "  'distance': 0,\n",
              "  'no': '832',\n",
              "  'parent': '3922'},\n",
              " {'Abstract': \"The success of using a streamline technique for visualizing a vector field usually depends largely on the choice of adequate seed points. G. Turk and D. Banks (1996) developed an elegant technique for automatically placing seed points to achieve a uniform distribution of streamlines on a 2D vector field. Their method uses an energy function calculated from the low-pass filtered streamline image to guide the optimization process of the streamline distribution. This paper proposes a new technique for creating evenly distributed streamlines on 3D parametric surfaces found in curvilinear grids. We make use of Turk and Banks's 2D algorithm by first mapping the vectors on a 3D surface into the computational space of the curvilinear grid. To take into the consideration the mapping distortion caused by the uneven grid density in a curvilinear grid, a new energy function is designed and used for guiding the placement of streamlines in the computational space with desired local densities.\",\n",
              "  'AuthorKeywords': ['vector',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'streamline,',\n",
              "   'curvilinear',\n",
              "   'grid'],\n",
              "  'MultipartiteRank': [{'score': 0.11504477582699794, 'word': 'streamline'},\n",
              "   {'score': 0.11504477582699794, 'word': 'technique'},\n",
              "   {'score': 0.07691259863846761, 'word': 'vector'},\n",
              "   {'score': 0.07691259863846761, 'word': 'field'},\n",
              "   {'score': 0.052196951598512335, 'word': 'adequate'},\n",
              "   {'score': 0.052196951598512335, 'word': 'seed'},\n",
              "   {'score': 0.052196951598512335, 'word': 'points'},\n",
              "   {'score': 0.04307918256083385, 'word': 'streamlines'},\n",
              "   {'score': 0.04108219770279382, 'word': 'curvilinear'},\n",
              "   {'score': 0.04108219770279382, 'word': 'grids'}],\n",
              "  'Title': 'Image-guided streamline placement on curvilinear grid surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '833',\n",
              "  'parent': '4775'},\n",
              " {'Abstract': 'We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.',\n",
              "  'AuthorKeywords': ['unsteady,',\n",
              "   'vector',\n",
              "   'field,',\n",
              "   'pathlines,',\n",
              "   'streakline,',\n",
              "   'advection,',\n",
              "   'texture,',\n",
              "   'hardware,',\n",
              "   'OpenGL'],\n",
              "  'MultipartiteRank': [{'score': 0.0668001769059663, 'word': 'novel'},\n",
              "   {'score': 0.0668001769059663, 'word': 'hardware'},\n",
              "   {'score': 0.04995262270543452, 'word': 'several'},\n",
              "   {'score': 0.04761848048333205, 'word': 'use'},\n",
              "   {'score': 0.047469466747544264, 'word': 'emxi'},\n",
              "   {'score': 0.047469466747544264, 'word': 'graphics'},\n",
              "   {'score': 0.04661563374000058, 'word': 'sgi'},\n",
              "   {'score': 0.04661563374000058, 'word': 'octane'}],\n",
              "  'Title': 'Hardware-accelerated texture advection for unsteady flow visualization',\n",
              "  'distance': 0,\n",
              "  'no': '834',\n",
              "  'parent': '3475'},\n",
              " {'Abstract': 'We address the texture level-of-detail problem for extremely large surfaces such as terrain during realtime, view-dependent rendering. A novel texture hierarchy is introduced based on 4-8 refinements of raster tiles, in which the texture grids in effect rotate 45 degrees for each level of refinement. This hierarchy provides twice as many levels of detail as conventional quadtree-style refinement schemes such as mipmaps, and thus provides per-pixel view-dependent filtering that is twice as close to the ideal cutoff frequency for an average pixel. Because of this more gradual change in low-pass filtering, and due to the more precise emulation of the ideal cutoff frequency, we find in practice that the transitions between texture levels of detail are not perceptible. This allows rendering systems to avoid the complexity and performance costs of per-pixel blending between texture levels of detail. The 4-8 texturing scheme is integrated into a variant of the real-time optimally adapting meshes (ROAM) algorithm for view-dependent multiresolution mesh generation. Improvements to ROAM included here are: the diamond data structure as a streamlined replacement for the triangle bintree elements, the use of low-pass-filtered geometry patches in place of individual triangles, integration of 4-8 textures, and a simple out-of-core data access mechanism for texture and geometry tiles.',\n",
              "  'AuthorKeywords': ['Large',\n",
              "   'Data',\n",
              "   'Set',\n",
              "   'Visualization,',\n",
              "   'Level-of-Detail',\n",
              "   'Techniques,',\n",
              "   'View-Dependent',\n",
              "   'Visualization,',\n",
              "   'Adaptive',\n",
              "   'Textures,',\n",
              "   'Out-of-Core',\n",
              "   'Algorithms'],\n",
              "  'MultipartiteRank': [{'score': 0.08576349720076623, 'word': 'detail'},\n",
              "   {'score': 0.06951442280345706, 'word': 'texture'},\n",
              "   {'score': 0.06951442280345706, 'word': 'level'},\n",
              "   {'score': 0.05059221589783631, 'word': 'problem'},\n",
              "   {'score': 0.04347233085742834, 'word': 'view'},\n",
              "   {'score': 0.029025500891100363, 'word': 'dependent'},\n",
              "   {'score': 0.029025500891100363, 'word': 'rendering'}],\n",
              "  'Title': 'Adaptive 4-8 texture hierarchies',\n",
              "  'distance': 0,\n",
              "  'no': '835',\n",
              "  'parent': '5002'},\n",
              " {'Abstract': 'We introduce local and global comparison measures for a collection of k /spl les/ d real-valued smooth functions on a common d-dimensional Riemannian manifold. For k = d = 2 we relate the measures to the set of critical points of one function restricted to the level sets of the other. The definition of the measures extends to piecewise linear functions for which they are easy to compute. The computation of the measures forms the centerpiece of a software tool which we use to study scientific datasets.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'Riemannian',\n",
              "   'manifolds,',\n",
              "   'smooth',\n",
              "   'functions,',\n",
              "   'time-varying',\n",
              "   'data,',\n",
              "   'comparison',\n",
              "   'measure,',\n",
              "   'differential',\n",
              "   'forms'],\n",
              "  'MultipartiteRank': [{'score': 0.2656025404797714, 'word': 'measures'},\n",
              "   {'score': 0.17923656803654028, 'word': 'global'},\n",
              "   {'score': 0.17923656803654028, 'word': 'comparison'},\n",
              "   {'score': 0.10144509259998452, 'word': 'smooth'},\n",
              "   {'score': 0.10144509259998452, 'word': 'functions'},\n",
              "   {'score': 0.08976811359820723, 'word': 'local'},\n",
              "   {'score': 0.07653378409151056, 'word': 'collection'}],\n",
              "  'Title': 'Local and global comparison of continuous functions',\n",
              "  'distance': 0,\n",
              "  'no': '836',\n",
              "  'parent': '3660'},\n",
              " {'Abstract': 'Sort-last parallel rendering is an efficient technique to visualize huge datasets on COTS clusters. The dataset is subdivided and distributed across the cluster nodes. For every frame, each node renders a full resolution image of its data using its local GPU, and the images are composited together using a parallel image compositing algorithm. In this paper, we present a performance evaluation of standard sort-last parallel rendering methods and of the different improvements proposed in the literature. This evaluation is based on a detailed analysis of the different hardware and software components. We present a new implementation of sort-last rendering that fully overlaps CPU(s), GPU and network usage all along the algorithm. We present experiments on a 3 years old 32-node PC cluster and on a 1.5 years old 5-node PC cluster, both with Gigabit interconnect, showing volume rendering at respectively 13 and 31 frames per second and polygon rendering at respectively 8 and 17 frames per second on a 1024 x 768 render area, and we show that our implementation outperforms or equals many other implementations and specialized visualization clusters.',\n",
              "  'AuthorKeywords': ['cluster-based',\n",
              "   'visualization,',\n",
              "   'sort-last',\n",
              "   'rendering,',\n",
              "   'parallel',\n",
              "   'image',\n",
              "   'compositing'],\n",
              "  'MultipartiteRank': [{'score': 0.06127512991036699, 'word': 'cots'},\n",
              "   {'score': 0.06127512991036699, 'word': 'clusters'},\n",
              "   {'score': 0.05684168426007611, 'word': 'full'},\n",
              "   {'score': 0.05684168426007611, 'word': 'resolution'},\n",
              "   {'score': 0.05684168426007611, 'word': 'image'},\n",
              "   {'score': 0.055330739350983094, 'word': 'huge'},\n",
              "   {'score': 0.055330739350983094, 'word': 'datasets'},\n",
              "   {'score': 0.05076798569762005, 'word': 'frame'},\n",
              "   {'score': 0.047637877984665414, 'word': 'last'},\n",
              "   {'score': 0.047637877984665414, 'word': 'parallel'},\n",
              "   {'score': 0.047637877984665414, 'word': 'rendering'}],\n",
              "  'Title': 'COTS cluster-based sort-last rendering: performance evaluation and pipelined implementation',\n",
              "  'distance': 0,\n",
              "  'no': '837',\n",
              "  'parent': '5455'},\n",
              " {'Abstract': \"In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.\",\n",
              "  'AuthorKeywords': ['Color,',\n",
              "   'perception,',\n",
              "   'visualization,',\n",
              "   'color',\n",
              "   'weaving,',\n",
              "   'color',\n",
              "   'blending'],\n",
              "  'MultipartiteRank': [{'score': 0.10458756500269702, 'word': 'color'},\n",
              "   {'score': 0.10458756500269702, 'word': 'mixing'},\n",
              "   {'score': 0.04194690620950263, 'word': 'data'},\n",
              "   {'score': 0.032130640471067055, 'word': 'observer'},\n",
              "   {'score': 0.032130640471067055, 'word': 'experiments'},\n",
              "   {'score': 0.029719585921661188, 'word': 'individual'},\n",
              "   {'score': 0.029719585921661188, 'word': 'values'},\n",
              "   {'score': 0.026282668923545673, 'word': 'information'}],\n",
              "  'Title': 'Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.',\n",
              "  'distance': 0,\n",
              "  'no': '838',\n",
              "  'parent': '5834'},\n",
              " {'Abstract': 'A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks.',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'drawing,',\n",
              "   'constraints,',\n",
              "   'stress',\n",
              "   'majorization,',\n",
              "   'force',\n",
              "   'directed',\n",
              "   'algorithms,',\n",
              "   'multidimensional',\n",
              "   'scaling'],\n",
              "  'MultipartiteRank': [{'score': 0.10623292401230898, 'word': 'detailed'},\n",
              "   {'score': 0.10623292401230898, 'word': 'view'},\n",
              "   {'score': 0.08512021438411668, 'word': 'layout'},\n",
              "   {'score': 0.08512021438411668, 'word': 'algorithms'},\n",
              "   {'score': 0.058665623490740774, 'word': 'large'},\n",
              "   {'score': 0.058665623490740774, 'word': 'network'},\n",
              "   {'score': 0.058665623490740774, 'word': 'visualization'},\n",
              "   {'score': 0.04939655519454366, 'word': 'overview'},\n",
              "   {'score': 0.03921669392422921, 'word': 'focal'},\n",
              "   {'score': 0.03921669392422921, 'word': 'node'}],\n",
              "  'Title': 'Exploration of Networks using overview+detail with Constraint-based cooperative layout',\n",
              "  'distance': 0,\n",
              "  'no': '839',\n",
              "  'parent': '6128'},\n",
              " {'Abstract': 'Analyzing unstructured text streams can be challenging. One popular approach is to isolate specific themes in the text, and to visualize the connections between them. Some existing systems, like ThemeRiver, provide a temporal view of changes in themes; other systems, like In-Spire, use clustering techniques to help an analyst identify the themes at a single point in time. Narratives combines both of these techniques; it uses a temporal axis to visualize ways that concepts have changed over time, and introduces several methods to explore how those concepts relate to each other. Narratives is designed to help the user place news stories in their historical and social context by understanding how the major topics associated with them have changed over time. Users can relate articles through time by examining the topical keywords that summarize a specific news event. By tracking the attention to a news article in the form of references in social media (such as weblogs), a user discovers both important events and measures the social relevance of these stories.',\n",
              "  'AuthorKeywords': ['blogs,',\n",
              "   'events,',\n",
              "   'trends,',\n",
              "   'time',\n",
              "   'series,',\n",
              "   'topic',\n",
              "   'detection',\n",
              "   'and',\n",
              "   'tracking'],\n",
              "  'MultipartiteRank': [{'score': 0.06769659112075449, 'word': 'time'},\n",
              "   {'score': 0.05694023997838509, 'word': 'specific'},\n",
              "   {'score': 0.05694023997838509, 'word': 'themes'},\n",
              "   {'score': 0.04854829488691501, 'word': 'social'},\n",
              "   {'score': 0.04854829488691501, 'word': 'context'},\n",
              "   {'score': 0.04240932205935099, 'word': 'unstructured'},\n",
              "   {'score': 0.04240932205935099, 'word': 'text'},\n",
              "   {'score': 0.04240932205935099, 'word': 'streams'},\n",
              "   {'score': 0.03726026207971757, 'word': 'temporal'},\n",
              "   {'score': 0.03726026207971757, 'word': 'view'}],\n",
              "  'Title': 'Narratives: A visualization to track narrative events as they develop',\n",
              "  'distance': 0,\n",
              "  'no': '840',\n",
              "  'parent': '5105'},\n",
              " {'Abstract': 'Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets.',\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'brushing,',\n",
              "   'scatter',\n",
              "   'plots,',\n",
              "   'parallel',\n",
              "   'coordinates,',\n",
              "   'multivariate',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.15395579161333903, 'word': 'data'},\n",
              "   {'score': 0.09253057002564108, 'word': 'uncertainty'},\n",
              "   {'score': 0.06783003763108654, 'word': 'density'},\n",
              "   {'score': 0.06783003763108654, 'word': 'plots'},\n",
              "   {'score': 0.06390845932921903, 'word': 'viewers'},\n",
              "   {'score': 0.061425221587697955, 'word': 'uncertain'},\n",
              "   {'score': 0.061425221587697955, 'word': 'multivariate'},\n",
              "   {'score': 0.061425221587697955, 'word': 'sets'},\n",
              "   {'score': 0.05254519014763819, 'word': 'values'}],\n",
              "  'Title': 'Matching Visual Saliency to Confidence in Plots of Uncertain Data',\n",
              "  'distance': 0,\n",
              "  'no': '841',\n",
              "  'parent': '4448'},\n",
              " {'Abstract': 'While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'diagrams,',\n",
              "   'whiteboards,',\n",
              "   'observational',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.10770222495538868, 'word': 'information'},\n",
              "   {'score': 0.10770222495538868, 'word': 'visualization'},\n",
              "   {'score': 0.10770222495538868, 'word': 'researchers'},\n",
              "   {'score': 0.05627514531443285, 'word': 'personal'},\n",
              "   {'score': 0.05627514531443285, 'word': 'use'},\n",
              "   {'score': 0.04983177233518863, 'word': 'visualizations'},\n",
              "   {'score': 0.04983177233518863, 'word': 'people'},\n",
              "   {'score': 0.04887714946316666, 'word': 'types'},\n",
              "   {'score': 0.04517188079148445, 'word': 'common'}],\n",
              "  'Title': 'Visual Thinking In Action: Visualizations As Used On Whiteboards',\n",
              "  'distance': 0,\n",
              "  'no': '842',\n",
              "  'parent': '3731'},\n",
              " {'Abstract': \"Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.\",\n",
              "  'AuthorKeywords': ['Radiofrequency',\n",
              "   'ablation,',\n",
              "   'ablation',\n",
              "   'zone',\n",
              "   'visualization,',\n",
              "   'distance',\n",
              "   'field,',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'GPU,',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.05842091534787105, 'word': 'ablation'},\n",
              "   {'score': 0.05842091534787105, 'word': 'zone'},\n",
              "   {'score': 0.05680903198144711, 'word': 'liver'},\n",
              "   {'score': 0.05680903198144711, 'word': 'tumors'},\n",
              "   {'score': 0.04682969191428791, 'word': 'rf'},\n",
              "   {'score': 0.04682969191428791, 'word': 'applicator'},\n",
              "   {'score': 0.04682969191428791, 'word': 'types'},\n",
              "   {'score': 0.04436208201340152, 'word': 'real'},\n",
              "   {'score': 0.04307543013155631, 'word': 'time'},\n",
              "   {'score': 0.04307543013155631, 'word': 'approximation'}],\n",
              "  'Title': 'GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation',\n",
              "  'distance': 0,\n",
              "  'no': '843',\n",
              "  'parent': '4682'},\n",
              " {'Abstract': 'Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.',\n",
              "  'AuthorKeywords': ['4D',\n",
              "   'pc-mri,',\n",
              "   'cardiac',\n",
              "   'blood',\n",
              "   'flow,',\n",
              "   'hemodynamics,',\n",
              "   'line',\n",
              "   'predicates,',\n",
              "   'vortex',\n",
              "   'extraction'],\n",
              "  'MultipartiteRank': [{'score': 0.043550075817036314, 'word': 'blood'},\n",
              "   {'score': 0.043550075817036314, 'word': 'flow'},\n",
              "   {'score': 0.043550075817036314, 'word': 'characteristics'},\n",
              "   {'score': 0.03672303509419574, 'word': '4d'},\n",
              "   {'score': 0.03672303509419574, 'word': 'pc'},\n",
              "   {'score': 0.03619767287553382, 'word': 'reliable'},\n",
              "   {'score': 0.03609864879969386, 'word': 'mri'},\n",
              "   {'score': 0.03609864879969386, 'word': 'acquisition'},\n",
              "   {'score': 0.032274859831090394, 'word': 'time'}],\n",
              "  'Title': 'Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates',\n",
              "  'distance': 0,\n",
              "  'no': '844',\n",
              "  'parent': '4536'},\n",
              " {'Abstract': 'We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.',\n",
              "  'AuthorKeywords': ['Eye-tracking,',\n",
              "   'space-time',\n",
              "   'cube,',\n",
              "   'dynamic',\n",
              "   'areas',\n",
              "   'of',\n",
              "   'interest,',\n",
              "   'spatiotemporal',\n",
              "   'clustering,',\n",
              "   'motion-compensated',\n",
              "   'heat',\n",
              "   'map'],\n",
              "  'MultipartiteRank': [{'score': 0.09656119908874061, 'word': 'data'},\n",
              "   {'score': 0.05359756009437634, 'word': 'time'},\n",
              "   {'score': 0.05359756009437634, 'word': 'sequences'},\n",
              "   {'score': 0.04235881055557378, 'word': 'eye'},\n",
              "   {'score': 0.04235881055557378, 'word': 'movement'},\n",
              "   {'score': 0.03567768000336641, 'word': 'space'},\n",
              "   {'score': 0.0340589291200603, 'word': 'color'},\n",
              "   {'score': 0.0340589291200603, 'word': 'mapping'}],\n",
              "  'Title': 'Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli',\n",
              "  'distance': 0,\n",
              "  'no': '845',\n",
              "  'parent': '4042'},\n",
              " {'Abstract': \"Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.\",\n",
              "  'AuthorKeywords': ['User',\n",
              "   'Interactions,',\n",
              "   'Analytic',\n",
              "   'Provenance,',\n",
              "   'Visualization,',\n",
              "   'Applied',\n",
              "   'Machine',\n",
              "   'Learning'],\n",
              "  'MultipartiteRank': [{'score': 0.10297635094279323, 'word': 'users'},\n",
              "   {'score': 0.06458529767771781, 'word': 'visual'},\n",
              "   {'score': 0.06458529767771781, 'word': 'analytics'},\n",
              "   {'score': 0.06177227969042683, 'word': 'interactions'},\n",
              "   {'score': 0.044552704199452495, 'word': 'computer'},\n",
              "   {'score': 0.03528431811445586, 'word': 'collaboration'}],\n",
              "  'Title': 'Finding Waldo: Learning about Users from their Interactions',\n",
              "  'distance': 0,\n",
              "  'no': '846',\n",
              "  'parent': '5202'},\n",
              " {'Abstract': 'Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.',\n",
              "  'AuthorKeywords': ['event',\n",
              "   'sequences;Clickstream',\n",
              "   'Data;sequence',\n",
              "   'mining;visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.08800057450166122, 'word': 'patterns'},\n",
              "   {'score': 0.08082619148347132, 'word': 'dimensional'},\n",
              "   {'score': 0.08082619148347132, 'word': 'sequences'},\n",
              "   {'score': 0.05467778561373688, 'word': 'multiple'},\n",
              "   {'score': 0.05467778561373688, 'word': 'levels'},\n",
              "   {'score': 0.05050025609682393, 'word': 'multivariate'},\n",
              "   {'score': 0.05050025609682393, 'word': 'events'},\n",
              "   {'score': 0.04647700838947328, 'word': 'granularity'}],\n",
              "  'Title': 'Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths',\n",
              "  'distance': 0,\n",
              "  'no': '847',\n",
              "  'parent': '4206'},\n",
              " {'Abstract': 'Techniques for displaying 3D isovalues of scalar fields such as stress within a solid finite-element model generally involve examining each element for values of interest. An inexpensive, straightforward method is discussed for reducing the number of elements searched for such isovalues. It takes advantage of one traversal of the element data to yield a compact classification of the model by result values and ranges, with no sorting required. This data structure can then relate any scalar isovalue to a set of element groups which are closely inclusive of the isovalue. This method is intended for applications requiring repeated access to the analysis data, such as animation and interactive rendering of isosurfaces and scalar fields. While applicable to general volume visualization problems, it is particularly well suited to optimizing real-valued continuum field results such as those found in finite-element data.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1454897822075864, 'word': 'element'},\n",
              "   {'score': 0.06082103888828776, 'word': '3d'},\n",
              "   {'score': 0.06082103888828776, 'word': 'isovalues'},\n",
              "   {'score': 0.060388127174880846, 'word': 'values'},\n",
              "   {'score': 0.054830958692042964, 'word': 'model'},\n",
              "   {'score': 0.04756508962714375, 'word': 'straightforward'},\n",
              "   {'score': 0.04756508962714375, 'word': 'method'}],\n",
              "  'Title': 'Span filtering: an optimization scheme for volume visualization of large finite element models',\n",
              "  'distance': 0,\n",
              "  'no': '848',\n",
              "  'parent': '4649'},\n",
              " {'Abstract': 'Oriented line integral convolution (OLIC) illustrates flow fields by convolving a sparse texture with an anisotropic convolution kernel. The kernel is aligned to the underlying flow of the vector field. OLIC does not only show the direction of the flow but also its orientation. The paper presents fast rendering of oriented line integral convolution (FROLIC), which is approximately two orders of magnitude faster than OLIC. Costly convolution operations as done in OLIC are replaced in FROLIC by approximating a streamlet through a set of disks with varying intensity. The issue of overlapping streamlets is discussed. Two efficient animation techniques for animating FROLIC images are described. FROLIC has been implemented as a Java applet. This allows researchers from various disciplines (typically with inhomogenous hardware environments) to conveniently explore and investigate analytically defined 2D vector fields.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09499510423958445, 'word': 'olic'},\n",
              "   {'score': 0.07461303177319464, 'word': 'frolic'},\n",
              "   {'score': 0.06258578417031813, 'word': 'fields'},\n",
              "   {'score': 0.05084121729832943, 'word': 'line'},\n",
              "   {'score': 0.05084121729832943, 'word': 'integral'},\n",
              "   {'score': 0.05084121729832943, 'word': 'convolution'},\n",
              "   {'score': 0.04970030643614823, 'word': 'underlying'},\n",
              "   {'score': 0.04970030643614823, 'word': 'flow'}],\n",
              "  'Title': 'Fast oriented line integral convolution for vector field visualization via the Internet',\n",
              "  'distance': 0,\n",
              "  'no': '849',\n",
              "  'parent': '4101'},\n",
              " {'Abstract': 'We describe a framework for time-critical rendering of graphics scenes composed of a large number of objects having complex geometric descriptions. Our technique relies upon a scene description in which objects are represented as multiresolution meshes. We perform a constrained optimization at each frame to choose the resolution of each potentially visible object that generates the best quality image while meeting timing constraints. The technique provides smooth level-of-detail control and aims at guaranteeing a uniform, bounded frame rate even for widely changing viewing conditions. The optimization algorithm is independent from the particular data structure used to represent multiresolution meshes. The only requirements are the ability to represent a mesh with an arbitrary number of triangles and to traverse a mesh structure at an arbitrary resolution in a short predictable time. A data structure satisfying these criteria is described and experimental results are discussed.',\n",
              "  'AuthorKeywords': ['multiresolution',\n",
              "   'modeling,level',\n",
              "   'of',\n",
              "   'detail,adaptive',\n",
              "   'rendering,',\n",
              "   'time-critical',\n",
              "   'graphics'],\n",
              "  'MultipartiteRank': [{'score': 0.07535125697239958, 'word': 'objects'},\n",
              "   {'score': 0.07048479291347576, 'word': 'time'},\n",
              "   {'score': 0.060369743824325514, 'word': 'graphics'},\n",
              "   {'score': 0.060369743824325514, 'word': 'scenes'},\n",
              "   {'score': 0.05795908744735796, 'word': 'multiresolution'},\n",
              "   {'score': 0.05795908744735796, 'word': 'meshes'},\n",
              "   {'score': 0.04938477685765833, 'word': 'large'},\n",
              "   {'score': 0.04938477685765833, 'word': 'number'}],\n",
              "  'Title': 'Time-critical Multiresolution Scene Rendering',\n",
              "  'distance': 0,\n",
              "  'no': '850',\n",
              "  'parent': '3782'},\n",
              " {'Abstract': 'We describe a method to visualize the connectivity graph of a mesh using a natural embedding in 3D space. This uses a 3D shape representation that is based solely on mesh connectivity: the connectivity shape. Given a connectivity, we define its natural geometry as a smooth embedding in space with uniform edge lengths and describe efficient techniques to compute it. Our main contribution is to demonstrate that a surprising amount of geometric information is implicit in the connectivity. We also show how to generate connectivity shapes that approximate given 3D shapes. Potential applications of connectivity shapes to modeling and mesh coding are described.',\n",
              "  'AuthorKeywords': ['Natural',\n",
              "   'embedding,',\n",
              "   'mesh',\n",
              "   'connectivity,',\n",
              "   'implicit',\n",
              "   'geometry,',\n",
              "   'polygon',\n",
              "   'meshes,',\n",
              "   'shape',\n",
              "   'compression'],\n",
              "  'MultipartiteRank': [{'score': 0.14541574803217658, 'word': '3d'},\n",
              "   {'score': 0.14375130375369466, 'word': 'connectivity'},\n",
              "   {'score': 0.14375130375369466, 'word': 'graph'},\n",
              "   {'score': 0.09776950027376954, 'word': 'mesh'},\n",
              "   {'score': 0.09494120174249639, 'word': 'natural'},\n",
              "   {'score': 0.09494120174249639, 'word': 'embedding'},\n",
              "   {'score': 0.08695646332359817, 'word': 'space'},\n",
              "   {'score': 0.05845928470857841, 'word': 'shape'},\n",
              "   {'score': 0.05845928470857841, 'word': 'representation'}],\n",
              "  'Title': 'Connectivity shapes',\n",
              "  'distance': 0,\n",
              "  'no': '851',\n",
              "  'parent': '3494'},\n",
              " {'Abstract': 'This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.',\n",
              "  'AuthorKeywords': ['vector',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'tetrahedral',\n",
              "   'grid,',\n",
              "   'unstructured',\n",
              "   'grid,',\n",
              "   'flow',\n",
              "   'surface'],\n",
              "  'MultipartiteRank': [{'score': 0.10582214521799943, 'word': 'stream'},\n",
              "   {'score': 0.10582214521799943, 'word': 'surfaces'},\n",
              "   {'score': 0.06598304294040688, 'word': 'new'},\n",
              "   {'score': 0.06598304294040688, 'word': 'algorithm'},\n",
              "   {'score': 0.06558842999464015, 'word': 'calculation'},\n",
              "   {'score': 0.05665686875839856, 'word': 'tetrahedral'},\n",
              "   {'score': 0.05665686875839856, 'word': 'faces'},\n",
              "   {'score': 0.056295018533201444, 'word': 'method'}],\n",
              "  'Title': 'A tetrahedra-based stream surface algorithm',\n",
              "  'distance': 0,\n",
              "  'no': '852',\n",
              "  'parent': '3512'},\n",
              " {'Abstract': 'The Temporal Bone Dissection Simulator is an ongoing research project for the construction of a synthetic environment suitable for virtual dissection of human temporal bone and related anatomy. Funded by the National Institute on Deafness and Other Communication Disorders (NIDCD), the primary goal of this project is to provide a safe, robust, and cost-effective virtual environment for learning the anatomy and surgical procedures associated with the temporal bone. Direct volume visualization has been indispensable for the necessary level of realism and interactivity that is vital to the success of this project. This work is being conducted by the Ohio Supercomputer Center in conjunction with the Department of Otolaryngology at the Ohio State University, and NIDCD.',\n",
              "  'AuthorKeywords': ['Temporal', 'Bone', 'Dissection'],\n",
              "  'MultipartiteRank': [{'score': 0.10511181857820254, 'word': 'temporal'},\n",
              "   {'score': 0.10511181857820254, 'word': 'bone'},\n",
              "   {'score': 0.10511181857820254, 'word': 'dissection'},\n",
              "   {'score': 0.10511181857820254, 'word': 'simulator'},\n",
              "   {'score': 0.08693948541585826, 'word': 'ongoing'},\n",
              "   {'score': 0.08693948541585826, 'word': 'research'},\n",
              "   {'score': 0.08693948541585826, 'word': 'project'},\n",
              "   {'score': 0.048970773039317, 'word': 'related'},\n",
              "   {'score': 0.048970773039317, 'word': 'anatomy'},\n",
              "   {'score': 0.04158092290987929, 'word': 'construction'},\n",
              "   {'score': 0.03933843820464025, 'word': 'synthetic'},\n",
              "   {'score': 0.03933843820464025, 'word': 'environment'},\n",
              "   {'score': 0.03933843820464025, 'word': 'suitable'}],\n",
              "  'Title': 'Virtual Temporal Bone Dissection: A Case Study',\n",
              "  'distance': 0,\n",
              "  'no': '853',\n",
              "  'parent': '3405'},\n",
              " {'Abstract': 'For some graphics applications, object interiors and hard-to-see regions contribute little to the final images and need not be processed. In this paper, we define a view-independent visibility measure on mesh surfaces based on the visibility function between the surfaces and a surrounding sphere of cameras. We demonstrate the usefulness of this measure with a visibility-guided simplification algorithm. Mesh simplification reduces the polygon counts of 3D models and speeds up the rendering process. Many mesh simplification algorithms are based on sequences of edge collapses that minimize geometric and attribute errors. By combining the surface visibility measure with a geometric error measure, we obtain simplified models with improvement proportional to the number of low visibility regions in the original models.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'Visibility,',\n",
              "   'Mesh',\n",
              "   'Simplification,',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.138966525766223, 'word': 'visibility'},\n",
              "   {'score': 0.08061140126387223, 'word': 'independent'},\n",
              "   {'score': 0.08061140126387223, 'word': 'measure'},\n",
              "   {'score': 0.06342850161555816, 'word': 'mesh'},\n",
              "   {'score': 0.06342850161555816, 'word': 'surfaces'},\n",
              "   {'score': 0.06141208976642151, 'word': 'simplification'},\n",
              "   {'score': 0.06141208976642151, 'word': 'algorithm'},\n",
              "   {'score': 0.05835512450235077, 'word': 'function'},\n",
              "   {'score': 0.04766992317050068, 'word': '3d'},\n",
              "   {'score': 0.04766992317050068, 'word': 'models'}],\n",
              "  'Title': 'Visibility-guided simplification',\n",
              "  'distance': 0,\n",
              "  'no': '854',\n",
              "  'parent': '3848'},\n",
              " {'Abstract': 'The InfoSky visual explorer is a system enabling users to interactively explore large, hierarchically structured document collections. Similar to a real-world telescope, InfoSky employs a planar graphical representation with variable magnification. Documents of similar content are placed close to each other and displayed as stars, while collections of documents at a particular level in the hierarchy are visualised as bounding polygons. Usability testing of an early prototype implementation of InfoSky revealed several design issues which prevented users from fully exploiting the power of the visual metaphor. Evaluation results have been incorporated into an advanced prototype, and another usability test has been conducted. A comparison of test results demonstrates enhanced system performance and points out promising directions for further work',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualisation,',\n",
              "   'navigation,',\n",
              "   'document',\n",
              "   'retrieval,',\n",
              "   'hierarchical',\n",
              "   'repositories,',\n",
              "   'knowledge',\n",
              "   'management,',\n",
              "   'information',\n",
              "   'management,',\n",
              "   'force-directed',\n",
              "   'placement,',\n",
              "   'Voronoi'],\n",
              "  'MultipartiteRank': [{'score': 0.09947822262899168, 'word': 'infosky'},\n",
              "   {'score': 0.09947822262899168, 'word': 'visual'},\n",
              "   {'score': 0.09947822262899168, 'word': 'explorer'},\n",
              "   {'score': 0.060695326236135015, 'word': 'users'},\n",
              "   {'score': 0.060374594254736215, 'word': 'structured'},\n",
              "   {'score': 0.060374594254736215, 'word': 'document'},\n",
              "   {'score': 0.060374594254736215, 'word': 'collections'},\n",
              "   {'score': 0.05992350399627414, 'word': 'system'},\n",
              "   {'score': 0.05693777879749988, 'word': 'similar'}],\n",
              "  'Title': 'Evaluating a System for Interactive Exploration of Large, Hierarchically Structured Document Repositories',\n",
              "  'distance': 0,\n",
              "  'no': '855',\n",
              "  'parent': '4316'},\n",
              " {'Abstract': 'Vortex breakdowns and flow recirculation are essential phenomena in aeronautics where they appear as a limiting factor in the design of modern aircrafts. Because of the inherent intricacy of these features, standard flow visualization techniques typically yield cluttered depictions. The paper addresses the challenges raised by the visual exploration and validation of two CFD simulations involving vortex breakdown. To permit accurate and insightful visualization we propose a new approach that unfolds the geometry of the breakdown region by letting a plane travel through the structure along a curve. We track the continuous evolution of the associated projected vector field using the theoretical framework of parametric topology. To improve the understanding of the spatial relationship between the resulting curves and lines we use direct volume rendering and multidimensional transfer functions for the display of flow-derived scalar quantities. This enriches the visualization and provides an intuitive context for the extracted topological information. Our results offer clear, synthetic depictions that permit new insight into the structural properties of vortex breakdowns.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'vortex',\n",
              "   'analysis,',\n",
              "   'parametric',\n",
              "   'topology,',\n",
              "   'cutting',\n",
              "   'planes,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.0863629803161711, 'word': 'vortex'},\n",
              "   {'score': 0.0863629803161711, 'word': 'breakdowns'},\n",
              "   {'score': 0.0511596543472556, 'word': 'visual'},\n",
              "   {'score': 0.0511596543472556, 'word': 'exploration'},\n",
              "   {'score': 0.038831856539109914, 'word': 'flow'},\n",
              "   {'score': 0.038831856539109914, 'word': 'recirculation'},\n",
              "   {'score': 0.03333665560277887, 'word': 'depictions'},\n",
              "   {'score': 0.030882575260330433, 'word': 'curve'}],\n",
              "  'Title': 'Visualization of intricate flow structures for vortex breakdown analysis',\n",
              "  'distance': 0,\n",
              "  'no': '856',\n",
              "  'parent': '4718'},\n",
              " {'Abstract': 'Diffusion tensor imaging (DTI) is a magnetic resonance imaging method that can be used to measure local information about the structure of white matter within the human brain. Combining DTI data with the computational methods of MR tractography, neuroscientists can estimate the locations and sizes of nerve bundles (white matter pathways) that course through the human brain. Neuroscientists have used visualization techniques to better understand tractography data, but they often struggle with the abundance and complexity of the pathways. We describe a novel set of interaction techniques that make it easier to explore and interpret such pathways. Specifically, our application allows neuroscientists to place and interactively manipulate box-shaped regions (or volumes of interest) to selectively display pathways that pass through specific anatomical areas. A simple and flexible query language allows for arbitrary combinations of these queries using Boolean logic operators. Queries can be further restricted by numerical path properties such as length, mean fractional anisotropy, and mean curvature. By precomputing the pathways and their statistical properties, we obtain the speed necessary for interactive question-and-answer sessions with brain researchers. We survey some questions that researchers have been asking about tractography data and show how our system can be used to answer these questions efficiently.',\n",
              "  'AuthorKeywords': ['Visualization,', 'DTI,', 'MR', 'Tractography'],\n",
              "  'MultipartiteRank': [{'score': 0.04891773703829811,\n",
              "    'word': 'neuroscientists'},\n",
              "   {'score': 0.042358753160405944, 'word': 'mr'},\n",
              "   {'score': 0.042358753160405944, 'word': 'tractography'},\n",
              "   {'score': 0.03985715368932677, 'word': 'flexible'},\n",
              "   {'score': 0.03985715368932677, 'word': 'query'},\n",
              "   {'score': 0.03985715368932677, 'word': 'language'},\n",
              "   {'score': 0.03892791967148324, 'word': 'pathways'},\n",
              "   {'score': 0.03690437057029158, 'word': 'white'},\n",
              "   {'score': 0.03690437057029158, 'word': 'matter'}],\n",
              "  'Title': \"Exploration of the brain's white matter pathways with dynamic queries\",\n",
              "  'distance': 0,\n",
              "  'no': '857',\n",
              "  'parent': '4954'},\n",
              " {'Abstract': 'We describe a new method for visualization of directed graphs. The method combines constraint programming techniques with a high performance force directed placement (FDP) algorithm so that the directed nature of the graph is highlighted while useful properties of FDP - such as emphasis of symmetries and preservation of proximity relations - are retained. Our algorithm automatically identifies those parts of the digraph that contain hierarchical information and draws them accordingly. Additionally, those parts that do not contain hierarchy are drawn at the same quality expected from a nonhierarchical, undirected layout algorithm. An interesting application of our algorithm is directional multidimensional scaling (DMDS). DMDS deals with low dimensional embedding of multivariate data where we want to emphasize the overall flow in the data (e.g. chronological progress) along one of the axes.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08810463845116093, 'word': 'algorithm'},\n",
              "   {'score': 0.052984265452355614, 'word': 'fdp'},\n",
              "   {'score': 0.04736063288726915, 'word': 'graphs'},\n",
              "   {'score': 0.046471354498877626, 'word': 'new'},\n",
              "   {'score': 0.046471354498877626, 'word': 'method'},\n",
              "   {'score': 0.04411313153415003, 'word': 'dmds'}],\n",
              "  'Title': 'Dig-CoLa: directed graph layout through constrained energy minimization',\n",
              "  'distance': 0,\n",
              "  'no': '858',\n",
              "  'parent': '3650'},\n",
              " {'Abstract': 'Diffusion tensor imaging is of high value in neurosurgery, providing information about the location of white matter tracts in the human brain. For their reconstruction, streamline techniques commonly referred to as fiber tracking model the underlying fiber structures and have therefore gained interest. To meet the requirements of surgical planning and to overcome the visual limitations of line representations, a new real-time visualization approach of high visual quality is introduced. For this purpose, textured triangle strips and point sprites are combined in a hybrid strategy employing GPU programming. The triangle strips follow the fiber streamlines and are textured to obtain a tube-like appearance. A vertex program is used to orient the triangle strips towards the camera. In order to avoid triangle flipping in case of fiber segments where the viewing and segment direction are parallel, a correct visual representation is achieved in these areas by chains of point sprites. As a result, high quality visualization similar to tubes is provided allowing for interactive multimodal inspection. Overall, the presented approach is faster than existing techniques of similar visualization quality and at the same time allows for real-time rendering of dense bundles encompassing a high number of fibers, which is of high importance for diagnosis and surgical planning',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'tensor',\n",
              "   'data,',\n",
              "   'fiber',\n",
              "   'tracking,',\n",
              "   'streamline',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.07755064253988248, 'word': 'high'},\n",
              "   {'score': 0.05538234136253249, 'word': 'fiber'},\n",
              "   {'score': 0.05538234136253249, 'word': 'tracking'},\n",
              "   {'score': 0.05538234136253249, 'word': 'model'},\n",
              "   {'score': 0.05172678469190941, 'word': 'textured'},\n",
              "   {'score': 0.05172678469190941, 'word': 'triangle'},\n",
              "   {'score': 0.05172678469190941, 'word': 'strips'},\n",
              "   {'score': 0.04124758921476656, 'word': 'visual'},\n",
              "   {'score': 0.04124758921476656, 'word': 'quality'},\n",
              "   {'score': 0.03630305332511592, 'word': 'value'},\n",
              "   {'score': 0.03476306731374036, 'word': 'time'},\n",
              "   {'score': 0.03476306731374036, 'word': 'visualization'},\n",
              "   {'score': 0.03476306731374036, 'word': 'approach'}],\n",
              "  'Title': 'Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites',\n",
              "  'distance': 0,\n",
              "  'no': '859',\n",
              "  'parent': '4698'},\n",
              " {'Abstract': 'We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.',\n",
              "  'AuthorKeywords': ['Acoustic', 'propagation,Interactive', 'systems'],\n",
              "  'MultipartiteRank': [{'score': 0.06213968560765988, 'word': 'new'},\n",
              "   {'score': 0.06213968560765988, 'word': 'approach'},\n",
              "   {'score': 0.06051619563171255, 'word': 'real'},\n",
              "   {'score': 0.056857577452398986, 'word': 'complex'},\n",
              "   {'score': 0.05634249818550513, 'word': 'time'},\n",
              "   {'score': 0.05634249818550513, 'word': 'sound'},\n",
              "   {'score': 0.05286928760989976, 'word': 'efficiency'}],\n",
              "  'Title': 'Interactive sound rendering in complex and dynamic scenes using frustum tracing',\n",
              "  'distance': 0,\n",
              "  'no': '860',\n",
              "  'parent': '3472'},\n",
              " {'Abstract': 'Software tools that make it easier for analysts to collaborate as a natural part of their work will lead to better analysis that is informed by more perspectives. We are interested to know if software tools can be designed that support collaboration even as they allow analysts to find documents and organize information (including evidence, schemas, and hypotheses). We have modified the Entity Workspace system, described previously, to test such designs. We have evaluated the resulting design in both a laboratory study and a study where it is situated with an analysis team. In both cases, effects on collaboration appear to be positive. Key aspects of the design include an evidence notebook optimized for organizing entities (rather than text characters), information structures that can be collapsed and expanded, visualization of evidence that emphasizes events and documents (rather than emphasizing the entity graph), and a notification system that finds entities of mutual interest to multiple analysts.',\n",
              "  'AuthorKeywords': ['sensemaking,',\n",
              "   'information',\n",
              "   'foraging,',\n",
              "   'collective',\n",
              "   'intelligence,',\n",
              "   'exploratory',\n",
              "   'search,',\n",
              "   'information',\n",
              "   'workspace,',\n",
              "   'entity-based,',\n",
              "   'collaboration,',\n",
              "   'intelligence',\n",
              "   'analysis,',\n",
              "   'visualization,',\n",
              "   'semantic',\n",
              "   'notebook,',\n",
              "   'argumentation',\n",
              "   'marshalling,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.06983278878212905, 'word': 'evidence'},\n",
              "   {'score': 0.059134925372372485, 'word': 'entity'},\n",
              "   {'score': 0.059134925372372485, 'word': 'workspace'},\n",
              "   {'score': 0.059134925372372485, 'word': 'system'},\n",
              "   {'score': 0.05859023734874075, 'word': 'analysts'},\n",
              "   {'score': 0.05147809174301737, 'word': 'documents'},\n",
              "   {'score': 0.047217184383189045, 'word': 'information'}],\n",
              "  'Title': 'Entity-based collaboration tools for intelligence analysis',\n",
              "  'distance': 0,\n",
              "  'no': '861',\n",
              "  'parent': '4853'},\n",
              " {'Abstract': 'One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.',\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'visual',\n",
              "   'hypothesis',\n",
              "   'generation,',\n",
              "   'interactive',\n",
              "   'visual',\n",
              "   'exploration',\n",
              "   'and',\n",
              "   'analysis,',\n",
              "   'visualization',\n",
              "   'for',\n",
              "   'climate',\n",
              "   'research'],\n",
              "  'MultipartiteRank': [{'score': 0.1334224121571057, 'word': 'climate'},\n",
              "   {'score': 0.0833189250220018, 'word': 'research'},\n",
              "   {'score': 0.050103487135103895, 'word': 'change'},\n",
              "   {'score': 0.03774738196434315, 'word': 'promising'},\n",
              "   {'score': 0.03774738196434315, 'word': 'hypotheses'},\n",
              "   {'score': 0.0348158073826761, 'word': 'investigation'},\n",
              "   {'score': 0.03429813255954063, 'word': 'prominent'},\n",
              "   {'score': 0.03429813255954063, 'word': 'topics'}],\n",
              "  'Title': 'Hypothesis Generation in Climate Research with Interactive Visual Data Exploration',\n",
              "  'distance': 0,\n",
              "  'no': '862',\n",
              "  'parent': '4519'},\n",
              " {'Abstract': 'We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.',\n",
              "  'AuthorKeywords': ['Tensor',\n",
              "   'fields,',\n",
              "   'tensor',\n",
              "   'invariants,',\n",
              "   'ridge',\n",
              "   'lines,',\n",
              "   'crease',\n",
              "   'extraction,',\n",
              "   'structural',\n",
              "   'analysis,',\n",
              "   'topology'],\n",
              "  'MultipartiteRank': [{'score': 0.14368713072977718, 'word': 'tensor'},\n",
              "   {'score': 0.14368713072977718, 'word': 'fields'},\n",
              "   {'score': 0.0950805339616013, 'word': 'order'},\n",
              "   {'score': 0.061894953015358835, 'word': 'degenerate'},\n",
              "   {'score': 0.061894953015358835, 'word': 'lines'},\n",
              "   {'score': 0.036953666301786155, 'word': 'dimensional'},\n",
              "   {'score': 0.036953666301786155, 'word': 'symmetric'},\n",
              "   {'score': 0.036953666301786155, 'word': 'second'},\n",
              "   {'score': 0.034999937945240235, 'word': 'standard'},\n",
              "   {'score': 0.034999937945240235, 'word': 'topological'},\n",
              "   {'score': 0.034999937945240235, 'word': 'approach'}],\n",
              "  'Title': 'Invariant Crease Lines for Topological and Structural Analysis of Tensor fields',\n",
              "  'distance': 0,\n",
              "  'no': '863',\n",
              "  'parent': '4813'},\n",
              " {'Abstract': \"Recent results have shown a link between geometric properties of isosurfaces and statistical properties of the underlying sampled data. However, this has two defects: not all of the properties described converge to the same solution, and the statistics computed are not always invariant under isosurface-preserving transformations. We apply Federer's Coarea Formula from geometric measure theory to explain these discrepancies. We describe an improved substitute for histograms based on weighting with the inverse gradient magnitude, develop a statistical model that is invariant under isosurface-preserving transformations, and argue that this provides a consistent method for algorithm evaluation across multiple datasets based on histogram equalization. We use our corrected formulation to reevaluate recent results on average isosurface complexity, and show evidence that noise is one cause of the discrepancy between the expected figure and the observed one.\",\n",
              "  'AuthorKeywords': ['Isosurfaces,', 'Histograms,', 'Coarea', 'Formula'],\n",
              "  'MultipartiteRank': [{'score': 0.12420350952124581, 'word': 'properties'},\n",
              "   {'score': 0.10391566531326708, 'word': 'isosurfaces'},\n",
              "   {'score': 0.07177661644451595, 'word': 'statistical'},\n",
              "   {'score': 0.052426893076729854, 'word': 'geometric'},\n",
              "   {'score': 0.04948641547626995, 'word': 'invariant'},\n",
              "   {'score': 0.04414458353826038, 'word': 'transformations'}],\n",
              "  'Title': 'Revisiting Histograms and Isosurface Statistics',\n",
              "  'distance': 0,\n",
              "  'no': '864',\n",
              "  'parent': '3945'},\n",
              " {'Abstract': 'A common task in literary analysis is to study characters in a novel or collection. Automatic entity extraction, text analysis and effective user interfaces facilitate character analysis. Using our interface, called POSvis, the scholar uses word clouds and self-organizing graphs to review vocabulary, to filter by part of speech, and to explore the network of characters located near characters under review. Further, visualizations show word usages within an analysis window (i.e. a book chapter), which can be compared with a reference window (i.e. the whole book). We describe the interface and report on an early case study with a humanities scholar.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'Design,',\n",
              "   'Experimentation,',\n",
              "   'Human',\n",
              "   'Factors'],\n",
              "  'MultipartiteRank': [{'score': 0.08716625833859853, 'word': 'literary'},\n",
              "   {'score': 0.08716625833859853, 'word': 'analysis'},\n",
              "   {'score': 0.08473187220291059, 'word': 'characters'},\n",
              "   {'score': 0.06854596368513433, 'word': 'word'},\n",
              "   {'score': 0.06854596368513433, 'word': 'clouds'},\n",
              "   {'score': 0.053242005599106856, 'word': 'scholar'},\n",
              "   {'score': 0.04421956884981597, 'word': 'interface'}],\n",
              "  'Title': 'What\\'s being said near \"Martha\"? Exploring name entities in literary text collections',\n",
              "  'distance': 0,\n",
              "  'no': '865',\n",
              "  'parent': '3791'},\n",
              " {'Abstract': 'Electronic test and measurement systems are becoming increasingly sophisticated in order to match the increased complexity and ultra-high speed of the devices under test. A key feature in many such instruments is a vastly increased capacity for storage of digital signals. Storage of 109 time points or more is now possible. At the same time, the typical screens on such measurement devices are relatively small. Therefore, these instruments can only render an extremely small fraction of the complete signal at any time. SignalLens uses a Focus+Context approach to provide a means of navigating to and inspecting low-level signal details in the context of the entire signal trace. This approach provides a compact visualization suitable for embedding into the small displays typically provided by electronic measurement instruments. We further augment this display with computed tracks which display time-aligned computed properties of the signal. By combining and filtering these computed tracks it is possible to easily and quickly find computationally detected features in the data which are often obscured by the visual compression required to render the large data sets on a small screen. Further, these tracks can be viewed in the context of the entire signal trace as well as visible high-level signal features. Several examples using real-world electronic measurement data are presented, which demonstrate typical use cases and the effectiveness of the design.',\n",
              "  'AuthorKeywords': ['Focus+Context,',\n",
              "   'Lens,',\n",
              "   'Test',\n",
              "   'and',\n",
              "   'Measurement,',\n",
              "   'Electronic',\n",
              "   'Signal,',\n",
              "   'Signal',\n",
              "   'Processing'],\n",
              "  'MultipartiteRank': [{'score': 0.07097008101336195, 'word': 'digital'},\n",
              "   {'score': 0.07097008101336195, 'word': 'signals'},\n",
              "   {'score': 0.06033432761483143, 'word': 'electronic'},\n",
              "   {'score': 0.06033432761483143, 'word': 'test'},\n",
              "   {'score': 0.054947813597304884, 'word': 'storage'},\n",
              "   {'score': 0.04709490975483984, 'word': 'time'},\n",
              "   {'score': 0.04709490975483984, 'word': 'points'},\n",
              "   {'score': 0.03321002888113701, 'word': 'small'}],\n",
              "  'Title': 'SignalLens: Focus+Context Applied to Electronic Time Series',\n",
              "  'distance': 0,\n",
              "  'no': '866',\n",
              "  'parent': '4766'},\n",
              " {'Abstract': 'Radial visualizations play an important role in the information visualization community. But the decision to choose a radial coordinate system is rather based on intuition than on scientific foundations. The empirical approach presented in this paper aims at uncovering strengths and weaknesses of radial visualizations by comparing them to equivalent ones in Cartesian coordinate systems. We identified memorizing positions of visual elements as a generic task when working with visualizations. A first study with 674 participants provides a broad data spectrum for exploring differences between the two visualization types. A second, complementing study with fewer participants focuses on further questions raised by the first study. Our findings document that Cartesian visualizations tend to outperform their radial counterparts especially with respect to answer times. Nonetheless, radial visualization seem to be more appropriate for focusing on a particular data dimension.',\n",
              "  'AuthorKeywords': ['Radial',\n",
              "   'visualization,',\n",
              "   'user',\n",
              "   'study,',\n",
              "   'visual',\n",
              "   'memory'],\n",
              "  'MultipartiteRank': [{'score': 0.2615665368726242, 'word': 'radial'},\n",
              "   {'score': 0.2156933145102805, 'word': 'visualizations'},\n",
              "   {'score': 0.05000378623453536, 'word': 'first'},\n",
              "   {'score': 0.05000378623453536, 'word': 'study'},\n",
              "   {'score': 0.045873222362343716, 'word': 'coordinate'},\n",
              "   {'score': 0.045873222362343716, 'word': 'system'},\n",
              "   {'score': 0.04387900273843304, 'word': 'weaknesses'},\n",
              "   {'score': 0.03630446297054436, 'word': 'uncovering'},\n",
              "   {'score': 0.03630446297054436, 'word': 'strengths'}],\n",
              "  'Title': 'Uncovering Strengths and Weaknesses of Radial Visualizations---an Empirical Approach',\n",
              "  'distance': 0,\n",
              "  'no': '867',\n",
              "  'parent': '3783'},\n",
              " {'Abstract': 'Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.',\n",
              "  'AuthorKeywords': ['Graph,',\n",
              "   'visualization,',\n",
              "   'curved',\n",
              "   'edges,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.1333610268883051, 'word': 'curved'},\n",
              "   {'score': 0.1333610268883051, 'word': 'edges'},\n",
              "   {'score': 0.06650422945812676, 'word': 'straight'},\n",
              "   {'score': 0.06650422945812676, 'word': 'line'},\n",
              "   {'score': 0.06650422945812676, 'word': 'segments'},\n",
              "   {'score': 0.06087377030298781, 'word': 'graphs'},\n",
              "   {'score': 0.0381149091062925, 'word': 'node'},\n",
              "   {'score': 0.03628438777260004, 'word': 'several'},\n",
              "   {'score': 0.03628438777260004, 'word': 'edge'},\n",
              "   {'score': 0.03628438777260004, 'word': 'variations'}],\n",
              "  'Title': 'A User Study on Curved Edges in Graph Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '868',\n",
              "  'parent': '5321'},\n",
              " {'Abstract': \"For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system “in the wild”, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of “exploring” a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.\",\n",
              "  'AuthorKeywords': ['Design',\n",
              "   'study,',\n",
              "   'investigative',\n",
              "   'journalism,',\n",
              "   'task',\n",
              "   'and',\n",
              "   'requirements',\n",
              "   'analysis,',\n",
              "   'text',\n",
              "   'and',\n",
              "   'document',\n",
              "   'data,',\n",
              "   'text',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.06622471648298213, 'word': 'documents'},\n",
              "   {'score': 0.06263675828210506, 'word': 'large'},\n",
              "   {'score': 0.06263675828210506, 'word': 'collection'},\n",
              "   {'score': 0.050078556448119455, 'word': 'investigative'},\n",
              "   {'score': 0.050078556448119455, 'word': 'journalist'},\n",
              "   {'score': 0.036655518100897795, 'word': 'visualization'},\n",
              "   {'score': 0.032268940196675984, 'word': 'overview'}],\n",
              "  'Title': 'Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists',\n",
              "  'distance': 0,\n",
              "  'no': '869',\n",
              "  'parent': '4697'},\n",
              " {'Abstract': 'We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.',\n",
              "  'AuthorKeywords': ['Visualization',\n",
              "   'Design,',\n",
              "   'Symmetries,',\n",
              "   'Visualization',\n",
              "   'Theory'],\n",
              "  'MultipartiteRank': [{'score': 0.15836291815317588, 'word': 'visualization'},\n",
              "   {'score': 0.13539223377684445, 'word': 'model'},\n",
              "   {'score': 0.0814061055826864, 'word': 'design'},\n",
              "   {'score': 0.07695681257048947, 'word': 'process'},\n",
              "   {'score': 0.03860595495679708, 'word': 'data'},\n",
              "   {'score': 0.03817132589494713, 'word': 'algebraic'},\n",
              "   {'score': 0.03817132589494713, 'word': 'considerations'}],\n",
              "  'Title': 'An Algebraic Process for Visualization Design',\n",
              "  'distance': 0,\n",
              "  'no': '870',\n",
              "  'parent': '4426'},\n",
              " {'Abstract': 'Various techniques are described for achieving interactive direct volume rendering of nonrectilinear data sets using fast projection (splatting) methods. The use of graphics hardware, rendering approximations, parallelization and reduced resolution meshes are discussed. Results from the use of these techniques are presented in the form of color photos and comparative timings.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11711205644566494, 'word': 'various'},\n",
              "   {'score': 0.11711205644566494, 'word': 'techniques'},\n",
              "   {'score': 0.10175970652592856, 'word': 'use'},\n",
              "   {'score': 0.07691402363483002, 'word': 'nonrectilinear'},\n",
              "   {'score': 0.07691402363483002, 'word': 'data'},\n",
              "   {'score': 0.07691402363483002, 'word': 'sets'},\n",
              "   {'score': 0.07549325807608237, 'word': 'fast'},\n",
              "   {'score': 0.07549325807608237, 'word': 'projection'},\n",
              "   {'score': 0.07234593509926909, 'word': 'splatting'}],\n",
              "  'Title': 'Interactive splatting of nonrectilinear volumes',\n",
              "  'distance': 0,\n",
              "  'no': '871',\n",
              "  'parent': '3341'},\n",
              " {'Abstract': 'Making accurate computer graphics representations of surfaces and volumes (2-manifolds and 3-manifolds) embedded in four-dimensional space typically involves complex and time-consuming computations. In order to make simulated worlds that help develop human intuition about the fourth dimensions, we need techniques that permit real-time, interactive manipulation of the most sophisticated depictions available. We propose the following new methods that bring us significantly closer to this goal: an approach to high-speed 4D illuminated surface rendering incorporating 4D shading and occlusion coding; a procedure for rapidly generating 2D screen images of tessellated 3-manifolds illuminated by 4D light. These methods are orders of magnitude faster than previous approaches, enabling the real-time manipulation of high-resolution 4D images on commercial graphics hardware.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08327405605179128, 'word': 'time'},\n",
              "   {'score': 0.057667602162372725, 'word': 'high'},\n",
              "   {'score': 0.055014373260427796, 'word': 'real'},\n",
              "   {'score': 0.053081070339502136, 'word': 'order'},\n",
              "   {'score': 0.05249562332362579, 'word': 'surfaces'}],\n",
              "  'Title': 'Interactive visualization methods for four dimensions',\n",
              "  'distance': 0,\n",
              "  'no': '872',\n",
              "  'parent': '4295'},\n",
              " {'Abstract': 'Maximum projection is a volume rendering technique that, for each pixel, finds the maximum intensity along a projector. For certain important classes of data, this is an approximation to summation rendering which produces superior visualizations. We show how maximum projection rendering with additional depth cues can be implemented using simple affine transformations in object space. This technique can be used together with 3D graphics libraries and standard graphics hardware, thus allowing interactive manipulations of the volume data. The algorithm presented allows for a wide range of tradeoffs between interactivity and image quality.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11987020105953915, 'word': 'maximum'},\n",
              "   {'score': 0.11987020105953915, 'word': 'projection'},\n",
              "   {'score': 0.06829302067311434, 'word': 'data'},\n",
              "   {'score': 0.0640336592735913, 'word': 'technique'},\n",
              "   {'score': 0.05737676764245918, 'word': 'interactive'},\n",
              "   {'score': 0.05737676764245918, 'word': 'manipulations'},\n",
              "   {'score': 0.04551254326572522, 'word': 'certain'},\n",
              "   {'score': 0.04551254326572522, 'word': 'important'},\n",
              "   {'score': 0.04551254326572522, 'word': 'classes'}],\n",
              "  'Title': 'Interactive maximum projection volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '873',\n",
              "  'parent': '3432'},\n",
              " {'Abstract': 'An algorithm for computing a triangulated surface which separates a collection of data points that have been segmented into a number of different classes is presented. The problem generalizes the concept of an isosurface which separates data points that have been segmented into only two classes: those for which data function values are above the threshold and those which are below the threshold value. The algorithm is very simple, easy to implement and applies without limit to the number of classes.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11491325619321238, 'word': 'different'},\n",
              "   {'score': 0.11491325619321238, 'word': 'classes'},\n",
              "   {'score': 0.10269715303986088, 'word': 'number'},\n",
              "   {'score': 0.08975625310292593, 'word': 'data'},\n",
              "   {'score': 0.08975625310292593, 'word': 'points'},\n",
              "   {'score': 0.07333827513691132, 'word': 'algorithm'},\n",
              "   {'score': 0.06794505622633418, 'word': 'threshold'}],\n",
              "  'Title': 'Computing the separating surface for segmented data',\n",
              "  'distance': 0,\n",
              "  'no': '874',\n",
              "  'parent': '3493'},\n",
              " {'Abstract': 'This paper proposes a new technique to visualize dependencies among cells in a spreadsheet. In this way, the system firstly visualizes a spreadsheet on a plane in three-dimensional space, and draws arcs between interrelated cells. By allowing a user to select an arbitrary cell and lift it up with direct manipulation, the system utilizes the third dimension to ameliorate visual occlusion of crossing arcs. As the user lifts a focused cell up, the interrelated cells are lifted up together; thus hidden dataflow networks can be visually intelligible interactively. Because spreadsheets are aimed at calculation itself rather than appearances of outputs, their mechanism is relatively invisible and not obvious for ordinary users. Our visualization helps such users to understand structures and mechanism of spreadsheets.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   '3D',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'spreadsheets,',\n",
              "   'inter-cell',\n",
              "   'dependencies,',\n",
              "   'lifting-up',\n",
              "   'operation,',\n",
              "   'Natto',\n",
              "   'View'],\n",
              "  'MultipartiteRank': [{'score': 0.10372398358317106, 'word': 'cells'},\n",
              "   {'score': 0.08930165808144835, 'word': 'spreadsheet'},\n",
              "   {'score': 0.0712126117059314, 'word': 'user'},\n",
              "   {'score': 0.05261198031149366, 'word': 'system'},\n",
              "   {'score': 0.04875118339236553, 'word': 'visual'},\n",
              "   {'score': 0.04875118339236553, 'word': 'occlusion'}],\n",
              "  'Title': '3D interactive visualization for inter-cell dependencies of spreadsheets',\n",
              "  'distance': 0,\n",
              "  'no': '875',\n",
              "  'parent': '3904'},\n",
              " {'Abstract': 'As the size and complexity of data sets continues to increase, the development of user interfaces and interaction techniques that expedite the process of exploring that data must receive new attention. Regardless of the speed of rendering, it is important to coherently organize the visual process of exploration: this information both grants insights about the data to a user and can be used by collaborators to understand the results. To fulfil these needs, we present a spreadsheet-like interface to data exploration. The interface displays a 2-dimensional window into visualization parameter space which users manipulate as they search for desired results. Through tabular organization and a clear correspondence between parameters and results, the interface eases the discovery, comparison and analysis of the underlying data. Users can utilize operators and the integrated interpreter to further explore and automate the visualization process; using a method introduced in this paper, these operations can be applied to cells in different stacks of the interface. Via illustrations using a variety of data sets, we demonstrate the efficacy of this novel interface.',\n",
              "  'AuthorKeywords': ['speadsheets,',\n",
              "   'user',\n",
              "   'interfaces,',\n",
              "   'knowledge',\n",
              "   'representation,',\n",
              "   'scientific',\n",
              "   'visualization,',\n",
              "   'visualization',\n",
              "   'systems,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.09701484642167058, 'word': 'interface'},\n",
              "   {'score': 0.0950690126168298, 'word': 'data'},\n",
              "   {'score': 0.0950690126168298, 'word': 'sets'},\n",
              "   {'score': 0.06119892904790367, 'word': 'like'},\n",
              "   {'score': 0.060906047294639, 'word': 'user'},\n",
              "   {'score': 0.060906047294639, 'word': 'interfaces'},\n",
              "   {'score': 0.041052850279440264, 'word': 'process'}],\n",
              "  'Title': 'A spreadsheet interface for visualization exploration',\n",
              "  'distance': 0,\n",
              "  'no': '876',\n",
              "  'parent': '4468'},\n",
              " {'Abstract': 'For the rendering of vector and tensor fields, several texture-based volumetric rendering methods were presented in recent years. While they have indisputable merits, the classical vertex-based rendering of integral curves has the advantage of better zooming capabilities as it is not bound to a fixed resolution. It has been shown that lighting can improve spatial perception of lines significantly, especially if lines appear in bundles. Although OpenGL does not directly support lighting of lines, fast rendering of illuminated lines can be achieved by using basic texture mapping. This existing technique is based on a maximum principle which gives a good approximation of specular reflection. Diffuse reflection however is essentially limited to bidirectional lights at infinity. We show how the realism can be further increased by improving diffuse reflection. We present simplified expressions for the Phong/Blinn lighting of infinitesimally thin cylindrical tubes. Based on these, we propose a fast rendering technique with diffuse and specular reflection for orthographic and perspective views and for multiple local and infinite lights. The method requires commonly available programmable vertex and fragment shaders and only two-dimensional lookup textures.',\n",
              "  'AuthorKeywords': ['Field',\n",
              "   'lines,',\n",
              "   'illumination,',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'visualization,texture',\n",
              "   'mapping,',\n",
              "   'graphics',\n",
              "   'hardware'],\n",
              "  'MultipartiteRank': [{'score': 0.11804715214792424, 'word': 'rendering'},\n",
              "   {'score': 0.07031245287393129, 'word': 'lighting'},\n",
              "   {'score': 0.06736581865844504, 'word': 'lines'},\n",
              "   {'score': 0.0378794128656417, 'word': 'diffuse'},\n",
              "   {'score': 0.0378794128656417, 'word': 'reflection'},\n",
              "   {'score': 0.03354497024849774, 'word': 'volumetric'},\n",
              "   {'score': 0.03354497024849774, 'word': 'methods'}],\n",
              "  'Title': 'Illuminated lines revisited',\n",
              "  'distance': 0,\n",
              "  'no': '877',\n",
              "  'parent': '5173'},\n",
              " {'Abstract': 'Tensors occur in many areas of science and engineering. Especially, they are used to describe charge, mass and energy transport (i.e. electrical conductivity tensor, diffusion tensor, thermal conduction tensor resp.) If the locale transport pattern is complicated, usual second order tensor representation is not sufficient. So far, there are no appropriate visualization methods for this case. We point out similarities of symmetric higher order tensors and spherical harmonics. A spherical harmonic representation is used to improve tensor glyphs. This paper unites the definition of streamlines and tensor lines and generalizes tensor lines to those applications where second order tensors representations fail. The algorithm is tested on the tractography problem in diffusion tensor magnetic resonance imaging (DT-MRI) and improved for this special application.',\n",
              "  'AuthorKeywords': ['Higher',\n",
              "   'order',\n",
              "   'tensors,',\n",
              "   'spherical',\n",
              "   'harmonics,',\n",
              "   'tensor',\n",
              "   'lines,',\n",
              "   'tractography,',\n",
              "   'vector/tensor',\n",
              "   'visualization,',\n",
              "   'visualization',\n",
              "   'in',\n",
              "   'medicine,',\n",
              "   'DT-MRI'],\n",
              "  'MultipartiteRank': [{'score': 0.16958611368671297, 'word': 'tensors'},\n",
              "   {'score': 0.1090986773267078, 'word': 'tensor'},\n",
              "   {'score': 0.06587509757286275, 'word': 'many'},\n",
              "   {'score': 0.06587509757286275, 'word': 'areas'},\n",
              "   {'score': 0.057651774232284736, 'word': 'usual'},\n",
              "   {'score': 0.057651774232284736, 'word': 'second'},\n",
              "   {'score': 0.057651774232284736, 'word': 'order'},\n",
              "   {'score': 0.057651774232284736, 'word': 'representation'},\n",
              "   {'score': 0.05438879705783081, 'word': 'science'},\n",
              "   {'score': 0.05144690309442307, 'word': 'electrical'},\n",
              "   {'score': 0.05144690309442307, 'word': 'conductivity'}],\n",
              "  'Title': 'HOT-lines: tracking lines in higher order tensor fields',\n",
              "  'distance': 0,\n",
              "  'no': '878',\n",
              "  'parent': '4027'},\n",
              " {'Abstract': 'This paper presents a network traffic analysis system that couples visual analysis with a declarative knowledge representation. The system supports multiple iterations of the sense-making loop of analytic reasoning by allowing users to save discoveries as they are found and to reuse them in future iterations. We show how the knowledge representation can be used to improve both the visual representations and the basic analytical tasks of filtering and changing level of detail. We describe how the system can be used to produce models of network patterns, and show results from classifying one day of network traffic in our laboratory',\n",
              "  'AuthorKeywords': ['network',\n",
              "   'traffic',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.1787928922386546, 'word': 'analysis'},\n",
              "   {'score': 0.17713176492476912, 'word': 'system'},\n",
              "   {'score': 0.09947879545025426, 'word': 'network'},\n",
              "   {'score': 0.09947879545025426, 'word': 'traffic'},\n",
              "   {'score': 0.07931409678840035, 'word': 'visual'},\n",
              "   {'score': 0.07627292730739758, 'word': 'declarative'},\n",
              "   {'score': 0.07627292730739758, 'word': 'knowledge'},\n",
              "   {'score': 0.07627292730739758, 'word': 'representation'},\n",
              "   {'score': 0.07431295714623065, 'word': 'multiple'},\n",
              "   {'score': 0.07431295714623065, 'word': 'iterations'}],\n",
              "  'Title': 'Enhancing Visual Analysis of Network Traffic Using a Knowledge Representation',\n",
              "  'distance': 0,\n",
              "  'no': '879',\n",
              "  'parent': '3562'},\n",
              " {'Abstract': 'We present empirical studies that consider the effects of stereopsis and simulated aerial perspective on depth perception in translucent volumes. We consider a purely absorptive lighting model, in which light is not scattered or reflected, but is simply absorbed as it passes through the volume. A purely absorptive lighting model is used, for example, when rendering digitally reconstructed radiographs (DRRs), which are synthetic X-ray images reconstructed from CT volumes. Surgeons make use of DRRs in planning and performing operations, so an improvement of depth perception in DRRs may help diagnosis and surgical planning',\n",
              "  'AuthorKeywords': ['Stereo,',\n",
              "   'Stereopsis,',\n",
              "   'X-ray,',\n",
              "   'Radiograph,',\n",
              "   'Volume',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.10577184638348112, 'word': 'drrs'},\n",
              "   {'score': 0.09809195383751565, 'word': 'depth'},\n",
              "   {'score': 0.09809195383751565, 'word': 'perception'},\n",
              "   {'score': 0.09414554725129062, 'word': 'translucent'},\n",
              "   {'score': 0.09414554725129062, 'word': 'volumes'},\n",
              "   {'score': 0.06897939261534185, 'word': 'absorptive'},\n",
              "   {'score': 0.06897939261534185, 'word': 'lighting'},\n",
              "   {'score': 0.06897939261534185, 'word': 'model'},\n",
              "   {'score': 0.06670702958770908, 'word': 'planning'}],\n",
              "  'Title': 'Enhancing Depth Perception in Translucent Volumes',\n",
              "  'distance': 0,\n",
              "  'no': '880',\n",
              "  'parent': '3424'},\n",
              " {'Abstract': 'In interfaces that provide multiple visual information resolutions (VIR), low-VIR overviews typically sacrifice visual details for display capacity, with the assumption that users can select regions of interest to examine at higher VI Rs. Designers can create low VIRs based on multi-level structure inherent in the data, but have little guidance with single-level data. To better guide design tradeoff between display capacity and visual target perceivability, we looked at overview use in two multiple-VIR interfaces with high-VIR displays either embedded within, or separate from, the overviews. We studied two visual requirements for effective overview and found that participants would reliably use the low-VIR overviews only when the visual targets were simple and had small visual spans. Otherwise, at least 20% chose to use the high-VIR view exclusively. Surprisingly, neither of the multiple-VIR interfaces provided performance benefits when compared to using the high-VIR view alone. However, we did observe benefits in providing side-by-side comparisons for target matching. We conjecture that the high cognitive load of multiple-VIR interface interactions, whether real or perceived, is a more considerable barrier to their effective use than was previously considered.',\n",
              "  'AuthorKeywords': ['Multiple',\n",
              "   'resolutions,',\n",
              "   'overview',\n",
              "   'use,',\n",
              "   'user',\n",
              "   'study'],\n",
              "  'MultipartiteRank': [{'score': 0.13035573090182145, 'word': 'vir'},\n",
              "   {'score': 0.072696618250871, 'word': 'overviews'},\n",
              "   {'score': 0.06586402713683807, 'word': 'interfaces'},\n",
              "   {'score': 0.0620835583983673, 'word': 'visual'},\n",
              "   {'score': 0.0620835583983673, 'word': 'details'},\n",
              "   {'score': 0.05931024660920144, 'word': 'low'}],\n",
              "  'Title': 'Overview Use in Multiple Visual Information Resolution Interfaces',\n",
              "  'distance': 0,\n",
              "  'no': '881',\n",
              "  'parent': '5900'},\n",
              " {'Abstract': 'Using mobile devices for visualization provides a ubiquitous environment for accessing information and effective decision making. These visualizations are critical in satisfying the knowledge needs of operators in areas as diverse as education, business, law enforcement, protective services, medical services, scientific discovery, and homeland security. In this paper, we present an efficient and interactive mobile visual analytic system for increased situational awareness and decision making in emergency response and training situations. Our system provides visual analytics with locational scene data within a simple interface tailored to mobile device capabilities. In particular, we focus on processing and displaying sensor network data for first responders. To verify our system, we have used simulated data of The Station nightclub fire evacuation.',\n",
              "  'AuthorKeywords': ['mobile',\n",
              "   'visualization,',\n",
              "   'visual',\n",
              "   'analytics,',\n",
              "   'emergency',\n",
              "   'response'],\n",
              "  'MultipartiteRank': [{'score': 0.0983827379662488, 'word': 'visualization'},\n",
              "   {'score': 0.05421267286618367, 'word': 'effective'},\n",
              "   {'score': 0.05421267286618367, 'word': 'decision'},\n",
              "   {'score': 0.05421267286618367, 'word': 'making'},\n",
              "   {'score': 0.04917067470955073, 'word': 'mobile'},\n",
              "   {'score': 0.04917067470955073, 'word': 'devices'},\n",
              "   {'score': 0.0454008706776701, 'word': 'protective'},\n",
              "   {'score': 0.0454008706776701, 'word': 'services'},\n",
              "   {'score': 0.035675047728830185, 'word': 'situational'},\n",
              "   {'score': 0.035675047728830185, 'word': 'awareness'}],\n",
              "  'Title': 'Visual Analytics on Mobile Devices for Emergency Response',\n",
              "  'distance': 0,\n",
              "  'no': '882',\n",
              "  'parent': '3726'},\n",
              " {'Abstract': 'Ranking data, which result from m raters ranking n items, are difficult to visualize due to their discrete algebraic structure, and the computational difficulties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efficient. The approach overcomes the structural and computational difficulties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences.',\n",
              "  'AuthorKeywords': ['Partial',\n",
              "   'rankings,',\n",
              "   'incomplete',\n",
              "   'rankings,',\n",
              "   'multidimensional',\n",
              "   'scaling'],\n",
              "  'MultipartiteRank': [{'score': 0.08889206042627572, 'word': 'raters'},\n",
              "   {'score': 0.08070463659997236, 'word': 'data'},\n",
              "   {'score': 0.06882156850089688, 'word': 'approach'},\n",
              "   {'score': 0.067518762268672, 'word': 'computational'},\n",
              "   {'score': 0.067518762268672, 'word': 'difficulties'},\n",
              "   {'score': 0.06315601981955313, 'word': 'discrete'},\n",
              "   {'score': 0.06315601981955313, 'word': 'algebraic'},\n",
              "   {'score': 0.06315601981955313, 'word': 'structure'}],\n",
              "  'Title': 'Visualizing Incomplete and Partially Ranked Data',\n",
              "  'distance': 0,\n",
              "  'no': '883',\n",
              "  'parent': '3663'},\n",
              " {'Abstract': 'Characteristic curves of vector fields include stream, path, and streak lines. Stream and path lines can be obtained by a simple vector field integration of an autonomous ODE system, i.e., they can be described as tangent curves of a vector field. This facilitates their mathematical analysis including the extraction of core lines around which stream or path lines exhibit swirling motion, or the computation of their curvature for every point in the domain without actually integrating them. Such a description of streak lines is not yet available, which excludes them from most of the feature extraction and analysis tools that have been developed in our community. In this paper, we develop the first description of streak lines as tangent curves of a derived vector field - the streak line vector field - and show how it can be computed from the spatial and temporal gradients of the flow map, i.e., a dense path line integration is required. We demonstrate the high accuracy of our approach by comparing it to solutions where the ground truth is analytically known and to solutions where the ground truth has been obtained using the classic streak line computation. Furthermore, we apply a number of feature extraction and analysis tools to the new streak line vector field including the extraction of cores of swirling streak lines and the computation of streak line curvature fields. These first applications foreshadow the large variety of possible future research directions based on our new mathematical description of streak lines.',\n",
              "  'AuthorKeywords': ['Unsteady',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'streak',\n",
              "   'lines,',\n",
              "   'streak',\n",
              "   'surfaces,',\n",
              "   'feature',\n",
              "   'extraction'],\n",
              "  'MultipartiteRank': [{'score': 0.09656421398938063, 'word': 'streak'},\n",
              "   {'score': 0.09656421398938063, 'word': 'lines'},\n",
              "   {'score': 0.07870361135155626, 'word': 'characteristic'},\n",
              "   {'score': 0.07870361135155626, 'word': 'curves'},\n",
              "   {'score': 0.06983833503194654, 'word': 'vector'},\n",
              "   {'score': 0.06983833503194654, 'word': 'fields'},\n",
              "   {'score': 0.061982122396111165, 'word': 'stream'},\n",
              "   {'score': 0.06093775688996386, 'word': 'path'}],\n",
              "  'Title': 'Streak Lines as Tangent Curves of a Derived Vector field',\n",
              "  'distance': 0,\n",
              "  'no': '884',\n",
              "  'parent': '5565'},\n",
              " {'Abstract': 'Traditionally, the visual analysis of hierarchies, respectively, trees, is conducted by focusing on one given hierarchy. However, in many research areas multiple, differing hierarchies need to be analyzed simultaneously in a comparative way - in particular to highlight differences between them, which sometimes can be subtle. A prominent example is the analysis of so-called phylogenetic trees in biology, reflecting hierarchical evolutionary relationships among a set of organisms. Typically, the analysis considers multiple phylogenetic trees, either to account for statistical significance or for differences in derivation of such evolutionary hierarchies; for example, based on different input data, such as the 16S ribosomal RNA and protein sequences of highly conserved enzymes. The simultaneous analysis of a collection of such trees leads to more insight into the evolutionary process. We introduce a novel visual analytics approach for the comparison of multiple hierarchies focusing on both global and local structures. A new tree comparison score has been elaborated for the identification of interesting patterns. We developed a set of linked hierarchy views showing the results of automatic tree comparison on various levels of details. This combined approach offers detailed assessment of local and global tree similarities. The approach was developed in close cooperation with experts from the evolutionary biology domain. We apply it to a phylogenetic data set on bacterial ancestry, demonstrating its application benefit.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09358153237966037, 'word': 'hierarchies'},\n",
              "   {'score': 0.07065303662482057, 'word': 'visual'},\n",
              "   {'score': 0.07065303662482057, 'word': 'analysis'},\n",
              "   {'score': 0.05182347955936785, 'word': 'trees'},\n",
              "   {'score': 0.0390494300828033, 'word': 'comparison'},\n",
              "   {'score': 0.03840620934175861, 'word': 'differences'}],\n",
              "  'Title': 'Interactive visual comparison of multiple trees',\n",
              "  'distance': 0,\n",
              "  'no': '885',\n",
              "  'parent': '4934'},\n",
              " {'Abstract': 'Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.',\n",
              "  'AuthorKeywords': ['Dynamic',\n",
              "   'networks,',\n",
              "   'hybrid',\n",
              "   'visualization,',\n",
              "   'taxonomy,',\n",
              "   'evolution,',\n",
              "   'animation,',\n",
              "   'difference',\n",
              "   'map'],\n",
              "  'MultipartiteRank': [{'score': 0.08784150903120022, 'word': 'graphs'},\n",
              "   {'score': 0.06991963748941725, 'word': 'visualization'},\n",
              "   {'score': 0.06704577051765705, 'word': 'time'},\n",
              "   {'score': 0.06704577051765705, 'word': 'interval'},\n",
              "   {'score': 0.0493777020866044, 'word': 'animation'},\n",
              "   {'score': 0.04692060252208399, 'word': 'tiles'}],\n",
              "  'Title': 'DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation',\n",
              "  'distance': 0,\n",
              "  'no': '886',\n",
              "  'parent': '4716'},\n",
              " {'Abstract': \"We present a novel area-preservation mapping/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n&lt;sup&gt;2&lt;/sup&gt;) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton's method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework.\",\n",
              "  'AuthorKeywords': ['Area-preservation',\n",
              "   'mapping,',\n",
              "   'surface',\n",
              "   'flattening,',\n",
              "   'optimal',\n",
              "   'transport',\n",
              "   'map,',\n",
              "   'Monge-Brenier',\n",
              "   'theory,',\n",
              "   'visualization',\n",
              "   'and',\n",
              "   'graphics',\n",
              "   'applications'],\n",
              "  'MultipartiteRank': [{'score': 0.06809034093217024, 'word': 'optimal'},\n",
              "   {'score': 0.06809034093217024, 'word': 'mass'},\n",
              "   {'score': 0.06809034093217024, 'word': 'transport'},\n",
              "   {'score': 0.06809034093217024, 'word': 'technique'},\n",
              "   {'score': 0.06610812311825015, 'word': 'flattening'},\n",
              "   {'score': 0.06610812311825015, 'word': 'method'},\n",
              "   {'score': 0.050021236777682276, 'word': 'novel'},\n",
              "   {'score': 0.050021236777682276, 'word': 'area'},\n",
              "   {'score': 0.04901172523526117, 'word': 'preservation'},\n",
              "   {'score': 0.04901172523526117, 'word': 'mapping'},\n",
              "   {'score': 0.04514209519032737, 'word': 'brenier'},\n",
              "   {'score': 0.04514209519032737, 'word': 'theory'}],\n",
              "  'Title': 'Area-Preservation Mapping using Optimal Mass Transport',\n",
              "  'distance': 0,\n",
              "  'no': '887',\n",
              "  'parent': '4081'},\n",
              " {'Abstract': 'We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.',\n",
              "  'AuthorKeywords': ['Ensemble',\n",
              "   'visualization,',\n",
              "   'uncertainty',\n",
              "   'visualization,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'streamlines,',\n",
              "   'statistical',\n",
              "   'modeling'],\n",
              "  'MultipartiteRank': [{'score': 0.09222668235274506, 'word': 'streamlines'},\n",
              "   {'score': 0.07105772924092683, 'word': 'multivariate'},\n",
              "   {'score': 0.07105772924092683, 'word': 'gaussian'},\n",
              "   {'score': 0.07105772924092683, 'word': 'distribution'},\n",
              "   {'score': 0.06781884117232552, 'word': 'dimensional'},\n",
              "   {'score': 0.06781884117232552, 'word': 'euclidean'},\n",
              "   {'score': 0.06781884117232552, 'word': 'space'},\n",
              "   {'score': 0.04204615360693081, 'word': 'low'},\n",
              "   {'score': 0.039279384123668215, 'word': 'statistical'},\n",
              "   {'score': 0.039279384123668215, 'word': 'properties'}],\n",
              "  'Title': 'Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles',\n",
              "  'distance': 0,\n",
              "  'no': '888',\n",
              "  'parent': '5203'},\n",
              " {'Abstract': 'Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios.',\n",
              "  'AuthorKeywords': ['Scatterplots,',\n",
              "   'user',\n",
              "   'interaction,',\n",
              "   'model',\n",
              "   'steering'],\n",
              "  'MultipartiteRank': [{'score': 0.12454046326673861,\n",
              "    'word': 'multidimensional'},\n",
              "   {'score': 0.12454046326673861, 'word': 'data'},\n",
              "   {'score': 0.08342910911210986, 'word': 'effective'},\n",
              "   {'score': 0.08342910911210986, 'word': 'visualization'},\n",
              "   {'score': 0.08342910911210986, 'word': 'techniques'},\n",
              "   {'score': 0.0683475461273985, 'word': 'axes'},\n",
              "   {'score': 0.05524181879857114, 'word': 'scatterplots'},\n",
              "   {'score': 0.034553244132436114, 'word': 'axis'}],\n",
              "  'Title': 'InterAxis: Steering Scatterplot Axes via Observation-Level Interaction',\n",
              "  'distance': 0,\n",
              "  'no': '889',\n",
              "  'parent': '4686'},\n",
              " {'Abstract': 'Methods for displaying scientific data using textures and raster operations rather than geometric techniques are described. The flexibility and simplicity of raster operations allow a greater choice of visualization techniques with only a small set of basic operations. In addition, texture mapping techniques that allow the representation of several variables simultaneously, without a high degree of clutter, are shown. The combination of traditional geometric techniques, image composition techniques, and image rendering techniques can be integrated into a single framework for the display of scientific data. A system for generating and operating on textures and images for the purposes of scientific visualization is presented. To illustrate its advantage, the development of bump maps for vector filters and contour lines is demonstrated.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.11055449302454615, 'word': 'techniques'},\n",
              "   {'score': 0.07780276357872466, 'word': 'raster'},\n",
              "   {'score': 0.07780276357872466, 'word': 'operations'},\n",
              "   {'score': 0.07267152160717491, 'word': 'textures'},\n",
              "   {'score': 0.056099959432319414, 'word': 'image'},\n",
              "   {'score': 0.056099959432319414, 'word': 'composition'},\n",
              "   {'score': 0.054454533592226725, 'word': 'geometric'},\n",
              "   {'score': 0.04854517208997029, 'word': 'scientific'},\n",
              "   {'score': 0.04854517208997029, 'word': 'data'}],\n",
              "  'Title': 'A scientific visualization synthesizer',\n",
              "  'distance': 0,\n",
              "  'no': '890',\n",
              "  'parent': '4001'},\n",
              " {'Abstract': 'This paper presents an analysis of progress in the use of sound as a tool in support of visualisation and gives an insight into its development and future needs. Special emphasis is given to the use of sound in scientific and engineering applications. A system developed to support surface data presentation and interaction by using sound is presented and discussed.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12664560799587896, 'word': 'sound'},\n",
              "   {'score': 0.09650483252109122, 'word': 'use'},\n",
              "   {'score': 0.05981854550008053, 'word': 'support'},\n",
              "   {'score': 0.059200653353116674, 'word': 'future'},\n",
              "   {'score': 0.059200653353116674, 'word': 'needs'},\n",
              "   {'score': 0.057400282801159906, 'word': 'scientific'}],\n",
              "  'Title': 'An illustrated analysis of sonification for scientific visualisation',\n",
              "  'distance': 0,\n",
              "  'no': '891',\n",
              "  'parent': '3360'},\n",
              " {'Abstract': \"Automated graphical generation systems should be able to design effective presentations for heterogeneous (quantitative and qualitative) information in static or interactive environments. When building such a system, it is important to thoroughly understand the presentation-related characteristics of domain-specific information. We define a data-analysis taxonomy that can be used to characterize heterogeneous information. In addition to capturing the presentation-related properties of data, our characterization takes into account the user's information-seeking goals and visual-interpretation preferences. We use automatically-generated examples from two different application domains to demonstrate the coverage of the proposed taxonomy and its utility for selecting effective graphical techniques.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07681225150530428, 'word': 'information'},\n",
              "   {'score': 0.07549880602892035, 'word': 'effective'},\n",
              "   {'score': 0.07549880602892035, 'word': 'presentations'},\n",
              "   {'score': 0.05902310116063786, 'word': 'heterogeneous'},\n",
              "   {'score': 0.052399240036499525, 'word': 'graphical'},\n",
              "   {'score': 0.052399240036499525, 'word': 'generation'},\n",
              "   {'score': 0.052399240036499525, 'word': 'systems'},\n",
              "   {'score': 0.042143479936953776, 'word': 'data'}],\n",
              "  'Title': 'Data characterization for automatically visualizing heterogeneous information',\n",
              "  'distance': 0,\n",
              "  'no': '892',\n",
              "  'parent': '3824'},\n",
              " {'Abstract': 'We describe a method for the visualization of information units on spherical domains which is employed in the banking industry for risk analysis, stock prediction and other tasks. The system is based on a quantification of the similarity of related objects that governs the parameters of a mass-spring system. Unlike existing approaches we initialize all information units onto the inner surface of two concentric spheres and attach them with springs to the outer sphere. Since the spring stiffnesses correspond to the computed similarity measures, the system converges into an energy minimum which reveals multidimensional relations and adjacencies in terms of spatial neighborhoods. Depending on the application scenario our approach supports different topological arrangements of related objects. In order to cope with large data sets we propose a blobby clustering mechanism that enables encapsulation of similar objects by implicit shapes. In addition, we implemented various interaction techniques allowing semantic analysis of the underlying data sets. Our prototype system IVORY is written in Java, and its versatility is illustrated by an example from financial service providers.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'physically-based',\n",
              "   'systems,',\n",
              "   'multidimensional',\n",
              "   'information',\n",
              "   'space,',\n",
              "   'hierarchies,',\n",
              "   'blobby',\n",
              "   'clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.06176604422033537, 'word': 'system'},\n",
              "   {'score': 0.06171964953519102, 'word': 'related'},\n",
              "   {'score': 0.06171964953519102, 'word': 'objects'},\n",
              "   {'score': 0.05641604473587261, 'word': 'similarity'},\n",
              "   {'score': 0.03709479888852059, 'word': 'information'},\n",
              "   {'score': 0.03709479888852059, 'word': 'units'},\n",
              "   {'score': 0.036455585205851716, 'word': 'approaches'}],\n",
              "  'Title': 'Visualizing information on a sphere',\n",
              "  'distance': 0,\n",
              "  'no': '893',\n",
              "  'parent': '4855'},\n",
              " {'Abstract': 'Splatting is a popular direct volume rendering algorithm. However, the algorithm does not correctly render cases where the volume sampling rate is higher than the image sampling rate (e.g. more than one voxel maps into a pixel). This situation arises with orthographic projections of high-resolution volumes, as well as with perspective projections of volumes of any resolution. The result is potentially severe spatial and temporal aliasing artifacts. Some volume ray-casting algorithms avoid these artifacts by employing reconstruction kernels which vary in width as the rays diverge. Unlike ray-casting algorithms, existing splatting algorithms do not have an equivalent mechanism for avoiding these artifacts. The authors propose such a mechanism, which delivers high-quality splatted images and has the potential for a very efficient hardware implementation.',\n",
              "  'AuthorKeywords': ['volume',\n",
              "   'rendering,',\n",
              "   'splatting,',\n",
              "   'direct',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'resampling,',\n",
              "   'reconstruction,',\n",
              "   'anti-aliasing,',\n",
              "   'perspective',\n",
              "   'projection'],\n",
              "  'MultipartiteRank': [{'score': 0.13013284670997227, 'word': 'volume'},\n",
              "   {'score': 0.09672266623092, 'word': 'algorithm'},\n",
              "   {'score': 0.07323307881417439, 'word': 'popular'},\n",
              "   {'score': 0.07323307881417439, 'word': 'direct'},\n",
              "   {'score': 0.06274606795156636, 'word': 'temporal'},\n",
              "   {'score': 0.06274606795156636, 'word': 'aliasing'},\n",
              "   {'score': 0.06274606795156636, 'word': 'artifacts'},\n",
              "   {'score': 0.056899767895797884, 'word': 'ray'},\n",
              "   {'score': 0.04352727697983079, 'word': 'orthographic'},\n",
              "   {'score': 0.04352727697983079, 'word': 'projections'}],\n",
              "  'Title': 'An anti-aliasing technique for splatting',\n",
              "  'distance': 0,\n",
              "  'no': '894',\n",
              "  'parent': '4095'},\n",
              " {'Abstract': 'The author proposes a simple and powerful graphical interface tool called the LensBar for filtering and visualizing large lists of data. Browsing and querying are the most important tasks in retrieving information and LensBar integrates the two techniques into a simple scroll window with slider. While it looks familiar to users of conventional graphical interface tools, its filtering and zooming features offer sophisticated handling of large lists of textual data.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09300541402197732, 'word': 'powerful'},\n",
              "   {'score': 0.09300541402197732, 'word': 'graphical'},\n",
              "   {'score': 0.09300541402197732, 'word': 'interface'},\n",
              "   {'score': 0.09300541402197732, 'word': 'tool'},\n",
              "   {'score': 0.09064749612904927, 'word': 'simple'},\n",
              "   {'score': 0.07875309805621682, 'word': 'lensbar'},\n",
              "   {'score': 0.07832601262770952, 'word': 'large'},\n",
              "   {'score': 0.07832601262770952, 'word': 'lists'},\n",
              "   {'score': 0.07202800687203696, 'word': 'data'}],\n",
              "  'Title': 'LensBar-visualization for browsing and filtering large lists of data',\n",
              "  'distance': 0,\n",
              "  'no': '895',\n",
              "  'parent': '3454'},\n",
              " {'Abstract': 'Time series are an important type of data with applications in virtually every aspect of the real world. Often a large number of time series have to be monitored and analyzed in parallel. Sets of time series may show intrinsic hierarchical relationships and varying degrees of importance among the individual time series. Effective techniques for visually analyzing large sets of time series should encode the relative importance and hierarchical ordering of the time series data by size and position, and should also provide a high degree of regularity in order to support comparability by the analyst. In this paper, we present a framework for visualizing large sets of time series. Based on the notion of inter time series importance relationships, we define a set of objective functions that space-filling layout schemes for time series data should obey. We develop an efficient algorithm addressing the identified problems by generating layouts that reflect hierarchy and importance based relationships in a regular layout with favorable aspect ratios. We apply our technique to a number of real world data sets including sales and stock data, and we compare our technique with an aspect ratio aware variant of the well known TreeMap algorithm. The examples show the advantages and practical usefulness of our layout algorithm.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'Visualization,',\n",
              "   'Time',\n",
              "   'Series,',\n",
              "   'Space-Filling',\n",
              "   'Layout',\n",
              "   'Generation'],\n",
              "  'MultipartiteRank': [{'score': 0.15814795023362274, 'word': 'time'},\n",
              "   {'score': 0.15814795023362274, 'word': 'series'},\n",
              "   {'score': 0.06293875266535896, 'word': 'important'},\n",
              "   {'score': 0.06293875266535896, 'word': 'type'},\n",
              "   {'score': 0.05705065228569989, 'word': 'sets'},\n",
              "   {'score': 0.03479496589066902, 'word': 'data'},\n",
              "   {'score': 0.03207462488663823, 'word': 'aspect'}],\n",
              "  'Title': 'Importance-driven visualization layouts for large time series data',\n",
              "  'distance': 0,\n",
              "  'no': '896',\n",
              "  'parent': '5594'},\n",
              " {'Abstract': \"Intelligence analysis often involves the task of gathering information about an organization. Knowledge about individuals in an organization and their relationships, often represented as a hierarchical organization chart, is crucial for understanding the organization. However, it is difficult for intelligence analysts to follow all individuals in an organization. Existing hierarchy visualizations have largely focused on the visualization of fixed structures and can not effectively depict the evolution of a hierarchy over time. We introduce TimeTree, a novel visualization tool designed to enable exploration of a changing hierarchy. TimeTree enables analysts to navigate the history of an organization, identify events associated with a specific entity (visualized on a TimeSlider), and explore an aggregate view of an individual's career path (a CareerTree). We demonstrate the utility of TimeTree by investigating a set of scenarios developed by an expert intelligence analyst. The scenarios are evaluated using a real dataset composed of eighteen thousand career events from more than eight thousand individuals. Insights gained from this analysis are presented\",\n",
              "  'AuthorKeywords': ['TimeTree,',\n",
              "   'DOI',\n",
              "   'Tree,',\n",
              "   'tree',\n",
              "   'visualization,organizational',\n",
              "   'chart,',\n",
              "   'timeseries',\n",
              "   'data,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.10531632922827162, 'word': 'organization'},\n",
              "   {'score': 0.07241949196372037, 'word': 'individuals'},\n",
              "   {'score': 0.055889677848376056, 'word': 'hierarchy'},\n",
              "   {'score': 0.055889677848376056, 'word': 'visualizations'},\n",
              "   {'score': 0.05490432546418904, 'word': 'intelligence'},\n",
              "   {'score': 0.05490432546418904, 'word': 'analysts'},\n",
              "   {'score': 0.0504672874887107, 'word': 'timetree'}],\n",
              "  'Title': 'Time Tree: Exploring Time Changing Hierarchies',\n",
              "  'distance': 0,\n",
              "  'no': '897',\n",
              "  'parent': '4258'},\n",
              " {'Abstract': 'In this paper, we show that histograms represent spatial function distributions with a nearest neighbour interpolation. We confirm that this results in systematic underrepresentation of transitional features of the data, and provide new insight why this occurs. We further show that isosurface statistics, which use higher quality interpolation, give better representations of the function distribution. We also use our experimentally collected isosurface statistics to resolve some questions as to the formal complexity of isosurfaces',\n",
              "  'AuthorKeywords': ['histograms,',\n",
              "   'isosurfaces,',\n",
              "   'isosurface',\n",
              "   'statistics'],\n",
              "  'MultipartiteRank': [{'score': 0.1254501256064339, 'word': 'spatial'},\n",
              "   {'score': 0.1254501256064339, 'word': 'function'},\n",
              "   {'score': 0.1254501256064339, 'word': 'distributions'},\n",
              "   {'score': 0.10655396185050531, 'word': 'isosurface'},\n",
              "   {'score': 0.10655396185050531, 'word': 'statistics'},\n",
              "   {'score': 0.08071405309595714, 'word': 'histograms'},\n",
              "   {'score': 0.07555919769041475, 'word': 'transitional'},\n",
              "   {'score': 0.07555919769041475, 'word': 'features'},\n",
              "   {'score': 0.06936714603045979, 'word': 'nearest'},\n",
              "   {'score': 0.06936714603045979, 'word': 'neighbour'},\n",
              "   {'score': 0.06936714603045979, 'word': 'interpolation'}],\n",
              "  'Title': 'On Histograms and Isosurface Statistics',\n",
              "  'distance': 0,\n",
              "  'no': '898',\n",
              "  'parent': '3660'},\n",
              " {'Abstract': 'Hardware-accelerated volume rendering using the GPU is now the standard approach for real-time volume rendering, although limited graphics memory can present a problem when rendering large volume data sets. Volumetric compression in which the decompression is coupled to rendering has been shown to be an effective solution to this problem; however, most existing techniques were developed in the context of software volume rendering, and all but the simplest approaches are prohibitive in a real-time hardware-accelerated volume rendering context. In this paper we present a novel block-based transform coding scheme designed specifically with real-time volume rendering in mind, such that the decompression is fast without sacrificing compression quality. This is made possible by consolidating the inverse transform with dequantization in such a way as to allow most of the reprojection to be precomputed. Furthermore, we take advantage of the freedom afforded by offline compression in order to optimize the encoding as much as possible while hiding this complexity from the decoder. In this context we develop a new block classification scheme which allows us to preserve perceptually important features in the compression. The result of this work is an asymmetric transform coding scheme that allows very large volumes to be compressed and then decompressed in real-time while rendering on the GPU.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Compression,',\n",
              "   'Compressed',\n",
              "   'Volume',\n",
              "   'Rendering,',\n",
              "   'Transform',\n",
              "   'Coding,',\n",
              "   'Hardware-accelerated',\n",
              "   'Volume',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.11515895533676969, 'word': 'volume'},\n",
              "   {'score': 0.06254851404020624, 'word': 'real'},\n",
              "   {'score': 0.04993359659815622, 'word': 'volumetric'},\n",
              "   {'score': 0.04993359659815622, 'word': 'compression'},\n",
              "   {'score': 0.03934156342193205, 'word': 'standard'},\n",
              "   {'score': 0.03934156342193205, 'word': 'approach'},\n",
              "   {'score': 0.03766073651851774, 'word': 'gpu'}],\n",
              "  'Title': 'Transform Coding for Hardware-accelerated Volume Rendering',\n",
              "  'distance': 0,\n",
              "  'no': '899',\n",
              "  'parent': '4926'},\n",
              " {'Abstract': 'Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.',\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'tensor,',\n",
              "   'probabilistic',\n",
              "   'fiber',\n",
              "   'tracking,',\n",
              "   'tensor',\n",
              "   'topology,',\n",
              "   'uncertainty',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.10686713033614778, 'word': 'topological'},\n",
              "   {'score': 0.10686713033614778, 'word': 'methods'},\n",
              "   {'score': 0.08123452686309289, 'word': 'expressive'},\n",
              "   {'score': 0.08123452686309289, 'word': 'visual'},\n",
              "   {'score': 0.08123452686309289, 'word': 'representations'},\n",
              "   {'score': 0.056732191201427654, 'word': 'flow'},\n",
              "   {'score': 0.056732191201427654, 'word': 'fields'},\n",
              "   {'score': 0.0547737105618903, 'word': 'concise'},\n",
              "   {'score': 0.048466791735722214, 'word': 'human'},\n",
              "   {'score': 0.048466791735722214, 'word': 'brain'},\n",
              "   {'score': 0.048466791735722214, 'word': 'diffusion'},\n",
              "   {'score': 0.048466791735722214, 'word': 'mri'},\n",
              "   {'score': 0.048466791735722214, 'word': 'data'}],\n",
              "  'Title': 'Topological Visualization of Brain Diffusion MRI Data',\n",
              "  'distance': 0,\n",
              "  'no': '900',\n",
              "  'parent': '5182'},\n",
              " {'Abstract': \"This paper describes a method for constructing isosurface triangulations of sampled, volumetric, three-dimensional scalar fields. The resulting meshes consist of triangles that are of consistently high quality, making them well suited for accurate interpolation of scalar and vector-valued quantities, as required for numerous applications in visualization and numerical simulation. The proposed method does not rely on a local construction or adjustment of triangles as is done, for instance, in advancing wavefront or adaptive refinement methods. Instead, a system of dynamic particles optimally samples an implicit function such that the particles' relative positions can produce a topologically correct Delaunay triangulation. Thus, the proposed method relies on a global placement of triangle vertices. The main contributions of the paper are the integration of dynamic particles systems with surface sampling theory and PDE-based methods for controlling the local variability of particle densities, as well as detailing a practical method that accommodates Delaunay sampling requirements to generate sparse sets of points for the production of high-quality tessellations.\",\n",
              "  'AuthorKeywords': ['Isosurface',\n",
              "   'extraction,',\n",
              "   'particle',\n",
              "   'systems,',\n",
              "   'Delaunay',\n",
              "   'triangulation'],\n",
              "  'MultipartiteRank': [{'score': 0.08180638396588517, 'word': 'method'},\n",
              "   {'score': 0.05089917453306289, 'word': 'triangles'},\n",
              "   {'score': 0.0506982612071362, 'word': 'dynamic'},\n",
              "   {'score': 0.0506982612071362, 'word': 'particles'},\n",
              "   {'score': 0.049939592481452216, 'word': 'sampled'},\n",
              "   {'score': 0.04205810569017251, 'word': 'dimensional'},\n",
              "   {'score': 0.04205810569017251, 'word': 'scalar'},\n",
              "   {'score': 0.04205810569017251, 'word': 'fields'}],\n",
              "  'Title': 'Topology, Accuracy, and Quality of Isosurface Meshes Using Dynamic Particles',\n",
              "  'distance': 0,\n",
              "  'no': '901',\n",
              "  'parent': '4592'},\n",
              " {'Abstract': \"Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.\",\n",
              "  'AuthorKeywords': ['Color',\n",
              "   'Calibration,',\n",
              "   'Multi-Projector',\n",
              "   'Displays,',\n",
              "   'Tiled',\n",
              "   'Displays'],\n",
              "  'MultipartiteRank': [{'score': 0.08314192321627505, 'word': 'variation'},\n",
              "   {'score': 0.08090588881237398, 'word': 'projectors'},\n",
              "   {'score': 0.0655680391389763, 'word': '3d'},\n",
              "   {'score': 0.0655680391389763, 'word': 'color'},\n",
              "   {'score': 0.0655680391389763, 'word': 'gamut'},\n",
              "   {'score': 0.053699805872578735, 'word': 'significant'},\n",
              "   {'score': 0.053699805872578735, 'word': 'spatial'},\n",
              "   {'score': 0.034533342081951066, 'word': 'entire'},\n",
              "   {'score': 0.034533342081951066, 'word': 'display'}],\n",
              "  'Title': 'Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing',\n",
              "  'distance': 0,\n",
              "  'no': '902',\n",
              "  'parent': '5498'},\n",
              " {'Abstract': 'We present a new algorithm to explore and visualize multivariate time-varying data sets. We identify important trend relationships among the variables based on how the values of the variables change over time and how those changes are related to each other in different spatial regions and time intervals. The trend relationships can be used to describe the correlation and causal effects among the different variables. To identify the temporal trends from a local region, we design a new algorithm called SUBDTW to estimate when a trend appears and vanishes in a given time series. Based on the beginning and ending times of the trends, their temporal relationships can be modeled as a state machine representing the trend sequence. Since a scientific data set usually contains millions of data points, we propose an algorithm to extract important trend relationships in linear time complexity. We design novel user interfaces to explore the trend relationships, to visualize their temporal characteristics, and to display their spatial distributions. We use several scientific data sets to test our algorithm and demonstrate its utilities.',\n",
              "  'AuthorKeywords': ['SUBDTW,',\n",
              "   'trend',\n",
              "   'sequence,',\n",
              "   'trend',\n",
              "   'sequence',\n",
              "   'clustering'],\n",
              "  'MultipartiteRank': [{'score': 0.12234438495864565, 'word': 'important'},\n",
              "   {'score': 0.12234438495864565, 'word': 'trend'},\n",
              "   {'score': 0.12234438495864565, 'word': 'relationships'},\n",
              "   {'score': 0.11204314516529428, 'word': 'multivariate'},\n",
              "   {'score': 0.11204314516529428, 'word': 'time'},\n",
              "   {'score': 0.07651467623044651, 'word': 'data'},\n",
              "   {'score': 0.07651467623044651, 'word': 'sets'},\n",
              "   {'score': 0.0733864291210333, 'word': 'new'},\n",
              "   {'score': 0.0733864291210333, 'word': 'algorithm'},\n",
              "   {'score': 0.06150389134456898, 'word': 'variables'}],\n",
              "  'Title': 'Visualization and Exploration of Temporal Trend Relationships in Multivariate Time-Varying Data',\n",
              "  'distance': 0,\n",
              "  'no': '903',\n",
              "  'parent': '4997'},\n",
              " {'Abstract': 'Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09706271821152263, 'word': 'modern'},\n",
              "   {'score': 0.09706271821152263, 'word': 'visualization'},\n",
              "   {'score': 0.09706271821152263, 'word': 'methods'},\n",
              "   {'score': 0.06672770611693189, 'word': 'dimensional'},\n",
              "   {'score': 0.06672770611693189, 'word': 'data'},\n",
              "   {'score': 0.05582129709746068, 'word': 'efficient'},\n",
              "   {'score': 0.05582129709746068, 'word': 'visual'},\n",
              "   {'score': 0.05582129709746068, 'word': 'analytical'},\n",
              "   {'score': 0.05582129709746068, 'word': 'techniques'},\n",
              "   {'score': 0.04905759203948874, 'word': 'different'},\n",
              "   {'score': 0.04905759203948874, 'word': 'quality'},\n",
              "   {'score': 0.04905759203948874, 'word': 'measures'},\n",
              "   {'score': 0.046073065742718265, 'word': 'large'},\n",
              "   {'score': 0.046073065742718265, 'word': 'number'}],\n",
              "  'Title': 'Improving the visual analysis of high-dimensional datasets using quality measures',\n",
              "  'distance': 0,\n",
              "  'no': '904',\n",
              "  'parent': '4156'},\n",
              " {'Abstract': 'The massive amount of financial time series data that originates from the stock market generates large amounts of complex data of high interest. However, adequate solutions that can effectively handle the information in order to gain insight and to understand the market mechanisms are rare. In this paper, we present two techniques and applications that enable the user to interactively analyze large amounts of time series data in real-time in order to get insight into the development of assets, market sectors, countries, and the financial market as a whole. The first technique allows users to quickly analyze combinations of single assets, market sectors as well as countries, compare them to each other, and to visually discover the periods of time where market sectors and countries get into turbulence. The second application clusters a selection of large amounts of financial time series data according to their similarity, and analyzes the distribution of the assets among market sectors. This allows users to identify the characteristic graphs which are representative for the development of a particular market sector, and also to identify the assets which behave considerably differently compared to other assets in the same sector. Both applications allow the user to perform investigative exploration techniques and interactive visual analysis in real-time.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics,',\n",
              "   'financial',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Time',\n",
              "   'Series',\n",
              "   'Data,',\n",
              "   'Time',\n",
              "   'Series',\n",
              "   'Clustering,',\n",
              "   'Explorative',\n",
              "   'Analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.12709165203013417, 'word': 'market'},\n",
              "   {'score': 0.10028508346558923, 'word': 'massive'},\n",
              "   {'score': 0.10028508346558923, 'word': 'amount'},\n",
              "   {'score': 0.09666676961978146, 'word': 'financial'},\n",
              "   {'score': 0.09666676961978146, 'word': 'time'},\n",
              "   {'score': 0.09666676961978146, 'word': 'series'},\n",
              "   {'score': 0.09666676961978146, 'word': 'data'},\n",
              "   {'score': 0.08896034983758344, 'word': 'stock'},\n",
              "   {'score': 0.049969355263456694, 'word': 'large'},\n",
              "   {'score': 0.049969355263456694, 'word': 'amounts'},\n",
              "   {'score': 0.038131302192550724, 'word': 'sectors'}],\n",
              "  'Title': 'Visual market sector analysis for financial time series data',\n",
              "  'distance': 0,\n",
              "  'no': '905',\n",
              "  'parent': '5448'},\n",
              " {'Abstract': \"The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.\",\n",
              "  'AuthorKeywords': ['Dynamic',\n",
              "   'graph',\n",
              "   'data,',\n",
              "   'multiform',\n",
              "   'visualization,',\n",
              "   'multi-focus+context'],\n",
              "  'MultipartiteRank': [{'score': 0.07628350202784355, 'word': 'large'},\n",
              "   {'score': 0.07628350202784355, 'word': 'dynamic'},\n",
              "   {'score': 0.07628350202784355, 'word': 'networks'},\n",
              "   {'score': 0.07493527192260052, 'word': 'visualization'},\n",
              "   {'score': 0.05810570775309833, 'word': 'analysis'},\n",
              "   {'score': 0.03755654466602523, 'word': 'single'},\n",
              "   {'score': 0.037378727256575296, 'word': 'techniques'},\n",
              "   {'score': 0.036529894332533744, 'word': 'dense'},\n",
              "   {'score': 0.036529894332533744, 'word': 'structure'}],\n",
              "  'Title': 'In Situ Exploration of Large Dynamic Networks',\n",
              "  'distance': 0,\n",
              "  'no': '906',\n",
              "  'parent': '5921'},\n",
              " {'Abstract': \"The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.\",\n",
              "  'AuthorKeywords': ['Performance',\n",
              "   'analysis,',\n",
              "   'network',\n",
              "   'traffic',\n",
              "   'visualization,',\n",
              "   'projected',\n",
              "   'graph',\n",
              "   'layouts'],\n",
              "  'MultipartiteRank': [{'score': 0.08615515264489952, 'word': 'network'},\n",
              "   {'score': 0.05730808255077333, 'word': 'views'},\n",
              "   {'score': 0.051650048086186985, 'word': 'parallel'},\n",
              "   {'score': 0.051650048086186985, 'word': 'applications'},\n",
              "   {'score': 0.04444347951347684, 'word': 'complexity'},\n",
              "   {'score': 0.03446953588037996, 'word': 'performance'}],\n",
              "  'Title': 'Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations',\n",
              "  'distance': 0,\n",
              "  'no': '907',\n",
              "  'parent': '4525'},\n",
              " {'Abstract': 'Data selection is a fundamental task in visualization because it serves as a pre-requisite to many follow-up interactions. Efficient spatial selection in 3D point cloud datasets consisting of thousands or millions of particles can be particularly challenging. We present two new techniques, TeddySelection and CloudLasso, that support the selection of subsets in large particle 3D datasets in an interactive and visually intuitive manner. Specifically, we describe how to spatially select a subset of a 3D particle cloud by simply encircling the target particles on screen using either the mouse or direct-touch input. Based on the drawn lasso, our techniques automatically determine a bounding selection surface around the encircled particles based on their density. This kind of selection technique can be applied to particle datasets in several application domains. TeddySelection and CloudLasso reduce, and in some cases even eliminate, the need for complex multi-step selection processes involving Boolean operations. This was confirmed in a formal, controlled user study in which we compared the more flexible CloudLasso technique to the standard cylinder-based selection technique. This study showed that the former is consistently more efficient than the latter - in several cases the CloudLasso selection time was half that of the corresponding cylinder-based selection.',\n",
              "  'AuthorKeywords': ['3D',\n",
              "   'interaction,',\n",
              "   'spatial',\n",
              "   'selection,',\n",
              "   'direct-touch',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.13836698038881518, 'word': 'data'},\n",
              "   {'score': 0.13836698038881518, 'word': 'selection'},\n",
              "   {'score': 0.06586385823674092, 'word': 'particles'},\n",
              "   {'score': 0.04969379491363661, 'word': 'fundamental'},\n",
              "   {'score': 0.04969379491363661, 'word': 'task'},\n",
              "   {'score': 0.037796025710232446, 'word': 'interactions'},\n",
              "   {'score': 0.03669761587688785, 'word': 'visualization'}],\n",
              "  'Title': 'Efficient Structure-Aware Selection Techniques for 3D Point Cloud Visualizations with 2DOF Input',\n",
              "  'distance': 0,\n",
              "  'no': '908',\n",
              "  'parent': '4874'},\n",
              " {'Abstract': 'Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'exploration,',\n",
              "   'volume',\n",
              "   'classification,',\n",
              "   'normalized',\n",
              "   'cut,',\n",
              "   'Information-guided',\n",
              "   'exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.12479386663717262, 'word': 'visual'},\n",
              "   {'score': 0.12479386663717262, 'word': 'exploration'},\n",
              "   {'score': 0.08576981306189928, 'word': 'volumetric'},\n",
              "   {'score': 0.08576981306189928, 'word': 'datasets'},\n",
              "   {'score': 0.05956622831887791, 'word': 'gradient'},\n",
              "   {'score': 0.05956622831887791, 'word': '2d'},\n",
              "   {'score': 0.05956622831887791, 'word': 'histogram'},\n",
              "   {'score': 0.04345356649841223, 'word': 'spatial'},\n",
              "   {'score': 0.04345356649841223, 'word': 'structures'},\n",
              "   {'score': 0.042682410172208154, 'word': 'features'}],\n",
              "  'Title': 'Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms',\n",
              "  'distance': 0,\n",
              "  'no': '909',\n",
              "  'parent': '3749'},\n",
              " {'Abstract': \"Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.\",\n",
              "  'AuthorKeywords': ['Physical',\n",
              "   'Visualizations,',\n",
              "   'Activity',\n",
              "   'Sculptures,',\n",
              "   'Physical',\n",
              "   'Activity,',\n",
              "   'Data',\n",
              "   'Sculptures,',\n",
              "   'Behavioral',\n",
              "   'Change'],\n",
              "  'MultipartiteRank': [{'score': 0.17148975763450677, 'word': 'sculptures'},\n",
              "   {'score': 0.11928033231897651, 'word': 'data'},\n",
              "   {'score': 0.09479089920985011, 'word': 'activity'},\n",
              "   {'score': 0.06930011490382249, 'word': 'visualizations'},\n",
              "   {'score': 0.047571075280258134, 'word': 'designers'},\n",
              "   {'score': 0.04258147389431985, 'word': 'running'}],\n",
              "  'Title': 'Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity',\n",
              "  'distance': 0,\n",
              "  'no': '910',\n",
              "  'parent': '4944'},\n",
              " {'Abstract': 'The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies.',\n",
              "  'AuthorKeywords': ['Computational',\n",
              "   'topology,',\n",
              "   'event',\n",
              "   'detection,',\n",
              "   'spatio-temporal',\n",
              "   'index,',\n",
              "   'urban',\n",
              "   'data,',\n",
              "   'visual',\n",
              "   'exploration'],\n",
              "  'MultipartiteRank': [{'score': 0.08760252363157196, 'word': 'data'},\n",
              "   {'score': 0.04520517305595957, 'word': 'event'},\n",
              "   {'score': 0.03966794390328769, 'word': 'cities'},\n",
              "   {'score': 0.0385995469987376, 'word': 'time'},\n",
              "   {'score': 0.035031868350673484, 'word': 'manual'},\n",
              "   {'score': 0.035031868350673484, 'word': 'exploration'}],\n",
              "  'Title': 'Using Topological Analysis to Support Event-Guided Exploration in Urban Data',\n",
              "  'distance': 0,\n",
              "  'no': '911',\n",
              "  'parent': '5192'},\n",
              " {'Abstract': 'Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'temporal',\n",
              "   'queries,',\n",
              "   'cohort',\n",
              "   'definition,',\n",
              "   'electronic',\n",
              "   'medical',\n",
              "   'records,',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.11271167894883789, 'word': 'many'},\n",
              "   {'score': 0.11271167894883789, 'word': 'researchers'},\n",
              "   {'score': 0.10763611612879558, 'word': 'cohorts'},\n",
              "   {'score': 0.07078917863295822, 'word': 'large'},\n",
              "   {'score': 0.07078917863295822, 'word': 'event'},\n",
              "   {'score': 0.07078917863295822, 'word': 'databases'},\n",
              "   {'score': 0.06268788441717957, 'word': 'behavior'},\n",
              "   {'score': 0.05860939011987197, 'word': 'coquito'}],\n",
              "  'Title': 'Supporting Iterative Cohort Construction with Visual Temporal Queries',\n",
              "  'distance': 0,\n",
              "  'no': '912',\n",
              "  'parent': '3861'},\n",
              " {'Abstract': \"Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.\",\n",
              "  'AuthorKeywords': ['Egocentric',\n",
              "   'network,',\n",
              "   'dynamic',\n",
              "   'graph,',\n",
              "   'network',\n",
              "   'visualization,',\n",
              "   'glyph-based',\n",
              "   'design,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.1479600843043479, 'word': 'ego'},\n",
              "   {'score': 0.12552171254844577, 'word': 'network'},\n",
              "   {'score': 0.03777657293337145, 'word': 'social'},\n",
              "   {'score': 0.03777657293337145, 'word': 'analysis'},\n",
              "   {'score': 0.03593748738662309, 'word': 'evolutionary'},\n",
              "   {'score': 0.03593748738662309, 'word': 'patterns'},\n",
              "   {'score': 0.03197286414867404, 'word': 'alters'}],\n",
              "  'Title': 'egoSlider: Visual Analysis of Egocentric Network Evolution',\n",
              "  'distance': 0,\n",
              "  'no': '913',\n",
              "  'parent': '3955'},\n",
              " {'Abstract': 'In this work a new method for visualization of three-dimensional turbulent flow using particle motion animation is presented. The method is based on Reynolds decomposition of a turbulent flow field into a convective and a turbulent motion. At each step of particle path generation a stochastic perturbation is added, resulting in random-walk motions of particles. A physical relation is established between the perturbations and the eddy-diffusivity, which is calculated in a turbulent flow simulation. The flow data used is a mean velocity field, and an eddy-diffusivity field. The erratic particle motions are more than just a visual effect, but represent a real physical phenomenon. An implementation of the method is described, and an example of a turbulent channel flow is given, which clearly shows the random particle motions in their context of general fluid motion patterns.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1405316237478914, 'word': 'turbulent'},\n",
              "   {'score': 0.13103781438161083, 'word': 'motion'},\n",
              "   {'score': 0.09346928242437655, 'word': 'dimensional'},\n",
              "   {'score': 0.09346928242437655, 'word': 'flow'},\n",
              "   {'score': 0.08737052673957689, 'word': 'new'},\n",
              "   {'score': 0.08737052673957689, 'word': 'method'},\n",
              "   {'score': 0.08397547305809598, 'word': 'particle'},\n",
              "   {'score': 0.08397547305809598, 'word': 'animation'},\n",
              "   {'score': 0.060066123286320855, 'word': 'visualization'}],\n",
              "  'Title': 'Visualization of turbulent flow with particles',\n",
              "  'distance': 0,\n",
              "  'no': '914',\n",
              "  'parent': '4108'},\n",
              " {'Abstract': \"The World-Wide-Web (WWW) has created a new paradigm for online information retrieval by providing immediate and ubiquitous access to digital information of any type from data repositories located throughout the world. The web's development enables not only effective access for the generic user but also more efficient and timely information exchange among scientists and researchers. We have extended the capabilities of the web to include access to three-dimensional volume data sets with integrated control of a distributed client-server volume visualization system. This paper provides a brief background on the World-Wide-Web, an overview of the extensions necessary to support these new data types and a description of an implementation of this approach in a WWW-compliant distributed visualization system.&lt;&lt;ETX&gt;&gt;\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08269464017267475, 'word': 'web'},\n",
              "   {'score': 0.07044706859204963, 'word': 'ubiquitous'},\n",
              "   {'score': 0.07044706859204963, 'word': 'access'},\n",
              "   {'score': 0.060209566106018575, 'word': 'world'},\n",
              "   {'score': 0.047437666863838594, 'word': 'type'},\n",
              "   {'score': 0.04415727230443566, 'word': 'wide'}],\n",
              "  'Title': 'Integrated control of distributed volume visualization through the World-Wide-Web',\n",
              "  'distance': 0,\n",
              "  'no': '915',\n",
              "  'parent': '3830'},\n",
              " {'Abstract': 'As the use of 3D information presentation becomes more prevalent, the need for effective viewing tools grows accordingly. Much work has been done in developing tools for 2D spaces which allow for detail in context views. We examine the extension of such 2D methods to 3D and explore the limitations encountered in accessing internal regions of the data with these methods. We then describe a novel solution to this problem of internal access with the introduction of a distortion function which creates a clear line of sight to the focus revealing sections previously obscured. The distortion is symmetric about the line of sight and is smoothly integrated back into the original 3D layout.',\n",
              "  'AuthorKeywords': ['distortion',\n",
              "   'viewing,',\n",
              "   'screen',\n",
              "   'layout,',\n",
              "   '3D',\n",
              "   'interaction,',\n",
              "   'information',\n",
              "   'visualization,',\n",
              "   'interface',\n",
              "   'metaphors,',\n",
              "   'interface',\n",
              "   'design',\n",
              "   'issues'],\n",
              "  'MultipartiteRank': [{'score': 0.06157913837630682, 'word': 'internal'},\n",
              "   {'score': 0.06157913837630682, 'word': 'regions'},\n",
              "   {'score': 0.05876839457198896, 'word': 'effective'},\n",
              "   {'score': 0.05876839457198896, 'word': 'viewing'},\n",
              "   {'score': 0.05876839457198896, 'word': 'tools'},\n",
              "   {'score': 0.056801756314643785, 'word': 'sight'},\n",
              "   {'score': 0.05610263928494063, 'word': 'clear'},\n",
              "   {'score': 0.05610263928494063, 'word': 'line'},\n",
              "   {'score': 0.05565843436074091, 'word': 'distortion'},\n",
              "   {'score': 0.05565843436074091, 'word': 'function'}],\n",
              "  'Title': 'Distortion viewing techniques for 3-dimensional data',\n",
              "  'distance': 0,\n",
              "  'no': '916',\n",
              "  'parent': '3794'},\n",
              " {'Abstract': 'Many techniques have been developed for visualizing multivariate (multidimensional) data. Most, if not all, are limited by the number of dimensions which can be effectively displayed. Multidimensional scaling (MDS) is an iterative non-linear technique for projecting n-D data down to a lower number of dimensions. This work presents extensions to MDS that enhance visualization of high-dimensional data sets. These extensions include animation, stochastic perturbation, and flow visualization techniques.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.10563228547608826,\n",
              "    'word': 'multidimensional'},\n",
              "   {'score': 0.1030444020099717, 'word': 'data'},\n",
              "   {'score': 0.08478500012896319, 'word': 'dimensions'},\n",
              "   {'score': 0.07882702545188798, 'word': 'extensions'},\n",
              "   {'score': 0.07569050633362157, 'word': 'mds'}],\n",
              "  'Title': 'Animating multidimensional scaling to visualize N-dimensional data sets',\n",
              "  'distance': 0,\n",
              "  'no': '917',\n",
              "  'parent': '3365'},\n",
              " {'Abstract': 'Volumetric data sets require enormous storage capacity even at moderate resolution levels. The excessive storage demands not only stress the capacity of the underlying storage and communications systems, but also seriously limit the speed of volume rendering due to data movement and manipulation. A novel volumetric data visualization scheme is proposed and implemented in this work that renders 2D images directly from compressed 3D data sets. The novelty of this algorithm is that rendering is performed on the compressed representation of the volumetric data without pre-decompression. As a result, the overheads associated with both data movement and rendering processing are significantly reduced. The proposed algorithm generalizes previously proposed whole-volume frequency-domain rendering schemes by first dividing the 3D data set into subcubes, transforming each subcube to a frequency-domain representation, and applying the Fourier projection theorem to produce the projected 2D images according to given viewing angles. Compared to the whole-volume approach, the subcube-based scheme not only achieves higher compression efficiency by exploiting local coherency, but also improves the quality of resultant rendering images because it approximates the occlusion effect on a subcube by subcube basis.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Compression,',\n",
              "   'Fourier',\n",
              "   'Projection',\n",
              "   'Theorem,',\n",
              "   'Discrete',\n",
              "   'Hartley',\n",
              "   'Transform,',\n",
              "   'Image',\n",
              "   'Compositing'],\n",
              "  'MultipartiteRank': [{'score': 0.18299010630789508, 'word': 'volumetric'},\n",
              "   {'score': 0.18299010630789508, 'word': 'data'},\n",
              "   {'score': 0.18299010630789508, 'word': 'sets'},\n",
              "   {'score': 0.14281809059201298, 'word': 'storage'},\n",
              "   {'score': 0.09386645069755965, 'word': 'enormous'},\n",
              "   {'score': 0.09386645069755965, 'word': 'capacity'},\n",
              "   {'score': 0.04895163989445332, 'word': 'excessive'},\n",
              "   {'score': 0.04413281255925467, 'word': 'moderate'},\n",
              "   {'score': 0.04413281255925467, 'word': 'resolution'},\n",
              "   {'score': 0.04413281255925467, 'word': 'levels'},\n",
              "   {'score': 0.03770745145493945, 'word': 'subcubes'}],\n",
              "  'Title': 'Integrated volume compression and visualization',\n",
              "  'distance': 0,\n",
              "  'no': '918',\n",
              "  'parent': '4118'},\n",
              " {'Abstract': 'Remote experience of sporting events has thus far been limited mostly to watching video and the scores and statistics associated with the sport. However, a fast-developing trend is the use of visualization techniques to give new insights into performance, style, and strategy of the players. Automated techniques can extract accurate information from video about player performance that not even the most skilled observer is able to discern. When presented as static images or as a three-dimensional virtual replay, this information makes viewing a game an entirely new and exciting experience. This paper presents one such sports visualization system called LucentVision, which has been developed for the sport of tennis. LucentVision uses real-time video analysis to obtain motion trajectories of players and the ball, and offers a rich set of visualization options based on this trajectory data. The system has been used extensively in the broadcast of international tennis tournaments, both on television and the Internet.',\n",
              "  'AuthorKeywords': ['sports',\n",
              "   'visualization,',\n",
              "   'virtual',\n",
              "   'environment,',\n",
              "   'telepresence,',\n",
              "   'real-time',\n",
              "   'video',\n",
              "   'analysis,',\n",
              "   'multi-camera',\n",
              "   'tracking,',\n",
              "   'multimedia',\n",
              "   'indexing'],\n",
              "  'MultipartiteRank': [{'score': 0.05970492867800732, 'word': 'video'},\n",
              "   {'score': 0.052200863540471855, 'word': 'remote'},\n",
              "   {'score': 0.052200863540471855, 'word': 'experience'},\n",
              "   {'score': 0.051595217586716306, 'word': 'performance'},\n",
              "   {'score': 0.04979045315963227, 'word': 'visualization'},\n",
              "   {'score': 0.04979045315963227, 'word': 'techniques'},\n",
              "   {'score': 0.04643957673761174, 'word': 'new'},\n",
              "   {'score': 0.04643957673761174, 'word': 'insights'}],\n",
              "  'Title': 'Visualization of Sports using Motion Trajectories: Providing Insights into Performance, Style, and Strategy',\n",
              "  'distance': 0,\n",
              "  'no': '919',\n",
              "  'parent': '4495'},\n",
              " {'Abstract': \"The bioactivity of a molecule strongly depends on its metastable conformational shapes and the transitions between these. Therefore, conformation analysis and visualization is a basic prerequisite for the understanding of biochemical processes. We present techniques for visual analysis of metastable molecular conformations. Core of these are flexibly applicable methods for alignment of molecular geometries, as well as methods for depicting shape and 'fuzziness' of metastable conformations. All analysis tools are provided in an integrated working environment. The described techniques are demonstrated with pharmaceutically active biomolecules.\",\n",
              "  'AuthorKeywords': ['uncertainty',\n",
              "   'visualization,',\n",
              "   'molecular',\n",
              "   'conformation',\n",
              "   'analysis,',\n",
              "   'molecular',\n",
              "   'modeling,',\n",
              "   'drug',\n",
              "   'design'],\n",
              "  'MultipartiteRank': [{'score': 0.10063924950626348, 'word': 'metastable'},\n",
              "   {'score': 0.10063924950626348, 'word': 'conformational'},\n",
              "   {'score': 0.10063924950626348, 'word': 'shapes'},\n",
              "   {'score': 0.08599124743728798, 'word': 'visualization'},\n",
              "   {'score': 0.07344539037033991, 'word': 'conformation'},\n",
              "   {'score': 0.07344539037033991, 'word': 'analysis'},\n",
              "   {'score': 0.056922507290071186, 'word': 'applicable'},\n",
              "   {'score': 0.056922507290071186, 'word': 'methods'},\n",
              "   {'score': 0.05382047946231379, 'word': 'techniques'}],\n",
              "  'Title': 'Visualizing dynamic molecular conformations',\n",
              "  'distance': 0,\n",
              "  'no': '920',\n",
              "  'parent': '3433'},\n",
              " {'Abstract': 'This is the first part (summary) of a three-part contest entry submitted to IEEE InfoVis 2004. The contest topic is visualizing InfoVis symposium papers from 1995 to 2002 and their references. The paper introduces the visualization tool IN-SPIRE, the visualization process and results, and presents lessons learned.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.2181598358100763, 'word': 'infovis'},\n",
              "   {'score': 0.12968378063765204, 'word': 'symposium'},\n",
              "   {'score': 0.12968378063765204, 'word': 'papers'},\n",
              "   {'score': 0.09796474848286335, 'word': 'contest'},\n",
              "   {'score': 0.09796474848286335, 'word': 'topic'},\n",
              "   {'score': 0.09080456689726271, 'word': 'visualization'},\n",
              "   {'score': 0.09080456689726271, 'word': 'process'},\n",
              "   {'score': 0.08847605517242428, 'word': 'ieee'},\n",
              "   {'score': 0.08270182059252826, 'word': 'results'}],\n",
              "  'Title': 'IN-SPIRE InfoVis 2004 Contest Entry',\n",
              "  'distance': 0,\n",
              "  'no': '921',\n",
              "  'parent': '3327'},\n",
              " {'Abstract': 'Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items',\n",
              "  'AuthorKeywords': ['Multi-dimensional',\n",
              "   'visualization,',\n",
              "   'pixel-oriented,',\n",
              "   'multi-dimensional',\n",
              "   'scaling,',\n",
              "   'high',\n",
              "   'dimensional',\n",
              "   'datasets'],\n",
              "  'MultipartiteRank': [{'score': 0.07549383259718344, 'word': 'high'},\n",
              "   {'score': 0.07549383259718344, 'word': 'dimensional'},\n",
              "   {'score': 0.07549383259718344, 'word': 'datasets'},\n",
              "   {'score': 0.061567031895957344, 'word': 'dimensions'},\n",
              "   {'score': 0.055365296245802824, 'word': 'var'},\n",
              "   {'score': 0.05390709812990982, 'word': 'difficult'},\n",
              "   {'score': 0.05390709812990982, 'word': 'user'},\n",
              "   {'score': 0.05390709812990982, 'word': 'navigation'},\n",
              "   {'score': 0.04749504559510544, 'word': 'traditional'},\n",
              "   {'score': 0.04749504559510544, 'word': 'multidimensional'},\n",
              "   {'score': 0.04749504559510544, 'word': 'visualization'},\n",
              "   {'score': 0.04749504559510544, 'word': 'techniques'}],\n",
              "  'Title': 'Value and Relation Display for Interactive Exploration of High Dimensional Datasets',\n",
              "  'distance': 0,\n",
              "  'no': '922',\n",
              "  'parent': '5153'},\n",
              " {'Abstract': 'With the growing size of captured 3D models it has become increasingly important to provide basic efficient processing methods for large unorganized raw surface-sample point data sets. In this paper we introduce a novel stream-based (and out-of-core) point processing framework. The proposed approach processes points in an orderly sequential way by sorting them and sweeping along a spatial dimension. The major advantages of this new concept are: (1) support of extensible and concatenate local operators called stream operators, (2) low main-memory usage and (3) applicability to process very large data sets out-of-core.',\n",
              "  'AuthorKeywords': ['point',\n",
              "   'processing,',\n",
              "   'sequential',\n",
              "   'processing,',\n",
              "   'normal',\n",
              "   'estimation,',\n",
              "   'curvature',\n",
              "   'estimation,',\n",
              "   'fairing'],\n",
              "  'MultipartiteRank': [{'score': 0.07356880043654783, 'word': 'point'},\n",
              "   {'score': 0.07356880043654783, 'word': 'processing'},\n",
              "   {'score': 0.07356880043654783, 'word': 'framework'},\n",
              "   {'score': 0.06274045038597903, 'word': 'local'},\n",
              "   {'score': 0.06274045038597903, 'word': 'operators'},\n",
              "   {'score': 0.06264844568427518, 'word': 'core'},\n",
              "   {'score': 0.050237200362762024, 'word': 'extensible'},\n",
              "   {'score': 0.046538835631645785, 'word': 'approach'}],\n",
              "  'Title': 'Stream-processing points',\n",
              "  'distance': 0,\n",
              "  'no': '923',\n",
              "  'parent': '3846'},\n",
              " {'Abstract': 'We present a new approach for the visual analysis of state transition graphs. We deal with multivariate graphs where a number of attributes are associated with every node. Our method provides an interactive attribute-based clustering facility. Clustering results in metric, hierarchical and relational data, represented in a single visualization. To visualize hierarchically structured quantitative data, we introduce a novel technique: the bar tree. We combine this with a node-link diagram to visualize the hierarchy and an arc diagram to visualize relational data. Our method enables the user to gain significant insight into large state transition graphs containing tens of thousands of nodes. We illustrate the effectiveness of our approach by applying it to a real-world use case. The graph we consider models the behavior of an industrial wafer stepper and contains 55 043 nodes and 289 443 edges',\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'multivariate',\n",
              "   'visualization,',\n",
              "   'interactive',\n",
              "   'clustering,',\n",
              "   'state',\n",
              "   'spaces,',\n",
              "   'transition',\n",
              "   'systems,',\n",
              "   'finite',\n",
              "   'state',\n",
              "   'machines'],\n",
              "  'MultipartiteRank': [{'score': 0.10422326952374174, 'word': 'graphs'},\n",
              "   {'score': 0.0708857698425822, 'word': 'node'},\n",
              "   {'score': 0.057998098679308455, 'word': 'state'},\n",
              "   {'score': 0.057998098679308455, 'word': 'transition'},\n",
              "   {'score': 0.05503669497143844, 'word': 'visual'},\n",
              "   {'score': 0.05503669497143844, 'word': 'analysis'},\n",
              "   {'score': 0.05043446181405352, 'word': 'attributes'},\n",
              "   {'score': 0.04622517084443328, 'word': 'multivariate'}],\n",
              "  'Title': 'Visual Analysis of Multivariate State Transition Graphs',\n",
              "  'distance': 0,\n",
              "  'no': '924',\n",
              "  'parent': '3867'},\n",
              " {'Abstract': 'Our ability to generate ever-larger, increasingly-complex data, has established the need for scalable methods that identify, and provide insight into, important variable trends and interactions. Query-driven methods are among the small subset of techniques that are able to address both large and highly complex datasets. This paper presents a new method that increases the utility of query-driven techniques by visually conveying statistical information about the trends that exist between variables in a query. In this method, correlation fields, created between pairs of variables, are used with the cumulative distribution functions of variables expressed in a users query. This integrated use of cumulative distribution functions and correlation fields visually reveals, with respect to the solution space of the query, statistically important interactions between any three variables, and allows for trends between these variables to be readily identified. We demonstrate our method by analyzing interactions between variables in two flame-front simulations.',\n",
              "  'AuthorKeywords': ['Multivariate', 'Data,', 'Query-Driven', 'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.09141625353163613, 'word': 'scalable'},\n",
              "   {'score': 0.09141625353163613, 'word': 'methods'},\n",
              "   {'score': 0.08159850195708805, 'word': 'query'},\n",
              "   {'score': 0.07477663221135665, 'word': 'variables'},\n",
              "   {'score': 0.056196584318127504, 'word': 'important'},\n",
              "   {'score': 0.056196584318127504, 'word': 'variable'},\n",
              "   {'score': 0.056196584318127504, 'word': 'trends'},\n",
              "   {'score': 0.05606170209787972, 'word': 'interactions'}],\n",
              "  'Title': 'Variable Interactions in Query-Driven Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '925',\n",
              "  'parent': '4474'},\n",
              " {'Abstract': 'Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The VAST 2008 Challenge is the third year that such a competition was held in conjunction with the IEEE Visual Analytics Science and Technology (VAST) symposium. The authors restructured the contest format used in 2006 and 2007 to reduce the barriers to participation and offered four mini-challenges and a Grand Challenge. Mini Challenge participants were to use visual analytic tools to explore one of four heterogeneous data collections to analyze specific activities of a fictitious, controversial movement. Questions asked in the Grand Challenge required the participants to synthesize data from all four data sets. In this paper we give a brief overview of the data sets, the tasks, the participation, the judging, and the results.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.1457409922451027, 'word': 'visual'},\n",
              "   {'score': 0.1457409922451027, 'word': 'analytics'},\n",
              "   {'score': 0.1457409922451027, 'word': 'experts'},\n",
              "   {'score': 0.05534822290392776, 'word': 'participation'},\n",
              "   {'score': 0.053655475115310804, 'word': 'challenge'},\n",
              "   {'score': 0.04979339065184135, 'word': 'heterogeneous'},\n",
              "   {'score': 0.04979339065184135, 'word': 'data'},\n",
              "   {'score': 0.04979339065184135, 'word': 'collections'},\n",
              "   {'score': 0.048498395197947144, 'word': 'vast'}],\n",
              "  'Title': 'VAST 2008 Challenge: Introducing mini-challenges',\n",
              "  'distance': 0,\n",
              "  'no': '926',\n",
              "  'parent': '3659'},\n",
              " {'Abstract': 'This paper presents a novel method for interactive exploration of industrial CT volumes such as cast metal parts, with the goal of interactively detecting, classifying, and quantifying features using a visualization-driven approach. The standard approach for defect detection builds on region growing, which requires manually tuning parameters such as target ranges for density and size, variance, as well as the specification of seed points. If the results are not satisfactory, region growing must be performed again with different parameters. In contrast, our method allows interactive exploration of the parameter space, completely separated from region growing in an unattended pre-processing stage. The pre-computed feature volume tracks a feature size curve for each voxel over time, which is identified with the main region growing parameter such as variance. A novel 3D transfer function domain over (density, feature.size, time) allows for interactive exploration of feature classes. Features and feature size curves can also be explored individually, which helps with transfer function specification and allows coloring individual features and disabling features resulting from CT artifacts. Based on the classification obtained through exploration, the classified features can be quantified immediately.',\n",
              "  'AuthorKeywords': ['Non-Destructive',\n",
              "   'Testing,',\n",
              "   'Multi-Dimensional',\n",
              "   'Transfer',\n",
              "   'Functions,',\n",
              "   'Region',\n",
              "   'Growing,',\n",
              "   'Volume',\n",
              "   'Rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.06655934596502763, 'word': 'quantifying'},\n",
              "   {'score': 0.06655934596502763, 'word': 'features'},\n",
              "   {'score': 0.06478076703654136, 'word': 'interactive'},\n",
              "   {'score': 0.06478076703654136, 'word': 'exploration'},\n",
              "   {'score': 0.06333299466170483, 'word': 'region'},\n",
              "   {'score': 0.06333299466170483, 'word': 'growing'},\n",
              "   {'score': 0.04850431732791455, 'word': 'size'},\n",
              "   {'score': 0.046524347879540254, 'word': 'approach'}],\n",
              "  'Title': 'Interactive Volume Exploration for Feature Detection and Quantification in Industrial CT Data',\n",
              "  'distance': 0,\n",
              "  'no': '927',\n",
              "  'parent': '5576'},\n",
              " {'Abstract': 'These current studies explored the impact of individual differences in personality factors on interface interaction and learning performance behaviors in both an interactive visualization and a menu-driven web table in two studies. Participants were administered 3 psychometric measures designed to assess Locus of Control, Extraversion, and Neuroticism. Participants were then asked to complete multiple procedural learning tasks in each interface. Results demonstrated that all three measures predicted completion times. Additionally, results analyses demonstrated personality factors also predicted the number of insights participants reported while completing the tasks in each interface. We discuss how these findings advance our ongoing research in the Personal Equation of Interaction.',\n",
              "  'AuthorKeywords': ['visual',\n",
              "   'analytics,',\n",
              "   'cognition',\n",
              "   'and',\n",
              "   'perception',\n",
              "   'theory,',\n",
              "   'embodied',\n",
              "   'cognition,',\n",
              "   'visualization',\n",
              "   'taxonomies',\n",
              "   'and',\n",
              "   'models'],\n",
              "  'MultipartiteRank': [{'score': 0.07531965201151475, 'word': 'personality'},\n",
              "   {'score': 0.07531965201151475, 'word': 'factors'},\n",
              "   {'score': 0.07122105672197009, 'word': 'interface'},\n",
              "   {'score': 0.07122105672197009, 'word': 'interaction'},\n",
              "   {'score': 0.06807499862744743, 'word': 'current'},\n",
              "   {'score': 0.06807499862744743, 'word': 'studies'},\n",
              "   {'score': 0.06766128421140044, 'word': 'participants'},\n",
              "   {'score': 0.04619658367279591, 'word': 'psychometric'},\n",
              "   {'score': 0.04619658367279591, 'word': 'measures'}],\n",
              "  'Title': 'Towards the Personal Equation of Interaction: The impact of personality factors on visual analytics interface interaction',\n",
              "  'distance': 0,\n",
              "  'no': '928',\n",
              "  'parent': '4665'},\n",
              " {'Abstract': 'Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case studies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.',\n",
              "  'AuthorKeywords': ['Ornithology,',\n",
              "   'species',\n",
              "   'distribution',\n",
              "   'models,',\n",
              "   'multiscale',\n",
              "   'analysis,',\n",
              "   'spatial',\n",
              "   'data,',\n",
              "   'temporal',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.06323621307649784, 'word': 'birds'},\n",
              "   {'score': 0.03366930935485565, 'word': 'ecological'},\n",
              "   {'score': 0.03366930935485565, 'word': 'well'},\n",
              "   {'score': 0.02930837262891653, 'word': 'species'},\n",
              "   {'score': 0.02930837262891653, 'word': 'distributions'},\n",
              "   {'score': 0.026081374597865865, 'word': 'unrivaled'},\n",
              "   {'score': 0.026081374597865865, 'word': 'windows'},\n",
              "   {'score': 0.023223832163098396, 'word': 'birdvis'}],\n",
              "  'Title': 'BirdVis: Visualizing and Understanding Bird Populations',\n",
              "  'distance': 0,\n",
              "  'no': '929',\n",
              "  'parent': '5248'},\n",
              " {'Abstract': 'Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.',\n",
              "  'AuthorKeywords': ['Inhomogeneous',\n",
              "   'data,',\n",
              "   'multiple',\n",
              "   'coordinated',\n",
              "   'views,',\n",
              "   'multiform',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.1435225920437621, 'word': 'data'},\n",
              "   {'score': 0.1033871183739088, 'word': 'world'},\n",
              "   {'score': 0.058072114132671424, 'word': 'visualization'},\n",
              "   {'score': 0.05290216068380302, 'word': 'visbricks'},\n",
              "   {'score': 0.049695226333029974, 'word': 'inhomogeneities'}],\n",
              "  'Title': 'VisBricks: Multiform Visualization of Large, Inhomogeneous Data',\n",
              "  'distance': 0,\n",
              "  'no': '930',\n",
              "  'parent': '4111'},\n",
              " {'Abstract': 'Because of the ever increasing size of output data from scientific simulations, supercomputers are increasingly relied upon to generate visualizations. One use of supercomputers is to generate field lines from large scale flow fields. When generating field lines in parallel, the vector field is generally decomposed into blocks, which are then assigned to processors. Since various regions of the vector field can have different flow complexity, processors will require varying amounts of computation time to trace their particles, causing load imbalance, and thus limiting the performance speedup. To achieve load-balanced streamline generation, we propose a workload-aware partitioning algorithm to decompose the vector field into partitions with near equal workloads. Since actual workloads are unknown beforehand, we propose a workload estimation algorithm to predict the workload in the local vector field. A graph-based representation of the vector field is employed to generate these estimates. Once the workloads have been estimated, our partitioning algorithm is hierarchically applied to distribute the workload to all partitions. We examine the performance of our workload estimation and workload-aware partitioning algorithm in several timings studies, which demonstrates that by employing these methods, better scalability can be achieved with little overhead.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'visualization,',\n",
              "   'Parallel',\n",
              "   'processing,',\n",
              "   '3D',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'visualization,',\n",
              "   'Streamlines'],\n",
              "  'MultipartiteRank': [{'score': 0.14989505917375967, 'word': 'field'},\n",
              "   {'score': 0.09958836831478514, 'word': 'lines'},\n",
              "   {'score': 0.08302310271578758, 'word': 'workload'},\n",
              "   {'score': 0.06124772171061986, 'word': 'aware'},\n",
              "   {'score': 0.06124772171061986, 'word': 'partitioning'},\n",
              "   {'score': 0.06124772171061986, 'word': 'algorithm'},\n",
              "   {'score': 0.050306690858974525, 'word': 'vector'},\n",
              "   {'score': 0.03963443621154297, 'word': 'supercomputers'}],\n",
              "  'Title': 'Load-Balanced Parallel Streamline Generation on Large Scale Vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '931',\n",
              "  'parent': '5025'},\n",
              " {'Abstract': 'We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.',\n",
              "  'AuthorKeywords': ['Just-in-time',\n",
              "   'descriptive',\n",
              "   'analytics,',\n",
              "   'feature',\n",
              "   'identification',\n",
              "   'and',\n",
              "   'characterization,',\n",
              "   'point-based',\n",
              "   'visualizations'],\n",
              "  'MultipartiteRank': [{'score': 0.07214727503989843,\n",
              "    'word': 'visualizations'},\n",
              "   {'score': 0.06997747208583238, 'word': 'users'},\n",
              "   {'score': 0.058461583728325994, 'word': 'time'},\n",
              "   {'score': 0.058461583728325994, 'word': 'descriptive'},\n",
              "   {'score': 0.058461583728325994, 'word': 'analytics'},\n",
              "   {'score': 0.049925928093095505, 'word': 'data'},\n",
              "   {'score': 0.042516734247900805, 'word': 'computational'}],\n",
              "  'Title': 'Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '932',\n",
              "  'parent': '5325'},\n",
              " {'Abstract': \"The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants' actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring.\",\n",
              "  'AuthorKeywords': ['Constructive',\n",
              "   'visualization,',\n",
              "   'Physical',\n",
              "   'visualization,',\n",
              "   'Dynamic',\n",
              "   'visualization,',\n",
              "   'Empirical',\n",
              "   'study,',\n",
              "   'Token,',\n",
              "   'Visualization',\n",
              "   'authoring,',\n",
              "   'Information',\n",
              "   'visualization,',\n",
              "   'Visual',\n",
              "   'mapping,',\n",
              "   'Novices,',\n",
              "   'Visualization',\n",
              "   'construction,',\n",
              "   'Visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.1117693520396116, 'word': 'visual'},\n",
              "   {'score': 0.1117693520396116, 'word': 'mappings'},\n",
              "   {'score': 0.08054334364111601, 'word': 'infovis'},\n",
              "   {'score': 0.06285512429844099, 'word': 'people'},\n",
              "   {'score': 0.05700107666943793, 'word': 'tools'},\n",
              "   {'score': 0.04894412460631284, 'word': 'development'}],\n",
              "  'Title': 'Constructing Visual Representations: Investigating the Use of Tangible Tokens',\n",
              "  'distance': 0,\n",
              "  'no': '933',\n",
              "  'parent': '3994'},\n",
              " {'Abstract': 'An efficient algorithm is presented for computing particle paths, streak lines and time lines in time-dependent flows with moving curvilinear grids. The integration, velocity interpolation, and step size control are all performed in physical space which avoids the need to transform the velocity field into computational space. This leads to higher accuracy because there are no Jacobian matrix approximations, and expensive matrix inversions are eliminated. Integration accuracy is maintained using an adaptive step size control scheme which is regulated by the path line curvature. The problem of point location and interpolation in physical space is simplified by decomposing hexahedral cells into tetrahedral cells. This enables the point location to be done analytically and substantially faster than with a Newton-Raphson iterative method. Results presented show this algorithm is up to six times faster than particle tracers which operate on hexahedral cells, and produces almost identical traces.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07686998892115689, 'word': 'time'},\n",
              "   {'score': 0.07686998892115689, 'word': 'lines'},\n",
              "   {'score': 0.06285861330331469, 'word': 'physical'},\n",
              "   {'score': 0.06285861330331469, 'word': 'space'},\n",
              "   {'score': 0.060668070648761736, 'word': 'velocity'},\n",
              "   {'score': 0.060668070648761736, 'word': 'interpolation'},\n",
              "   {'score': 0.05370961604326055, 'word': 'integration'},\n",
              "   {'score': 0.051525746818338845, 'word': 'particle'},\n",
              "   {'score': 0.051525746818338845, 'word': 'paths'}],\n",
              "  'Title': 'Optimization of time-dependent particle tracing using tetrahedral decomposition',\n",
              "  'distance': 0,\n",
              "  'no': '934',\n",
              "  'parent': '3959'},\n",
              " {'Abstract': 'Visualization of CFD data for turbomachinery design poses some special requirements which are often not addressed by standard flow visualization systems. The authors discuss the issues involved with this particular application and its requirements with respect to flow visualization. Aiming at a feature-based visualization for this task, they examine various existing techniques to locate vortices. The specific flow conditions for turbomachines demonstrate limitations of current methods. Visualization of turbomachinery flow thus raises some challenges and research topics, particularly regarding feature extraction.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.12082039183473071, 'word': 'visualization'},\n",
              "   {'score': 0.07898610739100817, 'word': 'turbomachinery'},\n",
              "   {'score': 0.07898610739100817, 'word': 'design'},\n",
              "   {'score': 0.07069990696699162, 'word': 'special'},\n",
              "   {'score': 0.07069990696699162, 'word': 'requirements'},\n",
              "   {'score': 0.04834194967691019, 'word': 'feature'},\n",
              "   {'score': 0.048165914926209016, 'word': 'cfd'},\n",
              "   {'score': 0.048165914926209016, 'word': 'data'}],\n",
              "  'Title': 'Flow visualization for turbomachinery design',\n",
              "  'distance': 0,\n",
              "  'no': '935',\n",
              "  'parent': '3729'},\n",
              " {'Abstract': 'The paper describes time management and time critical computing for a near real time interactive unsteady visualization environment. Subtle issues regarding the flow of time are described, formalized and addressed. The resulting system correctly reflects time behavior while allowing the user to control the flow of time. The problem of time critical computation is discussed and a solution is presented. These time critical algorithms provide control over the frame rate of a visualization system, allowing interactive exploration.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.276426480294899, 'word': 'time'},\n",
              "   {'score': 0.2236518205101277, 'word': 'management'},\n",
              "   {'score': 0.13160490357548335, 'word': 'paper'},\n",
              "   {'score': 0.08467519722657192, 'word': 'flow'},\n",
              "   {'score': 0.06500232299323916, 'word': 'system'}],\n",
              "  'Title': 'Time management, simultaneity and time-critical computation in interactive unsteady visualization environments',\n",
              "  'distance': 0,\n",
              "  'no': '936',\n",
              "  'parent': '3638'},\n",
              " {'Abstract': 'A method of lossless compression using wavelets is presented that enables progressive transmission of computational fluid dynamics (CFD) data in PLOT3D format. The floating point data is first converted to double-precision floating point format to maintain adequate precision throughout the transform process. It is then transformed using Haar wavelets-four times in two spatial dimensions, twice in the third spatial dimension, and twice in time for a total compression factor of 64 times. The double precision format will maintain enough precision during the transform to keep the process lossless. Next, the transformed data is compressed using Huffman coding and transmitted progressively using spectral selection. This allows most of the information to be transmitted in the first pass. Details are transmitted in later passes which ultimately provide for lossless reconstruction of the original data.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08197430584427468, 'word': 'data'},\n",
              "   {'score': 0.07555556507265387, 'word': 'lossless'},\n",
              "   {'score': 0.07555556507265387, 'word': 'compression'},\n",
              "   {'score': 0.062143411996646025, 'word': 'wavelets'},\n",
              "   {'score': 0.0564198334819313, 'word': 'times'},\n",
              "   {'score': 0.052369047730292564, 'word': 'precision'},\n",
              "   {'score': 0.052369047730292564, 'word': 'floating'},\n",
              "   {'score': 0.052369047730292564, 'word': 'point'},\n",
              "   {'score': 0.052369047730292564, 'word': 'format'}],\n",
              "  'Title': 'Wavelets applied to lossless compression and progressive transmission of floating point data in 3-D curvilinear grids',\n",
              "  'distance': 0,\n",
              "  'no': '937',\n",
              "  'parent': '4359'},\n",
              " {'Abstract': 'The paper introduces a tool for visualizing a multidimensional relevance space. Abstractly, the information to be displayed consists of a large number of objects, a set of features that are likely to be of interest to the user, and some function that measures the relevance level of every object to the various features. The goal is to provide the user with a concise and comprehensible visualization of that information. For the type of applications concentrated on, the exact relevance measures of the objects are not significant. This enables accuracy to be traded for a clearer display. The idea is to \"flatten\" the multidimensionality of the feature space into a 2D \"relevance map\", capturing the inter-relations among the features, without causing too many ambiguous interpretations of the results. To better reflect the nature of the data and to resolve the ambiguity the authors refine the given set of features and introduce the notion of composed features. The layout of the map is then obtained by grading it according to a set of rules and using a simulated annealing algorithm which optimizes the layout with respect to these rules. The technique proposed has been implemented and tested, in the context of visualizing the result of a Web search, in the RMAP (Relevance Map) prototype system.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.08170974796920677, 'word': 'features'},\n",
              "   {'score': 0.04879723983270133, 'word': 'set'},\n",
              "   {'score': 0.04596928192072955, 'word': 'objects'},\n",
              "   {'score': 0.04067646523044882, 'word': 'relevance'},\n",
              "   {'score': 0.04067646523044882, 'word': 'map'},\n",
              "   {'score': 0.03200634517516463, 'word': 'layout'}],\n",
              "  'Title': 'Displaying data in multidimensional relevance space with 2D visualization maps',\n",
              "  'distance': 0,\n",
              "  'no': '938',\n",
              "  'parent': '5080'},\n",
              " {'Abstract': 'In this paper we describe a battlefield visualization system, called Dragon, which we have implemented on a virtual reality responsive workbench. The Dragon system has been successfully deployed as part of two large military exercises: the Hunter Warrior advanced warfighting experiment, in March 1997, and the Joint Counter Mine advanced concept tactical demonstration, in August and September 1997. We describe battlefield visualization, the Dragon system, and the workbench, and we describe our experiences as part of these two real-world deployments, with an emphasis on lessons learned and needed future work.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.16918321319903737, 'word': 'dragon'},\n",
              "   {'score': 0.15472131588669116, 'word': 'system'},\n",
              "   {'score': 0.09429601422671413, 'word': 'battlefield'},\n",
              "   {'score': 0.09429601422671413, 'word': 'visualization'},\n",
              "   {'score': 0.07892068520897046, 'word': 'warfighting'},\n",
              "   {'score': 0.07892068520897046, 'word': 'experiment'},\n",
              "   {'score': 0.0721543204498882, 'word': 'part'}],\n",
              "  'Title': 'Battlefield visualization on the responsive workbench',\n",
              "  'distance': 0,\n",
              "  'no': '939',\n",
              "  'parent': '3500'},\n",
              " {'Abstract': 'Splatting is widely applied in many areas, including volume, point-based and image-based rendering. Improvements to splatting, such as eliminating popping and color bleeding, occasion-based acceleration, post-rendering classification and shading, have all been recently accomplished. These improvements share a common need for efficient frame-buffer accesses. We present an optimized software splatting package, using a newly designed primitive, called FastSplat, to scan-convert footprints. Our approach does not use texture mapping hardware, but supports the whole pipeline in memory. In such an integrated pipeline, we are then able to study the optimization strategies and address image quality issues. While this research is meant for a study of the inherent trade-off of splatting, our renderer, purely in software, achieves 3- to 5-fold speedups over a top-end texture hardware implementation (for opaque data sets). We further propose a method of efficient occlusion culling using a summed area table of opacity. 3D solid texturing and bump mapping capabilities are demonstrated to show the flexibility of such an integrated rendering pipeline. A detailed numerical error analysis, in addition to the performance and storage issues, is also presented. Our approach requires low storage and uses simple operations. Thus, it is easily implementable in hardware.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.044059883939213236, 'word': 'whole'},\n",
              "   {'score': 0.044059883939213236, 'word': 'pipeline'},\n",
              "   {'score': 0.040586083900229074, 'word': 'splatting'},\n",
              "   {'score': 0.039863786936058264, 'word': 'texture'},\n",
              "   {'score': 0.039863786936058264, 'word': 'mapping'},\n",
              "   {'score': 0.039863786936058264, 'word': 'hardware'},\n",
              "   {'score': 0.03239152161510445, 'word': 'improvements'},\n",
              "   {'score': 0.03215085573114878, 'word': 'rendering'}],\n",
              "  'Title': 'FastSplats: optimized splatting on rectilinear grids',\n",
              "  'distance': 0,\n",
              "  'no': '940',\n",
              "  'parent': '5173'},\n",
              " {'Abstract': \"This paper introduces an algorithm for rapid progressive simplification of tetrahedral meshes: TetFusion. We describe how a simple geometry decimation operation steers a rapid and controlled progressive simplification of tetrahedral meshes, while also taking care of complex mesh-inconsistency problems. The algorithm features a high decimation ratio per step, and inherently discourages any cases of self-intersection of boundary, element-boundary intersection at concave boundary-regions, and negative volume tetrahedra (flipping). We achieved rigorous reduction ratios of up to 98% for meshes consisting of 827,904 elements in less than 2 minutes, progressing through a series of level-of-details (LoDs) of the mesh in a controlled manner. We describe how the approach supports a balanced re-distribution of space between tetrahedral elements, and explain some useful control parameters that make it faster and more intuitive than 'edge collapse'-based decimation methods for volumetric meshes. Finally, we discuss how this approach can be employed for rapid LoD prototyping of large time-varying datasets as an aid to interactive visualization.\",\n",
              "  'AuthorKeywords': ['mesh',\n",
              "   'simplification,',\n",
              "   'multi',\n",
              "   'resolution,',\n",
              "   'level-of-detail,',\n",
              "   'unstructured',\n",
              "   'meshes'],\n",
              "  'MultipartiteRank': [{'score': 0.09362108092044473, 'word': 'tetrahedral'},\n",
              "   {'score': 0.09362108092044473, 'word': 'meshes'},\n",
              "   {'score': 0.052764573006840274, 'word': 'boundary'},\n",
              "   {'score': 0.052301783373651205, 'word': 'element'},\n",
              "   {'score': 0.05041577336027146, 'word': 'rapid'},\n",
              "   {'score': 0.05041577336027146, 'word': 'progressive'},\n",
              "   {'score': 0.05041577336027146, 'word': 'simplification'},\n",
              "   {'score': 0.04054916554058038, 'word': 'algorithm'}],\n",
              "  'Title': 'TetFusion: an algorithm for rapid tetrahedral mesh simplification',\n",
              "  'distance': 0,\n",
              "  'no': '941',\n",
              "  'parent': '4598'},\n",
              " {'Abstract': 'In this paper a novel volume-rendering technique based on Monte Carlo integration is presented. As a result of a preprocessing, a point cloud of random samples is generated using a normalized continuous reconstruction of the volume as a probability density function. This point cloud is projected onto the image plane, and to each pixel an intensity value is assigned which is proportional to the number of samples projected onto the corresponding pixel area. In such a way a simulated X-ray image of the volume can be obtained. Theoretically, for a fixed image resolution, there exists an M number of samples such that the average standard deviation of the estimated pixel intensities us under the level of quantization error regardless of the number of voxels. Therefore Monte Carlo Volume Rendering (MCVR) is mainly proposed to efficiently visualize large volume data sets. Furthermore, network applications are also supported, since the trade-off between image quality and interactivity can be adapted to the bandwidth of the client/server connection by using progressive refinement.',\n",
              "  'AuthorKeywords': ['X-ray',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'Monte',\n",
              "   'Carlo',\n",
              "   'integration,',\n",
              "   'importance',\n",
              "   'sampling,',\n",
              "   'progressive',\n",
              "   'refinement'],\n",
              "  'MultipartiteRank': [{'score': 0.07415339750819551, 'word': 'novel'},\n",
              "   {'score': 0.07415339750819551, 'word': 'volume'},\n",
              "   {'score': 0.05496250036632055, 'word': 'point'},\n",
              "   {'score': 0.05496250036632055, 'word': 'cloud'},\n",
              "   {'score': 0.05487610898902951, 'word': 'pixel'},\n",
              "   {'score': 0.050461130687079955, 'word': 'monte'},\n",
              "   {'score': 0.050461130687079955, 'word': 'carlo'},\n",
              "   {'score': 0.050461130687079955, 'word': 'integration'},\n",
              "   {'score': 0.04863993504034824, 'word': 'image'},\n",
              "   {'score': 0.04863993504034824, 'word': 'plane'}],\n",
              "  'Title': 'Monte Carlo volume rendering',\n",
              "  'distance': 0,\n",
              "  'no': '942',\n",
              "  'parent': '4314'},\n",
              " {'Abstract': 'Effective visualization of vector fields relies on the ability to control the size and density of the underlying mapping to visual cues used to represent the field. In this paper we introduce the use of a reaction-diffusion model, already well known for its ability to form irregular spatio-temporal patters, to control the size, density, and placement of the vector field representation. We demonstrate that it is possible to encode vector field information (orientation and magnitude) into the parameters governing a reaction-diffusion model to form a spot pattern with the correct orientation, size, and density, creating an effective visualization. To encode direction we texture the spots using a light to dark fading texture. We also show that it is possible to use the reaction-diffusion model to visualize an additional scalar value, such as the uncertainty in the orientation of the vector field. An additional benefit of the reaction-diffusion visualization technique arises from its automatic density distribution. This benefit suggests using the technique to augment other vector visualization techniques. We demonstrate this utility by augmenting a LIC visualization with a reaction-diffusion visualization. Finally, the reaction-diffusion visualization method provides a technique that can be used for streamline and glyph placement.',\n",
              "  'AuthorKeywords': ['Vector',\n",
              "   'Field',\n",
              "   'Visualization,',\n",
              "   'Flow',\n",
              "   'Visualization,',\n",
              "   'Reaction-Diffusion,',\n",
              "   'Vector',\n",
              "   'Fields'],\n",
              "  'MultipartiteRank': [{'score': 0.07926975427448554, 'word': 'effective'},\n",
              "   {'score': 0.07926975427448554, 'word': 'visualization'},\n",
              "   {'score': 0.07679891200480207, 'word': 'vector'},\n",
              "   {'score': 0.07679891200480207, 'word': 'fields'},\n",
              "   {'score': 0.07314664750918733, 'word': 'reaction'},\n",
              "   {'score': 0.06848087343384875, 'word': 'diffusion'},\n",
              "   {'score': 0.06848087343384875, 'word': 'model'},\n",
              "   {'score': 0.05400379620749494, 'word': 'density'}],\n",
              "  'Title': 'Display of vector fields using a reaction-diffusion model',\n",
              "  'distance': 0,\n",
              "  'no': '943',\n",
              "  'parent': '4915'},\n",
              " {'Abstract': \"The most common approach to support analysis of graphs with associated time series data include: overlay of data on graph vertices for one timepoint at a time by manipulating a visual property (e.g. color) of the vertex, along with sliders or some such mechanism to animate the graph for other timepoints. Alternatively, data from all the timepoints can be overlaid simultaneously by embedding small charts into graph vertices. These graph visualizations may also be linked to other visualizations (e.g., parallel co-ordinates) using brushing and linking. This paper describes a study performed to evaluate and rank graph+timeseries visualization options based on users' performance time and accuracy of responses on predefined tasks. The results suggest that overlaying data on graph vertices one timepoint at a time may lead to more accurate performance for tasks involving analysis of a graph at a single timepoint, and comparisons between graph vertices for two distinct timepoints. Overlaying data simultaneously for all the timepoints on graph vertices may lead to more accurate and faster performance for tasks involving searching for outlier vertices displaying different behavior than the rest of the graph vertices for all timepoints. Single views have advantage over multiple views on tasks that require topological information. Also, the number of attributes displayed on nodes has a non trivial influence on accuracy of responses, whereas the number of visualizations affect the performance time.\",\n",
              "  'AuthorKeywords': ['Graph',\n",
              "   'visualization,',\n",
              "   'data',\n",
              "   'overlay,',\n",
              "   'timeseries',\n",
              "   'data',\n",
              "   'analysis,',\n",
              "   'usability',\n",
              "   'experiments'],\n",
              "  'MultipartiteRank': [{'score': 0.10309626215931549, 'word': 'graphs'},\n",
              "   {'score': 0.07801735677212986, 'word': 'timepoint'},\n",
              "   {'score': 0.06250967886013878, 'word': 'graph'},\n",
              "   {'score': 0.06250967886013878, 'word': 'vertices'},\n",
              "   {'score': 0.0510004140100979, 'word': 'predefined'},\n",
              "   {'score': 0.0510004140100979, 'word': 'tasks'},\n",
              "   {'score': 0.046623918693807026, 'word': 'data'}],\n",
              "  'Title': 'Visualization of graphs with associated timeseries data',\n",
              "  'distance': 0,\n",
              "  'no': '944',\n",
              "  'parent': '6128'},\n",
              " {'Abstract': \"Understanding and analyzing complex volumetrically varying data is a difficult problem. Many computational visualization techniques have had only limited success in succinctly portraying the structure of three-dimensional turbulent flow. Motivated by both the extensive history and success of illustration and photographic flow visualization techniques, we have developed a new interactive volume rendering and visualization system for flows and volumes that simulates and enhances traditional illustration, experimental advection, and photographic flow visualization techniques. Our system uses a combination of varying focal and contextual illustrative styles, new advanced two-dimensional transfer functions, enhanced Schlieren and shadowgraphy shaders, and novel oriented structure enhancement techniques to allow interactive visualization, exploration, and comparative analysis of scalar, vector, and time-varying volume datasets. Both traditional illustration techniques and photographic flow visualization techniques effectively reduce visual clutter by using compact oriented structure information to convey three-dimensional structures. Therefore, a key to the effectiveness of our system is using one-dimensional (Schlieren and shadowgraphy) and two-dimensional (silhouette) oriented structural information to reduce visual clutter, while still providing enough three-dimensional structural information for the user's visual system to understand complex three-dimensional flow data. By combining these oriented feature visualization techniques with flexible transfer function controls, we can visualize scalar and vector data, allow comparative visualization of flow properties in a succinct, informative manner, and provide continuity for visualizing time-varying datasets.\",\n",
              "  'AuthorKeywords': ['interactive',\n",
              "   'volume',\n",
              "   'illustration,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'non-photorealistic',\n",
              "   'rendering,',\n",
              "   'photographic',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.10308832167194257, 'word': 'visualization'},\n",
              "   {'score': 0.06426657226847214, 'word': 'many'},\n",
              "   {'score': 0.06426657226847214, 'word': 'computational'},\n",
              "   {'score': 0.06426657226847214, 'word': 'techniques'},\n",
              "   {'score': 0.04715963429606282, 'word': 'illustration'},\n",
              "   {'score': 0.04448493743024588, 'word': 'structure'},\n",
              "   {'score': 0.03882174940347043, 'word': 'system'},\n",
              "   {'score': 0.03882138970547634, 'word': 'limited'},\n",
              "   {'score': 0.03882138970547634, 'word': 'success'}],\n",
              "  'Title': 'Illustration and photography inspired visualization of flows and volumes',\n",
              "  'distance': 0,\n",
              "  'no': '945',\n",
              "  'parent': '5369'},\n",
              " {'Abstract': 'Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events',\n",
              "  'AuthorKeywords': ['Video',\n",
              "   'visualization,',\n",
              "   'volume',\n",
              "   'visualization,',\n",
              "   'flow',\n",
              "   'visualization,',\n",
              "   'human',\n",
              "   'factors,',\n",
              "   'user',\n",
              "   'study,',\n",
              "   'visual',\n",
              "   'signatures,',\n",
              "   'video',\n",
              "   'processing,',\n",
              "   'optical',\n",
              "   'flow,',\n",
              "   'GPU',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.21735627369342692, 'word': 'visualization'},\n",
              "   {'score': 0.13111600175659327, 'word': 'video'},\n",
              "   {'score': 0.05192389161587379, 'word': 'user'},\n",
              "   {'score': 0.05192389161587379, 'word': 'study'},\n",
              "   {'score': 0.04262519420309914, 'word': 'users'},\n",
              "   {'score': 0.03928800536475264, 'word': 'flow'},\n",
              "   {'score': 0.03928800536475264, 'word': 'techniques'}],\n",
              "  'Title': 'Visual Signatures in Video Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '946',\n",
              "  'parent': '5635'},\n",
              " {'Abstract': 'Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.',\n",
              "  'AuthorKeywords': ['Data', 'integration,', 'RDF,', 'attribute', 'inference'],\n",
              "  'MultipartiteRank': [{'score': 0.12619696316700146, 'word': 'data'},\n",
              "   {'score': 0.09405954564177738, 'word': 'flexible'},\n",
              "   {'score': 0.09405954564177738, 'word': 'visualization'},\n",
              "   {'score': 0.04883196639298104, 'word': 'kind'},\n",
              "   {'score': 0.04793335646542573, 'word': 'systems'},\n",
              "   {'score': 0.04580094893183547, 'word': 'schema'}],\n",
              "  'Title': 'Visualization of Heterogeneous Data',\n",
              "  'distance': 0,\n",
              "  'no': '947',\n",
              "  'parent': '4023'},\n",
              " {'Abstract': \"Multiple spatially-related videos are increasingly used in security, communication, and other applications. Since it can be difficult to understand the spatial relationships between multiple videos in complex environments (e.g. to predict a person's path through a building), some visualization techniques, such as video texture projection, have been used to aid spatial understanding. In this paper, we identify and begin to characterize an overall class of visualization techniques that combine video with 3D spatial context. This set of techniques, which we call contextualized videos, forms a design palette which must be well understood so that designers can select and use appropriate techniques that address the requirements of particular spatial video tasks. In this paper, we first identify user tasks in video surveillance that are likely to benefit from contextualized videos and discuss the video, model, and navigation related dimensions of the contextualized video design space. We then describe our contextualized video testbed which allows us to explore this design space and compose various video visualizations for evaluation. Finally, we describe the results of our process to identify promising design patterns through user selection of visualization features from the design space, followed by user interviews.\",\n",
              "  'AuthorKeywords': ['situational',\n",
              "   'awareness,',\n",
              "   'videos,',\n",
              "   'virtual',\n",
              "   'environment',\n",
              "   'models,',\n",
              "   'design',\n",
              "   'space,',\n",
              "   'testbed',\n",
              "   'design',\n",
              "   'and',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.11981168765550608, 'word': 'videos'},\n",
              "   {'score': 0.06989000881820892, 'word': 'visualization'},\n",
              "   {'score': 0.06989000881820892, 'word': 'techniques'},\n",
              "   {'score': 0.061334735755597385, 'word': 'multiple'},\n",
              "   {'score': 0.055962947852903226, 'word': 'design'},\n",
              "   {'score': 0.055962947852903226, 'word': 'palette'},\n",
              "   {'score': 0.03489795368005372, 'word': 'user'},\n",
              "   {'score': 0.03489795368005372, 'word': 'tasks'}],\n",
              "  'Title': 'Contextualized Videos: Combining Videos with Environment Models to Support Situational Understanding',\n",
              "  'distance': 0,\n",
              "  'no': '948',\n",
              "  'parent': '5734'},\n",
              " {'Abstract': 'Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.',\n",
              "  'AuthorKeywords': ['Navigation,',\n",
              "   'interaction,',\n",
              "   'linked',\n",
              "   'views,',\n",
              "   'medical',\n",
              "   'visualization,',\n",
              "   'viewpoint',\n",
              "   'selection'],\n",
              "  'MultipartiteRank': [{'score': 0.07513791485549391, 'word': 'large'},\n",
              "   {'score': 0.07513791485549391, 'word': 'data'},\n",
              "   {'score': 0.07513791485549391, 'word': 'sets'},\n",
              "   {'score': 0.052759973215509036, 'word': 'slices'},\n",
              "   {'score': 0.04414805522647586, 'word': 'appropriate'},\n",
              "   {'score': 0.04414805522647586, 'word': 'viewpoint'},\n",
              "   {'score': 0.04302820152736915, 'word': 'volumetric'},\n",
              "   {'score': 0.04302820152736915, 'word': 'views'},\n",
              "   {'score': 0.032170176016065415, 'word': 'users'}],\n",
              "  'Title': 'LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation',\n",
              "  'distance': 0,\n",
              "  'no': '949',\n",
              "  'parent': '4815'},\n",
              " {'Abstract': 'This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.',\n",
              "  'AuthorKeywords': ['DECT',\n",
              "   'image',\n",
              "   'fusion,',\n",
              "   'local',\n",
              "   'surface',\n",
              "   'extraction,',\n",
              "   'Dual',\n",
              "   'Energy',\n",
              "   'CT,',\n",
              "   'metrology,',\n",
              "   'dimensional',\n",
              "   'measurement,',\n",
              "   'variance',\n",
              "   'comparison'],\n",
              "  'MultipartiteRank': [{'score': 0.04700611294798767, 'word': 'dimensional'},\n",
              "   {'score': 0.04700611294798767, 'word': 'measurement'},\n",
              "   {'score': 0.03944744043990969, 'word': 'image'},\n",
              "   {'score': 0.03944744043990969, 'word': 'fusion'},\n",
              "   {'score': 0.03348350312855481, 'word': 'surface'},\n",
              "   {'score': 0.03348350312855481, 'word': 'models'},\n",
              "   {'score': 0.032400826185488125, 'word': 'workflow'},\n",
              "   {'score': 0.03225987252329567, 'word': 'tomography'}],\n",
              "  'Title': 'Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT',\n",
              "  'distance': 0,\n",
              "  'no': '950',\n",
              "  'parent': '6378'},\n",
              " {'Abstract': 'The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.',\n",
              "  'AuthorKeywords': ['Direct',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'image',\n",
              "   'enhancement,',\n",
              "   'layer',\n",
              "   'perception'],\n",
              "  'MultipartiteRank': [{'score': 0.08950113036283151, 'word': 'images'},\n",
              "   {'score': 0.08282760722070161, 'word': 'visual'},\n",
              "   {'score': 0.08282760722070161, 'word': 'quality'},\n",
              "   {'score': 0.07560588529504138, 'word': 'layered'},\n",
              "   {'score': 0.07560588529504138, 'word': 'structures'},\n",
              "   {'score': 0.06955363117437736, 'word': 'direct'},\n",
              "   {'score': 0.06955363117437736, 'word': 'volume'},\n",
              "   {'score': 0.04800059340293755, 'word': 'layers'}],\n",
              "  'Title': 'Perception-Based Transparency Optimization for Direct Volume Rendering',\n",
              "  'distance': 0,\n",
              "  'no': '951',\n",
              "  'parent': '4305'},\n",
              " {'Abstract': 'Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains.',\n",
              "  'AuthorKeywords': ['Uncertainty,',\n",
              "   'Data',\n",
              "   'Transformations,',\n",
              "   'Principal',\n",
              "   'Component',\n",
              "   'Analysis,',\n",
              "   'Model',\n",
              "   'fitting'],\n",
              "  'MultipartiteRank': [{'score': 0.07119796976407673, 'word': 'data'},\n",
              "   {'score': 0.0644626162539886, 'word': 'scatterplots'},\n",
              "   {'score': 0.05030233474794429, 'word': 'number'},\n",
              "   {'score': 0.03992128519463095, 'word': 'variations'},\n",
              "   {'score': 0.03432724826821824, 'word': 'sensitivity'},\n",
              "   {'score': 0.03432724826821824, 'word': 'coefficients'}],\n",
              "  'Title': 'Flow-based scatterplots for sensitivity analysis',\n",
              "  'distance': 0,\n",
              "  'no': '952',\n",
              "  'parent': '4688'},\n",
              " {'Abstract': 'Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.',\n",
              "  'AuthorKeywords': ['cartography,',\n",
              "   'schematic',\n",
              "   'maps,',\n",
              "   'fish-eye',\n",
              "   'view,',\n",
              "   'graph',\n",
              "   'drawing,',\n",
              "   'optimization,',\n",
              "   'quadratic',\n",
              "   'programming'],\n",
              "  'MultipartiteRank': [{'score': 0.11127700356123904, 'word': 'maps'},\n",
              "   {'score': 0.0949264009950602, 'word': 'mobile'},\n",
              "   {'score': 0.0949264009950602, 'word': 'users'},\n",
              "   {'score': 0.04399699086100677, 'word': 'detailed'},\n",
              "   {'score': 0.04399699086100677, 'word': 'information'},\n",
              "   {'score': 0.03359868788454673, 'word': 'network'},\n",
              "   {'score': 0.03202316709963898, 'word': 'roads'},\n",
              "   {'score': 0.03202316709963898, 'word': 'relevant'}],\n",
              "  'Title': 'Drawing Road Networks with Focus Regions',\n",
              "  'distance': 0,\n",
              "  'no': '953',\n",
              "  'parent': '5136'},\n",
              " {'Abstract': 'This paper reports on a between-subject, comparative online study of three information visualization demonstrators that each displayed the same dataset by way of an identical scatterplot technique, yet were different in style in terms of visual and interactive embellishment. We validated stylistic adherence and integrity through a separate experiment in which a small cohort of participants assigned our three demonstrators to predefined groups of stylistic examples, after which they described the styles with their own words. From the online study, we discovered significant differences in how participants execute specific interaction operations, and the types of insights that followed from them. However, in spite of significant differences in apparent usability, enjoyability and usefulness between the style demonstrators, no variation was found on the self-reported depth, expert-rated depth, confidence or difficulty of the resulting insights. Three different methods of insight analysis have been applied, revealing how style impacts the creation of insights, ranging from higher-level pattern seeking to a more reflective and interpretative engagement with content, which is what underlies the patterns. As this study only forms the first step in determining how the impact of style in information visualization could be best evaluated, we propose several guidelines and tips on how to gather, compare and categorize insights through an online evaluation study, particularly in terms of analyzing the concise, yet wide variety of insights and observations in a trustworthy and reproducable manner.',\n",
              "  'AuthorKeywords': ['Visualization,',\n",
              "   'design,',\n",
              "   'style,',\n",
              "   'aesthetics,',\n",
              "   'evaluation,',\n",
              "   'online',\n",
              "   'study,',\n",
              "   'user',\n",
              "   'experience'],\n",
              "  'MultipartiteRank': [{'score': 0.05493479383509352, 'word': 'insights'},\n",
              "   {'score': 0.04975291906190356, 'word': 'comparative'},\n",
              "   {'score': 0.04975291906190356, 'word': 'online'},\n",
              "   {'score': 0.04975291906190356, 'word': 'study'},\n",
              "   {'score': 0.049670475209059185, 'word': 'style'},\n",
              "   {'score': 0.04916545572363777, 'word': 'different'},\n",
              "   {'score': 0.04630951605631206, 'word': 'information'},\n",
              "   {'score': 0.04630951605631206, 'word': 'visualization'},\n",
              "   {'score': 0.04630951605631206, 'word': 'demonstrators'}],\n",
              "  'Title': 'Evaluating the Effect of Style in Information Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '954',\n",
              "  'parent': '5190'},\n",
              " {'Abstract': 'Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.',\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'visual',\n",
              "   'analysis,',\n",
              "   'high-dimensional',\n",
              "   'data',\n",
              "   'analysis'],\n",
              "  'MultipartiteRank': [{'score': 0.10908705702692846, 'word': 'dimensions'},\n",
              "   {'score': 0.07843052642232412, 'word': 'visual'},\n",
              "   {'score': 0.07843052642232412, 'word': 'analysis'},\n",
              "   {'score': 0.057471970934150955, 'word': 'datasets'},\n",
              "   {'score': 0.04839325770027954, 'word': 'representative'},\n",
              "   {'score': 0.04839325770027954, 'word': 'factors'},\n",
              "   {'score': 0.03883073534626561, 'word': 'computational'}],\n",
              "  'Title': 'Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data',\n",
              "  'distance': 0,\n",
              "  'no': '955',\n",
              "  'parent': '4613'},\n",
              " {'Abstract': 'Data visualization has been used extensively to inform users. However, little research has been done to examine the effects of data visualization in influencing users or in making a message more persuasive. In this study, we present experimental research to fill this gap and present an evidence-based analysis of persuasive visualization. We built on persuasion research from psychology and user interfaces literature in order to explore the persuasive effects of visualization. In this experimental study we define the circumstances under which data visualization can make a message more persuasive, propose hypotheses, and perform quantitative and qualitative analyses on studies conducted to test these hypotheses. We compare visual treatments with data presented through barcharts and linecharts on the one hand, treatments with data presented through tables on the other, and then evaluate their persuasiveness. The findings represent a first step in exploring the effectiveness of persuasive visualization.',\n",
              "  'AuthorKeywords': ['Persuasive',\n",
              "   'visualization,',\n",
              "   'elaboration',\n",
              "   'likelihood',\n",
              "   'model,',\n",
              "   'evaluation'],\n",
              "  'MultipartiteRank': [{'score': 0.17997014031165226, 'word': 'visualization'},\n",
              "   {'score': 0.13722617587479466, 'word': 'persuasive'},\n",
              "   {'score': 0.11518626495528139, 'word': 'data'},\n",
              "   {'score': 0.0581390741235568, 'word': 'effects'},\n",
              "   {'score': 0.057709114343369214, 'word': 'users'}],\n",
              "  'Title': 'The Persuasive Power of Data Visualization',\n",
              "  'distance': 0,\n",
              "  'no': '956',\n",
              "  'parent': '4622'},\n",
              " {'Abstract': \"The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed.\",\n",
              "  'AuthorKeywords': ['Survey,',\n",
              "   'evaluation,',\n",
              "   'guidelines,',\n",
              "   'parallel',\n",
              "   'coordinates'],\n",
              "  'MultipartiteRank': [{'score': 0.06666487735089924, 'word': 'multivariate'},\n",
              "   {'score': 0.06666487735089924, 'word': 'data'},\n",
              "   {'score': 0.06552040666795078, 'word': 'parallel'},\n",
              "   {'score': 0.05336223243176817, 'word': 'technique'},\n",
              "   {'score': 0.05048698331057047, 'word': 'evaluations'},\n",
              "   {'score': 0.042845530893266204, 'word': 'usability'},\n",
              "   {'score': 0.042845530893266204, 'word': 'issues'}],\n",
              "  'Title': 'Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research',\n",
              "  'distance': 0,\n",
              "  'no': '957',\n",
              "  'parent': '4818'},\n",
              " {'Abstract': 'Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data.',\n",
              "  'AuthorKeywords': ['Convolutional',\n",
              "   'Neural',\n",
              "   'Networks,deep',\n",
              "   'learning,image',\n",
              "   'classification,large-scale',\n",
              "   'classification,confusion',\n",
              "   'matrix'],\n",
              "  'MultipartiteRank': [{'score': 0.09006095022231204, 'word': 'classes'},\n",
              "   {'score': 0.0782001550226546, 'word': 'cnns'},\n",
              "   {'score': 0.06232396964686282, 'word': 'convolutional'},\n",
              "   {'score': 0.06232396964686282, 'word': 'neural'},\n",
              "   {'score': 0.06232396964686282, 'word': 'networks'},\n",
              "   {'score': 0.05488513755052627, 'word': 'art'},\n",
              "   {'score': 0.05488513755052627, 'word': 'accuracy'},\n",
              "   {'score': 0.049402156209234854, 'word': 'confusion'},\n",
              "   {'score': 0.049402156209234854, 'word': 'increase'}],\n",
              "  'Title': 'Do Convolutional Neural Networks Learn Class Hierarchy?',\n",
              "  'distance': 0,\n",
              "  'no': '958',\n",
              "  'parent': '4780'},\n",
              " {'Abstract': 'Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.',\n",
              "  'AuthorKeywords': ['deep',\n",
              "   'learning,deep',\n",
              "   'generative',\n",
              "   'models,blue',\n",
              "   'noise',\n",
              "   'sampling,credit',\n",
              "   'assignment'],\n",
              "  'MultipartiteRank': [{'score': 0.1104150509469956, 'word': 'training'},\n",
              "   {'score': 0.0721865903854554, 'word': 'dgms'},\n",
              "   {'score': 0.05181981436540176, 'word': 'time'},\n",
              "   {'score': 0.05181981436540176, 'word': 'series'},\n",
              "   {'score': 0.05181981436540176, 'word': 'data'},\n",
              "   {'score': 0.047149809396011065, 'word': 'deep'},\n",
              "   {'score': 0.047149809396011065, 'word': 'models'},\n",
              "   {'score': 0.044294437299877164, 'word': 'visual'},\n",
              "   {'score': 0.044294437299877164, 'word': 'analytics'},\n",
              "   {'score': 0.044294437299877164, 'word': 'approach'}],\n",
              "  'Title': 'Analyzing the Training Processes of Deep Generative Models',\n",
              "  'distance': 0,\n",
              "  'no': '959',\n",
              "  'parent': '5198'},\n",
              " {'Abstract': 'A software architecture is presented to integrate a database management system with data visualization. One of its primary objectives, the retention of user-data interactions, is detailed. By storing all queries over the data along with high-level descriptions of the query results and the associated visualization, the processes by which a database is explored can be analyzed. This approach can lead to important contributions in the development of user models as \"data explorers\", metadata models for scientific databases, intelligent assistants and data exploration services. We describe the underlying elements of this approach, specifically the visual database exploration model and the metadata objects that support the model.',\n",
              "  'AuthorKeywords': ['visual',\n",
              "   'database',\n",
              "   'exploration,',\n",
              "   'database',\n",
              "   'visualization,',\n",
              "   'metadata,',\n",
              "   'user',\n",
              "   'modeling,',\n",
              "   'interaction'],\n",
              "  'MultipartiteRank': [{'score': 0.16870379226921317, 'word': 'data'},\n",
              "   {'score': 0.10283606743792813, 'word': 'interactions'},\n",
              "   {'score': 0.07570385943247332, 'word': 'database'},\n",
              "   {'score': 0.07570385943247332, 'word': 'management'},\n",
              "   {'score': 0.07570385943247332, 'word': 'system'},\n",
              "   {'score': 0.07336108079934016, 'word': 'user'},\n",
              "   {'score': 0.06586772483128504, 'word': 'visualization'},\n",
              "   {'score': 0.05431963739958946, 'word': 'queries'}],\n",
              "  'Title': 'An architecture for retaining and analyzing visual explorations of databases',\n",
              "  'distance': 0,\n",
              "  'no': '960',\n",
              "  'parent': '3447'},\n",
              " {'Abstract': 'We outline a spreadsheet-based system for visualization of real-time financial information. Our system permits the user to define arithmetic and presentation relationships amongst the various cells of the spreadsheet. The cells contain primitives that can be numbers, text, images, functions and graphics. Presenting financial information in this format allows its intended clients, the financial analysts, to work in the familiar environment of a spreadsheet and allows them the flexibility afforded by the powerful interface of the spreadsheet paradigm. In addition, our system permits real-time visualization of the financial data stream allowing its user to visually trade the changing market trends in two and three dimensions.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.0847289843156545, 'word': 'spreadsheet'},\n",
              "   {'score': 0.07786125483170628, 'word': 'system'},\n",
              "   {'score': 0.07126436327616957, 'word': 'time'},\n",
              "   {'score': 0.07126436327616957, 'word': 'financial'},\n",
              "   {'score': 0.07126436327616957, 'word': 'information'},\n",
              "   {'score': 0.06176749481603531, 'word': 'real'},\n",
              "   {'score': 0.055413636374443624, 'word': 'visualization'}],\n",
              "  'Title': 'FINESSE: a financial information spreadsheet',\n",
              "  'distance': 0,\n",
              "  'no': '961',\n",
              "  'parent': '4004'},\n",
              " {'Abstract': 'An eigenvector method for vortex identification has been applied to recent numerical and experimental studies in external flow aerodynamics. It is shown to be an effective way to extract and visualize features such as vortex cores, spiral vortex breakdowns, vortex bursting, and vortex diffusion. Several problems are reported and illustrated. These include: disjointed line segments, detecting non-vortical flow features, and vortex core displacement. Future research and applications are discussed, such as using vortex cores to guide automatic grid refinement.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.20778062806905, 'word': 'vortex'},\n",
              "   {'score': 0.20778062806905, 'word': 'identification'},\n",
              "   {'score': 0.11007151677515828, 'word': 'eigenvector'},\n",
              "   {'score': 0.11007151677515828, 'word': 'method'},\n",
              "   {'score': 0.09007387974284156, 'word': 'experimental'},\n",
              "   {'score': 0.09007387974284156, 'word': 'studies'},\n",
              "   {'score': 0.08900716294066655, 'word': 'recent'},\n",
              "   {'score': 0.08900716294066655, 'word': 'numerical'},\n",
              "   {'score': 0.07185616529688423, 'word': 'external'},\n",
              "   {'score': 0.07185616529688423, 'word': 'flow'},\n",
              "   {'score': 0.07185616529688423, 'word': 'aerodynamics'}],\n",
              "  'Title': 'Vortex identification-applications in aerodynamics: a case study',\n",
              "  'distance': 0,\n",
              "  'no': '962',\n",
              "  'parent': '3604'},\n",
              " {'Abstract': 'Currently, the most popular method of visualizing music is music notation. Through music notation, an experienced musician can gain an impression of how a particular piece of music sounds simply by looking at the notes on paper. However, most listeners are unfamiliar or uncomfortable with the complex nature of music notation. The goal of this project is to present an alternate method for visualizing music that makes use of color and 3D space. This paper describes one method of visualizing music in 3D space. The implementation of this method shows that music visualization is an effective technique, although it is certainly not the only possible method for accomplishing the task. Throughout the course of this project, several variations and alternative approaches were discussed. The final version of this project reflects the decisions that were made in order to present the best possible representation of music data.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.2085052105069627, 'word': 'music'},\n",
              "   {'score': 0.09260902074601185, 'word': 'popular'},\n",
              "   {'score': 0.09260902074601185, 'word': 'method'},\n",
              "   {'score': 0.05420439063065914, 'word': 'project'},\n",
              "   {'score': 0.05072232614514914, 'word': 'notation'},\n",
              "   {'score': 0.050498367256311974, 'word': '3d'},\n",
              "   {'score': 0.050498367256311974, 'word': 'space'}],\n",
              "  'Title': 'A visualization of music',\n",
              "  'distance': 0,\n",
              "  'no': '963',\n",
              "  'parent': '5575'},\n",
              " {'Abstract': 'We have developed a fast, perceptual method for selecting color scales for data visualization that takes advantage of our sensitivity to luminance variations in human faces. To do so, we conducted experiments in which we mapped various color scales onto the intensity values of a digitized photograph of a face and asked observers to rate each image. We found a very strong correlation between the perceived naturalness of the images and the degree to which the underlying color scales increased monotonically in luminance. Color scales that did not include a monotonically increasing luminance component produced no positive rating scores. Since color scales with monotonic luminance profiles are widely recommended for visualizing continuous scalar data, a purely visual technique for identifying such color scales could be very useful, especially in situations where color calibration is not integrated into the visualization environment, such as over the Internet.',\n",
              "  'AuthorKeywords': ['Perceptual',\n",
              "   'color',\n",
              "   'scales,',\n",
              "   'visual',\n",
              "   'artifacts',\n",
              "   'in',\n",
              "   'visualization,',\n",
              "   'Internet',\n",
              "   'color,',\n",
              "   'human',\n",
              "   'color',\n",
              "   'vision'],\n",
              "  'MultipartiteRank': [{'score': 0.14040978331219814, 'word': 'color'},\n",
              "   {'score': 0.14040978331219814, 'word': 'scales'},\n",
              "   {'score': 0.06565825752189995, 'word': 'luminance'},\n",
              "   {'score': 0.06394350114712966, 'word': 'data'},\n",
              "   {'score': 0.06394350114712966, 'word': 'visualization'},\n",
              "   {'score': 0.05627000598711061, 'word': 'human'},\n",
              "   {'score': 0.05627000598711061, 'word': 'faces'},\n",
              "   {'score': 0.04891010653180221, 'word': 'image'}],\n",
              "  'Title': 'The \"Which Blair project\": a quick visual method for evaluating perceptual color maps',\n",
              "  'distance': 0,\n",
              "  'no': '964',\n",
              "  'parent': '5085'},\n",
              " {'Abstract': \"Research in several areas provides scientific guidance for use of graphical encoding to convey information in an information visualization display. By graphical encoding we mean the use of visual display elements such as icon color, shape, size, or position to convey information about objects represented by the icons. Literature offers inconclusive and often conflicting viewpoints, including the suggestion that the effectiveness of a graphical encoding depends on the type of data represented. Our empirical study suggests that the nature of the users' perceptual task is more indicative of the effectiveness of a graphical encoding than the type of data represented.\",\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.09595256910984143, 'word': 'graphical'},\n",
              "   {'score': 0.09595256910984143, 'word': 'encoding'},\n",
              "   {'score': 0.07295435696237329, 'word': 'information'},\n",
              "   {'score': 0.06165266723007714, 'word': 'icon'},\n",
              "   {'score': 0.06165266723007714, 'word': 'color'},\n",
              "   {'score': 0.0518739384061519, 'word': 'use'},\n",
              "   {'score': 0.05028403640633969, 'word': 'effectiveness'}],\n",
              "  'Title': 'Graphical encoding for information visualization: an empirical study',\n",
              "  'distance': 0,\n",
              "  'no': '965',\n",
              "  'parent': '3746'},\n",
              " {'Abstract': 'The Internet pervades many aspects of our lives and is becoming indispensable to critical functions in areas such as commerce, government, production and general information dissemination. To maintain the stability and efficiency of the Internet, every effort must be made to protect it against various forms of attacks, malicious users, and errors. A key component in the Internet security effort is the routine examination of Internet routing data, which unfortunately can be too large and complicated to browse directly. We have developed an interactive visualization process which proves to be very effective for the analysis of Internet routing data. In this application paper, we show how each step in the visualization process helps direct the analysis and glean insights from the data. These insights include the discovery of patterns, detection of faults and abnormal events, understanding of event correlations, formation of causation hypotheses, and classification of anomalies. We also discuss lessons learned in our visual analysis study.',\n",
              "  'AuthorKeywords': ['information',\n",
              "   'visualization,',\n",
              "   'text',\n",
              "   'visualization,',\n",
              "   'network',\n",
              "   'visualization',\n",
              "   ',',\n",
              "   'internet',\n",
              "   'stability,',\n",
              "   'homeland',\n",
              "   'security'],\n",
              "  'MultipartiteRank': [{'score': 0.10115756347870236, 'word': 'internet'},\n",
              "   {'score': 0.051554646812890535, 'word': 'routing'},\n",
              "   {'score': 0.051554646812890535, 'word': 'data'},\n",
              "   {'score': 0.04301869222975485, 'word': 'analysis'},\n",
              "   {'score': 0.03595237542042274, 'word': 'effort'},\n",
              "   {'score': 0.03548740869944225, 'word': 'abnormal'},\n",
              "   {'score': 0.03548740869944225, 'word': 'events'}],\n",
              "  'Title': 'A visual exploration process for the analysis of Internet routing data',\n",
              "  'distance': 0,\n",
              "  'no': '966',\n",
              "  'parent': '4270'},\n",
              " {'Abstract': 'This paper describes a set of techniques developed for the visualization of high-resolution volume data generated from industrial computed tomography for nondestructive testing (NDT) applications. Because the data are typically noisy and contain fine features, direct volume rendering methods do not always give us satisfactory results. We have coupled region growing techniques and a 2D histogram interface to facilitate volumetric feature extraction. The new interface allows the user to conveniently identify, separate or composite, and compare features in the data. To lower the cost of segmentation, we show how partial region growing results can suggest a reasonably good classification function for the rendering of the whole volume. The NDT applications that we work on demand visualization tasks including not only feature extraction and visual inspection, but also modeling and measurement of concealed structures in volumetric objects. An efficient filtering and modeling process for generating surface representation of extracted features is also introduced. Four CT data sets for preliminary NDT are used to demonstrate the effectiveness of the new visualization strategy that we have developed.',\n",
              "  'AuthorKeywords': ['Computed',\n",
              "   'tomography,',\n",
              "   'feature',\n",
              "   'extraction,',\n",
              "   'hardware-acceleration',\n",
              "   'rendering,',\n",
              "   'image',\n",
              "   'processing,',\n",
              "   'interactive',\n",
              "   'visualization,',\n",
              "   'nondestructive',\n",
              "   'testing',\n",
              "   'and',\n",
              "   'evaluation,',\n",
              "   'scientific',\n",
              "   'visualization,',\n",
              "   'surface',\n",
              "   'modeling,',\n",
              "   'user',\n",
              "   'interface,',\n",
              "   'volume',\n",
              "   'rendering'],\n",
              "  'MultipartiteRank': [{'score': 0.10938361622046976, 'word': 'volume'},\n",
              "   {'score': 0.07008318660800504, 'word': 'resolution'},\n",
              "   {'score': 0.07008318660800504, 'word': 'data'},\n",
              "   {'score': 0.06626458104988778, 'word': 'fine'},\n",
              "   {'score': 0.06626458104988778, 'word': 'features'},\n",
              "   {'score': 0.0488160733807942, 'word': 'visualization'},\n",
              "   {'score': 0.04203697826016109, 'word': 'techniques'},\n",
              "   {'score': 0.039300429612464716, 'word': 'direct'}],\n",
              "  'Title': 'Visualizing industrial CT volume data for nondestructive testing applications',\n",
              "  'distance': 0,\n",
              "  'no': '967',\n",
              "  'parent': '4596'},\n",
              " {'Abstract': 'Real-world data is known to be imperfect, suffering from various forms of defects such as sensor variability, estimation errors, uncertainty, human errors in data entry, and gaps in data gathering. Analysis conducted on variable quality data can lead to inaccurate or incorrect results. An effective visualization system must make users aware of the quality of their data by explicitly conveying not only the actual data content, but also its quality attributes. While some research has been conducted on visualizing uncertainty in spatio-temporal data and univariate data, little work has been reported on extending this capability into multivariate data visualization. In this paper we describe our approach to the problem of visually exploring multivariate data with variable quality. As a foundation, we propose a general approach to defining quality measures for tabular data, in which data may experience quality problems at three granularities: individual data values, complete records, and specific dimensions. We then present two approaches to visual mapping of quality information into display space. In particular, one solution embeds the quality measures as explicit values into the original dataset by regarding value quality and record quality as new data dimensions. The other solution is to superimpose the quality information within the data visualizations using additional visual variables. We also report on user studies conducted to assess alternate mappings of quality attributes to visual variables for the second method. In addition, we describe case studies that expose some of the advantages and disadvantages of these two approaches',\n",
              "  'AuthorKeywords': ['Uncertainty',\n",
              "   'visualization,',\n",
              "   'multivariate',\n",
              "   'visualization,data',\n",
              "   'quality'],\n",
              "  'MultipartiteRank': [{'score': 0.2137506686687606, 'word': 'data'},\n",
              "   {'score': 0.13482923257946586, 'word': 'world'},\n",
              "   {'score': 0.07892143608929475, 'word': 'variable'},\n",
              "   {'score': 0.07892143608929475, 'word': 'quality'},\n",
              "   {'score': 0.043385503006566406, 'word': 'real'},\n",
              "   {'score': 0.03958993898991793, 'word': 'estimation'},\n",
              "   {'score': 0.03958993898991793, 'word': 'errors'},\n",
              "   {'score': 0.03430373913682205, 'word': 'sensor'},\n",
              "   {'score': 0.03430373913682205, 'word': 'variability'}],\n",
              "  'Title': 'Exploratory Visualization of Multivariate Data with Variable Quality',\n",
              "  'distance': 0,\n",
              "  'no': '968',\n",
              "  'parent': '5909'},\n",
              " {'Abstract': \"We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through &lt;i&gt;gw-choropleth maps&lt;/i&gt;, multivariate &lt;i&gt;gw-boxplots, gw-shading&lt;/i&gt; and &lt;i&gt;scalograms&lt;/i&gt;. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry's dataset of 'moral statistics', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The &lt;i&gt;geowigs &lt;/i&gt;proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in &lt;i&gt;gw-shading&lt;/i&gt;. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.\",\n",
              "  'AuthorKeywords': ['Geographical',\n",
              "   'weighting,',\n",
              "   'exploratory',\n",
              "   'data',\n",
              "   'analysis,',\n",
              "   'scale,',\n",
              "   'multivariate,',\n",
              "   'directional,',\n",
              "   'interaction,',\n",
              "   'coordinated',\n",
              "   'views'],\n",
              "  'MultipartiteRank': [{'score': 0.07292305997227067, 'word': 'statistical'},\n",
              "   {'score': 0.07292305997227067, 'word': 'proximity'},\n",
              "   {'score': 0.0689397106156279, 'word': 'information'},\n",
              "   {'score': 0.0558319483549392, 'word': 'scales'},\n",
              "   {'score': 0.05449159637290046, 'word': 'interactive'},\n",
              "   {'score': 0.05449159637290046, 'word': 'graphics'},\n",
              "   {'score': 0.04554165049930315, 'word': 'geographic'}],\n",
              "  'Title': 'Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis',\n",
              "  'distance': 0,\n",
              "  'no': '969',\n",
              "  'parent': '5382'},\n",
              " {'Abstract': 'Visualizations of large multi-dimensional data sets, occurring in scientific and commercial applications, often reveal interesting local patterns. Analysts want to identify the causes and impacts of these interesting areas, and they also want to search for similar patterns occurring elsewhere in the data set. In this paper we introduce the Intelligent Visual Analytics Query (IVQuery) concept that combines visual interaction with automated analytical methods to support analysts in discovering the special properties and relations of identified patterns. The idea of IVQuery is to interactively select focus areas in the visualization. Then, according to the characteristics of the selected areas, such as the data dimensions and records, IVQuery employs analytical methods to identify the relationships to other portions of the data set. Finally, IVQuery generates visual representations for analysts to view and refine the results. IVQuery has been applied successfully to different real-world data sets, such as data warehouse performance, product sales, and sever performance analysis, and demonstrates the benefits of this technique over traditional filtering and zooming techniques. The visual analytics query technique can be used with many different types of visual representation. In this paper we show how to use IVQuery with parallel coordinates, visual maps, and scatter plots.',\n",
              "  'AuthorKeywords': ['Visual',\n",
              "   'Analytics',\n",
              "   'Query,',\n",
              "   'Similarity',\n",
              "   'Queries,',\n",
              "   'Interactive',\n",
              "   'Queries'],\n",
              "  'MultipartiteRank': [{'score': 0.1265462599942118, 'word': 'visualizations'},\n",
              "   {'score': 0.07561254246937339, 'word': 'ivquery'},\n",
              "   {'score': 0.05534877799672505, 'word': 'data'},\n",
              "   {'score': 0.05200509632196619, 'word': 'interesting'},\n",
              "   {'score': 0.05200509632196619, 'word': 'areas'},\n",
              "   {'score': 0.04968176580215958, 'word': 'analysts'}],\n",
              "  'Title': 'Intelligent Visual Analytics Queries',\n",
              "  'distance': 0,\n",
              "  'no': '970',\n",
              "  'parent': '5117'},\n",
              " {'Abstract': 'Proteins are highly flexible and large amplitude deformations of their structure, also called slow dynamics, are often decisive to their function. We present a two-level rendering approach that enables visualization of slow dynamics of large protein assemblies. Our approach is aligned with a hierarchical model of large scale molecules. Instead of constantly updating positions of large amounts of atoms, we update the position and rotation of residues, i.e., higher level building blocks of a protein. Residues are represented by one vertex only indicating its position and additional information defining the rotation. The atoms in the residues are generated on-the-fly on the GPU, exploiting the new graphics hardware geometry shader capabilities. Moreover, we represent the atoms by billboards instead of tessellated spheres. Our representation is then significantly faster and pixel precise. We demonstrate the usefulness of our new approach in the context of our collaborative bioinformatics project.',\n",
              "  'AuthorKeywords': ['Molecular',\n",
              "   'visualization,',\n",
              "   'hardware',\n",
              "   'acceleration,',\n",
              "   'protein',\n",
              "   'dynamics'],\n",
              "  'MultipartiteRank': [{'score': 0.09831928555241869, 'word': 'proteins'},\n",
              "   {'score': 0.07043083736650635, 'word': 'residues'},\n",
              "   {'score': 0.0667935710744896, 'word': 'positions'},\n",
              "   {'score': 0.0611520658511005, 'word': 'atoms'},\n",
              "   {'score': 0.05566349011196658, 'word': 'level'},\n",
              "   {'score': 0.05566349011196658, 'word': 'rendering'},\n",
              "   {'score': 0.05566349011196658, 'word': 'approach'}],\n",
              "  'Title': 'Two-Level Approach to Efficient Visualization of Protein Dynamics',\n",
              "  'distance': 0,\n",
              "  'no': '971',\n",
              "  'parent': '4567'},\n",
              " {'Abstract': 'In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.',\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'labeling,',\n",
              "   'dynamic',\n",
              "   'labeling,',\n",
              "   'automatic',\n",
              "   'label',\n",
              "   'placement,',\n",
              "   'occlusion-free,',\n",
              "   'information',\n",
              "   'visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.08814000447618484, 'word': 'techniques'},\n",
              "   {'score': 0.08769722854769618, 'word': 'labels'},\n",
              "   {'score': 0.05009923733145605, 'word': 'many'},\n",
              "   {'score': 0.05009923733145605, 'word': 'information'},\n",
              "   {'score': 0.05009923733145605, 'word': 'visualization'},\n",
              "   {'score': 0.04556215820992101, 'word': 'approaches'},\n",
              "   {'score': 0.03877885467220093, 'word': 'visual'},\n",
              "   {'score': 0.03877885467220093, 'word': 'representation'}],\n",
              "  'Title': 'Particle-based labeling: Fast point-feature labeling without obscuring other visual features',\n",
              "  'distance': 0,\n",
              "  'no': '972',\n",
              "  'parent': '5610'},\n",
              " {'Abstract': 'Network data frequently arises in a wide variety of fields, and node-link diagrams are a very natural and intuitive representation of such data. In order for a node-link diagram to be effective, the nodes must be arranged well on the screen. While many graph layout algorithms exist for this purpose, they often have limitations such as high computational complexity or node colocation. This paper proposes a new approach to graph layout through the use of space filling curves which is very fast and guarantees that there will be no nodes that are colocated. The resulting layout is also aesthetic and satisfies several criteria for graph layout effectiveness.',\n",
              "  'AuthorKeywords': ['Information',\n",
              "   'visualization,',\n",
              "   'Graph',\n",
              "   'layout,',\n",
              "   'Space',\n",
              "   'filling',\n",
              "   'curves'],\n",
              "  'MultipartiteRank': [{'score': 0.14137238240980204, 'word': 'node'},\n",
              "   {'score': 0.0936282482231143, 'word': 'many'},\n",
              "   {'score': 0.0936282482231143, 'word': 'graph'},\n",
              "   {'score': 0.0936282482231143, 'word': 'layout'},\n",
              "   {'score': 0.0936282482231143, 'word': 'algorithms'},\n",
              "   {'score': 0.07739508720217131, 'word': 'link'},\n",
              "   {'score': 0.07739508720217131, 'word': 'diagrams'},\n",
              "   {'score': 0.04153358377418604, 'word': 'screen'},\n",
              "   {'score': 0.03954913600862121, 'word': 'effective'}],\n",
              "  'Title': 'Rapid Graph Layout Using Space filling Curves',\n",
              "  'distance': 0,\n",
              "  'no': '973',\n",
              "  'parent': '4282'},\n",
              " {'Abstract': 'Local shape descriptors compactly characterize regions of a surface, and have been applied to tasks in visualization, shape matching, and analysis. Classically, curvature has be used as a shape descriptor; however, this differential property characterizes only an infinitesimal neighborhood. In this paper, we provide shape descriptors for surface meshes designed to be multi-scale, that is, capable of characterizing regions of varying size. These descriptors capture statistically the shape of a neighborhood around a central point by fitting a quadratic surface. They therefore mimic differential curvature, are efficient to compute, and encode anisotropy. We show how simple variants of mesh operations can be used to compute the descriptors without resorting to expensive parameterizations, and additionally provide a statistical approximation for reduced computational cost. We show how these descriptors apply to a number of uses in visualization, analysis, and matching of surfaces, particularly to tasks in protein surface analysis.',\n",
              "  'AuthorKeywords': ['Curvature,',\n",
              "   'descriptors,',\n",
              "   'npr,',\n",
              "   'stylized',\n",
              "   'rendering,',\n",
              "   'shape',\n",
              "   'matching'],\n",
              "  'MultipartiteRank': [{'score': 0.17618508198276503, 'word': 'local'},\n",
              "   {'score': 0.17618508198276503, 'word': 'shape'},\n",
              "   {'score': 0.17618508198276503, 'word': 'descriptors'},\n",
              "   {'score': 0.08334864656345951, 'word': 'surface'},\n",
              "   {'score': 0.07233316895019852, 'word': 'regions'},\n",
              "   {'score': 0.05603856920311811, 'word': 'analysis'},\n",
              "   {'score': 0.05175430481487154, 'word': 'visualization'}],\n",
              "  'Title': 'Multi-Scale Surface Descriptors',\n",
              "  'distance': 0,\n",
              "  'no': '974',\n",
              "  'parent': '5283'},\n",
              " {'Abstract': \"We demonstrate the application of advanced 3D visualization techniques to determine the optimal implant design and position in hip joint replacement planning. Our methods take as input the physiological stress distribution inside a patient's bone under load and the stress distribution inside this bone under the same load after a simulated replacement surgery. The visualization aims at showing principal stress directions and magnitudes, as well as differences in both distributions. By visualizing changes of normal and shear stresses with respect to the principal stress directions of the physiological state, a comparative analysis of the physiological stress distribution and the stress distribution with implant is provided, and the implant parameters that most closely replicate the physiological stress state in order to avoid stress shielding can be determined. Our method combines volume rendering for the visualization of stress magnitudes with the tracing of short line segments for the visualization of stress directions. To improve depth perception, transparent, shaded, and antialiased lines are rendered in correct visibility order, and they are attenuated by the volume rendering. We use a focus+context approach to visually guide the user to relevant regions in the data, and to support a detailed stress analysis in these regions while preserving spatial context information. Since all of our techniques have been realized on the GPU, they can immediately react to changes in the simulated stress tensor field and thus provide an effective means for optimal implant selection and positioning in a computational steering environment.\",\n",
              "  'AuthorKeywords': ['Stress',\n",
              "   'Tensor',\n",
              "   'fields,',\n",
              "   'Biomedical',\n",
              "   'Visualization,',\n",
              "   'Comparative',\n",
              "   'Visualization,',\n",
              "   'Implant',\n",
              "   'Planning,',\n",
              "   'GPU',\n",
              "   'Techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.13885538940112824, 'word': 'stress'},\n",
              "   {'score': 0.07315632799563258, 'word': 'principal'},\n",
              "   {'score': 0.07315632799563258, 'word': 'directions'},\n",
              "   {'score': 0.06569906140549565, 'word': 'physiological'},\n",
              "   {'score': 0.06569906140549565, 'word': 'distribution'},\n",
              "   {'score': 0.05020874152362227, 'word': 'optimal'},\n",
              "   {'score': 0.05020874152362227, 'word': 'implant'},\n",
              "   {'score': 0.05020874152362227, 'word': 'design'},\n",
              "   {'score': 0.03814898725221214, 'word': 'visualization'},\n",
              "   {'score': 0.03200736197076991, 'word': 'position'}],\n",
              "  'Title': 'Stress Tensor field Visualization for Implant Planning in Orthopedics',\n",
              "  'distance': 0,\n",
              "  'no': '975',\n",
              "  'parent': '5636'},\n",
              " {'Abstract': 'Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'visualization,',\n",
              "   'deferred',\n",
              "   'interaction,',\n",
              "   'image-based',\n",
              "   'rendering,',\n",
              "   'volume',\n",
              "   'distortion',\n",
              "   'camera'],\n",
              "  'MultipartiteRank': [{'score': 0.14576028343175024, 'word': 'volume'},\n",
              "   {'score': 0.14576028343175024, 'word': 'data'},\n",
              "   {'score': 0.12183799938332714, 'word': 'interactivity'},\n",
              "   {'score': 0.08920055618166423, 'word': 'exploration'},\n",
              "   {'score': 0.055419497991207156, 'word': 'key'},\n",
              "   {'score': 0.029944246712658575, 'word': 'many'},\n",
              "   {'score': 0.029944246712658575, 'word': 'factors'}],\n",
              "  'Title': 'Visualization by Proxy: A Novel Framework for Deferred Interaction with Volume Data',\n",
              "  'distance': 0,\n",
              "  'no': '976',\n",
              "  'parent': '4172'},\n",
              " {'Abstract': 'In this paper we present a framework to define transfer functions from a target distribution provided by the user. A target distribution can reflect the data importance, or highly relevant data value interval, or spatial segmentation. Our approach is based on a communication channel between a set of viewpoints and a set of bins of a volume data set, and it supports 1D as well as 2D transfer functions including the gradient information. The transfer functions are obtained by minimizing the informational divergence or Kullback-Leibler distance between the visibility distribution captured by the viewpoints and a target distribution selected by the user. The use of the derivative of the informational divergence allows for a fast optimization process. Different target distributions for 1D and 2D transfer functions are analyzed together with importance-driven and view-based techniques.',\n",
              "  'AuthorKeywords': ['Transfer',\n",
              "   'function,',\n",
              "   'Information',\n",
              "   'theory,',\n",
              "   'Informational',\n",
              "   'divergence,',\n",
              "   'Kullback-Leibler',\n",
              "   'distance'],\n",
              "  'MultipartiteRank': [{'score': 0.10191605416593612, 'word': 'target'},\n",
              "   {'score': 0.10191605416593612, 'word': 'distribution'},\n",
              "   {'score': 0.09039444863335211, 'word': 'transfer'},\n",
              "   {'score': 0.09039444863335211, 'word': 'functions'},\n",
              "   {'score': 0.07149117096058692, 'word': 'set'},\n",
              "   {'score': 0.06766892367583902, 'word': 'gradient'},\n",
              "   {'score': 0.06766892367583902, 'word': 'information'},\n",
              "   {'score': 0.05849674048145274, 'word': 'viewpoints'}],\n",
              "  'Title': 'Automatic Transfer Functions Based on Informational Divergence',\n",
              "  'distance': 0,\n",
              "  'no': '977',\n",
              "  'parent': '4383'},\n",
              " {'Abstract': 'Medical imaging plays a central role in a vast range of healthcare practices. The usefulness of 3D visualizations has been demonstrated for many types of treatment planning. Nevertheless, full access to 3D renderings outside of the radiology department is still scarce even for many image-centric specialties. Our work stems from the hypothesis that this under-utilization is partly due to existing visualization systems not taking the prerequisites of this application domain fully into account. We have developed a medical visualization table intended to better fit the clinical reality. The overall design goals were two-fold: similarity to a real physical situation and a very low learning threshold. This paper describes the development of the visualization table with focus on key design decisions. The developed features include two novel interaction components for touch tables. A user study including five orthopedic surgeons demonstrates that the system is appropriate and useful for this application domain.',\n",
              "  'AuthorKeywords': ['Medical',\n",
              "   'visualization,',\n",
              "   'multi-touch,',\n",
              "   'tabletop',\n",
              "   'display,',\n",
              "   'treatment',\n",
              "   'planning'],\n",
              "  'MultipartiteRank': [{'score': 0.08898348147645266, 'word': 'visualization'},\n",
              "   {'score': 0.05163011491205327, 'word': 'medical'},\n",
              "   {'score': 0.05163011491205327, 'word': 'table'},\n",
              "   {'score': 0.04365386823782579, 'word': 'many'},\n",
              "   {'score': 0.04365386823782579, 'word': 'types'},\n",
              "   {'score': 0.04249670286628656, 'word': '3d'},\n",
              "   {'score': 0.04249670286628656, 'word': 'visualizations'},\n",
              "   {'score': 0.04118300161603728, 'word': 'usefulness'},\n",
              "   {'score': 0.03735336656439938, 'word': 'systems'}],\n",
              "  'Title': 'Multi-Touch Table System for Medical Visualization: Application to Orthopedic Surgery Planning',\n",
              "  'distance': 0,\n",
              "  'no': '978',\n",
              "  'parent': '3725'},\n",
              " {'Abstract': 'The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots.',\n",
              "  'AuthorKeywords': ['Psychophysics,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Perceptual',\n",
              "   'Study'],\n",
              "  'MultipartiteRank': [{'score': 0.07430701792497789, 'word': 'set'},\n",
              "   {'score': 0.06734466483488345, 'word': 'efficient'},\n",
              "   {'score': 0.06734466483488345, 'word': 'aggregate'},\n",
              "   {'score': 0.06734466483488345, 'word': 'judgements'},\n",
              "   {'score': 0.06630990769080823, 'word': 'visual'},\n",
              "   {'score': 0.06630990769080823, 'word': 'summarization'},\n",
              "   {'score': 0.06630990769080823, 'word': 'tasks'},\n",
              "   {'score': 0.04501941985578643, 'word': 'objects'},\n",
              "   {'score': 0.04106698202266585, 'word': 'ramifications'}],\n",
              "  'Title': 'Perception of Average Value in Multiclass Scatterplots',\n",
              "  'distance': 0,\n",
              "  'no': '979',\n",
              "  'parent': '5593'},\n",
              " {'Abstract': \"We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.\",\n",
              "  'AuthorKeywords': ['Design,',\n",
              "   'Information',\n",
              "   'Visualization,',\n",
              "   'Dynamic',\n",
              "   'visualization,',\n",
              "   'Dynamic',\n",
              "   'data,',\n",
              "   'Data',\n",
              "   'stream,',\n",
              "   'Real',\n",
              "   'time,',\n",
              "   'Metaphor'],\n",
              "  'MultipartiteRank': [{'score': 0.14079411643902323, 'word': 'data'},\n",
              "   {'score': 0.1403468314634912, 'word': 'metaphor'},\n",
              "   {'score': 0.1081852623951981, 'word': 'streams'},\n",
              "   {'score': 0.09122518145433482, 'word': 'novel'},\n",
              "   {'score': 0.09122518145433482, 'word': 'design'},\n",
              "   {'score': 0.07935906443158276, 'word': 'visual'},\n",
              "   {'score': 0.07935906443158276, 'word': 'sedimentation'},\n",
              "   {'score': 0.03260885404382512, 'word': 'incoming'}],\n",
              "  'Title': 'Visual Sedimentation',\n",
              "  'distance': 0,\n",
              "  'no': '980',\n",
              "  'parent': '4844'},\n",
              " {'Abstract': \"Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.\",\n",
              "  'AuthorKeywords': ['Co-occurrence,',\n",
              "   'human',\n",
              "   'mobility,',\n",
              "   'telco',\n",
              "   'data,',\n",
              "   'bicluster,',\n",
              "   'visual',\n",
              "   'analytics'],\n",
              "  'MultipartiteRank': [{'score': 0.08748032061969041, 'word': 'urban'},\n",
              "   {'score': 0.05705168786713538, 'word': 'human'},\n",
              "   {'score': 0.05705168786713538, 'word': 'mobility'},\n",
              "   {'score': 0.04872281059846861, 'word': 'analysts'},\n",
              "   {'score': 0.04326003062757892, 'word': 'regions'},\n",
              "   {'score': 0.03196319004084895, 'word': 'people'},\n",
              "   {'score': 0.03042863275255503, 'word': 'place'}],\n",
              "  'Title': 'TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data',\n",
              "  'distance': 0,\n",
              "  'no': '981',\n",
              "  'parent': '4591'},\n",
              " {'Abstract': 'Current software visualization tools are inadequate for understanding, debugging, and tuning realistically complex applications. These tools often present only static structure, or they present dynamics from only a few of the many layers of a program and its underlying system. This paper introduces \"PV\", a prototype program visualization system which provides concurrent visual presentation of behavior from all layers, including: the program itself, user-level libraries, the operating system, and the hardware, as this behavior unfolds over time. PV juxtaposes views from different layers in order to facilitate visual correlation, and allows these views to be navigated in a coordinated fashion. This results in an extremely powerful mechanism for exploring application behavior. Experience is presented from actual use of PV in production settings with programmers facing real deadlines and serious performance problems.&lt;&lt;ETX&gt;&gt;',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.07499934601542493, 'word': 'many'},\n",
              "   {'score': 0.07499934601542493, 'word': 'layers'},\n",
              "   {'score': 0.0688610528475097, 'word': 'behavior'},\n",
              "   {'score': 0.06047185847487836, 'word': 'program'},\n",
              "   {'score': 0.053818406255961945, 'word': 'system'},\n",
              "   {'score': 0.040844306750988615, 'word': 'views'}],\n",
              "  'Title': 'Strata-various: multi-layer visualization of dynamics in software system behavior',\n",
              "  'distance': 0,\n",
              "  'no': '982',\n",
              "  'parent': '4089'},\n",
              " {'Abstract': 'Volume rendering generates 2D images by ray tracing 3D volume data. This technique imposes considerable demands on storage space as the data set grows in size. In this paper, we describe a method to render compressed volume data directly to reduce the memory requirements of the rendering process. The volume data was compressed by a technique called the Laplacian pyramid. A compression ratio of 10:1 was achieved by uniform quantization over the Laplacian pyramid. The quality of the images obtained by this technique as virtually indistinguishable from that of the images generated from the uncompressed volume data. A significant improvement in computational performance was achieved by using a cache algorithm to temporarily retain the reconstructed voxels to be used by the adjacent rays.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.13013222067804717, 'word': '3d'},\n",
              "   {'score': 0.13013222067804717, 'word': 'volume'},\n",
              "   {'score': 0.13013222067804717, 'word': 'data'},\n",
              "   {'score': 0.08986843356463584, 'word': 'technique'},\n",
              "   {'score': 0.08948870136133641, 'word': 'images'},\n",
              "   {'score': 0.06753568018374917, 'word': 'ray'},\n",
              "   {'score': 0.05040523406494936, 'word': 'laplacian'},\n",
              "   {'score': 0.05040523406494936, 'word': 'pyramid'}],\n",
              "  'Title': 'Direct rendering of Laplacian pyramid compressed volume data',\n",
              "  'distance': 0,\n",
              "  'no': '983',\n",
              "  'parent': '3822'},\n",
              " {'Abstract': 'Rendering deformable volume data currently needs separate processes for deformation and rendering, and is expensive in terms of both computational and memory costs. Recognizing the importance of unifying these processes, we present a new approach to the direct rendering of deformable volumes without explicitly constructing the intermediate deformed volumes. The volume deformation is done by a radial basis function that is piecewise linearly approximated by an adaptive subdivision of the octree encoded target volume. The octree blocks in the target volume are then projected, reverse morphed and texture mapped, using the SGI 3D texture mapping hardware, in a back-to-front order. A template-based Z-plane/block intersection method is used to expedite the block projection computation.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'Rendering,',\n",
              "   '3D',\n",
              "   'Texture',\n",
              "   'Mapping,',\n",
              "   'Morphing,',\n",
              "   'Volume',\n",
              "   'Deformation,',\n",
              "   'Octree,',\n",
              "   'Scientific',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.17669334684567806, 'word': 'deformable'},\n",
              "   {'score': 0.17669334684567806, 'word': 'volume'},\n",
              "   {'score': 0.17669334684567806, 'word': 'data'},\n",
              "   {'score': 0.0940141877639063, 'word': 'separate'},\n",
              "   {'score': 0.0940141877639063, 'word': 'processes'},\n",
              "   {'score': 0.07112750349405815, 'word': 'rendering'},\n",
              "   {'score': 0.04560888125882073, 'word': 'computational'},\n",
              "   {'score': 0.042131791327310195, 'word': 'expensive'}],\n",
              "  'Title': 'Deformable volume rendering by 3D texture mapping and octree encoding',\n",
              "  'distance': 0,\n",
              "  'no': '984',\n",
              "  'parent': '3515'},\n",
              " {'Abstract': 'An isosurface can be efficiently generated by visiting adjacent intersected cells in order, as if the isosurface were propagating itself. We previously proposed an extrema graph method (T. Itoh and K. Koyamada, 1995), which generates a graph connecting extremum points. The isosurface propagation starts from some of the intersected cells that are found both by visiting the cells through which arcs of the graph pass and by visiting the cells on the boundary of a volume. We propose an efficient method of searching for cells intersected by an isosurface. This method generates a volumetric skeleton. consisting of cells, like an extrema graph, by applying a thinning algorithm used in the image recognition area. Since it preserves the topological features of the volume and the connectivity of the extremum points, it necessarily intersects every isosurface. The method is more efficient than the extrema graph method, since it does not require that cells on the boundary be visited.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.21518029445688489, 'word': 'cells'},\n",
              "   {'score': 0.13626633745235564, 'word': 'adjacent'},\n",
              "   {'score': 0.13626633745235564, 'word': 'intersected'},\n",
              "   {'score': 0.1175458036988787, 'word': 'isosurface'},\n",
              "   {'score': 0.09053216047748895, 'word': 'extrema'},\n",
              "   {'score': 0.09053216047748895, 'word': 'graph'},\n",
              "   {'score': 0.09053216047748895, 'word': 'method'},\n",
              "   {'score': 0.06336883263337605, 'word': 'order'}],\n",
              "  'Title': 'Volume Thinning for Automatic Isosurface Propagation',\n",
              "  'distance': 0,\n",
              "  'no': '985',\n",
              "  'parent': '4353'},\n",
              " {'Abstract': 'Presents the results of an evaluation of the ARCHAVE (ARCHAeological Virtual Environment) system, an immersive virtual reality (VR) environment for archaeological research. ARCHAVE is implemented in a Cave. The evaluation studied researchers analyzing lamp and coin finds throughout the excavation trenches at the Petra Great Temple site in Jordan. Experienced archaeologists used our system to study excavation data, confirming existing hypotheses and postulating new theories they had not been able to discover without the system. ARCHAVE provided access to the excavation database, and researchers were able to examine the data in the context of a life-size representation of the present-day architectural ruins of the temple. They also had access to a miniature model for site-wide analysis. Because users quickly became comfortable with the interface, they concentrated their efforts on examining the data being retrieved and displayed. The immersive VR visualization of the recovered information gave them the opportunity to explore it in a new and dynamic way and, in several cases, enabled them to make discoveries that opened new lines of investigation about the excavation.',\n",
              "  'AuthorKeywords': ['Scientific',\n",
              "   'Visualization,',\n",
              "   'Archaeological',\n",
              "   'Data',\n",
              "   'Analysis,',\n",
              "   'Immersive',\n",
              "   'Virtual',\n",
              "   'Reality',\n",
              "   'Interfaces'],\n",
              "  'MultipartiteRank': [{'score': 0.07951716109535256, 'word': 'excavation'},\n",
              "   {'score': 0.05315763846337329, 'word': 'archaeological'},\n",
              "   {'score': 0.05315763846337329, 'word': 'research'},\n",
              "   {'score': 0.05288279045108114, 'word': 'archave'},\n",
              "   {'score': 0.0514718699579932, 'word': 'system'},\n",
              "   {'score': 0.04013486879915653, 'word': 'data'},\n",
              "   {'score': 0.03938229229619603, 'word': 'trenches'}],\n",
              "  'Title': 'Archaeological Data Visualization in VR: Analysis of Lamp Finds at the Great Temple of Petra, a Case Study',\n",
              "  'distance': 0,\n",
              "  'no': '986',\n",
              "  'parent': '5250'},\n",
              " {'Abstract': 'We discuss 3d interaction techniques for the quantitative analysis of spatial relations in medical visualizations. We describe the design and implementation of measurement tools to measure distances, angles and volumes in 3d visualizations. The visualization of measurement tools as recognizable 3d objects and a 3d interaction, which is both intuitive and precise, determines the usability of such facilities. Measurements may be carried out in 2d visualizations of the original radiological data and in 3d visualizations. The result of a measurement carried out in one view is also displayed in the other view appropriately. We discuss the validation of the obtained measures. Finally, we describe how some important measurement tasks may be solved automatically.',\n",
              "  'AuthorKeywords': ['medical',\n",
              "   'visualization,',\n",
              "   'computer-assisted',\n",
              "   'surgery,',\n",
              "   'quantitative',\n",
              "   'analysis,',\n",
              "   'interaction',\n",
              "   'techniques'],\n",
              "  'MultipartiteRank': [{'score': 0.12866264146580478, 'word': 'medical'},\n",
              "   {'score': 0.12866264146580478, 'word': 'visualizations'},\n",
              "   {'score': 0.11251111635378384, 'word': 'measurement'},\n",
              "   {'score': 0.11251111635378384, 'word': 'tools'},\n",
              "   {'score': 0.06417418430265205, 'word': 'spatial'},\n",
              "   {'score': 0.06417418430265205, 'word': 'relations'},\n",
              "   {'score': 0.0631779467834677, 'word': '3d'},\n",
              "   {'score': 0.0631779467834677, 'word': 'interaction'},\n",
              "   {'score': 0.0631779467834677, 'word': 'techniques'},\n",
              "   {'score': 0.052212358256522276, 'word': 'quantitative'},\n",
              "   {'score': 0.052212358256522276, 'word': 'analysis'}],\n",
              "  'Title': 'Integration of measurement tools in medical 3d visualizations',\n",
              "  'distance': 0,\n",
              "  'no': '987',\n",
              "  'parent': '4029'},\n",
              " {'Abstract': 'Topological methods aim at the segmentation of a vector field into areas of different flow behavior. For 2D time-dependent vector fields, two such segmentations are possible: either concerning the behavior of stream lines, or of path lines. While stream line oriented topology is well established, we introduce path line oriented topology as a new visualization approach in this paper. As a contribution to stream line oriented topology we introduce new methods to detect global bifurcations like saddle connections and cyclic fold bifurcations. To get the path line oriented topology we segment the vector field into areas of attracting, repelling and saddle-like behavior of the path lines. We compare both kinds of topologies and apply them to a number of data sets.',\n",
              "  'AuthorKeywords': ['flow',\n",
              "   'visualization,',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'topology,',\n",
              "   'bifurcations,',\n",
              "   'stream',\n",
              "   'lines,',\n",
              "   'path',\n",
              "   'lines'],\n",
              "  'MultipartiteRank': [{'score': 0.17701709399946933, 'word': 'topological'},\n",
              "   {'score': 0.17701709399946933, 'word': 'methods'},\n",
              "   {'score': 0.09204176946387772, 'word': 'stream'},\n",
              "   {'score': 0.09204176946387772, 'word': 'lines'},\n",
              "   {'score': 0.08294467953638109, 'word': 'vector'},\n",
              "   {'score': 0.08294467953638109, 'word': 'field'},\n",
              "   {'score': 0.06840297693309172, 'word': 'different'},\n",
              "   {'score': 0.06840297693309172, 'word': 'flow'},\n",
              "   {'score': 0.06840297693309172, 'word': 'behavior'},\n",
              "   {'score': 0.05874683830415698, 'word': 'topology'}],\n",
              "  'Title': 'Stream line and path line oriented topology for 2D time-dependent vector fields',\n",
              "  'distance': 0,\n",
              "  'no': '988',\n",
              "  'parent': '4463'},\n",
              " {'Abstract': 'Computer-aided diagnosis (CAD) is a helpful addition to laborious visual inspection for preselection of suspected colonic polyps in virtual colonoscopy. Most of the previous work on automatic polyp detection makes use of indicators based on the scalar curvature of the colon wall and can result in many false-positive detections. Our work tries to reduce the number of false-positive detections in the preselection of polyp candidates. Polyp surface shape can be characterized and visualized using lines of curvature. In this paper, we describe techniques for generating and rendering lines of curvature on surfaces and we show that these lines can be used as part of a polyp detection approach. We have adapted existing approaches on explicit triangular surface meshes, and developed a new algorithm on implicit surfaces embedded in 3D volume data. The visualization of shaded colonic surfaces can be enhanced by rendering the derived lines of curvature on these surfaces. Features strongly correlated with true-positive detections were calculated on lines of curvature and used for the polyp candidate selection. We studied the performance of these features on 5 data sets that included 331 pre-detected candidates, of which 50 sites were true polyps. The winding angle had a significant discriminating power for true-positive detections, which was demonstrated by a Wilcoxon rank sum test with p&amp;lt;0.001. The median winding angle and inter-quartile range (IQR) for true polyps were 7.817 and 6.770-9.288 compared to 2.954 and 1.995-3.749 for false-positive detections',\n",
              "  'AuthorKeywords': ['Medical',\n",
              "   'visualization,',\n",
              "   'virtual',\n",
              "   'colonoscopy,',\n",
              "   'polyp',\n",
              "   'detection,',\n",
              "   'line',\n",
              "   'of',\n",
              "   'curvature,',\n",
              "   'implicit',\n",
              "   'surface'],\n",
              "  'MultipartiteRank': [{'score': 0.055420464092772966, 'word': 'positive'},\n",
              "   {'score': 0.055420464092772966, 'word': 'detections'},\n",
              "   {'score': 0.05533414284059887, 'word': 'scalar'},\n",
              "   {'score': 0.05533414284059887, 'word': 'curvature'},\n",
              "   {'score': 0.048132121880175294, 'word': 'polyp'},\n",
              "   {'score': 0.048132121880175294, 'word': 'surface'},\n",
              "   {'score': 0.048132121880175294, 'word': 'shape'},\n",
              "   {'score': 0.04565228619776155, 'word': 'lines'},\n",
              "   {'score': 0.03751671097929264, 'word': 'colonic'},\n",
              "   {'score': 0.03751671097929264, 'word': 'polyps'}],\n",
              "  'Title': 'Lines of Curvature for Polyp Detection in Virtual Colonoscopy',\n",
              "  'distance': 0,\n",
              "  'no': '989',\n",
              "  'parent': '5851'},\n",
              " {'Abstract': 'Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.',\n",
              "  'AuthorKeywords': ['Multiple-view',\n",
              "   'techniques,',\n",
              "   'geospatial',\n",
              "   'visualization,',\n",
              "   'geospatial',\n",
              "   'analysis,',\n",
              "   'focus',\n",
              "   '+',\n",
              "   'context,',\n",
              "   'probes'],\n",
              "  'MultipartiteRank': [{'score': 0.11684497187830538, 'word': 'traditional'},\n",
              "   {'score': 0.11684497187830538, 'word': 'geospatial'},\n",
              "   {'score': 0.11684497187830538, 'word': 'information'},\n",
              "   {'score': 0.11684497187830538, 'word': 'visualizations'},\n",
              "   {'score': 0.06334850510408539, 'word': 'user'},\n",
              "   {'score': 0.04866238822643382, 'word': 'regions'},\n",
              "   {'score': 0.03973238623888374, 'word': 'individual'},\n",
              "   {'score': 0.03973238623888374, 'word': 'probe'},\n",
              "   {'score': 0.03973238623888374, 'word': 'interfaces'},\n",
              "   {'score': 0.03742431213969355, 'word': 'views'}],\n",
              "  'Title': 'Multi-Focused Geospatial Analysis Using Probes',\n",
              "  'distance': 0,\n",
              "  'no': '990',\n",
              "  'parent': '5241'},\n",
              " {'Abstract': 'In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.',\n",
              "  'AuthorKeywords': ['Volume',\n",
              "   'editing,',\n",
              "   'GPU,',\n",
              "   'painting,',\n",
              "   'carving,',\n",
              "   'annotations'],\n",
              "  'MultipartiteRank': [{'score': 0.07130037054374705, 'word': 'structure'},\n",
              "   {'score': 0.05092949849855278, 'word': 'volumetric'},\n",
              "   {'score': 0.05092949849855278, 'word': 'scalar'},\n",
              "   {'score': 0.05092949849855278, 'word': 'fields'},\n",
              "   {'score': 0.04447785981855213, 'word': 'fast'},\n",
              "   {'score': 0.04447785981855213, 'word': 'techniques'},\n",
              "   {'score': 0.043264490427262714, 'word': 'interactive'},\n",
              "   {'score': 0.043264490427262714, 'word': 'volume'},\n",
              "   {'score': 0.041122149699511064, 'word': 'resolution'},\n",
              "   {'score': 0.041122149699511064, 'word': 'selection'},\n",
              "   {'score': 0.041122149699511064, 'word': 'volumes'}],\n",
              "  'Title': 'Direct Volume Editing',\n",
              "  'distance': 0,\n",
              "  'no': '991',\n",
              "  'parent': '5208'},\n",
              " {'Abstract': 'Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.',\n",
              "  'AuthorKeywords': ['Interactive',\n",
              "   'computational',\n",
              "   'steering,',\n",
              "   'interactive',\n",
              "   'visual',\n",
              "   'analysis,',\n",
              "   'simulation,',\n",
              "   'common',\n",
              "   'rail',\n",
              "   'injection',\n",
              "   'system'],\n",
              "  'MultipartiteRank': [{'score': 0.08579304705283397, 'word': 'visualization'},\n",
              "   {'score': 0.08458418675026626, 'word': 'system'},\n",
              "   {'score': 0.07030633321934368, 'word': 'interactive'},\n",
              "   {'score': 0.07030633321934368, 'word': 'steering'},\n",
              "   {'score': 0.06308660318216407, 'word': 'simulation'},\n",
              "   {'score': 0.05008303164673559, 'word': 'powertrain'},\n",
              "   {'score': 0.03450115510353067, 'word': 'automotive'},\n",
              "   {'score': 0.03450115510353067, 'word': 'industry'},\n",
              "   {'score': 0.03450115510353067, 'word': 'design'}],\n",
              "  'Title': 'Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System',\n",
              "  'distance': 0,\n",
              "  'no': '992',\n",
              "  'parent': '6078'},\n",
              " {'Abstract': 'In this paper, we discuss dimension reduction methods for 2D visualization of high dimensional clustered data. We propose a two-stage framework for visualizing such data based on dimension reduction methods. In the first stage, we obtain the reduced dimensional data by applying a supervised dimension reduction method such as linear discriminant analysis which preserves the original cluster structure in terms of its criteria. The resulting optimal reduced dimension depends on the optimization criteria and is often larger than 2. In the second stage, the dimension is further reduced to 2 for visualization purposes by another dimension reduction method such as principal component analysis. The role of the second-stage is to minimize the loss of information due to reducing the dimension all the way to 2. Using this framework, we propose several two-stage methods, and present their theoretical characteristics as well as experimental comparisons on both artificial and real-world text data sets.',\n",
              "  'AuthorKeywords': ['dimension',\n",
              "   'reduction,',\n",
              "   'linear',\n",
              "   'discriminant',\n",
              "   'analysis,',\n",
              "   'principal',\n",
              "   'component',\n",
              "   'analysis,',\n",
              "   'orthogonal',\n",
              "   'centroid',\n",
              "   'method,',\n",
              "   '2D',\n",
              "   'projection,',\n",
              "   'clustered',\n",
              "   'data,',\n",
              "   'regularization,',\n",
              "   'generalized',\n",
              "   'singular',\n",
              "   'value',\n",
              "   'decomposition'],\n",
              "  'MultipartiteRank': [{'score': 0.11800513584409023, 'word': 'dimension'},\n",
              "   {'score': 0.11800513584409023, 'word': 'reduction'},\n",
              "   {'score': 0.11800513584409023, 'word': 'methods'},\n",
              "   {'score': 0.06656813227571062, 'word': '2d'},\n",
              "   {'score': 0.06656813227571062, 'word': 'visualization'},\n",
              "   {'score': 0.0630133234070529, 'word': 'data'},\n",
              "   {'score': 0.05901932037031536, 'word': 'first'},\n",
              "   {'score': 0.05901932037031536, 'word': 'stage'},\n",
              "   {'score': 0.05516006199535967, 'word': 'high'},\n",
              "   {'score': 0.05516006199535967, 'word': 'dimensional'}],\n",
              "  'Title': 'Two-stage framework for visualization of clustered high dimensional data',\n",
              "  'distance': 0,\n",
              "  'no': '993',\n",
              "  'parent': '4343'},\n",
              " {'Abstract': 'In this paper, we present the first algorithm to geometrically register multiple projectors in a view-independent manner (i.e. wallpapered) on a common type of curved surface, vertically extruded surface, using an uncalibrated camera without attaching any obtrusive markers to the display screen. Further, it can also tolerate large non-linear geometric distortions in the projectors as is common when mounting short throw lenses to allow a compact set-up. Our registration achieves sub-pixel accuracy on a large number of different vertically extruded surfaces and the image correction to achieve this registration can be run in real time on the GPU. This simple markerless registration has the potential to have a large impact on easy set-up and maintenance of large curved multi-projector displays, common for visualization, edutainment, training and simulation applications.',\n",
              "  'AuthorKeywords': ['Registration,',\n",
              "   'Calibration,',\n",
              "   'Multi-Projector',\n",
              "   'Displays,',\n",
              "   'Tiled',\n",
              "   'Displays'],\n",
              "  'MultipartiteRank': [{'score': 0.08566557549101847, 'word': 'curved'},\n",
              "   {'score': 0.08566557549101847, 'word': 'surface'},\n",
              "   {'score': 0.08438395054266598, 'word': 'common'},\n",
              "   {'score': 0.08438395054266598, 'word': 'type'},\n",
              "   {'score': 0.054369587482264566, 'word': 'registration'},\n",
              "   {'score': 0.052300405644011595, 'word': 'multiple'},\n",
              "   {'score': 0.052300405644011595, 'word': 'projectors'},\n",
              "   {'score': 0.04274920641407076, 'word': 'large'},\n",
              "   {'score': 0.04274920641407076, 'word': 'number'}],\n",
              "  'Title': 'Markerless View-Independent Registration of Multiple Distorted Projectors on Extruded Surfaces Using an Uncalibrated Camera',\n",
              "  'distance': 0,\n",
              "  'no': '994',\n",
              "  'parent': '4751'},\n",
              " {'Abstract': \"Visual exploration is essential to the visualization and analysis of densely sampled 3D DTI fibers in biological speciments, due to the high geometric, spatial, and anatomical complexity of fiber tracts. Previous methods for DTI fiber visualization use zooming, color-mapping, selection, and abstraction to deliver the characteristics of the fibers. However, these schemes mainly focus on the optimization of visualization in the 3D space where cluttering and occlusion make grasping even a few thousand fibers difficult. This paper introduces a novel interaction method that augments the 3D visualization with a 2D representation containing a low-dimensional embedding of the DTI fibers. This embedding preserves the relationship between the fibers and removes the visual clutter that is inherent in 3D renderings of the fibers. This new interface allows the user to manipulate the DTI fibers as both 3D curves and 2D embedded points and easily compare or validate his or her results in both domains. The implementation of the framework is GPU based to achieve real-time interaction. The framework was applied to several tasks, and the results show that our method reduces the user's workload in recognizing 3D DTI fibers and permits quick and accurate DTI fiber selection.\",\n",
              "  'AuthorKeywords': ['Diffusion',\n",
              "   'Tensor',\n",
              "   'Imaging,',\n",
              "   'fibers,',\n",
              "   'fiber',\n",
              "   'Clustering,',\n",
              "   'Visualization',\n",
              "   'Interface'],\n",
              "  'MultipartiteRank': [{'score': 0.14219841657900673, 'word': '3d'},\n",
              "   {'score': 0.1113473922198958, 'word': 'dti'},\n",
              "   {'score': 0.1113473922198958, 'word': 'fibers'},\n",
              "   {'score': 0.10336263121292225, 'word': 'visual'},\n",
              "   {'score': 0.10336263121292225, 'word': 'exploration'},\n",
              "   {'score': 0.037778206277152705, 'word': 'essential'},\n",
              "   {'score': 0.03707589397792584, 'word': 'previous'},\n",
              "   {'score': 0.03707589397792584, 'word': 'methods'},\n",
              "   {'score': 0.030851024359110926, 'word': 'space'}],\n",
              "  'Title': 'A Novel Interface for Interactive Exploration of DTI fibers',\n",
              "  'distance': 0,\n",
              "  'no': '995',\n",
              "  'parent': '4434'},\n",
              " {'Abstract': 'Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.',\n",
              "  'AuthorKeywords': ['fiber',\n",
              "   'Tracking,',\n",
              "   'Parameter',\n",
              "   'Sensitivity,',\n",
              "   'Stopping',\n",
              "   'Criteria,',\n",
              "   'Diffusion',\n",
              "   'Tensor',\n",
              "   'Imaging,',\n",
              "   'Uncertainty',\n",
              "   'Visualization'],\n",
              "  'MultipartiteRank': [{'score': 0.11205322419079104, 'word': 'fiber'},\n",
              "   {'score': 0.11205322419079104, 'word': 'tracking'},\n",
              "   {'score': 0.09108727568089317, 'word': 'user'},\n",
              "   {'score': 0.07489831062183755, 'word': 'input'},\n",
              "   {'score': 0.07489831062183755, 'word': 'parameters'},\n",
              "   {'score': 0.06926074480427265, 'word': 'output'},\n",
              "   {'score': 0.06926074480427265, 'word': 'results'},\n",
              "   {'score': 0.0442541911437633, 'word': 'parameter'},\n",
              "   {'score': 0.0442541911437633, 'word': 'values'}],\n",
              "  'Title': 'Parameter Sensitivity Visualization for DTI fiber Tracking',\n",
              "  'distance': 0,\n",
              "  'no': '996',\n",
              "  'parent': '5003'},\n",
              " {'Abstract': 'Direct volume rendering and isosurfacing are ubiquitous rendering techniques in scientific visualization, commonly employed in imaging 3D data from simulation and scan sources. Conventionally, these methods have been treated as separate modalities, necessitating different sampling strategies and rendering algorithms. In reality, an isosurface is a special case of a transfer function, namely a Dirac impulse at a given isovalue. However, artifact-free rendering of discrete isosurfaces in a volume rendering framework is an elusive goal, requiring either infinite sampling or smoothing of the transfer function. While preintegration approaches solve the most obvious deficiencies in handling sharp transfer functions, artifacts can still result, limiting classification. In this paper, we introduce a method for rendering such features by explicitly solving for isovalues within the volume rendering integral. In addition, we present a sampling strategy inspired by ray differentials that automatically matches the frequency of the image plane, resulting in fewer artifacts near the eye and better overall performance. These techniques exhibit clear advantages over standard uniform ray casting with and without preintegration, and allow for high-quality interactive volume rendering with sharp C&lt;sup&gt;0&lt;/sup&gt; transfer functions.',\n",
              "  'AuthorKeywords': ['direct',\n",
              "   'volume',\n",
              "   'rendering,',\n",
              "   'isosurface,',\n",
              "   'ray',\n",
              "   'casting,',\n",
              "   'ray',\n",
              "   'differentials,',\n",
              "   'sampling,',\n",
              "   'transfer',\n",
              "   'function,',\n",
              "   'preintegration,',\n",
              "   'view',\n",
              "   'dependent'],\n",
              "  'MultipartiteRank': [{'score': 0.10238701462932034, 'word': 'direct'},\n",
              "   {'score': 0.10238701462932034, 'word': 'volume'},\n",
              "   {'score': 0.07656257607837626, 'word': 'isosurfacing'},\n",
              "   {'score': 0.048944997975310364, 'word': 'ubiquitous'},\n",
              "   {'score': 0.048944997975310364, 'word': 'rendering'},\n",
              "   {'score': 0.048944997975310364, 'word': 'techniques'},\n",
              "   {'score': 0.04806609766533181, 'word': 'transfer'},\n",
              "   {'score': 0.04806609766533181, 'word': 'function'},\n",
              "   {'score': 0.04382377382542349, 'word': 'different'},\n",
              "   {'score': 0.04382377382542349, 'word': 'sampling'},\n",
              "   {'score': 0.04382377382542349, 'word': 'strategies'}],\n",
              "  'Title': 'Volume Ray Casting with Peak finding and Differential Sampling',\n",
              "  'distance': 0,\n",
              "  'no': '997',\n",
              "  'parent': '4254'},\n",
              " {'Abstract': 'Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham &amp; Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations.',\n",
              "  'AuthorKeywords': ['Flow',\n",
              "   'visualization,',\n",
              "   'Stream',\n",
              "   'surfaces,',\n",
              "   'Illustrative',\n",
              "   'rendering,',\n",
              "   'Silhouettes,',\n",
              "   'GPU',\n",
              "   'technique,',\n",
              "   '3D',\n",
              "   'vector',\n",
              "   'field',\n",
              "   'data'],\n",
              "  'MultipartiteRank': [{'score': 0.11585890227777809, 'word': 'stream'},\n",
              "   {'score': 0.11585890227777809, 'word': 'surfaces'},\n",
              "   {'score': 0.07351288564111685, 'word': 'rendering'},\n",
              "   {'score': 0.04840695976871241, 'word': 'traditional'},\n",
              "   {'score': 0.04840695976871241, 'word': 'flow'},\n",
              "   {'score': 0.04840695976871241, 'word': 'illustrations'},\n",
              "   {'score': 0.04622335904168895, 'word': 'intuitive'},\n",
              "   {'score': 0.04622335904168895, 'word': 'approach'},\n",
              "   {'score': 0.04288116989017724, 'word': 'adequate'},\n",
              "   {'score': 0.04288116989017724, 'word': 'methods'},\n",
              "   {'score': 0.030631715750939616, 'word': 'illustrative'},\n",
              "   {'score': 0.030631715750939616, 'word': 'strategy'}],\n",
              "  'Title': 'Illustrative Stream Surfaces',\n",
              "  'distance': 0,\n",
              "  'no': '998',\n",
              "  'parent': '5260'},\n",
              " {'Abstract': 'Tabular data are pervasive. Although tables often describe multivariate data without explicit network semantics, it may be advantageous to explore the data modeled as a graph or network for analysis. Even when a given table design conveys some static network semantics, analysts may want to look at multiple networks from different perspectives, at different levels of abstraction, and with different edge semantics. We present a system called Ploceus that offers a general approach for performing multi-dimensional and multi-level network-based visual analysis on multivariate tabular data. Powered by an underlying relational algebraic framework, Ploceus supports flexible construction and transformation of networks through a direct manipulation interface, and integrates dynamic network manipulation with visual exploration for a seamless analytic experience.',\n",
              "  'AuthorKeywords': [],\n",
              "  'MultipartiteRank': [{'score': 0.17923107695097842, 'word': 'tabular'},\n",
              "   {'score': 0.17923107695097842, 'word': 'data'},\n",
              "   {'score': 0.14432215771395565, 'word': 'network'},\n",
              "   {'score': 0.10760047347903379, 'word': 'explicit'},\n",
              "   {'score': 0.10760047347903379, 'word': 'semantics'},\n",
              "   {'score': 0.07410305353262009, 'word': 'pervasive'},\n",
              "   {'score': 0.06783129251894154, 'word': 'tables'}],\n",
              "  'Title': 'Network-based visual analysis of tabular data',\n",
              "  'distance': 0,\n",
              "  'no': '999',\n",
              "  'parent': '4061'},\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rkHx9tOjatY"
      },
      "source": [
        "for i in range(len(trainings)):\n",
        "  tmp = {}\n",
        "  ind = df.index.get_loc(trainings[i].tags[0])\n",
        "  if numpy.isnan(float('NaN')) != df.loc[ind]['AuthorKeywords']:\n",
        "    tmp['Title'] = df.loc[ind]['Title']\n",
        "    tmp['Abstract'] = df.loc[ind]['Abstract']\n",
        "    try:\n",
        "      tmp['AuthorKeywords'] = df.loc[ind]['AuthorKeywords'].split()\n",
        "    except:\n",
        "      tmp['AuthorKeywords'] = []\n",
        "    df_exp.append(model.docvecs[trainings[i].tags[0]])\n",
        "    samples_list.append(tmp)\n",
        "  if i%1000 == 0:\n",
        "    print('doing')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}